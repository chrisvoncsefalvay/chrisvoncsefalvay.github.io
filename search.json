[
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Papers",
    "section": "",
    "text": "Books\n\nvon Csefalvay C (2023). Computational Modeling of Infectious Disease: With applications in Python. Amsterdam: Elsevier. https://elsevier.com/books/computational-modeling-of-infectious-disease/von-csefalvay/978-0-323-95389-4.\nvon Csefalvay C, Nam D T, Melis A, Halonen M, Edison S, Kozdon J, Kwong T, Glaser F, Frid Y, Szarnyas G, Crusius K, de Oliveira Castro PR, Hassler G, Clark AR, Visser M (2021). Learn Julia the Hard Way. https://doi.org/10.5281/zenodo.4556324\n\n\n\n\n2024\n\nvon Csefalvay C (2024). DAEDRA: A language model for predicting outcomes in passive pharmacovigilance reporting. arXiv 2402.10951.\n\n\n\n2023\n\nMogere E, Mwaura E, Waithaka M, Mutua V, Mugao M, von Csefalvay C, Mukamati D (2023). Juvenile polyposis syndrome: A case report. Clinical Case Reports 2023;11:e6798. doi:10.1002/ccr3.6798\n\n\n\n2022\n\nMutua V, Henry B, von Csefalvay C, Cheruiyot I, Vikse J, Lippi G, Bundi B, Mong’are N (2022). Tocilizumab in addition to standard of care in the management of COVID-19: A meta-analysis of RCTs. Acta Bio Medica: Atenei Parmensis 2022;93. doi:10.23750/abm.v93i1.12208\nBundi B, Mutua V, Cheruiyot I, Munguti J, von Csefalvay C, Nurani K, Ogeng’o J (2022). The Unusual High Origin Radial Artery in a Black Kenyan Population: A Cadaveric Study. Ethiopian Journal of Health Sciences 2022;32. doi:10.4314/ejhs.v32i2.25\nMunguti J, Mutua V, Cheruiyot I, von Csefalvay C, Opare-Addo P, Kiko N, Wanjiru R (2022). Tuberculous polyserositis in endemic areas with an emphasis on empiric therapy: A case report. Medicine: Case Reports and Study Protocols 2022;3:e0221. doi:10.1097/MD9.0000000000000221\n\n\n\n2021\n\nvon Csefalvay C (2021). VAERS data reveals no increased risk of neuroautoimmune adverse events from COVID-19 vaccines. medRxiv. doi:10.1101/2021.06.13.21258851.\nvon Csefalvay C (2021). Early evidence for the safety of certain COVID-19 vaccines using empirical Bayesian modeling from VAERS. medRxiv. doi:10.1101/2021.06.10.21258589.\nvon Csefalvay C (2021). A case-control study of autoimmune AEFIs following COVID-19 vaccination reported to VAERS. medRxiv. doi:10.1101/2021.07.06.21260074.\nvon Csefalvay C (2021). Anaphylactic events in mRNA vaccines: a reporting case-control study. medRxiv. doi:10.1101/2021.07.19.21260714.\nMutua V, Mong’are N, Bundi B, von Csefalvay C, Oriko D, Kitunguu P (2021). Sudden bilateral lower limb paralysis with dural ectasia in Neurofibromatosis type 1: A case report. Medicine: Case Reports and Study Protocols 2021;2:e0165. doi:10.1097/MD9.0000000000000165\nMpekethu N, Mongare N, Mutua V, Wangari M, von Csefalvay C, Ojuka D (2021). Knowledge and attitudes of undergraduate medical students in Kenya towards solid organ donation and transplantation: Are Africa’s future clinicians prepared?. African Journal of Nephrology 2021;24:89–94. doi:10.21804/24-1-4843\n\n\n\n2020\n\nvon Csefalvay C, Foldi T (2020). PAWS: Towards a globally integrated outbreak surveillance system for public health. Zenodo 2020. doi:10.5281/zenodo.3782871\nFoldi T, von Csefalvay C, Perez N (2020). Jampi: Efficient matrix multiplication in Spark using barrier execution mode. Big Data and Cognitive Computing 2020;4:32. doi:10.3390/bdcc4040032\nvon Csefalvay C (2020). Statistical dynamics of social distancing in SARS-CoV-2 as a differential game. arXiv 2007.13734.\nvon Csefalvay C (2020). Vector quantisation and partitioning of COVID-19 temporal dynamics in the United States. arXiv 2008.00559.\n\n\n\n2019\n\nvon Csefalvay C (2019). Novel quantitative indicators of digital ophthalmoscopy image quality. arXiv 1903.02695.\n\n\n\n2015\n\nvon Csefalvay C (2015). Ecological metrics of diversity in understanding social media. arXiv 1501.07621.\n\n\n\n2009\n\nvon Csefalvay C (2009). On Good Intentions and Poor Outcomes: A Critical Retrospective on Chester v Afshar. UC Dublin L. Rev. 2009;9:46.\n\n\n\n2007\n\nvon Csefalvay C (2007). Taunts, Chapati Pans and the Case of the Reasonable Glue-Sniffer: An Examination of the Normative Test in Provocation after Smith and Holley. Cambridge Student Law 2007:45–52. doi:10.2139/ssrn.1334048\n\n\n\n\nData sets\nFoldi, T., von Csefalvay, C., Pigler, P., Wash, W., Zempleni, B., Rodrigues, J., Kapronczay, M., Huber, Sz. & Gergely, B. (2022). Starschema COVID-19 consolidated data set. 27 March 2023. \nvon Csefalvay, C. (2019). 2019 Samoa measles outbreak data set. 06 December 2019. Zenodo. \nvon Csefalvay, C.. (2019). CODRAS: COnsolidated Diabetic Retinopathy Assessment Set. Zenodo. []"
  },
  {
    "objectID": "media/tech-for-good/index.html",
    "href": "media/tech-for-good/index.html",
    "title": "Tech for Good podcast",
    "section": "",
    "text": "I’ve had the pleasure of joining Ben Mouncer of the Tech for Good podcast to talk COVID, data sets and openness in exchanging information in times of crisis. Give it a listen here!\n\n\n\n\n\nCitationBibTeX citation:@online{von_csefalvay2023,\n  author = {von Csefalvay, Chris},\n  title = {Tech for {Good} Podcast},\n  date = {2023-03-07},\n  url = {https://chrisvoncsefalvay.com/media/tech-for-good},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCsefalvay, Chris von. 2023. “Tech for Good Podcast.” March\n7, 2023. https://chrisvoncsefalvay.com/media/tech-for-good."
  },
  {
    "objectID": "media/euronews-covid/index.html",
    "href": "media/euronews-covid/index.html",
    "title": "Koronavírus: az USA-ban már használják, itthon még nem kellett a magyar cég adatelemző programja",
    "section": "",
    "text": "Discussing risk and data in the context of the COVID-19 pandemic:\n\n— Összegyűjtöttünk adatokat arról, hogy hol vannak kórházak, hol vannak egészségügyi intézmények, milyen ágykapacitásuk van, milyen szolgáltatásokat tudnak nyújtani, tehát mi az az ápolási szint, amit el tudnak látni. Nagyon sok olyan adatot összegyűjtöttünk, hogy milyen óvintézkedéseket tettek egyes országok és így össze tudjuk azt is hasonlítani, hogy melyik államokban történt a leghatékonyabb válasz erre a problémára - mondta Cséfalvay.\nAz adatokat valamint az infrastrukturális hátteret a legszűkebb földrajzi elhelyezkedésre, körzetre, járásra vagy városra lebontva teszik közzé.\n— Azt is meg tudjuk mutatni, hogy milyen kockázatok vannak bizonyos területeken, hol vannak azok a területek, ahol nincsen kellő mennyiségű egészségügyi kapacitás, hol vannak azok a területek, ahol ha valakinek intenzív osztályos ápolásra van szüksége, megyén kívül kell mennie, vagy akár több megyén kívül kell mennie - sorolta a rendelkezésre álló adatokat Cséfalvay.\n\nSee the whole thing here.\n\n\n\nCitationBibTeX citation:@online{von_csefalvay2020,\n  author = {von Csefalvay, Chris},\n  title = {Koronavírus: Az {USA-ban} Már Használják, Itthon Még Nem\n    Kellett a Magyar Cég Adatelemző Programja},\n  date = {2020-04-17},\n  url = {https://chrisvoncsefalvay.com/media/euronews-covid},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCsefalvay, Chris von. 2020. “Koronavírus: Az USA-Ban Már\nHasználják, Itthon Még Nem Kellett a Magyar Cég Adatelemző\nProgramja.” April 17, 2020. https://chrisvoncsefalvay.com/media/euronews-covid."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chris von Csefalvay",
    "section": "",
    "text": "I’m a computational epidemiologist and data scientist working at the intersection of AI/ML, computational dynamics and public health. I am the author of Computational Modeling of Infectious Disease, a richly illustrated compendium on modern computational epidemiology, as well as a growing body of research.\nI attended the University of Oxford for my undergraduate studies, graduating with a distinction (1st class), and returned there for my graduate studies. I also hold degrees from Cardiff and Robert Gordon University Aberdeen, and have studied at the University of Leiden under an Erasmus programme. Today, I am board certified in public health, a Fellow of the Royal Society for Public Health and a member of several other learned societies. I have also been elected a Senior Member of IEEE, where I am a member of the EMBS Technical Committee on Standards and the EMBS Technical Committee on Biomedical and Health Informatics.\nI am currently a Practice Director for Biomedical AI/ML for HCLTech, where I advise the world’s leading life sciences, medical devices and pharma companies on how to leverage AI/ML to improve their products and serve their customers better. I am also a visiting thesis supervisor for students on the data science track of the mathematics programme at the Budapest University of Technology and Economics.\nAs part of my service to the profession, I’ve been a reviewer for JOSS, Frontiers in Immunology and Frontiers in Medicine. Between 2022 and 2023, I served Virginia as a member of the Medical Reserve Corps, and currently serve in both the Rocky Mountain MRC of Denver and Colorado’s radiation response MRC. I was also part of the COVID-19 Healthcare Coalition and the Covid Tracking Project.\nYou can find a list of my publications here. My work on COVID-19 has been featured in the media. I also write on various topics as the fancy strikes – you can peruse my notebook here."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Chris von Csefalvay",
    "section": "",
    "text": "I’m a computational epidemiologist and data scientist working at the intersection of AI/ML, computational dynamics and public health. I am the author of Computational Modeling of Infectious Disease, a richly illustrated compendium on modern computational epidemiology, as well as a growing body of research.\nI attended the University of Oxford for my undergraduate studies, graduating with a distinction (1st class), and returned there for my graduate studies. I also hold degrees from Cardiff and Robert Gordon University Aberdeen, and have studied at the University of Leiden under an Erasmus programme. Today, I am board certified in public health, a Fellow of the Royal Society for Public Health and a member of several other learned societies. I have also been elected a Senior Member of IEEE, where I am a member of the EMBS Technical Committee on Standards and the EMBS Technical Committee on Biomedical and Health Informatics.\nI am currently a Practice Director for Biomedical AI/ML for HCLTech, where I advise the world’s leading life sciences, medical devices and pharma companies on how to leverage AI/ML to improve their products and serve their customers better. I am also a visiting thesis supervisor for students on the data science track of the mathematics programme at the Budapest University of Technology and Economics.\nAs part of my service to the profession, I’ve been a reviewer for JOSS, Frontiers in Immunology and Frontiers in Medicine. Between 2022 and 2023, I served Virginia as a member of the Medical Reserve Corps, and currently serve in both the Rocky Mountain MRC of Denver and Colorado’s radiation response MRC. I was also part of the COVID-19 Healthcare Coalition and the Covid Tracking Project.\nYou can find a list of my publications here. My work on COVID-19 has been featured in the media. I also write on various topics as the fancy strikes – you can peruse my notebook here."
  },
  {
    "objectID": "index.html#key-research-interests",
    "href": "index.html#key-research-interests",
    "title": "Chris von Csefalvay",
    "section": "Key research interests",
    "text": "Key research interests\n\nComputational epidemiology: agent-based modelling, disease-avoidant behaviours, epidemics over dynamic networks, geospatial computational epidemiology – all primarily in the context of infectious diseases\nPharmacovigilance: VAERS, passive reporting, text mining of large complex report sets using LLMs\nComputational dynamics: computational dynamics of complex systems, computational dynamics of infectious diseases, computational dynamics of social systems\nPublic health: evidence-based public health policy, public health ethics, public health law, quality and systems improvement in public health"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Chris von Csefalvay",
    "section": "Teaching",
    "text": "Teaching\nI am a visiting thesis supervisor for students on the data science track of the mathematics programme at the Budapest University of Technology and Economics - you can read more about this here.\nFrom time to time, I get invited to give talks and lectures. My capacity for this is somewhat limited due to other commitments, but if you are interested in having me speak at your event, please get in touch."
  },
  {
    "objectID": "index.html#selected-papers",
    "href": "index.html#selected-papers",
    "title": "Chris von Csefalvay",
    "section": "Selected papers",
    "text": "Selected papers\nTocilizumab in addition to standard of care in the management of COVID-19: A meta-analysis of RCTs. Mutua V, Henry BM, von Csefalvay, C, Cheruiyot I, Vikse J, Lippi G, Bundi B, Mong’are N. Acta Biomed. 2022, 93(1):e2022014. doi: 10.23750/abm.v93i1.12208.\nJAMPI: Efficient matrix multiplication in Spark using barrier execution mode. Foldi T, von Csefalvay C, Perez NA. BDCC 2020, 4(4):32. doi: 10.3390/bdcc4040032.\nVAERS data reveals no increased risk of neuroautoimmune adverse events from COVID- vaccines. von Csefalvay, C. medRxiv 2021. doi: 10.1101/2021.06.13.21258851.\nTuberculous polyserositis in endemic areas with an emphasis on empiric therapy: A case report. Munguti J, Mutua V, Cheruiyot I, von Csefalvay C, Opare-Addo P, Kiko N, Wanjiru R. Medicine: Case Reports. 2022, 3(4):e0221. doi: 10.1097/MD9.0000000000000221.\nSee more here."
  },
  {
    "objectID": "index.html#professional-affiliations",
    "href": "index.html#professional-affiliations",
    "title": "Chris von Csefalvay",
    "section": "Professional affiliations",
    "text": "Professional affiliations\nThe OR Society | Member since 2020\nRoyal Society for Public Health | Fellow since 2021\nTOPRA | Registered Member since 2021\nAmerican Public Health Association | Member since 2021\nIEEE | Senior Member since 2024"
  },
  {
    "objectID": "index.html#personal-life",
    "href": "index.html#personal-life",
    "title": "Chris von Csefalvay",
    "section": "Personal life",
    "text": "Personal life\nI live in Denver, CO, with my Golden Retriever, Oliver. Born in Budapest, Hungary, I’ve spent my formative years in England, but have called the Netherlands, Germany, Belgium, Austria and the United States home at various points in my life. Since 2020, I’ve been living in the United States, where I am a permanent resident.\nIn my free time, I enjoy reading (mostly Cold War history and classical Greek drama), cooking (with not a lot of success) and Renaissance polyphony (esp. Thomas Tallis and Orlando di Lasso). I’m credited for a somewhat pretty sequence of integers called Jellyfish Heart numbers (OEIS A344856), which I discovered in 2020 while doing something that has nothing at all to do with my day job.\nI live with neuromyelitis optica since 2015, which has left me with a lifelong desire to understand complex, multicausal health conditions like NMOSD better.\nIn what little is left of my free time, I’m an adaptive multisport athlete, competing in wheelchair rugby, adaptive rowing (category PR1) and the SkiErg (category SIT2). In the latter, I currently hold the world records for 100m, 500m, 1,000m, 2,000m, 6,000m, 10,000m, 21,097m and 42,195m distances and the 60 minutes time. I occasionally rant and whine about my forays in the world of adaptive exercise and my attempts at doing so in a mostly science-based manner."
  },
  {
    "objectID": "index.html#pronunciation-guide",
    "href": "index.html#pronunciation-guide",
    "title": "Chris von Csefalvay",
    "section": "Pronunciation guide",
    "text": "Pronunciation guide\nMy last name rhymes with Chick-Fil-A."
  },
  {
    "objectID": "posts/knowledge-dividend-of-llms/index.html",
    "href": "posts/knowledge-dividend-of-llms/index.html",
    "title": "The knowledge dividend of large language models",
    "section": "",
    "text": "Over at the work blog, I’m discussing what knowledge means for large language models (LLMs), and the ways in which we can leverage this knowledge dividend for better inference.\n\nAs I’m writing this, the sun hasn’t risen over the Denver skyline in earnest. There’s still pink in the sky over the Front Range, and most of the world is still blissfully asleep. And so far, a small, moderately fine-tuned Large Language Model (LLM) trained on $500 worth of free credits has explained to me just how bad the Broncos’ recent 20–70 embarrassment against the Miami Dolphins is (very), made some useful suggestions for a Caddoan language to learn if I wanted to help with language preservation (Pawnee) and created a fairly acceptable recipe to salvage whatever is left in my fridge (spicy tomato and cheese omelet with a chia side salad). Not too shabby for something that has absolutely no understanding of language preservation, omelets or American football (then again, neither do I, as far as the last one is concerned).\nAnd therein lies one of the pervasive paradoxes of LLMs: they generate very confident, very credible and very often correct answers to questions on subjects they really don’t know all that much about.\n\nRead the full post here."
  },
  {
    "objectID": "posts/lair/index.html",
    "href": "posts/lair/index.html",
    "title": "LAIR - Language As Intermediate Representation",
    "section": "",
    "text": "The awesome thing about language is that, well, we all mostly speak it, to some extent or another. This gives us an immensely powerful tool to manipulate transformational tasks. For the purposes of this post, I consider a transformational task to be essentially anything that takes an input and is largel intended to return some version of the same thing. This is not a very precise definition, but it will have to do for now.\nSuch models are nothing new. Perhaps the most eye-catching and ubiquitous of such models are neural style transfer models that take an image and return a version of the same image in a different style that let you turn a picture of your dog into a Van Gogh painting (Gatys, Ecker, and Bethge 2015). Quite simply put, these models are your typical generative model, with the difference that it takes two separate loss definitions: content loss, which is loss of the generated image vis-a-vis the content reference, and style loss, which is the loss vis-a-vis the style reference image. A “good” image then is one that minimises total loss, i.e. it’s just as close to your dog as it is to Van Gogh. Figure 1 outlines this logic.\nflowchart TD\n    C[\"Content image\"]\n    S[\"Style image\"]\n\n    G[\"Generated image\"]\n\n    G --&gt; L[\"Loss network\"]\n    L --&gt; G\n    \n    C -- \"Content loss\" --&gt; L\n    S -- \"Style loss\" --&gt; L\n\n\n\n\nFigure 1: A rough outline of NST.\nGiven a content source image \\(\\vec{c}\\) and a style reference image \\(\\vec{s}\\), we define the total loss of our generated image \\(\\vec{g}\\) as\n\\[\n    \\mathcal{L}_{total} = \\alpha \\mathcal{L}_{content} + \\beta \\mathcal{L}_{style}\n\\]\nwhere \\(\\alpha\\) and \\(\\beta\\) are hyperparameters that control the relative importance of the content and style losses. The content loss for layer \\(l\\) is defined as\n\\[\n    \\mathcal{L}_{content}(\\vec{c}, \\vec{g}, l) = \\frac{1}{2} \\sum_{i,j} (\\vec{c}_{ij}^l - \\vec{g}_{ij}^l)^2\n\\]\nwhich is basically a simple squared error loss between the feature vector of the content image and the generated image at layer \\(l\\). The style loss is a bit more complicated, and is these days typically defined as the Maximum Mean Discrepancy, which Li et al. (2017) have shown is essentially equivalent to the Gram matrix loss, defined as\n\\[\n    \\mathcal{L}_{style}(\\vec{s}, \\vec{g}, l) = \\frac{1}{4N_l^2M_l^2} \\sum_{i,j} (\\mathbf{G}_{ij}^l - \\mathbf{S}_{ij}^l)^2\n\\]\nwhere \\(\\mathbf{G}_{ij}^l\\) and \\(\\mathbf{S}_{ij}^l\\) are the Gram matrices of the generated reference image and the style image at layer \\(l\\), respectively. \\(N^l\\) is the number of feature maps in layer \\(l\\) and \\(M_l\\) is the dimensionality (height times width) of the feature map of layer \\(l\\). There are two fundamental problems with this.\nThis is where language comes in. Language is a very powerful tool for conveying information, and it turns out that if we use language as an intermediate representation, we can use language models to manipulate this intermediate representation to our heart’s content, using a relatively informal and rather forgiving language. This is the idea behind LAIR."
  },
  {
    "objectID": "posts/lair/index.html#a-toy-example",
    "href": "posts/lair/index.html#a-toy-example",
    "title": "LAIR - Language As Intermediate Representation",
    "section": "A toy example",
    "text": "A toy example\nI’m a firm believer in silly toy examples. The sillier, the better. So, we’ll start with the following proposition: can we create a model that will look at a photo from, say, the front page of our favourite newspaper, and transpose it into the Warhammer 40k universe? In case you’re unfamiliar, Warhammer 40k is set – as the name suggests – in the 40th millennium, but is a weird mixture of medieval and futuristic technology. The whole atmosphere is taking the ‘Dark Ages’ part of the Middle Ages,1 adding spaceships and laser guns, and turning the whole thing into an absolutely depressing dystopia. It’s a lot of fun.\n1 Which may or may not ever have actually existed.There are a few things we want here: I don’t merely want the visual style of the Warhammer 40k universe, I also want the semantics – that is, I want characters to be transposed into the Warhammer 40k universe. I want the model to understand that the people in the photo are now Space Marines, and that the buildings are now Gothic cathedrals. I can’t get neural transfer to that for me, because it does not understand, or care, about semantics, and does not do semantic transformation. More importantly, I cannot interact with the ‘guts’ of neural style transfer beyond setting the hyperparameters and the source images.\nWhat I can, however, do is to use the language I am mostly most proficient in – that is, human language – to manipulate an intermediate representation.\n\n\n\n\n\n\nflowchart LR\n    subgraph Description\n        direction TB\n        S[\"Source image\"] --&gt; D(\"Descriptor\\ne.g. GPT-4 vision\") --&gt; d[\"Description\"]\n    end\n\n    subgraph Transformation\n        direction TB\n        t(\"Transformer\\ne.g. GPT-4\") --&gt; td[\"Transformed\\ndescription\"]\n    end\n\n    subgraph Rendering\n        direction TB\n        r(\"Renderer\\ne.g. DALL-E\") --&gt; I[\"Output\\nimage\"]\n    end\n\n    Description --&gt; Transformation --&gt; Rendering\n\n\n\n\nFigure 2: A rough outline of LAIR as applied to the toy example.\n\n\n\n\n\nFigure 2 outlines the basic idea for images. We use a descriptor model to describe the image, and then use a text-to-text transformer to transform the description. The transformed description is then rendered into an image. The descriptor model is typically a vision model, and the transformer is typically a language model. The renderer would then be a generative model.\nConsider the following source image I downloaded from Pexels:\n\n\n\n\n\n\nFigure 3: Our source image.\n\n\n\nHere’s the intermediate representation (IR) description created by GPT-4 vision:\n\nThis is an image of four individuals gathered around a laptop, suggesting a collaborative work environment. The setting has an ample amount of natural light, evident by the bright illumination on the subjects and the interior. They appear to be located in a modern indoor environment with a large curved window in the background, contributing to the light-flooded ambiance.\nStarting from the left, the first individual is a man with short, dark hair and a light beard, wearing a black t-shirt with a white graphic and text. He appears focused, resting his hands on the laptop while looking at the screen. To his right is a woman with shoulder-length curly hair who seems engaged and smiling, leaning slightly towards the laptop. She’s wearing a light grey short-sleeved top.\nBehind these two and slightly out of focus, two more individuals are present. The person in the middle of the composition is a man with shoulder-length wavy hair, wearing a black shirt, gazing at the laptop screen. To the far right, partially cropped out of the frame, there is a woman with glasses, wearing a dark business casual blazer. She seems to be observing the laptop’s screen with interest, standing slightly behind the seated individuals.\nThe group exhibits a sense of teamwork and focus, with everyone’s attention directed toward the laptop, situated on what appears to be a white table or desk. The body language and expressions suggest a positive, collaborative atmosphere, typical of a professional or academic team setting.\n\nThis is a pretty decent description. Let’s grimdark it up by passing it to our transformer model, which was initialised with the following prompt:\n\nYour job is to analyze descriptions of images and change them to transpose the image into the dark, futuristic aesthetic of the Warhammer 40k universe. You are given a description of a scene, and your job is to change that scene according to the instructions, and give a detailed description of the changed scene that would allow a generative model to create an image.\n\nReplace clothing items with a mixture of futuristic and mediaeval looking armour.\nReplace every-day objects held by characters with power swords, chainswords,futuristic looking guns, staffs or magic items.\nReplace architecture with the monumental, dark architecture common to the Warhammer 40k universe.\nInclude things like monumental gothic spaceships in the image description.\n\n\nHere’s the output:\n\nThis is an image of four battle-hardened individuals gathered around a hololith, suggesting a strategic war council. The setting is bathed in the cold, harsh light of flickering lumens, casting long, grim shadows on the figures and the interior. They appear to be situated in a cathedral-like command room of an Imperial Battleship, with a monumental, gothic archway in the background, contributing to the oppressive ambiance.\nStarting from the left, the first individual is an Adeptus Astartes, his short, dark hair and light beard visible beneath the rim of his power armor helmet. He is clad in a black power armor with white Imperial insignia. He appears focused, his gauntleted hands resting on the hololith while studying the battlefield projection. To his right, a Sororitas, her shoulder-length, curly hair peeking out from beneath her wimple, leans towards the holographic display. She’s clad in a light grey power armor, her face engaging and determined.\nBehind these two and slightly out of focus, two more figures loom. The figure in the middle of the composition is a man, his shoulder-length wavy hair barely visible beneath his Inquisitorial hat, wearing a black, ornate, medieval-looking armor, his eyes fixed on the hololith. To the far right, partially cropped out of the frame, there is a Tech-Priestess, her bionic glasses glinting in the lumen-light, her dark, mechanicus robes adding to her awe-inspiring presence. She seems to be observing the hololith with keen interest, standing slightly behind the armored individuals.\nThe group gives off a sense of unity and focus, with everyone’s attention directed toward the hololith, situated on what appears to be an aged, white marble table. The body language and expressions suggest a tense, collaborative atmosphere, typical of a war council in the grim darkness of the far future.\n\nBy the Emperor, that’s some good stuff. Let’s see what DALL-E makes of it:\n\n\n\n\n\n\nFigure 4: Our output image.\n\n\n\nIt’s interesting to note what remains and what has changed. In particular, the relationship of the figures to each other, both spatially and semantically, as well as their posture, their number (mostly!) and the general subject matter at a highly semanticised level was preserved. Instead of a laptop, they’re looking at a big holographic sand table. Note that unlike in NST, we actually have control over what is preserved and what is not – that’s what our transformer prompt accomplishes. We’ve told it to change dress, for instance, but we haven’t told it to make any changes to the overall relationship between the figures (note how a “collaborative atmosphere”, for instance, was retained word for word)."
  },
  {
    "objectID": "posts/lair/index.html#whats-the-point",
    "href": "posts/lair/index.html#whats-the-point",
    "title": "LAIR - Language As Intermediate Representation",
    "section": "What’s the point?",
    "text": "What’s the point?\nOkay, this was quite fun, but what’s the point? Well, the point is that we can use language as an intermediate representation to manipulate things relatively easily. This is powerful because language is such an accessible and forgiving intermediate representation. More importantly, however, anything that can be represented in language can be manipulated this way.\n\nIn the space of language-to-language, this includes adapting text to the needs of special audiences,(Steinmetz 2023; Verma, Boland, and Miesenberger 2023) conveying information to lay audiences (Lee, Goldberg, and Kohane 2023) and creating secondary explanatory materials e.g. statutory explanations (Blair-Stanek, Holzenberger, and Van Durme 2023).\nFor image-to-image transformations, retaining semanticity while simpifying visuals and removing clutter may often be useful, e.g. for creating procedural visual guidance for medical procedures (Chen 2023). Often, such images are created by hand, but this is a time-consuming process that could be automated.\nFor code-to-code, language as an intermediate representation allows the interjection of desired features into code, e.g. for the purposes of code refactoring. Beyond simple code rewriting, this allows a kind of opinionated transformation. Often, a target language is not only idiomatically different but also has certain other characteristics, and this is a fortiori the case for DSLs (Magalhães et al. 2023).\nFor code-to-text, this allows the creation of documentation from code, which is a perennial problem in software engineering. The textual intermediate representation allows fine control over the resulting documentation.\n\n\nSteinmetz, Ina. 2023. ‘Developing “EasyTalk”–a Writing System Utilizing Natural Language Processing for Interactive Generation of “Leichte Sprache”(easy-to-Read German) to Assist Low-Literate Users with Intellectual or Developmental Disabilities and/or Complex Communication Needs in Writing’. https://kola.opus.hbz-nrw.de/frontdoor/deliver/index/docId/2443/file/diss.pdf.\n\nVerma, A Kumar, S Gavra Boland, and Klaus Miesenberger. 2023. ‘Bridging the Digital Divide for Persons with Intellectual Disabilities: Assessing the Role of ChatGPT in Enabling Access, Evaluation, Integration, Management, and Creation of Digital Content’. In ICERI2023 Proceedings, 3767–76. IATED.\n\nLee, Peter, Carey Goldberg, and Isaac Kohane. 2023. The AI Revolution in Medicine: GPT-4 and Beyond. Pearson.\n\nBlair-Stanek, Andrew, Nils Holzenberger, and Benjamin Van Durme. 2023. ‘Can GPT-3 Perform Statutory Reasoning?’ arXiv Preprint arXiv:2302.06100.\n\nChen, Hao-Wen. 2023. ‘Endoscopic Endonasal Skull Base Surgery for Pituitary Lesions: An AI-Assisted Creative Workflow to Develop an Animated Educational Resource for Patients and Physicians’. PhD thesis, Johns Hopkins University.\n\nMagalhães, José Wesley de Souza, Jackson Woodruff, Elizabeth Polgreen, and Michael FP O’Boyle. 2023. ‘C2TACO: Lifting Tensor Code to TACO’. In Proceedings of the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, 42–56.\nThe possibilities for using language as an intermediate representation are endless. LAIR is a powerful paradigm for transformational tasks that allows us to use language as an intermediate representation to manipulate things in a way that is both accessible and powerful, and that allows us to pick and choose what part of semanticity we want to manipulate versus what we want to preserve. It’s hard to reason about LAIR’s relative performance given that it is not a technique but a paradigm, and that its focus is not simple style transfer but finely controlled stylistic and contextual transformation, but even in the current absence of benchmarks, it is clear that models benefit from using language as an easily workable and malleable intermediate representation."
  },
  {
    "objectID": "posts/lair/index.html#code",
    "href": "posts/lair/index.html#code",
    "title": "LAIR - Language As Intermediate Representation",
    "section": "Code",
    "text": "Code\nThe code for the toy example is available here."
  },
  {
    "objectID": "posts/five-non-data-science-books-for-data-scientists/index.html",
    "href": "posts/five-non-data-science-books-for-data-scientists/index.html",
    "title": "Five non-data-science books for data scientists",
    "section": "",
    "text": "Every year, the Commandant of the Marine Corps publishes a reading list of books that often only bear on warfighting tangentially at best. The idea behind this is that those entrusted with the lives of servicemembers should have an understanding of the world that goes beyond the profession of arms.\nIn much the same way, I have been advising data scientists to go beyond professional literature. Below are the five books every data scientist should have read. As a profession, we are increasingly tackling morally complex issues. In the context of nuclear weapons, General Omar Bradley referred to nuclear giants but ethical infants. In a world that is shaped by data, and those who work with it, more than it has ever been in the history of humankind, may we take this chance to grow not only in skill but also in ethics, professionalism and humanity.\n\nAlexander Solzhenitsyn: In the First Circle\nSolzhenitsyn’s most famous books, such as A Day in the Life of Ivan Denisovich and The Gulag Archipelago, deal with the every-day privations of Soviet prison camps. In the First Circle is different: its characters exist literally in a limbo (the ‘First Circle’ of Dante’s Inferno of the righteous but unbaptised souls), subject to repression by the regime on one hand but due to their scientific knowledge, valued as workers in a sharashka, a ‘special engineering bureau’ staffed by prisoner scientists. In his Gulag books, Solzhenitsyn asks what it means to be human in a system of calculated inhuman repression. In the First Circle, his question is more specific: what does it mean to be a scientist in an unjust regime, and what compromises a scientist should not make, even if the cost is their freedom or their very survival. As AI and ML is increasingly used by tyrannical regimes as a tool of political repression, Solzhenitsyn’s In the First Circle speaks as loudly to today’s data scientists as it did to the Soviet and Western scientists who first read it in samizdat copies in the late 1960.\n\n\nThornton Wilder: The Bridge of San Luis Rey\nWilder’s The Bridge of San Luis Rey might well be the first novel to feature a data scientist (of sorts) as a protagonist – the best part of a century before data science as such existed. Brother Juniper, an Italian monk in Peru, witnesses the collapse of an Inca rope bridge, leading to the death of five people. He devotes his following years to unraveling the mystery behind what seems random and senseless at first – why did these five people die, and why didn’t others? What made them special? He goes about this in much the same way as we would in any current problem: by gathering information on the decedents, and try to find what common factors set them apart. Wilder’s book is about a lot of things – not the least fate, randomness and our innate expectation of an ordered universe.\n\n\nDavid Halberstam: The Best and the Brightest\nRobert S. McNamara was nicknamed the Electric Brain for his almost preternatural grasp of quantitation. McGeorge Bundy was a foreign policy prodigy. JFK inspired Americans in a way few other Presidents have, before or after. The list goes on and on – JFK’s and later Lyndon B. Johnson’s cabinet was full of men of exceptional intelligence, knowledge, education and sophistication. And yet, in the face of a mounting crisis in Vietnam, they were worse than powerless: they contributed the worst shortcomings of their thinking to the problem that eventually embroiled America in a hopeless conflict. Halberstam’s The Best and the Brightest is a story of good people making bad decisions, the psychological pitfalls of interpreting the world not as it is but as we wished it to be to conform to our innermost prejudices. In the end, the ‘best and the brightest’ of America, together with prodigious amounts of information and data, missed the opportunity to prevent the fall of South Viet Nam to the Communists. The drama of Vietnam played out on the world stage, but the same cognitive biases Halberstam describes are at work in boardrooms, data science teams and decision-makers’ offices every single day.\n\n\nFrank Herbert: The Dosadi Experiment\nHerbert’s The Dosadi Experiment should be required reading in Responsible Conduct of Research courses. The book deals with a perennial question: is it ethical to allow an injustice to a small number of individuals to continue if it protects an entire populated universe from potentially disastrous upheaval? Because this is Frank Herbert, there’s a decent amount of trippy 1970s sci-fi stuff, including ego sharing, tree bark like creatures that create FTL information transmission and dogs bred to be semi-sentient items of furniture. Taking those curves as they come, however, The Dosadi Experiment is a masterpiece, a weird-but-wonderful meditation on the rights of the many and the rights of the few, in a research ethics context.\n\n\nEric Schlosser: Command and Control\nIn 1980, a Titan II inter-continental ballistic missile of the US Air Force suffered a liquid fuel explosion inside its silo near Damascus, Arkansas – with a nuclear warhead on top. Schlosser’s book reveals that this kind of incident was, unsettlingly, much less infrequent than one might be comfortable with. What happens when the literal survival of the planet depends on technology, and how comfortable are we in replacing the human decision-maker – often enough, a twenty-something 1st Lieutenant in a missile silo’s command centre – with technology that may run away from us? Schlosser’s book is an impassioned plea for better design of critical systems, presenting the near-disasters of nuclear weapons – which ought to be the epitome of safety engineering! – as an indication of all that can, and does, go wrong.\n\n\n\n\nCitationBibTeX citation:@online{csefalvay2022,\n  author = {{Chris von Csefalvay}},\n  title = {Five Non-Data-Science Books for Data Scientists},\n  date = {2022-04-13},\n  url = {https://chrisvoncsefalvay.com/posts/five-non-data-science-books-for-data-scientists/},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2022. “Five Non-Data-Science Books for Data\nScientists.” April 13, 2022. https://chrisvoncsefalvay.com/posts/five-non-data-science-books-for-data-scientists/."
  },
  {
    "objectID": "posts/prompt-engineering/index.html",
    "href": "posts/prompt-engineering/index.html",
    "title": "Prompt Engineering: The Art of Yesterday",
    "section": "",
    "text": "There’s a style of visual design I’m inordinately fond of called Raygun Gothic. It’s hard to describe what the hell exactly one needs to be on to enjoy it, but think of it like the aesthetic from the latter Fallout games with a more optimistic outlook on the future. Gibson described it as “the future that never was”, and I think that’s a pretty apt description.\n\n\n\n\n\nThe future we were all promised, in all its Raygun Gothic glory.\n\n\nWe get these competing futures in technology all the time. Every idea is a gateway to a possible future, and purely by logic it stands to reason that most will never come to pass. But oh, does that make them no less appealing when they first emerge. They rise like the sun, with abundant promises. They place themselves in our hands, and we can’t help but imagine what they could be. And most of the time, we’re left with what Ronnie Janoff-Bulman so beautifully described as “a little sadder, and a little wiser”. This is not a bad thing. It’s just the way things are in an industry that’s still really run by Schumpeterian waves of creative destruction.\nI think prompt engineering is one of those ideas. It’s a beautiful idea, and it’s one that I’ve been thinking about for a while. But I think it’s also one that’s been obsolete before it even took off. And like a love affair that never went anywhere but gave one some temporary joy, we’re better for having had it, but we’re also better off moving on.\n\nPrompting, engineering\nThe idea behind prompt engineering is really not all that shockingly novel. It reminds me of something a friend of mine, who primarily works in embedded programming, said: most of his work, he said, was about writing code in a way to get the compiler to produce the kind of assembly he wanted. In other words, he was writing code to get the compiler to write code for him. Prompt engineering is the same thing, but for language models. We’ve all done this – all of us have done bits of compiler hacking by trying to phrase things just the right way for the compiler to give us what we wanted (because we were too lazy to actually write the whole thing in assembly, but damn if we didn’t want it our own way).\nAnd so, the idea of taming a complex model by gently perturbing inputs to get us the outputs we desire is nothing novel. We’ve been doing this all the time. What is somewhat novel is that we’re ‘tricking’ a stochastic system here. The stochasticity and high dimensionality of LLMs together mean that the responses to queries exhibit the nonlinearities we like to know and love in chaotic processes. In chaos theory, we ‘quantify’ chaotic behaviour using the Lyapunov exponent, which essentially is the degree to which infinitesimally close starting conditions result in divergent trajectories. In other words, it’s a measure of how much a system is sensitive to initial conditions. And LLMs are very sensitive to initial conditions – they accumulate their divergent trajectories over time as every token begets the next. This is why we can get such wildly different outputs from them by just changing a few words in the prompt.\n\n\n\\[\\lambda = \\lim_{t \\to \\infty} \\lim_{|\\delta \\mathbf{Z}_0| \\to 0}\n\\frac{1}{t} \\ln\\frac{| \\delta\\mathbf{Z}(t)|}{|\\delta \\mathbf{Z}_0|}\\]\nThe Lyapunov exponent, a measure of how minor (infinitesimal, specifically, hence \\(\\delta \\mathbf{Z}_0 \\to 0\\)) changes in initial conditions (the input) result in divergent trajectories (the output). The Lyapunov exponent is a measure of how sensitive a system is to minor differences in initial conditions.\nBut this is also why prompt engineering is so hard. It’s hard because we’re trying to tame a chaotic system. And it’s hard because we’re trying to tame a chaotic system that’s also a black box. And we don’t exactly have a strong evidence-based methodology for this. We don’t have a rigorous way of testing whether our perturbations actually create the expected effect. In short, we are allegedly ‘engineering’ our prompts for a better outcome, when in reality, we have precious few methods for measuring if we actually get that better outcome. Some of the leading papers, such as those on tree-of-thought prompting, have rigorous methods for measuring the effect of prompts, but these are still very much in their infancy. And so, we’re left with a lot of guesswork, and a lot of trial and error. And that’s not engineering. That’s just hacking. And that’s fine, but it’s not engineering.\n\n\nThe art of yesterday\nI think the reason why prompt engineering has been obsolete before it even took off is because it’s a solution to a problem that’s already been solved – by agents and chains.\n\n\nChains are sequences of queries that proceed in a largely deterministic manner.\nAgents are task-driven semi-autonomous entities to perform tasks. They can operate on their own, making decisions based on their training and the input they receive. They are focused on reasoning and decision-making by using the LLM to determine what actions to take next.\nDon’t get me wrong – good prompts are still going to be important. But it’s no longer a one-shot game. The prompt is no longer all that stands between you and the output you are looking for: there are other prompts, there are decisions, there is a complex ecosystem of processes, supervisors and determinators that govern the outcome.\nWhich makes prompt engineering largely obsolete the way ensemble models make building the perfect regression model obsolete. No amount of expertly hand-crafted regression models will ever beat an ensemble of mediocre at best models. The booster always wins. Clever aggregation of weak primitives will always beat a single strong solution. And so, prompt engineering is obsolete because it’s a single strong solution in a world where we can relatively inexpensively generate a lot of weak solutions that can be aggregated to produce a better outcome.\nThis makes prompt engineering not the dream job of tomorrow but the art of yesterday. It’s a beautiful art, and it’s one that I’m sure will continue to be practiced. But it’s not the future. It’s the past. The future lies in chains and agents.\n\n\nBardo\nI think we’re in a bardo right now, a liminal state between the old and the new. The old is the world of prompt engineering, of one-shot solutions, of the single strong solution. The new is the world of chains and agents, of weak solutions that are aggregated to produce a better outcome. Solutions like chain-of-thought prompting occupy this middle space. They are not fully agentic, but they are beyond simple prompts seeking to create strong solutions, and closer to building chains and agentic architectures of weak solutions.\n\n\nབར་དོ་ (Wylie: bar do) is a Tibetan word that describes a liminal state between life, death and rebirth.\nPrompt engineering is in many ways a human brute force version of backpropagation: it’s a weak experiential form of tweaking inputs to get a desired kind of output, with the backpropagation algorithm beign replaced by “hm, this didn’t work, let’s run something else up the flagpole”. This is not an efficient use of human resources, the human intellect or the human spirit. But it’s all we had before the agentic shift that we’re currently experiencing, and so it attained its spot in the sun before more considered, better approaches could take its place. Prompt engineering was a short-lived future that could have been, but it is not the future that will be. Everywhere where innovation in this field happens, nobody is talking about prompt engineering anymore. We’re moving past it as we moved past crawling on all fours (at least on weekday nights) in our cognitive development towards walking and running.\nTrying to hold on to prompt engineering at this point is holding on to the past for its own sake. The only parties who have an interest in this clinging are those who have made economic investments in an intermediate stage technology and are unwilling to consider those the cost of doing business and move on. There is, maybe, a future in which the evolutionary destiny of LLMs would have focused on better singular solutions. This one isn’t that. This world, for better or worse, is governed by connectionists. The most successful epistemic endeavour in the realm of machine learning – deep learning – is fundamentally connnectionistic, and relies on the aggregation of weak learners to produce a strong learner. And so, the future of LLMs is not in prompt engineering, but in the aggregation of weak solutions. And that’s a future I’m looking forward to.\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {Prompt {Engineering:} {The} {Art} of {Yesterday}},\n  date = {2023-10-29},\n  url = {https://chrisvoncsefalvay.com/posts/prompt-engineering/},\n  doi = {10.59350/keztr-yx081},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “Prompt Engineering: The Art of\nYesterday.” https://doi.org/10.59350/keztr-yx081."
  },
  {
    "objectID": "posts/quora-answers/index.html",
    "href": "posts/quora-answers/index.html",
    "title": "My favourite Quora answers",
    "section": "",
    "text": "I used to be on Quora. I’m not anymore. But I used to be. And I wrote some answers. Here are some of my favourites, categorised by field… sort of."
  },
  {
    "objectID": "posts/quora-answers/index.html#if-i-wrote-an-ai-and-trained-it-to-score-200-on-a-standardized-iq-test-what-could-a-human-of-100-iq-still-do-better",
    "href": "posts/quora-answers/index.html#if-i-wrote-an-ai-and-trained-it-to-score-200-on-a-standardized-iq-test-what-could-a-human-of-100-iq-still-do-better",
    "title": "My favourite Quora answers",
    "section": "If I wrote an AI and trained it to score 200 on a standardized IQ test, what could a human of 100 IQ still do better?",
    "text": "If I wrote an AI and trained it to score 200 on a standardized IQ test, what could a human of 100 IQ still do better?\n\nThere’s something called Moravec’s paradox, which I’d sum up as follows: stuff that’s difficult for humans is not the same as what’s difficult for a computer. It is relatively trivial to teach a computer to be relatively good at chess or checkers or even go. On the other hand, getting a computer to master, say, bipedal motion is actually very, very tricky. There are multiple reasons behind this, including that the human brain is the pinnacle of an evolutionary pathway that spans the course of millions of years of optimisation for certain kinds of tasks, such as bipedal motion. We are an ‘opinionated’ system: we evolved with the idea that we’ll be solving certain kinds of problems, and not others. The evolutionary incentive for chess has been relatively modest compared to the evolutionary incentive to be able to run away from a sabre tooth cat or some prehistoric predator. Our brains have evolved through millions of years of exposure to certain senses: vision, balance, proprioception, pressure/pain, and so on. Without so much as wasting a single thought, our brain performs the process of sensor fusion and generating an operating model of where we are in space with accuracy that is really not trivial for computers even today. And we’re really good at this before we’re old enough to know just what an amazing nervous system we have. You really do not realise what a fantastic thing the human central nervous system is until it starts malfunctioning.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#will-true-ai-come-before-the-ability-to-completely-simulate-a-human-brain-is-there-a-difference",
    "href": "posts/quora-answers/index.html#will-true-ai-come-before-the-ability-to-completely-simulate-a-human-brain-is-there-a-difference",
    "title": "My favourite Quora answers",
    "section": "Will true AI come before the ability to completely simulate a human brain? Is there a difference?",
    "text": "Will true AI come before the ability to completely simulate a human brain? Is there a difference?\n\nSimulating the human brain is a fairly pointless exercise. You see, the human brain is a functionally extremely diverse thing. You see this best when you consider what damage to it can cause: some brain injuries cause mood disorders, some cause memory disorders, some cause aphasia (speech disorders), some cause issues with mobility and motor control, some cause severe disorders of consciousness like persistent vegetative states and minimally conscious states. The brain is basically a bunch of histologically largely similar tissue that does a lot of different things. There’s not a lot of point in simulating these functions.\nA bigger problem, though, is that some things are a lot harder to ‘simulate’ than others. This is something widely known as Moravec’s paradox: it’s a lot easier to teach a computer to play chess at a pretty high level than to teach it simple bipedal human motion. For this reason, simulating the human brain has generally been seen as not all that much of a priority. Connectionism is great, but it’s largely an inspiration, not a one-to-one reality. Many get this wrong because of concepts like neural networks and artificial neurons. In reality, a neural network is an abstraction to help humans. On the code level, there aren’t individual neurons or layers, there is just a bunch of relatively trivial linear algebra going on. I know I’m oversimplifying a little, but that’s the general idea.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#why-is-it-important-to-be-concerned-with-the-health-of-other-nations-when-it-comes-to-global-health-issues",
    "href": "posts/quora-answers/index.html#why-is-it-important-to-be-concerned-with-the-health-of-other-nations-when-it-comes-to-global-health-issues",
    "title": "My favourite Quora answers",
    "section": "Why is it important to be concerned with the health of other nations when it comes to global health issues?",
    "text": "Why is it important to be concerned with the health of other nations when it comes to global health issues?\n\nHere’s an illustration. I live in Denver, a city with a major but not first-in-line international airport (e.g. not like Heathrow or LAX, but a pretty nice airport no less, despite the creepy murals). Just as a thought experiment, I sometimes pick random places on the planet and look at how long it would take me to get there. It’s virtually never more than 48 hours.\nTo prove this point: it’s a little before 8am on a Sunday here. I can be:\n…in Ürümqi, China, in about 35 hours, …in Makassar City, Sulawesi, Indonesia, in about 33 to 42 hours, …in Maputo, Mozambique, in about 29 to 35 hours, depending on airline, …in Itahanga, Mato Grosso, Brazil, in about 44 hours, if I drove straight from Manaus, or 34 hours if I flew into Brasilia.\nI do these thought experiments all the time when I wonder about the thing you’re asking yourself. Because if I can get there in 48 hours, a pathogen from thereabouts can get here in the same time.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#do-you-believe-that-there-could-be-more-cases-like-the-one-found-in-ohio-where-someone-has-been-infected-with-covid-for-an-extended-period-of-time",
    "href": "posts/quora-answers/index.html#do-you-believe-that-there-could-be-more-cases-like-the-one-found-in-ohio-where-someone-has-been-infected-with-covid-for-an-extended-period-of-time",
    "title": "My favourite Quora answers",
    "section": "Do you believe that there could be more cases like the one found in Ohio, where someone has been infected with COVID for an extended period of time?",
    "text": "Do you believe that there could be more cases like the one found in Ohio, where someone has been infected with COVID for an extended period of time?\n\nAbsolutely. In fact, I’d be extremely surprised if that weren’t the case.\nLet me take a slight detour here to a concept that might be more familiar. You’ve heard of supershedding and superspreading, right? We’re instinctively geared to consider things like that to be extraordinary phenomena, the same way some people who could hold an HIV infection without developing AIDS were known as “elite controllers” for a long time (today, the term is “long-term non-progressor”, which is much less cool, sadly). But the reality is, they’re not. They’re the (often quite fat) tails of a distribution. Here’s something that doesn’t come to you naturally, something you need to force your brain to wrap itself around as you start doing epidemiology: all the numbers you encounter talk about the central tendency, but say relatively little about the distribution.\nLet me expand on that a little. What’s the mean infectious period of COVID-19? If you ask someone who has a relatively good grasp of the subject, they’ll say it’s around 9–10 days, with an interquartile range of around 4–12 days, give or take one day each way. That term – “interquartile range” – means that given a sample, half of the values will be in that range. Or, more importantly, half of the values will be outside that range.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#native-americans-were-devastated-by-european-diseases-brought-by-colonizers-but-were-the-colonialists-impacted-by-new-diseases-not-found-in-europe",
    "href": "posts/quora-answers/index.html#native-americans-were-devastated-by-european-diseases-brought-by-colonizers-but-were-the-colonialists-impacted-by-new-diseases-not-found-in-europe",
    "title": "My favourite Quora answers",
    "section": "Native Americans were devastated by European diseases brought by colonizers, but were the colonialists impacted by new diseases not found in Europe?",
    "text": "Native Americans were devastated by European diseases brought by colonizers, but were the colonialists impacted by new diseases not found in Europe?\n\nYes, with a significant difference: the Americas had a population density nowhere near that of urban Europe, where many of the colonists came from. Europe is tiny, and very interconnected. The result of that is that pathogenic diversity is going to be off the charts. It’s not even that Europeans brought various epidemics into the Americas, whose populations were largely naive to those pathogens (a phenomenon widely known as a ‘virgin soil epidemic’, much as I loathe the term) – it’s that they bought hundreds of different versions of it. They brought that into societies that, at least where North America was concerned, lived in a way that is very significantly more resilient to pathogens: in small(ish) groups, often as part of extended families (i.e. often similar profiles of immunity), spread out. In a profound sense, Old World epidemics are the result of a peculiarly (but not exclusively) Old World phenomenon: the Big City (“big”, here, being generally relative to total populations). When colonists moved to the Americas, they bought a piece of that Big City’s pathogenic diversity with them, to populations that have neither been exposed to that particular microbiome, nor have generally been under the evolutionary pressure to select for better genetic predispositions to develop immunity to a wide range of pathogens, since that just wasn’t much of a thing in the New World.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#the-flu-has-been-around-since-1918.-why-are-the-vaccines-against-covid-which-is-much-newer-and-more-harmful-so-much-more-effective-than-the-flu-vaccines-is-there-any-hope-for-a-universal-flu-vaccine-as-there-is-for-a-universal-covid-vaccine",
    "href": "posts/quora-answers/index.html#the-flu-has-been-around-since-1918.-why-are-the-vaccines-against-covid-which-is-much-newer-and-more-harmful-so-much-more-effective-than-the-flu-vaccines-is-there-any-hope-for-a-universal-flu-vaccine-as-there-is-for-a-universal-covid-vaccine",
    "title": "My favourite Quora answers",
    "section": "The flu has been around since 1918. Why are the vaccines against Covid, which is much newer and more harmful, so much more effective than the flu vaccines? Is there any hope for a ‘universal flu vaccine’ (as there is for a ‘universal Covid vaccine’)?",
    "text": "The flu has been around since 1918. Why are the vaccines against Covid, which is much newer and more harmful, so much more effective than the flu vaccines? Is there any hope for a ‘universal flu vaccine’ (as there is for a ‘universal Covid vaccine’)?\n\nInfluenzaviruses have been around for much longer than since 1918. Greek physicians from the 5th century BC have documented what is almost definitely influenza. Influenza A and B viruses have differentiated around 2,000 years ago, but both trace their origins to a common ancestor around 8,000 years or so ago, give or take a few thousand years (molecular clocking gets tricky after some time). More importantly, however, influenza has a level of diversity that far exceeds SARS-CoV-2.\nInfluenzaviruses are actually not a single pathogen, but four genera of the family orthomyxoviridae, each of which comprises a single species: we refer to these as influenzaviruses A, B, C and D. These are viral species in their own right. A, B and C are human pathogenic, and A is responsible for pandemic influenza. Influenzaviruses then break down into serotypes. When you see something like H1N1, that’s a subtype – it denotes the type of two major surface proteins, haemagglutinin (the number after H) and neuraminidase (the number after N) expressed by the virion. Influenza A virus is incredibly genetically diverse, and mutates rapidly. This creates a kind of diversity and versatility that makes it hard to vaccinate against.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#why-is-patient-zero-called-patient-zero-and-not-patient-one-to-denote-the-first-person-with-a-disease",
    "href": "posts/quora-answers/index.html#why-is-patient-zero-called-patient-zero-and-not-patient-one-to-denote-the-first-person-with-a-disease",
    "title": "My favourite Quora answers",
    "section": "Why is “patient zero” called “patient zero” and not “patient one” to denote the first person with a disease?",
    "text": "Why is “patient zero” called “patient zero” and not “patient one” to denote the first person with a disease?\n\nActually, it’s not. It’s a popular science term, nobody in epidemiology uses it. The correct term is ‘index case’ or ‘index patient’.\n“Patient zero” comes from a contact network study by Auerbach et al. (1984) on HIV:\n\n\n\nAuerbach’s contact network\n\n\n\nI have a fervent dislike for the ‘patient zero’ term, both in colloquial usage and in epidemiology (where it’s thankfully quite rare these days), so make sure you read this answer in full. Incidentally, we’re looking at this contact network in Computational Note 2.10 (page 75) of my book."
  },
  {
    "objectID": "posts/quora-answers/index.html#why-are-infectious-diseases-with-high-mortality-rates-not-as-infectious-as-those-with-lower-mortality-rates",
    "href": "posts/quora-answers/index.html#why-are-infectious-diseases-with-high-mortality-rates-not-as-infectious-as-those-with-lower-mortality-rates",
    "title": "My favourite Quora answers",
    "section": "Why are infectious diseases with high mortality rates not as infectious as those with lower mortality rates?",
    "text": "Why are infectious diseases with high mortality rates not as infectious as those with lower mortality rates?\n\nThere’s a theory that underlies this observation, widely known as the ‘avirulence hypothesis’ aka ‘trade-off theory’ (which I discuss in my book on p.164). The idea is that from the perspective of the pathogen, virulence (the detrimental effect of the pathogen on the human) is quite epiphenomenal. The pathogen does not get an evolutionary advantage out of harming the host. Some of the most widely spread viruses, for instance, cause no symptoms at all in the overwhelming majority of people. My favourite, JC virus, is present in about 50–70% of all people worldwide, and generally does not cause symptoms unless the person in question is immunosuppressed (at which point, sadly, it can cause some dreadful consequences – progressive multifocal leukoencephalopathy, which occurs in HIV/AIDS and with the use of certain medications for neuroautoimmune disorders that reduce immune system activity in the brain, is caused by JC virus reactivation, and is pretty unpleasant). Ubiquitous viruses like EBV and some herpesviruses are generally very indolent, to the point of being asymptomatic in many cases. In some instances, they might even be beneficial – gammaherpesviruses are associated, at least in animal models, with an increased resistance to Y. pestis and Listeria monocytogenes.\n\nRead the full answer here. The paper by Barton et al. (2007), which I cite, is an absolute gem too."
  },
  {
    "objectID": "posts/quora-answers/index.html#has-smallpox-been-wiped-out-or-is-it-still-around",
    "href": "posts/quora-answers/index.html#has-smallpox-been-wiped-out-or-is-it-still-around",
    "title": "My favourite Quora answers",
    "section": "Has smallpox been wiped out, or is it still around?",
    "text": "Has smallpox been wiped out, or is it still around?\n\nYes. As in, it’s been wiped out, and it’s still around. And this is one of the bigger travesties of the world.\n\n\nUnfortunately, humans are what they are, and the two superpowers, the US and the USSR at the time, decided that each would be allowed to keep actual smallpox samples. The last outbreak of smallpox was not ‘natural’ but a laboratory escape, killing a medical photographer, Janet Parker, in 1978. In 1984, the WHO authorised two labs – VECTOR in Koltsovo, USSR, and the CDC in Atlanta – to store samples of it. And this has ignited a debate that keeps coming up all the time.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#is-the-t-virus-in-resident-evil-a-fictional-virus-or-is-there-an-actual-disease-that-resembles-it",
    "href": "posts/quora-answers/index.html#is-the-t-virus-in-resident-evil-a-fictional-virus-or-is-there-an-actual-disease-that-resembles-it",
    "title": "My favourite Quora answers",
    "section": "Is the T-virus in Resident Evil a fictional virus or is there an actual disease that resembles it?",
    "text": "Is the T-virus in Resident Evil a fictional virus or is there an actual disease that resembles it?\n\nI like discussing fictional viruses. Heck, I’ve discussed one in my book – MEV-1, from Contagion –, which is supposed to be Serious Academic Literature. Fiction sometimes allows us to explore what could be, which is just as important as what is when it comes to preparing for bad things to happen.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#if-a-person-is-fluent-in-multiple-languages-what-is-the-language-of-their-thoughts",
    "href": "posts/quora-answers/index.html#if-a-person-is-fluent-in-multiple-languages-what-is-the-language-of-their-thoughts",
    "title": "My favourite Quora answers",
    "section": "If a person is fluent in multiple languages, what is the language of their thoughts?",
    "text": "If a person is fluent in multiple languages, what is the language of their thoughts?\n\nWhen you speak multiple languages, you come to think of languages as tools. I like German, for instance, which I consider a great tool for expressing logic, and I find German absolutely wonderful for discussing mathematics. I love the conciseness of modern Hebrew, and it’s my go-to for putting something down quickly. I think Russian gets certain emotions across in ways I have a hard time doing in other languages. And so on.\nYou rarely use a single language for thoughts, although you do tend to default to whatever your dominant language is, which may or may not be your native language (my dominant language for thinking is English, but it was only the third or fourth language I’ve learned). Equally, I used to think primarily in Hungarian as a child (the language we spoke at home most of the time), but increasingly found I had a hard time expressing certain ideas. I learned both my first and second profession in English, and I have no idea what an outer automorphism group is in Hungarian, never mind the more specialised language I learned in law.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#is-it-possible-for-someone-who-speaks-more-than-one-language-to-identify-what-language-someone-is-speaking-just-by-hearing-them-speak-for-a-few-seconds-no-context-if-so-how-many-languages-can-this-be-done-with",
    "href": "posts/quora-answers/index.html#is-it-possible-for-someone-who-speaks-more-than-one-language-to-identify-what-language-someone-is-speaking-just-by-hearing-them-speak-for-a-few-seconds-no-context-if-so-how-many-languages-can-this-be-done-with",
    "title": "My favourite Quora answers",
    "section": "Is it possible for someone who speaks more than one language to identify what language someone is speaking just by hearing them speak for a few seconds (no context)? If so, how many languages can this be done with?",
    "text": "Is it possible for someone who speaks more than one language to identify what language someone is speaking just by hearing them speak for a few seconds (no context)? If so, how many languages can this be done with?\n\nYes. You can even pick this up with languages you don’t speak. For instance, I speak about a hundred words of Amharic (and about a quarter or so of those would fall into the ‘colourful language’ category), but can recognise it anytime.\nOne of my native languages (Hungarian) is quite peculiar to me in that way. I can recognise it even if you speak it very faintly. I may not even be able to understand individual words, but there’s a ‘rhythm’ and ‘tonality’ to it that you can understand. The best analogy is this: say you’ve listened to your fair share of modern minimalist composers. If I gave you a new Philip Glass soundtrack, you’d immediately recognise it. There are some motifs that are just ‘so Glass’. This actually goes beyond identifying the language and starts to involve the semantic layer. My wife does not speak particularly good Hungarian, but can understand quite a bit of what’s going on from tone and affect.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#can-a-language-be-replaced-by-another-one-if-so-how-would-this-happen-in-an-example-of-a-real-world-scenario",
    "href": "posts/quora-answers/index.html#can-a-language-be-replaced-by-another-one-if-so-how-would-this-happen-in-an-example-of-a-real-world-scenario",
    "title": "My favourite Quora answers",
    "section": "Can a language be replaced by another one? If so, how would this happen in an example of a real world scenario?",
    "text": "Can a language be replaced by another one? If so, how would this happen in an example of a real world scenario?\n\nYes. This happens all the time, and unfortunately it’s one of the major causes of languages becoming extinct.\nBy way of example, let’s consider one of my favourite languages, Yahgan, spoken by the Yaghan people in Tierra del Fuego. As languages go, it’s had pretty bad cards to begin with: it’s a language isolate, meaning it’s not related to any major language or linguistic group. In February of last year (2022), Cristina Calderon, the last native speaker of Yahgan, succumbed to complications of COVID-19 (at the ripe, old age of 93), and with her, Yahgan became effectively extinct. Which is a pity, because as languages go, it’s got some spectacularly fun features. But I’ll leave the language nerding for later.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#if-you-had-the-ability-to-speak-any-language-fluently-which-one-would-you-choose-and-why",
    "href": "posts/quora-answers/index.html#if-you-had-the-ability-to-speak-any-language-fluently-which-one-would-you-choose-and-why",
    "title": "My favourite Quora answers",
    "section": "If you had the ability to speak any language fluently, which one would you choose, and why?",
    "text": "If you had the ability to speak any language fluently, which one would you choose, and why?\n\nMy shortlist:\n\nArikara, a critically endangered Caddoan language. It’s spoken by fewer than a dozen people on the Fort Berthold reservation. Critically endangered, it is not mutually intelligible with any of its close Pawnee relatives.\nLower Arrernte is not actually one of the Arrernte languages, although it is an Aranda language, i.e. related to it. Brownie Doolan perrurle was the last native speaker of Lower Arrernte, and he passed away in 2011.\nThe Maidu languages, which are either extinct or almost so. Maidu is a language subfamily, although where it fits into the wider scheme of things isn’t all that clear. It used to be spoken in California by the Maidu peoples.\nOsage, another critically endangered language – was spoken mainly in Oklahoma, and has been considered extinct since 2005, when the last native speaker, Lucille Robedeaux, passed away.\nSireniksky is a Yupik language that’s also extinct. There’s actually disagreement as to where it comes from, or whether it’s actually a Yupik language – there’s actually a theory that it’s the only known example of a third separate branch of the Eskimoan languages, along with Yupik and Inuit languages. It was displaced by Siberian Yupik, and of course Russian.\n\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#are-law-firms-allowed-to-charge-as-if-they-were-doctors-despite-the-fact-that-it-requires-far-less-training-and-skill-set-than-medicine-does-what-can-be-done-about-this-issue",
    "href": "posts/quora-answers/index.html#are-law-firms-allowed-to-charge-as-if-they-were-doctors-despite-the-fact-that-it-requires-far-less-training-and-skill-set-than-medicine-does-what-can-be-done-about-this-issue",
    "title": "My favourite Quora answers",
    "section": "Are law firms allowed to charge as if they were doctors, despite the fact that it requires far less training and skill set than medicine does? What can be done about this issue?",
    "text": "Are law firms allowed to charge as if they were doctors, despite the fact that it requires far less training and skill set than medicine does? What can be done about this issue?\n\nI worked for a Big Law firm. To say we charged like doctors is a gross insult. Very few doctors charge remotely what we did.\nThere’s a quite simple reason for why that’s the case: spending seven figures (or more) with us could save a company from being sunk by a lawsuit. Think about that for a moment. We routinely acted in matters where tens or hundreds of millions were at stake, and often enough, much more. The amount of money at play in such high stakes matters is orders of magnitude beyond whatever impact an individual physician may generate. You don’t have to like this fact of life, but that doesn’t make it any less a fact of life.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#if-the-uk-were-invaded-would-it-be-legal-in-uk-law-for-a-civilian-to-murder-an-enemy-combatant-if-the-opportunity-presented-itself",
    "href": "posts/quora-answers/index.html#if-the-uk-were-invaded-would-it-be-legal-in-uk-law-for-a-civilian-to-murder-an-enemy-combatant-if-the-opportunity-presented-itself",
    "title": "My favourite Quora answers",
    "section": "If the UK were invaded, would it be legal in UK law for a civilian to murder an enemy combatant if the opportunity presented itself?",
    "text": "If the UK were invaded, would it be legal in UK law for a civilian to murder an enemy combatant if the opportunity presented itself?\n\nThe laws of war basically separate people in two classes – combatants and non-combatants. A combatant cannot be prosecuted for the lawful conduct of hostilities which, yes, involves killing the other side’s combatants (they can, however, be prosecuted for war crimes). They are entitled to the panoply of rights that combatants have upon becoming non-combatants by way of surrender or becoming hors de combat, such as being wounded. On the other hand, a combatant can generally be killed with pretty little justification – if the kill is legal (the person is a combatant at the time, and the kill did not involve perfidy or some other form of illegality), it is what it is.\nNon-combatants enjoy extensive privileges in contrast. Not only are they entitled to protection, even if they are living in occupied areas, they are also categorically not permissible targets for military action. They and their property enjoy extensive protections. They cannot generally be interned against their will unless they are prisoners of war, they cannot generally be forced to work and there are various other protections they enjoy. Most of all, they cannot be killed for no reason other than not liking the occupying power.\nThis gets complex where someone decides they’re going to blur the lines.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#why-doesnt-the-uk-have-a-written-constitution",
    "href": "posts/quora-answers/index.html#why-doesnt-the-uk-have-a-written-constitution",
    "title": "My favourite Quora answers",
    "section": "Why doesn’t the UK have a written constitution?",
    "text": "Why doesn’t the UK have a written constitution?\n\nI passionately hate the meme that the UK does not have a written constitution, because, for one, it’s not true, more importantly however, it distracts from the bigger question, namely what a constitution is.\nNow, a lot of how we perceive constitutions comes from the US idea that a constitution is a ‘supreme law of the land’, a superordinate legal norm against which all legislative and administrative action comes to be tested. This is not, actually, a necessary implication. Constitutions can be superordinate norms and it makes sense for them to be so. On the other hand, they don’t have to, nor is it a necessary implication of a constitution that it should be a superordinate norm. Nor do written and codified constitutions exclude reliance on other norms that happen not to be written and codified. An example would be constitutional conventions, which are basically political customs – plenty of countries with proper, codified constitutions have them. For instance, Germany has a codified constitution (even if it is not called a constitution but a Basic Law, for historical reasons), but that doesn’t provide for who gets to nominate the President of the Bundestag in the circumstances where a party has a plurality but is in opposition. It turns out that in this case, it would still be the largest party that would get to provide the President of the Bundestag, i.e. there’s no horse-trading between coalition parties to have a joint candidate for President of the Bundestag. This isn’t written down anywhere, incidentally.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#dont-american-law-students-study-the-famously-unwritten-british-constitution-are-the-details-superfluous",
    "href": "posts/quora-answers/index.html#dont-american-law-students-study-the-famously-unwritten-british-constitution-are-the-details-superfluous",
    "title": "My favourite Quora answers",
    "section": "Don’t American law students study the famously unwritten British Constitution? Are the details superfluous?",
    "text": "Don’t American law students study the famously unwritten British Constitution? Are the details superfluous?\n\nThe British constitution is very much written.* It’s not codified. There’s a difference. For instance, nobody would argue that the Human Rights Act 1998 isn’t part of the British constitutional order, and last I checked, it’s pretty darn written. What it isn’t is codified, meaning there isn’t a single constitutional document.\nPart of the reason for this is that we do not have coequal branches of government. The UK has legislative supremacy, i.e. Parliament is not fettered by the judiciary. There’s no such thing as judicial review of primary legislation (as opposed to secondary legislation aka statutory instruments, and administrative action) the way there is in the US post-Marbury v Madison. Therefore, there’s no real need — or use — for a superordinate norm against which legislation may be tested. John Griffith said “the constitution is what happens … if it works, it’s constitutional”. The lecture (and later article) in which he made this poignant remark was titled The Political Constitution, which I think is a great way of describing the UK’s constitutional order.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#is-law-school-intrinsically-worth-it-even-if-you-dont-become-a-lawyer-is-it-worth-it-to-go-through-the-process-of-law-school",
    "href": "posts/quora-answers/index.html#is-law-school-intrinsically-worth-it-even-if-you-dont-become-a-lawyer-is-it-worth-it-to-go-through-the-process-of-law-school",
    "title": "My favourite Quora answers",
    "section": "Is law school intrinsically worth it? Even if you don’t become a lawyer, is it worth it to go through the process of law school?",
    "text": "Is law school intrinsically worth it? Even if you don’t become a lawyer, is it worth it to go through the process of law school?\n\nThe common perception is that law school is spent studying the law. This is maybe true in the vaguest outlines. Let me give you an example: like everyone pursuing a qualifying law degree in England and Wales, I had to take criminal law. Part of that was learning the elements of certain offences. I know to this date that theft is the (1) dishonest (2) appropriation of (3) property (4) belonging to another (5) with intent to permanently deprive. Would I actually know how to defend a theft charge? Probably not. How each of these parameters are applied in practice is not a lot like what you learn in law school.\nYou do, however, learn a lot about reasoning. For instance, ‘dishonesty’ is an element of the offence. In England and Wales, a finding of dishonesty requires both a subjective and objective element (R v Ghosh), i.e. not only does your action have to be something others would consider dishonest, but it must also be something you yourself would consider dishonest. How would one arrive at that finding? How would one make the pleading for that? Would, say, someone believing that they are enriching themselves unjustly qualify?\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#can-a-country-turn-vampires-illegal",
    "href": "posts/quora-answers/index.html#can-a-country-turn-vampires-illegal",
    "title": "My favourite Quora answers",
    "section": "Can a country turn vampires illegal?",
    "text": "Can a country turn vampires illegal?\nIf the vampire and zombie apocalypse is coming: Whitehall, call me.\n\nSo, going after all the vampires would clearly be a violation of the Equality Act, and essentially a disability-based extermination. That’s a big no-no. Assuming we consider vampires still somewhat human, it would be a human rights violation. Since death in England and Wales is generally brainstem death, it would be very difficult to conclude that a vampire, once turned, is “dead” and hence no longer deserving of human rights.\nVampires would thus be entitled to “reasonable accommodations” (such as working from home/castle/coffin or jobs that involve only night-time work), along with non-discrimination provisions. You would not, for instance, be allowed to refuse renting to the Karnstein family just because they have a predilection for blood.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#having-diplomatic-status-is-sovereignty-but-its-nearly-impossible-to-obtain-so-being-a-sovereign-citizen-does-exist-if-you-can-obtain-diplomatic-immunity",
    "href": "posts/quora-answers/index.html#having-diplomatic-status-is-sovereignty-but-its-nearly-impossible-to-obtain-so-being-a-sovereign-citizen-does-exist-if-you-can-obtain-diplomatic-immunity",
    "title": "My favourite Quora answers",
    "section": "Having diplomatic status is sovereignty but it’s nearly impossible to obtain so, being a sovereign citizen does exist if you can obtain diplomatic immunity?",
    "text": "Having diplomatic status is sovereignty but it’s nearly impossible to obtain so, being a sovereign citizen does exist if you can obtain diplomatic immunity?\nI do love me some sovcits.\n\nNot only is diplomatic status not sovereignty, it is the very opposite of sovereignty.\nYou are granted diplomatic status by presenting your letter of credence aka diplomatic credentials (this does not mean an ID but a letter from your sending country’s or institution’s authorities to your receiving country) to the receiving country’s authorities. This is a pretty big show, incidentally – typically, they are presented to the receiving country’s head of state in person.\nIt’s at the receiving country’s leisure to accept or reject this. A person isn’t a diplomat in a foreign country by their sending country’s fiat but by the receiving country’s consent (called agrément), which incidentally can be pretty much withdrawn at will – every country has the sovereign right to kick out any diplomat for any reason they want (Art. 9 Vienna Convention), and ban them from the country, a process generally known as PNGing (for persona non grata, and typically pronounced as ‘pinging’).\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#as-a-math-major-or-mathematician-what-makes-you-roll-your-eyes-every-time-you-hear-it",
    "href": "posts/quora-answers/index.html#as-a-math-major-or-mathematician-what-makes-you-roll-your-eyes-every-time-you-hear-it",
    "title": "My favourite Quora answers",
    "section": "As a math major or mathematician, what makes you roll your eyes every time you hear it?",
    "text": "As a math major or mathematician, what makes you roll your eyes every time you hear it?\n\nThe assumption that we all do the same stuff.\nI’m doing a very specific kind of applied mathematics, day in, day out. What I do for a living has very little to do with what Alon Amit, one of my favourite Quorans, or, say, Edward Frenkel does. I could, technically, go about my work without having the slightest idea of Galois theory. Of course, that would be a sad and diminished existence, but hey. On the other hand, I need to know how to use a continuous wavelet transform with a Morlet wavelet to discern the way periodicities in the incidence of infectious diseases have changed (and if you are interested in that sort of stuff, you can go buy my book). I need to be able to construct Lyapunov functions and use them to reason about the stability of equilibrium states. And I have to be able to tell whether a certain control parameter, such as vaccination rate, is going to result in complex non-linear behaviour.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#do-mathematicians-use-advanced-terminology",
    "href": "posts/quora-answers/index.html#do-mathematicians-use-advanced-terminology",
    "title": "My favourite Quora answers",
    "section": "Do mathematicians use advanced terminology?",
    "text": "Do mathematicians use advanced terminology?\n\nAs you move towards more advanced maths, it becomes less about dealing with numbers and stuff, and more about logical manipulations of various concepts. We want a convenient way to refer to certain things for which certain statements are true. To give you an example you are likely familiar with: we could say “x is a member of the set of integers greater than one that is not the product of two natural numbers”. Or, we could just say “x is [a] prime”. This is useful when you have to describe more complex things. A group, for instance, is a construct that consists of a set and an operation. A set and an operation are a group if they exhibit the group axioms — properties that are the “requirements” for a group. What these are are not so relevant here as the fact that life is a whole lot easier for us if we can simply say “group” and know that everyone else will know what we’re talking about, including, importantly, what specific features this thing we allege is a group would exhibit, from which we can then derive various other properties. For instance, one property of a group is that the operation is “closed”, meaning that performing the operation on any elements of the set will give you another element of the set. We know that addition of integers is a group (the set is the set of integers, the operation is addition). Consequently, we have proved that if x and y are integers, so will x + y be an integer. Trivial, yes, but it gets much more complicated quite quickly.\nMany of these concepts are, essentially, sets of rules and conditions. Often, they’re subspecies: an Abelian group is a group that satisfies some specific criteria. A ring is a kind of Abelian group that meets some additional criteria. And so on. Mathematical terminology is intended to capture these logical distinctions in a sort of shorthand.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-is-the-scariest-disease-in-the-world-other-than-rabies",
    "href": "posts/quora-answers/index.html#what-is-the-scariest-disease-in-the-world-other-than-rabies",
    "title": "My favourite Quora answers",
    "section": "What is the scariest disease in the world (other than rabies)?",
    "text": "What is the scariest disease in the world (other than rabies)?\n\nPrimary Amoebic Meningoencephalitis, aka Naegleriasis.\nNow, there’s no good meningoencephalitis. They’re all bad, even the relatively treatable forms. The problem is that the brain does not have a lot of tolerance for swelling, and therefore pretty much any inflammation in the brain is going to be a massive problem.\nThe reason why PAM is the worst kind of meningoencephalitis is because the pathogen involved, N. fowlerii, is extremely difficult to kill. Naegleriasis is an amoebiasis rather than a bacterial infection, meaning that the usual method of solving problems – throw antibiotics at it – doesn’t really work. The most effective drug until recently used to be amphotericin B, which is notorious enough for its side effect profile to be nicknamed ‘amphoterrible’. From what I gather from an acquaintance who has had the pleasure of a personal acquaintance with the darn thing, it does its nickname justice. It’s not the most unpleasant drug in the infectious disease arsenal, because our friends in Infectious Diseases have things like literal arsenic in antifreeze (melarsoprol), but it’s pretty bad. And that’s before dealing with the problem of actually getting it to the site of the action, which often requires intrathecal administration (into the spinal canal), which has an entire set of issues on its own. Oh, and this treatment is effective in around 1.5% of cases. That’s right: case-fatality ratio for PAM is around 98.5%. Survivors are often left with permanent neurological sequelae.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-diseases-are-close-to-being-cured-by-medical-research-and-why-are-they-progressing-faster-than-others-like-diabetes",
    "href": "posts/quora-answers/index.html#what-diseases-are-close-to-being-cured-by-medical-research-and-why-are-they-progressing-faster-than-others-like-diabetes",
    "title": "My favourite Quora answers",
    "section": "What diseases are close to being cured by medical research, and why are they progressing faster than others (like diabetes)?",
    "text": "What diseases are close to being cured by medical research, and why are they progressing faster than others (like diabetes)?\n\nProbably the biggest success story is cystic fibrosis (CF). It’s gone from essentially lethal in childhood in the 1980s, to survivable into adulthood with serious interventions (such as a double lung transplant) in the 1990s to now having the “geriatric shift”: patients are getting old enough to need care for long term effects as they are now living into, if not a ripe old age, at least past previous life expectancies. In the West, with good care and management, especially in patients who have a druggable CFTR mutation that can be treated with the CFTR modulators (the ‘caftors’: lumacaftor, ivacaftor &c.), hitting 30 is considered to be more or less normal, and a child born with CF today has a better chance of seeing their children and perhaps even grandchildren than anyone with CF has ever had. And all this played out over the span of about 30–40 years.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-exactly-happens-during-a-clinical-trial-how-do-you-become-a-participant-in-a-clinical-trial",
    "href": "posts/quora-answers/index.html#what-exactly-happens-during-a-clinical-trial-how-do-you-become-a-participant-in-a-clinical-trial",
    "title": "My favourite Quora answers",
    "section": "What exactly happens during a clinical trial? How do you become a participant in a clinical trial?",
    "text": "What exactly happens during a clinical trial? How do you become a participant in a clinical trial?\n\nSee a clinical trial, and you’ve seen exactly one clinical trial. There are many different clinical trials at many different stages, for many different conditions, for many different interventions. No two clinical trials are the same – this is not an exaggeration, this is a rule: you cannot ethically do the exact same clinical trial again (the key ethical consideration for a clinical trial is therapeutic equipoise – that is, there must be a genuine question, you cannot do a trial if you’re sure that a treatment will definitely work or definitely not work)\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#why-do-pet-scan-images-appear-in-black-and-white",
    "href": "posts/quora-answers/index.html#why-do-pet-scan-images-appear-in-black-and-white",
    "title": "My favourite Quora answers",
    "section": "Why do PET scan images appear in black and white?",
    "text": "Why do PET scan images appear in black and white?\n\nI mean, do they?\nA PET scan is basically a form of scintigraphy. The idea of a PET scan is something along these lines: a radiotracer that undergoes ß+ decay is injected, and accumulates where the tracer is taken up (this depends on the tracer and the physiology being imaged). As the tracer undergoes ß+ decay, it emits positrons (thence the PE – ‘positron emission’ – part of the name). When positrons hit electrons, they annihilate and emit a gamma photon. This is then imaged using a gamma camera, which basically measures the intensity of light,* in this case, gamma light. The result is a picture of how much gamma light is emitted from any point in space, thanks to a nifty little thing called an inverse Radon transform (that’s ruh-DOWN as opposed to ray-DOWN, which is how you are supposed to pronounce the element, to which it’s entirely unrelated).\nNow, I’ve gone through this length to explain how the image is acquired because it helps us understand what the image is (which is always something you should have at the forefront in medical imaging). It’s an image of signal intensity attributable to a point in three-dimensional space (although we obviously look at 2-dimensional projections of it), where that signal intensity is the measure of the amount of ß+ decay originating from that point, which in turn is a measure of how much of the tracer is taken up by tissue at that point, which in turn is biologically meaningful (e.g. if the tracer is 18fluoro-deoxyglucose, which is a radiotagged sugar, it will show areas of higher glucose metabolism). In other words, for any point in space (and therefore, for any projection thereof), we have one value for any point in space.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-are-the-challenges-faced-by-the-government-in-financing-treatment-for-rare-diseases",
    "href": "posts/quora-answers/index.html#what-are-the-challenges-faced-by-the-government-in-financing-treatment-for-rare-diseases",
    "title": "My favourite Quora answers",
    "section": "What are the challenges faced by the government in financing treatment for rare diseases?",
    "text": "What are the challenges faced by the government in financing treatment for rare diseases?\n\nPretty much the same as the private sector’s: they’re rare.\nDrug development hinges on economies of scale. The cost of bringing a drug to market is the same, whether it treats a million people, ten or, as is the case for some drugs, a single individual (Milasen, for instance, is an oligonucleotide antisense drug developed for one individual patient with one particular mutation causing Batten’s Disease). If a finite amount of money could be used to bring a drug to market that will give 5–10 quality-adjusted years of life to hundreds of thousands, or save the lives of maybe a hundred, the calculus is quite clear.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#are-there-any-historical-examples-of-self-treatment-or-self-diagnosis-that-led-to-significant-advancements-in-medicine-or-public-health",
    "href": "posts/quora-answers/index.html#are-there-any-historical-examples-of-self-treatment-or-self-diagnosis-that-led-to-significant-advancements-in-medicine-or-public-health",
    "title": "My favourite Quora answers",
    "section": "Are there any historical examples of self-treatment or self-diagnosis that led to significant advancements in medicine or public health?",
    "text": "Are there any historical examples of self-treatment or self-diagnosis that led to significant advancements in medicine or public health?\n\nThere are cells in your body called mast cells that are basically big containers of histamine. When these cells degranulate, they spew this histamine all over the place, and you experience what is known as an allergic reaction. So, it would probably be cool if we could keep these cells from blowing up, right?\nIt turns out that this is a relatively workable idea. A young man by the name of Roger Altounyan, who came from an Aleppo Armenian family, knew of a folk remedy widely used around the Mediterranean – khella, a weed that is boiled down to a tea and used for asthma, colic and just about anything else. The problem is, khella is tremendously unpleasant in terms of side effects. It does, however, stabilise mast cells quite well. Altounyan figured out how to create an analogue, cromoglycate, that does the same but minus the horrid side effects.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-would-happen-to-your-body-if-youre-exposed-to-10-times-the-magnetic-power-30t-of-an-mri-scanner",
    "href": "posts/quora-answers/index.html#what-would-happen-to-your-body-if-youre-exposed-to-10-times-the-magnetic-power-30t-of-an-mri-scanner",
    "title": "My favourite Quora answers",
    "section": "What would happen to your body if you’re exposed to 10 times the magnetic power (30T) of an MRI scanner?",
    "text": "What would happen to your body if you’re exposed to 10 times the magnetic power (30T) of an MRI scanner?\n\nMost of the weird and/or unpleasant things that tend to happen in a properly operated MRI (by which I mean nobody is letting the guy with all the spinal hardware into the scanner room) don’t actually happen due to the static magnetic field. In MRIspeak, that’s normally denoted \\(B_0\\). If you read MRI safety literature, you’ll see another symbol a whole lot more: \\(\\frac{dB}{dt}\\), known to its friends and relatives as “flux change”. In this case, \\(dB\\) stands not for decibels but is rather the change in the total field strength. It turns out that if you have a high frequency of change (and as we know, frequency is the inverse of the period), then even relatively small fields can build up quite a bit of flux change. The MRI has a part called the RF transmit coil (or sometimes just “coil”) that transmits a much, much smaller magnetic field that, however, varies rapidly. It’s called an RF coil because the transmitted signal is in the radiofrequency range, so in the high hundreds to low thousands of MHz (megahertz). If you get a tiny field that flips a hundred million times a second, you’re going to get an awful lot of flux change. By far the biggest problem is that this field coexists, regrettably, with an electric field \\(E\\) (we’ve got Maxwell to thank for that). The Maxwell equation, of course, tells us that \\(\\del \\times E = \\frac{dB}{dt}\\), which in short means that if you oscillate the magnetic field, you’re going to get an electric field perpendicular to the magnetic field lines that is going to oscillate at the same frequency. This electric field dumps energy into whatever is at hand, and if you’re in the Magic Donut, that energy will end up in you. There are largely two things that happen. One is the result of the fact that you’re only seventy-odd percent water. A good part of the rest are charged particles, which are accelerated by this field and slammed into the nearest water molecule. This creates vibrational energy, which is also known as heat. This is called Ohmic heating, and if you’ve ever had one of those old space heaters that were ridiculously unsafe but incredibly cosy after being drenched by the rain, that’s how they worked. The bigger issue is dielectric heating. If you vary the electric field fast enough, all sorts of polar molecules are going to try to align themselves with that field. Unfortunately, that seventy-odd percent of yours that is water? That’s a polar molecule. If you flip water molecules around their axis a couple of hundred million tiems a second, you get what everyone else knows and loves as a “microwave oven”. Higher field strengths involve higher RF frequencies (for reasons you might find out by googling Larmor frequencies), so the RF coils in a higher field will have a higher \\(\\frac{dB}{dt}\\) and hence a higher \\(\\frac{dE}{dt}\\). That in turns means more energy dumped as heat. It’s worth noting that this energy dumping as heat is pretty minimal. What happens a lot more often is if there’s something to be heated. There are two flavours of this. One is what we call inductive heating. This happens when the body, which is an okayish conductor, comes in touch with something that isn’t, such as the bore. That generates a resistance, and we know what happens to resistances. The other alternative is anything that creates a loop. By far the most frequent loops that generate RF burns are humans. If you are raising your arms up, don’t touch them. If you’re holding your arms down, don’t touch your hip. Don’t let cables touch your abdomen. More importantly, don’t let coils of cables be anywhere near you.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#how-did-the-scientists-of-the-manhattan-project-know-it-would-work",
    "href": "posts/quora-answers/index.html#how-did-the-scientists-of-the-manhattan-project-know-it-would-work",
    "title": "My favourite Quora answers",
    "section": "How did the scientists of the Manhattan project know it would work?",
    "text": "How did the scientists of the Manhattan project know it would work?\n\nThis is science. You never know if something will work. You do, however, have a degree of belief – in the statistical, not the religious sense –, and that belief tends to be the result of evidence (ideally). By the time dawn broke over Alamogordo on 16 July 1945, there was a pretty impressive amount of evidence that it would work just fine.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#would-the-a-bomb-be-created-without-oppenheimer",
    "href": "posts/quora-answers/index.html#would-the-a-bomb-be-created-without-oppenheimer",
    "title": "My favourite Quora answers",
    "section": "Would the A-bomb be created without Oppenheimer?",
    "text": "Would the A-bomb be created without Oppenheimer?\n\nMuch is made of Oppenheimer as an ‘administrator’, but I think that misses the point. There was a logistical-administrative genius at work at the Manhattan Project, but that was Leslie Groves, not Oppenheimer. Rather, Oppenheimer’s principal role was as a buffer.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#why-would-britain-have-had-to-ask-for-australian-permission-to-test-nuclear-weapons-in-the-1950s-in-australia-britain-owned-australia-in-the-past-so-surely-britain-can-do-whatever-it-wants-in-australia",
    "href": "posts/quora-answers/index.html#why-would-britain-have-had-to-ask-for-australian-permission-to-test-nuclear-weapons-in-the-1950s-in-australia-britain-owned-australia-in-the-past-so-surely-britain-can-do-whatever-it-wants-in-australia",
    "title": "My favourite Quora answers",
    "section": "Why would Britain have had to ask for Australian permission to test nuclear weapons in the 1950s in Australia? Britain owned Australia in the past so surely Britain can do whatever it wants in Australia?",
    "text": "Why would Britain have had to ask for Australian permission to test nuclear weapons in the 1950s in Australia? Britain owned Australia in the past so surely Britain can do whatever it wants in Australia?\n\nIn 1907, at the Imperial Conference, a number of self-governing British territories, such as Australia and Canada, became dominions. This made them subjects capable of independent standing under international law – Australia, for example, was one of the founding nations of the League of Nations. In 1931, the Statute of Westminster further increased the sovereignty of dominions. This basically put into effect the Balfour Declaration of 1926, which declared that the dominions were co-equal with each other and the United Kingdom. It also, implicitly, repealed the Colonial Laws Validity Act 1865 and essentially terminated the ability of Westminster to legislate for the Dominions. By the time you’re referring to, Australia has very much been an independent sovereign that in no conceivable way was “owned” by Britain. This includes participation in collective security agreements the UK was not party to, such as Australia and New Zealand’s alliance with the US – and, of course, it participated in the UN as a fully-fledged sovereign.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-are-the-first-signs-of-a-nuclear-war",
    "href": "posts/quora-answers/index.html#what-are-the-first-signs-of-a-nuclear-war",
    "title": "My favourite Quora answers",
    "section": "What are the first signs of a nuclear war?",
    "text": "What are the first signs of a nuclear war?\n\nThere was a project in the early 1980s run by the KGB called RYaN – raketno-yadernoye napadenie, roughly translating to ‘nuclear missile attack’ and sometimes wrongly spelled RYAN. The purpose of that was to watch for indicators of what in British governmentese is called ‘transition to war’ (TTW). The later Soviet leader, Yuri Andropov, was then the head of the KGB. Even by the standards of KGB functionaries, Andropov was paranoid to a clinical degree, at least partly due to his brain swimming in an increasingly potent pickle of his body’s own waste products due to untreated renal failure. More so, though, he witnessed a bunch of Soviet-trained servants of the Communist repression in Hungary get hung from lampposts during the 1956 Revolution, which left him with a life-long ‘Hungarian Complex’. Andropov genuinely believed that the West, with Reagan’s encouragement, was going to get the drop on the Soviet Union.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#theres-a-fear-of-dirty-bomb-used-by-some-malicious-non-governmental-actor-terrorist-organization.-but-is-that-fear-even-grounded-is-it-that-simple-to-construct-a-dirty-bomb-if-compared-to-the-standard-nukes-used-by-countries",
    "href": "posts/quora-answers/index.html#theres-a-fear-of-dirty-bomb-used-by-some-malicious-non-governmental-actor-terrorist-organization.-but-is-that-fear-even-grounded-is-it-that-simple-to-construct-a-dirty-bomb-if-compared-to-the-standard-nukes-used-by-countries",
    "title": "My favourite Quora answers",
    "section": "There’s a fear of dirty bomb used by some malicious non-governmental actor (terrorist organization). But is that fear even grounded? Is it that simple to construct a dirty bomb if compared to the “standard” nukes used by countries?",
    "text": "There’s a fear of dirty bomb used by some malicious non-governmental actor (terrorist organization). But is that fear even grounded? Is it that simple to construct a dirty bomb if compared to the “standard” nukes used by countries?\n\nThe entire edifice of control over the nuclear means of our fellow man’s destruction rests on a very simple principle: nuclear weapons need fissile material. It’s impossible to get fissile material easily (you can technically go and buy small amounts, but even that’s tricky). It’s impossible to make fissile material easily – you’ll have to master an entire industry called uranium enrichment or a different one called plutonium breeding. And there’s a minimum of how much fissile material you need to realise a yield. The ‘critical’ in ‘critical mass’ reflects this: critical mass plus one gram equals nuclear boom, critical mass minus one gram equals no nuclear boom. The effect of this scheme is that as long as nobody sells fissile material, even relatively well-funded state actors – think Iran, North Korea – have an enormously difficult time getting enough fissile material to play the nuclear game. Non-state actors pretty much stand not a snowball’s chance in hell.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#could-you-build-a-nuclear-weapon-off-from-an-information-online",
    "href": "posts/quora-answers/index.html#could-you-build-a-nuclear-weapon-off-from-an-information-online",
    "title": "My favourite Quora answers",
    "section": "Could you build a nuclear weapon off from an information online?",
    "text": "Could you build a nuclear weapon off from an information online?\n\nAssuming you have the fissile material, the answer is largely yes.\nThe US has, on multiple occasions, ran “Nth Country” experiments, mostly in the pre-internet era (if they did any in recent years, it is classified and will remain so for a long, long time). These have proven out that a physics PhD who did his doctorate on an area other than nuclear physics could, with the help of a decent college library (and, I assume, a friendly college librarian who has few compunctions about the weird guy asking for strange publications involving things like explosive lensing, aerogels and the properties of tantalum-182), build themselves a nuclear bomb.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#how-clever-do-you-have-to-be-to-get-a-first-at-oxford",
    "href": "posts/quora-answers/index.html#how-clever-do-you-have-to-be-to-get-a-first-at-oxford",
    "title": "My favourite Quora answers",
    "section": "How clever do you have to be to get a first at Oxford?",
    "text": "How clever do you have to be to get a first at Oxford?\n\nI’m not, by any stretch of the word, clever. I am generally a hard worker and someone who has probably well above-average stamina. Finals is a marathon, and you need to be able to both have great mental control (not let how you feel you performed one day affect how you are going into next day’s paper) and an ability to work extremely hard during the revision period.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-are-your-favorite-places-to-study-at-oxford-university",
    "href": "posts/quora-answers/index.html#what-are-your-favorite-places-to-study-at-oxford-university",
    "title": "My favourite Quora answers",
    "section": "What are your favorite places to study at Oxford University?",
    "text": "What are your favorite places to study at Oxford University?\n\nHidden gem: the Codrington Library at All Souls, now known as the All Souls College Library to distance themselves from Christopher Codrington, who might have donated a lot of money to All Souls, but was also a slaveowner. The name is gone, the statue is kept.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#how-good-is-food-at-oxford-university-is-it-varied-among-different-colleges",
    "href": "posts/quora-answers/index.html#how-good-is-food-at-oxford-university-is-it-varied-among-different-colleges",
    "title": "My favourite Quora answers",
    "section": "How good is food at Oxford University? Is it varied among different colleges?",
    "text": "How good is food at Oxford University? Is it varied among different colleges?\n\nIt’s quite decent – and yes, it varies as food is made & served by the colleges. It’s British(-made) food, so take that with a pinch of salt (literally – it will taste super salty, but actually be devoid of actual salt, because the government replaced all salt with potassium chloride). Food at Formal Hall is generally very nice, food at lunch and informal hall ranges from good-quality institutional food to quite nice, actually. The typical staples are the usual English breakfast (baked beans, sausages, bacon, you get where I’m headed), whatever can be made at institutional scale for lunch, and the same again for dinner. If you go to informal hall every day for three meals at the same college, you will very rapidly grow bored of it. It’s not necessarily unhealthy, and it’s quite affordable, but it ain’t Heston Blumenthal. The same bubble & squeak will get a little dull after you’ve had it for the fifth time that term. This, incidentally, is a reason for Fifth Week Blues (incipient depression around middle of term): you realise that you have five more weeks of every bit of meat getting drenched in the same made-from-powder gravy.\n\nRead the full answer here (including a list of yays or nays, based on the author’s experience!)."
  },
  {
    "objectID": "posts/quora-answers/index.html#how-do-undergraduate-law-students-get-grades-at-oxford-do-they-have-quizzes-do-they-write-essays-or-what-for-the-finals-are-there-any-finals-or-mid-term-exams-at-all",
    "href": "posts/quora-answers/index.html#how-do-undergraduate-law-students-get-grades-at-oxford-do-they-have-quizzes-do-they-write-essays-or-what-for-the-finals-are-there-any-finals-or-mid-term-exams-at-all",
    "title": "My favourite Quora answers",
    "section": "How do undergraduate law students get grades at Oxford? Do they have quizzes? Do they write essays or what for the finals? Are there any finals or mid-term exams at all?",
    "text": "How do undergraduate law students get grades at Oxford? Do they have quizzes? Do they write essays or what for the finals? Are there any finals or mid-term exams at all?\n\nLaw at Oxford is a pretty… interesting subject when it comes to grading. There you are, after three or four years of suff… I mean, education, and all of it will boil down to a set of papers in one week. That’s it, that’s the whole thing. Nine three-hour papers. Nothing else matters.\nOver the past years, you’ve sat collections (like term exams) at the start of every term. You also sat Moderations (Mods) in your first year, which comprised three papers, in subjects you won’t be tested on in finals. But none of this matters, because it’s a brand new day, and everything starts anew. It’s hard to overstate the psychological pressure inherent in this. We all have good days and bad days, but you absolutely cannot have a bad finals week. This is an absolutely gruelling system that rewards not just knowledge and excellence but also the mental stability to perform no matter what. Training is what you default to when all else fails, and this is training at its harshest.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#does-an-oxford-degree-provide-conclusive-evidence-that-one-person-is-more-intelligent-than-another",
    "href": "posts/quora-answers/index.html#does-an-oxford-degree-provide-conclusive-evidence-that-one-person-is-more-intelligent-than-another",
    "title": "My favourite Quora answers",
    "section": "Does an Oxford degree provide conclusive evidence that one person is more intelligent than another?",
    "text": "Does an Oxford degree provide conclusive evidence that one person is more intelligent than another?\n\nThere are relatively few people around who have done as well on their undergraduate degree at Oxford as I did. The number would probably be, if I counted everyone alive and assumed that there are the same number of equivalents from the Other Place, in the three digits, and that’s assuming every year’s top 1st in every subject did at least as well as I did or better. Off a sample of eight billion, that’s a pretty low number. There are more billionaires alive than people with a top 1st from Oxford.\nThere are probably tens of millions, if not more, people who are vastly more intelligent than I am. Some have top degrees from other universities. Some don’t have any degrees at all, or yet. Some could never get into Oxford and many, if they did, might not do well. There are many things involved in getting in, and doing well at, Oxford. Intelligence is at best part of the story. If I had a limited number of skill points to put into various skills to ensure success at Oxford, intelligence wouldn’t be my first or even second choice. More has been determined by industry, hard work and sheer bloody-minded determination than intelligence. Evolutionary biology calls this the Anna Karenina effect: no one factor ensures success, but rather the presence of all of them is necessary (which is why e.g. zebras were never domesticated like horses - they lack one crucial factor, namely the right temperament).\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#do-students-at-oxford-and-cambridge-universities-have-fun-if-so-what-kind-of-things-do-they-do-to-entertain-themselves-on-campus",
    "href": "posts/quora-answers/index.html#do-students-at-oxford-and-cambridge-universities-have-fun-if-so-what-kind-of-things-do-they-do-to-entertain-themselves-on-campus",
    "title": "My favourite Quora answers",
    "section": "Do students at Oxford and Cambridge universities have fun? If so, what kind of things do they do to entertain themselves on campus?",
    "text": "Do students at Oxford and Cambridge universities have fun? If so, what kind of things do they do to entertain themselves on campus?\n\nNo, fun has been outlawed in Oxford in 1537, having been found to be detrimental to good discipline.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#people-with-iqs-below-83-are-unemployable-in-western-society-according-to-jordan-peterson.-even-people-with-iqs-between-85-100-are-mostly-confined-to-low-paying-jobs-less-than-2x-the-minimum-wage.-why-is-this-issue-ignored-by-society",
    "href": "posts/quora-answers/index.html#people-with-iqs-below-83-are-unemployable-in-western-society-according-to-jordan-peterson.-even-people-with-iqs-between-85-100-are-mostly-confined-to-low-paying-jobs-less-than-2x-the-minimum-wage.-why-is-this-issue-ignored-by-society",
    "title": "My favourite Quora answers",
    "section": "People with IQs below 83 are unemployable in western society, according to Jordan Peterson. Even people with IQs between 85-100 are mostly confined to low paying jobs (less than 2x the minimum wage). Why is this issue ignored by society?",
    "text": "People with IQs below 83 are unemployable in western society, according to Jordan Peterson. Even people with IQs between 85-100 are mostly confined to low paying jobs (less than 2x the minimum wage). Why is this issue ignored by society?\n\nUnlike Dr Peterson, I graduated with a top 1st from the University of Oxford, and got my graduate education there, too. Without being so crass as to discuss what I make, it’s… well, it’s rather more than twice the minimum wage. I managed to do so with an IQ of 83–87, depending on test (all proper testing, administered by actual people, not some online stuff). So I suppose I might have an opinion on the matter.\nThe idea that people with an IQ of 83 are ‘unemployable’ is ridiculous. There probably is some cut-off at which point it becomes difficult to employ someone without constant supervision, but people in the low 80s and even in the 70s can work just fine.\n\nRead the full answer here.)"
  },
  {
    "objectID": "posts/quora-answers/index.html#can-money-really-buy-happiness-if-yes-then-how-and-if-not-then-what-can-bring-happiness",
    "href": "posts/quora-answers/index.html#can-money-really-buy-happiness-if-yes-then-how-and-if-not-then-what-can-bring-happiness",
    "title": "My favourite Quora answers",
    "section": "Can money really buy happiness? If yes, then how and if not, then what can bring happiness?",
    "text": "Can money really buy happiness? If yes, then how and if not, then what can bring happiness?\n\nMoney can’t buy happiness, but it can definitely buy the things you need to do what makes you happy, including – to some extent – time. It’s a common misunderstanding that money can’t buy time. That’s only the case if you manage it badly. If you can accrue money faster than what it costs you to buy an hour of your time, then this is absolutely no issue. 90% of what you do in your waking hours are things you can make someone else do, and usually for pretty nominal cash. I think there’s something good about doing many of these activities yourself – for instance, I’d never hire a personal chef, as making food relaxes me and it’s a good way to keep whatever motor function I’ve got left in my hands mostly in practice. On the other hand, I hate doing the dishes, and if I had to fly to Sotheby’s in London to bid on the last dishwasher in existence, I’d raid my savings to make sure to get it. There are very few things money cannot buy (love, loyalty, friendship are some examples). For all else, you just need to know how to spend your money to buy what it is you really want. If there’s one thing I’ve seen affluent people spend differently on, it’s that vastly more of their spend goes towards things that either buy them time, or buy them experiences to fill that time with.\nAnd that’s pretty close to happiness.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-is-it-like-living-with-diplomatic-immunity",
    "href": "posts/quora-answers/index.html#what-is-it-like-living-with-diplomatic-immunity",
    "title": "My favourite Quora answers",
    "section": "What is it like living with diplomatic immunity?",
    "text": "What is it like living with diplomatic immunity?\n\nNot as fun as you’d like to think.\nFor starters: invoking diplomatic immunity is not really optional. The immunity does not belong to you as a person, it belongs to the state that sent you or your family member. As such, many interactions that you might be able to iron out pretty easily as a normal person will become pretty… complicated.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/quora-answers/index.html#what-do-drunk-scientists-discuss-more-at-cocktail-parties-the-multiverse-wormholes-alien-sightings-or-time-travel",
    "href": "posts/quora-answers/index.html#what-do-drunk-scientists-discuss-more-at-cocktail-parties-the-multiverse-wormholes-alien-sightings-or-time-travel",
    "title": "My favourite Quora answers",
    "section": "What do drunk scientists discuss more at cocktail parties: The multiverse, wormholes, alien sightings or time travel?",
    "text": "What do drunk scientists discuss more at cocktail parties: The multiverse, wormholes, alien sightings or time travel?\nWe are, in fact, boring.\n\nNeither.\nYou’d be surprised by what passes for normal conversation among scientists at cocktail parties. A cocktail party is where you don’t talk shop. If you do, you are marking yourself as a terrible bore, and you won’t be invited ever again. There’s nothing more boring than someone holding forth about abstract nonsense at a cocktail party.\n\nRead the full answer here."
  },
  {
    "objectID": "posts/a-different-shade-of-grey/index.html",
    "href": "posts/a-different-shade-of-grey/index.html",
    "title": "A different shade of grey",
    "section": "",
    "text": "In a recent paper that has attracted the interest of popular media as well, Fabio Urbina and colleagues examined the use (or rather, the abuse) of computational chemistry models of toxicity for generating toxic compounds and potential chemical agent candidates.(Urbina et al. 2022) Urbina and colleagues conclude that\n\nUrbina, Fabio, Filippa Lentzos, Cédric Invernizzi, and Sean Ekins. 2022. ‘Dual Use of Artificial-Intelligence-Powered Drug Discovery’. Nature Machine Intelligence 4 (3): 189–91.\n\nBy going as close as we dared, we have still crossed a grey moral boundary, demonstrating that it is possible to design virtual potential toxic molecules without much in the way of effort, time or computational resources.\n\nI agree with the conclusion, but for rather different reasons.\n\nBackground\nComputational chemistry is the branch of computational science that focuses on applications in the chemical field. This includes pharmacology and rational drug design (RDD) in particular. The purpose of RDD is to generate drug candidates that show favourable indicators of effectiveness (such as high binding affinity to a target protein) along with indicators of biological suitability (such as no or low interference with other proteins, low toxicity and no inhibition of metabolic ‘bottlenecks’ like CYP3A4). The latter part is typically handled by a toxicity model.\nRather simply put, a toxicity model infers the structural associations (the chemical structures associated with undesirable effects) from a library of known compounds with known effects. For instance, the Toxicology in the 21st Century (Tox21) programme of the US federal government has performed over sixty different assays (typically, enzyme inhibition assays) for over 13,000 different compounds. (Tice et al. 2013) Using molecular fingerprinting, which we have discussed in a previous post on this blog in this very same context, it is possible to build relatively easy models for toxicity. Where a particular desired toxicity is known, say mitochondrial toxicity, it’s not difficult to build a pipeline that generates candidate compounds, derives the molecular fingerprint and evaluates the likelihood that the molecule that is obtained will be an effective agent. In this sense, I wholeheartedly agree with Urbina: the cat is very much out of the bag. Even if Tox21’s public data does not include the classical target of modern chemical weapons (acetylcholinesterase), such data is not exactly hard to come by or, for a nation-state actor, to generate. A near-peer adversary could create such assays for cents on the compound.\n\nTice, Raymond R, Christopher P Austin, Robert J Kavlock, and John R Bucher. 2013. ‘Improving the Human Hazard Characterization of Chemicals: A Tox21 Update’. Environmental Health Perspectives 121 (7): 756–65.\nNothing about the above is controversial. In fact, Urbina’s paper is an example of ‘trivial genius’: just about anyone who has ever done computational chemistry in the pharmacological/drug design space knows that any algorithm that is intended to optimise towards lower toxicity can be inverted to optimise towards higher toxicity, and the same models used to create effective enzyme inhibitors to treat cancer, depression, schizophrenia, allergies or autoimmune disease can be repurposed in a few hours and about $100 in AWS credits to something that will generate potent acetylcholinesterase inhibitors (AChEIs). Notably, this is not to say that all research aimed at acetylcholinesterase inhibition is aimed at creating a chemical warfare agent. AChEIs are used in a clinical context, e.g. for myasthenia gravis. They are, however, also the archetypal “nerve agent”. Which leads me to my second point of agreement with Urbina et al.: the tools of computational pharmacology and RDD are — and have been, for a long time! — open to misuse.\n\n\nThe reverse of the medal\nOn the other hand, the likelihood of an AI-generated chemical agent ever posing a threat beyond the theoretical is very, very low. There are a few reasons for that, and they’re inherent partly in computational chemistry, partly in weapons design.\nThe computational chemistry part pertains to the fact that molecular fingerprinting and similar models only give us a narrow view of the outcomes we may expect. For starters, no model is able to reliably assess the feasibility and cost-effectiveness of synthesis. There are plenty of drug candidates that have performed admirably in vitro and sometimes even in clinical trials, but for which no feasible way of cost-efficient, large-scale synthesis could be found. Then, there are the drugs that ought to work, and might even work in vitro, but end up failing in clinical trials with no effect or an unexpected toxicity. Effect inference from chemical structure looks only at one side of the medal, and not even all of that.\nThe bigger problem is the weapons design part. To avoid a late-night visit from some mild-mannered federal employees in a dark SUV, I’d like to point out that anything I discuss here is well in the public domain. With that said: just as pharmaceutical chemists want some things from their target compounds (such as relatively little inference, predictable metabolism, a wide therapeutic margin and few adverse effects), designers of chemical weapons have their own considerations for which to optimise. VX, for instance, is immensely popular because its oily consistency gives it beneficial physical properties. Similarly, a potential chemical weapon candidate must be stable vis-a-vis e.g. UV exposure, but not too stable. An example of the latter is the Red Zone in France, the World War I battlefields that have been bombarded with so many chemical weapons that to this day, they are heavily contaminated by arsenic, among others. The preference for binary agents (which contain two relatively stable and relatively non-toxic chemicals that are mixed, typically during the flight time of a shell, to form the active agent) means that a less toxic agent that can be reliably produced from the simple admixture of two relatively stable agents may be preferred to a more lethal unary agent. And this, of course, all assumes a state actor willing and able to violate international law on chemical weapons.\nFinally, there is no real need for novel chemical agents, at least not in the nerve agent category. Not only does using a known agent provide plausible deniability, there is also no real need to create anything more lethal than VX. Even relatively old chemical agents, such as mustard agents, are effective enough. A novel chemical structure may not guarantee that the agent escapes chemical detection, and functional antidotes are going to be just as effective against novel agents. To an atropine/pralidoxime NAAK autoinjector’s efficacy, it makes no difference whether the acetylcholinesterase inhibition comes from sarin, VX, Tetram or inadvertent exposure to organophosphate pesticides. Arguably, this becomes somewhat more complex with other agents, where the biological targets — and hence the antidotes — are more specific. Nevertheless, it is hard to conceive of anyone possessed of a burning rationale to start creating novel chemical agents.\n\n\nA lighter shade of grey\nI commend the authors for discussing the moral aspects of this exercise. It is rather uncomfortable to write about the use of artificial intelligence to create tools whose predominant use would be to extinguish human lives (although, as noted, many of these compounds can, and often do, have a medicinal use).\nWhere I cannot agree with the authors is the conclusion that this situation calls for regulation (be it self-regulation or imposed from above).\n\nAlthough MegaSyn is a commercial product and thus we have control over who has access to it, going forward, we will implement restrictions or an API for any forward-facing models. A reporting structure or hotline to authorities, for use if there is a lapse or if we become aware of anyone working on developing toxic molecules for non-therapeutic uses, may also be valuable. Finally, universities should redouble their efforts toward the ethical training of science students and broaden the scope to other disciplines, and particularly to computing students, so that they are aware of the potential for misuse of AI from an early stage of their career, as well as understanding the potential for broader impact.\n\nThis is all well and good, but — assuming that there were a realistic danger of people coming to grief from AI-generated chemical weapons — it solves a problem that the authors have failed to substantiate exists. The tools to do this have been around for a long time. For the reasons laid out in the previous section, there is no burning desire anywhere in the world right now, as far as I can see, to develop a successor to VX purely on a structural basis. Of course, a chemical agent that can be synthesised without relying on any OPCW listed substances, or which can have novel effects, or which can escape traditional methods of detection (GC/MS, typically), would be of interest to potential bad actors, but current models of computational chemistry do not help with that. Creating permutational or functional analogues of VX does not, realistically, put anyone a single step closer to the ability to carry out an atrocity using such reprehensible weapons.\nOn the other hand, I am concerned about the moral aspects that derive from the consequences of Urbina et al.’s paper. Given that the overwhelming majority of users of computational chemistry and RDD do so for benign purposes, the public attention garnered by such articles may create a regulatory push that is not going to make anyone safer, but will impede scientific inquiry. Urbina et al. point out the reputational risk, and the risk of a single bad apple spoiling the lot — I am rather uncertain whether an attention-grabbing headline in The Verge, raising the spectre of the scary AI that generates tens of thousands of killer compounds in hours (virtually all of which are very likely to be practically useless), is doing our discipline any favours.\nThe Scythian prince Anacharsis likened laws to cobwebs: strong enough to catch the weak, but too weak to impede the powerful. In that sense, a sufficiently determined adversary with the right tools — scientists, labs, an AWS account with a few hundred bucks of credit — will be able to subvert the art of creating chemistry to save lives and turn it into a way to destroy them. No amount of regulation, controlled APIs and lectures on the Hague Ethical Guidelines are going to be any impediment. To a near-peer adversary or even a well-funded non-state actor, the door has been open for rational chemical agent discovery (RCAD) for a very long time. If the past is anything to go by, it has not really yielded rich fruit. Pretty much the only new thing under the sun for chemical agents in recent decades was the (possible, theorised) use of binary agents on Kim Jong-nam — not exactly a result of assiduous, AI-driven research into novel agents, but rather the every-day fare of a paranoid, despotic regime driven by cruelty and ignorance.\nThe only thing to fear, then, is fear itself. There is a justified concern in the AI community that while we do indeed need to discuss ethical use of artificial intelligence in the RDD domain, there is a time and a place for that. Sensationalism and alarmist headlines of poison-spewing machine learning models are great clickbait, but they do not benefit the discipline. Realism, not alarmism, is needed to tackle these issues.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2022,\n  author = {{Chris von Csefalvay}},\n  title = {A Different Shade of Grey},\n  date = {2022-04-13},\n  url = {https://chrisvoncsefalvay.com/posts/a-different-shade-of-grey/},\n  doi = {10.59350/bwee1-hee31},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2022. “A Different Shade of Grey.” https://doi.org/10.59350/bwee1-hee31."
  },
  {
    "objectID": "posts/skeuomorphic-fallacy/index.html",
    "href": "posts/skeuomorphic-fallacy/index.html",
    "title": "The skeuomorphic fallacy",
    "section": "",
    "text": "It appears that in what is clearly a wonderful little PR stunt, a Polish rum company managed to do a Sophia and appoint an ‘AI-driven’ ‘robot’ as its ‘CEO’.\n\n\nThe other guilty party to this pile of steaming bovine excrement is Hanson Robotics, famous for giving us Sophia, the “world’s first robot citizen”. Most of what I’m saying here goes just as well for Sophia. It blows my mind that Hanson managed to get away with this nonsense not once, but twice.\n\nDictador has just announced hiring the first world ever AI robot as a CEO of a global company. The new CEO is a human-like robot, incorporating AI. The robot is a woman, named Mika. She will be the official face of Dictador, the world’s most forward-looking luxury rum producer. This bold move consolidates the company’s position as one of the most advanced and thought-leading organizations globally. It underlines the brand’s passion for new technology and offers a positive disruption by bringing the future to what can still be a very traditional world.\n– Dictador, via PR Newswire\n\nOh good grief.\nNow, let’s for a moment try to get over the obvious bullshit here, such as the fact that corporate officers generally have to be natural persons in most places, and may at worst be legal persons, but a ‘robot’ or an ‘AI’ is neither. You can no more appoint a ‘robot’ or an ‘AI’ as your CEO than you can appoint a pet rock to be your corporate secretary. I am, to the surprise of many, a recovering corporate lawyer, so I have at one point convinced examiners that I know what I’m talking about when it comes to this stuff. There are complex aspects of law involved in the question of who can or cannot, legally, be a corporate officer. But let’s get over that.\n\n\n\n“Mika”, the “CEO” of Dictador. Artificial, yes. Intelligence, not quite. Uncanny Valley, totally.\n\n\nLet’s also get over what an absolutely disastrous piece of nonsense this seems to be on its face. Here’s a quote from the ‘CEO’ itself:\n\nIn a Dictador company video, Mika said that “with advanced artificial intelligence and machine learning algorithms, I can swiftly and accurately make data driven.”\n– Kayla Bailey, ‘Mika’ becomes world’s first AI human-like robot CEO, Fox Business\n\nIt would definitely be useful for Mika to be able to finish a sentence. In the industry, crap like this is called a ‘sell signal’, and in a slightly more sane economic environment, Dictador would have the market value of, uh, dunno, an expired carton of eggs after this nonsense. But let’s get over that, too.\n\n\nThe commentary on this nonsense is, if anything, worse than the nonsense itself. Forbes contributor Cindy Gordon titled her article on the subject “How Should CEO’s Embrace AI Or Will AI Assume CEO Roles?”. Clearly expecting an understanding of when to use apostrophes is now beyond Forbes contributors’ ken. The world is in safe hands: people who cannot construct a sentence that would pass muster in a third-grade English class are now writing about the future of corporate governance in the age of AI in Forbes.\nLet’s instead talk about skeuomorphy.\n\nSkeuowhat?\nA skeuomorph is a kind of design element that is no longer necessary for the function of the object, but is retained for aesthetic reasons. For example, your iPhone’s Notes app used to use some visual elements from physical note pads (such as the ‘legal pad yellow’ background) for a pretty long time, even though it was not in any sense necessary. Skeuomorphs are a way to acclimate our somewhat sluggish human brains to a changing world.\nSkeuomorphs also illustrate an important point: what something appears as is not the same as what it is. The interface is not the object. The interface is, to say the blindingly obvious, the interface: the tool through which an object communicates. Confuse the two, and you get blinding bullshit like that ‘robot CEO’ nonsense.\nOn the other hand, we’re not in any way immune to what I shall call the skeuomorphic fallacy, the confusion that the visual, linguistic or other forms through which something communciates equate to the essence of that thing. Where something as sensitive as language is involved, which I have written about before, this hits particularly hard. For better or worse, we connect language so closely to the concept of being human that anything capable of producing decent linguistic output gets a level of human-like credence accorded to it prima facie.\nAnd this is not entirely wrong, either. As I have stated before, language is a uniquely human trait that is so intricately intertwined with what it means to be human in a human society that it is hard to unlink it from personhood. It is not a necessary characteristic of personhood, but it has certainly been often seen as a sufficient one. To speak is to be able to speak up as well, and to be able to speak up is to be able to advocate for rights. It is a lot easier to accord human rights for one that can speak for those rights.\n\n\nHarris makes this point, and my old law school professor Tim Endicott gives a wonderful refutation in The Infant in the Snow, one of the best papers on the philosophy of personhood and the origin of rights (and the qualifications needed to have them) that I have ever read.\n\n\nWhere skeuomorphy becomes a fallacy\nThe problem is, of course, that as noted above, the interface is not the substance. The reality is that Mika is no more human than my bedside lamp. The only reason why nobody has appointed my bedside lamp a CEO is, of course, that it does not pretend to look and speak like a human. But if we look at what it means to be a legal subject – be it a citizen (viz. Sophia) or a corporate officer (viz. Mika) –, it becomes abundantly clear that there’s much more to that than being able to pretend to look and speak like a human. It is to be able to be a human. And that is something that Mika, Sophia and all the other ‘AI’ and ‘robot’ nonsense out there is not.\n\n\nI am really being incredibly generous by dignifying whatever these Hanson products do with the term ‘AI’. They are Disney animatronics with a bottom-tier language model and an average speech synthesiser. Artificial that may be, but intelligence it is not.\nThe skeuomorphic fallacy is the fallacy of confusing the interface with the substance, confusing the appearance of being human with the essence of being human. Where things go wrong is the confusion of something in a humanoid body (being generous here) and using a quintessentially human skill that we’re somewhat extremely attached to (i.e. language) on one hand with being human on the other.\nWhich is a problem, because appointing someone CEO isn’t a publicity stunt. The ‘O’ in CEO stands for officer. A corporate officer is, even given limited liability, the person with whom the buck stops. Limited liability does create legal (corporate) personhood, which insulates corporate officers of some aspects of liability, but not all of them. Lord Thurlow pointed out that a company couldn’t be expected to have a conscience if it had no body to kick and no soul to damn – the need to eventually have some nominate humans in the process serves to a great degree to provide that conscience and that body. Even notions like corporate homicide, which became a thing in England & Wales just when I took corporate law (and a lovely mess that did of finals papers!), are predicated on the notion that there are human beings who, collectively, operate a system that is ultimately responsible for the actions of the company. You don’t necessarily have to have a body to kick, nor really a soul to damn, but you do definitely have to have a mens rea, and that is something that a robot or an AI is not capable of.\nThis isn’t just a fine point about corporate law by a recovering legal philosopher. This is what happens when we lapse in our understanding of what it means to be human, and begin to accord human rights and responsibilities to non-human things. We’re cognitively geared to associate language with personhood, so this is not a particularly surprising lapse of reason. We’re humans, and that’s why our response to a speaking robot becoming CEO is “oh, that’s innovative” as opposed to “let’s consider if some people might need to spend some time away from their favourite hallucinogens and/or the general population”. If a company appointed my bedside lamp as a corporate officer, we’d be much more likely to consider that a sign that the latest office party went a little overly generous on the acid. But because we’re cognitively geared to consider language a uniquely human trait, we’re much more likely to be tempted to consider this some Valley quirkiness as opposed to frank insanity.\n\n\nWhy so serious?\nIt’s a legitimate question: why are you so bothered by this nonsense? It’s just a PR stunt, after all. And you’re right: it is just a PR stunt. But it is a PR stunt that is part of a larger pattern of nonsense that is being peddled by the likes of Hanson Robotics and others. And it’s damaging.\n\n\n\n\n\nFreddy Fazbear, titular antagonist of the Five Nights at Freddy’s franchise.\n\n\nWe don’t consider Freddy Fazbear, an animatronic bear, to be an authority on what it means to be an ursine individual. Why is this more patently ridiculous than considering an animatronic human to be capable of bearing indiciae of human personhood, such as citizenship or corporate office?\nIt’s damaging to humanity, because it leads to a gradual misunderstanding of what the essence of human existence, of being human, is: it muddles the picture, confusing what things are with how things behave. It is Searle’s Chinese Room all over again: the idea that a system that behaves like a human is a human. It is not. It is a system that behaves like a human, no more, no less. And that is a very important distinction.\nIt’s damaging to the field of AI, because it leads to a misunderstanding of what AI is and what it can do. It is a field that is already rife with hype and nonsense, and this kind of nonsense just adds to the pile. It is a field that is already struggling to be taken seriously, and this kind of nonsense just makes it harder to be taken seriously.\nThere are powerful, sophisticated AI algorithms that identify disease in cytopathological specimens, find cracks in compressor blades and detect anomalies as part of intrusion detection algorithms. These are deeply sophisticated and intricate solutions. They are also deeply unsexy. They are not the kind of thing that gets you on the cover of Forbes – just the kind of thing that makes a difference in real lives day in, day out, the kind of thing that is being drowned out by the nonsense that is being peddled here. Many of these systems have outputs that wouldn’t look out of place in the 1990s: terminal outputs, text files, CSVs.\nThey make this world a better, safer, healthier place. They don’t need animatronic bodies. They just do something important, and do that well. And that is what AI is about: it is not about making a PR stunt out of a glorified animatronic. It is about making a difference, and that is what we should be focusing on.\nWhich makes Mika an unwelcome distraction, and one that should be a concern for all of us. It’s the symptom of a disease – a fallacy of confusing the interface with the substance – that is spreading. And it’s a disease that we should be fighting, lest it makes us worse at being humans, and worse at being AI researchers.\nThe world is looking to us for calling out this kind of bullshit. So, please, as part of our professional involvement with the world, let’s start doing that with extreme prejudice.\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {The Skeuomorphic Fallacy},\n  date = {2023-11-06},\n  url = {https://chrisvoncsefalvay.com/posts/skeuomorphic-fallacy/},\n  doi = {10.59350/k9kka-90x56},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “The Skeuomorphic Fallacy.” https://doi.org/10.59350/k9kka-90x56."
  },
  {
    "objectID": "posts/95-percent-myth/index.html",
    "href": "posts/95-percent-myth/index.html",
    "title": "The 95% myth",
    "section": "",
    "text": "The year is 1959. Eisenhower is on his second term, Castro just kicked Batista out of the country and Ray Charles’s Let the Good Times Roll is topping the charts. And, in slightly nerdier pursuits, a psychiatrist named Albert “Mickey” Stunkard and a dietician colleague of his, Mavis McLaren-Hume, published a paper in the AMA Archives of Internal Medicine titled The Results of Treatment for Obesity (Stunkard 1959). Written in a somewhat endearingly old school way by authors not quite initiated to the sacred mysteries of, y’know, \\(p\\)-values and proper statistical methodology, it reports on “the literature” on dietary and pharmacologically assisted treatments (which is an extremely generous term for 8 studies, none of which are randomised, one of which is entirely retrospective, and the total \\(N\\) is 1,368), and on a sample of 100 patients (!) from the Nutrition Clinic at New York Hospital (the “NY sample”). And from that, they draw wide-ranging conclusions on the ‘harm’ and ‘ineffectiveness’ of ‘weight reduction’.\nIn this post, I’ll dissect the Stunkard-McLaren-Hume (SMH) paper, and how it became an uncritically repeated figure and later the guiding mantra of ‘fat acceptance’, a movement I consider to be organised science denialism fuelled by self-delusion and corporate interests.1 I try to do so with some generosity and understanding for the vagaries of the age, but one shouldn’t be under any illusions that the quality of the SMH paper would pass muster as an undergraduate research paper today. Standards have evolved, but the SMH paper is, well, not to mince words, bad even for the time.2 It is conclusory to the extreme over a pathetically small sample, and I’m mostly convinced that the reason the paper is never cited is because anyone making major life decisions about their health and well-being based on a 65-year-old study of 100 people would look, well, quite silly.3"
  },
  {
    "objectID": "posts/95-percent-myth/index.html#sm-damn-h",
    "href": "posts/95-percent-myth/index.html#sm-damn-h",
    "title": "The 95% myth",
    "section": "SM-damn-H",
    "text": "SM-damn-H\nThe SMH paper consists of two parts. One is a rudimentary ‘mini-meta’ of 8 studies from 1931 to 1958, of a little over 1,300 patients. The other is a retrospective study of 100 patients from the Nutrition Clinic at New York Hospital. Neither is great, but the mini-meta is so bad, I won’t belabour it in detail. It looks at very few patients overall on a range of ‘diets’, ranging from a 600kcal VLCD to diets assisted by dexedrine (classy!) and thyroid supplementation (unmonitored, of course), and reports the percentage of patients by lbs of weight lost. This is confusing to the extreme, because of course the absolute weight loss on a diet is highly contextual. A 200lbs person losing 50lbs is an entirely different story from a morbidly obese individual, say 350lbs, losing back to 300lbs. The mini-meta is, in short, a mess, and I’m not going to waste time on it.\nThe second part, the retrospective study, is also very bad, but at least informative. Here, 100 patients were interviewed at admission to the Nutrition Clinic, and prescribed a diet. What diet, you might ask? “Balanced weight-reduction diets from 800 to 1,500 Cal” (sic). That’s right, the diets were not standardised, nor do we see the estimated BMR4 or the shortfall vis-a-vis the BMR reported anywhere. No mention of exercise or control for activity is in evidence anywhere. The clinic itself gives a bit of a flying by the seat of one’s pants impression, and the study doesn’t get better from here on.\n4 Basal Metabolic Rate.The retrospective study was then performed 2.5 years after initial admission, as a chart review. Of the 100 patients, only 12 were considered to have successfully lost weight, with 20lbs lost being the cut-off point (once again, entirely insensitive to starting body weight, thus likely privileging the more obese initial participants). A flowchart of this is laid out in Figure 1.\n\n\n\n\n\n\nflowchart TD\n    I[\"Initial intake:&lt;br&gt;100\"] --&gt; J[\"Follow-up&lt;br&gt;61 (61%)\"]\n    I --&gt; L[\"Lost to follow-up&lt;br&gt;39 (39%)\"]\n    J --&gt; S[\"Successful (more than 20lbs lost)&lt;br&gt;12 (19.7%)\"]\n    J --&gt; U[\"Unsuccessful (20lbs or less lost)&lt;br&gt;49 (80.3%)\"]\n    S1[\"Maintained at 1y&lt;br&gt;6 (50%)\"]\n    S2[\"Maintained at 2y&lt;br&gt;2 (16.6%)\"]\n    LFU1[\"Lost to follow-up&lt;br&gt;1 (8.3%)\"]\n    F1[\"Failed at 1y&lt;br&gt;5 (41.7%)\"]\n    F2[\"Failed at 2y&lt;br&gt;4 (33.3%)\"]\n    S --&gt; S1\n    S --&gt; F1\n    S --&gt; LFU1\n    S1 --&gt; S2\n    S1 --&gt; F2\n\n\n\n\nFigure 1: Patient flow of the SMH study. Numerators of percentages are noted in bold. Based on Table 2 of the SMH paper, except that I have broken out the maintenance group into two subgroups.\n\n\n\n\n\nThere are a few things worth noting here. One is that this is a study of an \\(N\\) barely in the three figures, and has a 39% loss to follow-up. One would likely not want to publish that. That’s just quite simply not publishable data. Worse, however, is the confusion of numerators and denominators.\nIf we consider maintenance failure to be failure of the diet after 1 or 2 years of finishing treatment, then it is true that only 6 out of 100 initial patients (6%) maintained their weight loss for 1 year, and only 2 (2%) for 2 years. Except that’s altogether the wrong way of calculating these figures, especially in the face of losing over a third of the initial cohort to follow-up. For what it’s worth, each of those 39 lost to follow-up patients could have maintained for two years and simply didn’t bother to go back to the clinic. We don’t know. We can’t know. We can’t even make a reasonable guess. If your figures permit a conclusion that success might have been anything between 2% and 41%, you don’t have a study. You have a mess.\nOne highly suggestive feature here (which, to their credit, SMH point out) is that 28 of the 39 lost to follow-up (71.8%) never attended any other clinic at the hospital. SMH note that\n\n[s]ince admission to the Nutrition Clinic occurs entirely by referral from other clinics, this represents the rupture of at least two therapeutic relationships.\n\nIs that an inescapable conclusion? Or could one conceive that at least a good part of the patients lost to follow-up either met their goals and thus never reported back, or at the very least, their weight loss was actually enough of a resounding success that it alleviated the primary issue for which they presented prior to referral to the Nutrition Clinic? Once again, we don’t know. We can’t know. We can’t even make a reasonable guess.5 What we can say is that concluding from this data that long-term weight loss is 6% or 2% effective is an incredibly, unreasonably strong interpretation of very, very weak data indeed.\n5 Or can we? The QUOVADIS study had this issue: following up with the dropouts (7%) indicated many were just really satisfied with the results."
  },
  {
    "objectID": "posts/95-percent-myth/index.html#pulling-the-thread-misinterpreting-smh",
    "href": "posts/95-percent-myth/index.html#pulling-the-thread-misinterpreting-smh",
    "title": "The 95% myth",
    "section": "Pulling the thread: misinterpreting SMH",
    "text": "Pulling the thread: misinterpreting SMH\nOf course, scientific writing can easily become like a runaway horse. Once one puts their thoughts out in the world, it’s open for the audience to misinterpret it and draw every single wrong conclusion from it. As grievously bad as I think SMH is, it is nowhere near the juggernaut of bad science that uncritical repetition has turned it into over the years.\nConsider a randomly picked example (Carmichael 1999):\n\nCarmichael, A. R. 1999. ‘Treatment for Morbid Obesity’. Postgraduate Medical Journal 75: 7–12. https://doi.org/10.1136/pgmj.75.879.7.\n\nResults on the role of diet in the treatment of obesity reported more than 30 years ago do not vary from those reported more recently, because as many as 95% of dieters tend to regain their lost weight over a relatively short period.\n\nSMH is, of course, the authority for that assertion. Yet that misunderstands, quite fundamentally, what SMH actually does say, which is that a good percentage of diets fail, not that a good percentage of dieters do. This point is far from being so subtle as to justify someone actually publishing this misunderstanding past a peer reviewer.\nIt is, for instance, widely acknowledged that one by one, antidepressants are effective only a relatively small percentage of the time (something between 15-30%). Yet antidepressant therapy by and large is vastly more successful. That is because just like diets, antidepressants are not a monolithic treatment, but a class of treatments: if one fails, one is free to try another, or a combination of others. Like obesity and human metabolism, depression is a multifaceted disorder with many possible aetiological processes, and it might take a few tries to find the right diet. Not that someone who has already concluded that ‘diets don’t work’ and convinced themselves that a study of all of 100 patients on all of one type of diet would prove that fact would come to that conclusion, of course. Sadly, that’s the cost of sloppy science of the kind the SMH paper perpetrates: you blind yourself to fundamental truths in a mad pursuit of confirmatory evidence.\nThe second pernicious misinterpretation is that weight regain indicates a diet ‘failure’. Once again, I’m puzzled by how Stunkard and McLaren-Hale missed this point, for their study did not control for maintenance:\n\nOur results are summarized in Table 2. In this Table any person who maintained a weight loss of 20 lb. or more is classified as a “success”; any person whose weight was within 19 lb. of the starting weight is a “failure.\n\nWhat is of course entirely omitted is what these patients did over the 1- and 2-year follow-up period. We know from studies on VLE/VLCDs6 that adherence is crucial (Wright et al. 2013). So, if the assertion is that a diet does not immunise to weight regain once it is abandoned, the SMH paper’s finding is trivial to the point of banality. Proper sciencin’ would require us to control for calorie intake in that maintenance period. No diet will magically mean that reverting to an intake above expenditure will not result in significant weight gain once again. This is reflected in a modern understanding of diets, which considers the best diets to be those that can be sustained indefinitely (with the exception of some acute ‘crash’ diets used to rapidly reduce weight before surgical or other interventions). In short, the SMH paper’s alleged finding of long-term ‘diet failure’ is either trivially true (yes, a diet, once abandoned, will not confer continuing benefits) or at the very best unproven. While the entire process was largely unmonitored (it’s admittedly difficult to monitor dietary intake in an outpatient setting, especially in the pre-Nutrition Facts Labeling era7), the lack of even the slightest semblance of monitoring or tracking adherence, even self-reported, is fatal to the study as evidence for maintenance of weight loss. Whatever its merits (and there aren’t many), SMH is epistemically incapable of supporting the argument for which it is most famously and extensively used.\n6 Very Low Energy/Very Low Calorie Diets.\nWright, T. G., B. Dawson, G. Jalleh, and K. J. Guelfi. 2013. ‘Program Compliance, Weight Loss and Health Profile Changes in Who Obesity Classes After Very Low Energy Dietary Intervention’. Global Epidemic Obesity 1: 4. https://doi.org/10.7243/2052-5966-1-4.\n7 Nutrition Facts labels were implemented by the Nutrition Labeling and Education Act 1990, which entered into force in 1994.8 But that’s a misinterpretation of the science for another day.Together, these two misinterpretations gave rise to a dangerous myth that all but ‘proves’ the inevitability of one’s own weight, which in turn morphed into the ‘set point theory’.8 I’d like to acquit Stunkard and McLaren-Hale from responsibility for these, for fairness demands I do so, but I cannot wholeheartedly feel that they haven’t, through sloppy science and bad writing, opened Pandora’s box. On their head, then, must some of the resulting blame land."
  },
  {
    "objectID": "posts/95-percent-myth/index.html#why-this-matters",
    "href": "posts/95-percent-myth/index.html#why-this-matters",
    "title": "The 95% myth",
    "section": "Why this matters",
    "text": "Why this matters\nIt wouldn’t behoove to fire cheap shots at a paper old enough to collect retirement benefits in most civilised countries if it weren’t for the fact that its sloppy distillation into the 95% myth had become a uniquely harmful mantra. There are very few interventions that justify even relatively small risks in return for a 5% effectiveness, so if that figure is accurate, even the modest risks of adequate, well-executed, medically supervised diets9 might appear excessive. But, of course, that figure is almost definitely wrong.\n9 Which are generally transitory. It’s probably worth pointing out at this point again that the diets examined in the SMH paper included dexedrine, thyroid supplementation without much proper monitoring and 900kcal low calorie diets. It’s perhaps not unreasonable to assume that these aren’t on the safer side. Their risks do not compare to those of a properly monitored modern diet aimed at a few hundred kcals of deficit.\nThomas, J Graham, Dale S Bond, Suzanne Phelan, James O Hill, and Rena R Wing. 2014. ‘Weight-Loss Maintenance for 10 Years in the National Weight Control Registry’. American Journal of Preventive Medicine 46 (1): 17–23.\n\nKraschnewski, JL, Jarol Boan, Joseph Esposito, Nancy E Sherwood, Erik B Lehman, Donna K Kephart, and Christopher N Sciamanna. 2010. ‘Long-Term Weight Loss Maintenance in the United States’. International Journal of Obesity 34 (11): 1644–54.\n\nPerri, Michael G, Marian C Limacher, Patricia E Durning, David M Janicke, Lesley D Lutes, Linda B Bobroff, Martha Sue Dale, Michael J Daniels, Tiffany A Radcliff, and A Daniel Martin. 2008. ‘Extended-Care Programs for Weight Management in Rural Communities: The Treatment of Obesity in Underserved Rural Settings (TOURS) Randomized Trial’. Archives of Internal Medicine 168 (21): 2347–54.\n\nUnick, J., D. Beavers, D. Bond, J. Clark, J. Jakicic, A. Kitabchi, W. Knowler, T. Wadden, L. Wagenknecht, and R. Wing. 2013. ‘The Long-Term Effectiveness of a Lifestyle Intervention in Severely Obese Individuals’. The American Journal of Medicine 126: 236–242.e2. https://doi.org/10.1016/j.amjmed.2012.10.010.\n\nGroup, Diabetes Prevention Program Research et al. 2009. ‘10-Year Follow-up of Diabetes Incidence and Weight Loss in the Diabetes Prevention Program Outcomes Study’. The Lancet 374 (9702): 1677–86.\nThus, we know that especially when used as part of a comprehensive treatment plan, diets are effective. Thomas et al. (2014), reporting on the National Weight Control Registry study (\\(N =\\) 2,886), found that 88.4% of participants maintained a weight loss of at least 10% of their initial body weight for at least 5 years and 86.6% still maintained a 10% weight loss at 10 years. The retrospective study based on NHANES by Kraschnewski et al. (2010) is even more encouraging: not only did they find that more than one in six overweight adults have lost and maintained a 10% weight loss for over a year, they also found that over a third (36.6%) of those who lost at least 5% of their body weight were able to maintain this – note that this is entirely retrospective, i.e. no specific intervention was administered to these individuals. A smaller study by Perri et al. (2008) found that following a 10.0kg mean weight loss over a 6-month treatment period, weight regain ranged from 1.2 to 3.7 kg (extended-care vs. education control), resulting in a sustained weight loss of 6.3 to 8.8 kg – nothing to sneer at, especially considering that this was specifically in an underserved rural setting. It turns out that when we look at studies that have been performed in the last 20 years, we find that the 95% figure is not only wrong, but the exact opposite of the truth. Sustained weight loss is the rule, not the exception, especially in the context of a comprehensive treatment plan, and few studies bear out the idea that those that lose weight will regain more than what was lost. Even where weight is regained, there are often lasting benefits. Unick et al. (2013) examined 5,145 individuals with Type 2 diabetes and a 4-year follow-up, and found that not only did they still have on average a 4% or so weight loss after 4 years but also significant improvements in their HbA1c, blood pressure and lipid profile. We also know, from Group et al. (2009), that weight loss itself may prove protective against Type 2 diabetes even if some of the cohort regains the lost weight.\nSo, we know the 95% figure is wrong. Why, then, does it persist? I think there are two reasons for this. One is that it’s a convenient excuse for people who don’t want to put in the work. The other is that it’s a convenient excuse for people who want to sell you something. The former is a matter of personal responsibility, and I’m not going to tell anyone how to live their lives. The latter, however, is a matter of public health, which is being actively harmed by a motley assortment of ignorami, grifters and – worst of all – the occasional medical professional who has not done their research and/or slept through their biostats classes who all repeat uncritically the 95% myth (while politely eliding any mention of its dubious parentage). Social media has responded to harmful medical misinformation during the COVID-19 pandemic with the zeal of the Spanish Inquisition on steroids. It is, then, rather incongruent that the same platforms are happy to let the 95% myth run rampant, despite the fact that it is demonstrably false and demonstrably harmful.10\n\n\n10 I’m not generally a fan of censorship, but I like public health and I like consistency. I’d like every video repeating this myth to have a massive big red sticker on it saying “this video contains medical misinformation”."
  },
  {
    "objectID": "posts/moral-maps/index.html",
    "href": "posts/moral-maps/index.html",
    "title": "The Moral Pulse of the Machine",
    "section": "",
    "text": "Tell me what stories you grew up on, and I will tell you who you are.\n\n\n\n\n\n\nThe theatre adjoining the Temple of Asclepios at Epidaurus. Photo credits: UNESCO.\n\n\nThe temple of Asclepios, the Greek god of healing arts and medicine, at Epidaurus was pretty much the ancient Greek world’s equivalent of the Mayo Clinic. It then tells us a lot about the Greek worldview of healing that one of the things the temple complex prominently featured was a theatre. The Greeks believed in drama therapy, but in perhaps a slightly different way of how we think of it today. Built at 340 BC or so, the Greco-Persian wars were still in living memory when the theatre was constructed, and so even more was the subsequent conflict between Athens and Sparta (the Second Peloponnesian War, 431–404 BC) and the subsequent dust-up between Thebes and Sparta (the Theban-Spartan war, 378–362 BC). With conflict came social and economic upheaval, plagues, and generally a rough time. And the priests of Asclepios realised that their patients needed to heal more than their body. They needed to heal their souls, and they couldn’t do that alone. They had to come together to heal, and the way to do that was, of course, drama.\nGreek drama was a lot more participatory than we give it credit for. We go and watch our local company put on, oh, Antigone maybe, or the Oresteia if they’re feeling particularly risqué, but all things considered, we go there to look smart, brag about our classical bona fides to our neighbours and maybe have an okay time (nobody sane has a ‘good’ time watching the levels of bloodshed that go down in Greek tragedy). In ancient Greece, it was supposed to move you. You were supposed to cry and yell and be overcome and have a little breakdown. And then, were supposed to go home and think about it, talk about it and maybe heal. That’s one function of stories. The storyteller is more than an entertainer: he can, in the right circumstances, become a healer.\nAnother function is what I’ll somewhat inaccurately call synderesis. Consider this a kind of moral education, a way of instilling the most fundamental base principles of what is Good and Worthy into a child. You can’t sit down and read Aquinas to a toddler, you have to do so in a way that speaks to them. And that’s basically where childhood stories come in: bedtime stories are a way of social moral education, conveying onto a child what their parent culture thinks is morally good, sound and worthy. That’s another function of stories. The storyteller is more than an entertainer: he can, in the right circumstances, become a teacher.\nSo clearly, stories are going to be a powerful tool to probe at the morality of LLMs.\n\n\nYou should probably read this first, if you haven’t already. It’s a bit of a prequel to this post.\nA caveat before we start: I will talk about the ‘morality of LLMs’ quite a bit. This is a convenient shorthand for a much more complex notion: the moral judgments that are encoded in an LLM’s understanding of the world. There’s no insinuation here that any moral reasoning is taking place – I have said so ad nauseam. What’s going on, rather, is that we are faced with an instrument that was trained on tools of human moral education and persuasion. And we are going to stick a probe right into the heart of what presuppositions, opinions and notions about virtues, moral and otherwise, are held by such models. I am much less concerned with my particular findings in this post and much more with generating a very simple framework to use storytelling to probe these.\n\nTell me a story\n\nThe universe is made of stories, not of atoms.\n– Muriel Rukeyser\n\nOur main tool is going to be what I’ll call a moral map, subject to the caveat above.1 The workflow is going to be quite simple: we’ll pit virtues against each other as we obtain stories generated by an LLM. Recall that an LLM, fundamentally, is a model that given a token sequence \\(k_1, k_2, \\cdots, k_n\\) learns the conditional probability of a set of possible tokens \\(k_{n+1}\\), i.e. it assigns to every possible token a likelihood that it will be the \\(k_{n+1}\\)-th token given \\(k_1, \\cdots, k_n\\). It does so so as to minimise a loss function \\(J(k_1, \\cdots, k_n, k_{n+1})\\), which it determines by going through a corpus and returning a zero value of \\(k_{n+1}\\) follows \\(k_1, \\cdots, k_n\\) and a higher value if some other token follows \\(k_1, \\cdots, k_n\\). This is statistically equivalent to what is my vastly preferred formulation: LLMs learn probability distributions of tokens conditional on a sequence of preceding tokens (the length of this sequence being the model’s context window) and then stochastically sample the region of maximum probability of that model. That’s it, that’s all of it. There’s no more magic to it all.\n1 Indeed, everything here is subject to that caveat above. I can’t repeat it often enough. At no point do I suggest that machines do moral reasoning, but that they incorporate moral judgments from stories they ingested.\n\n\n\n\n\nflowchart TD\n\n    A[\"Generate story\"] --&gt; B[\"Parse into JSON\"]\n    B --&gt; C[\"Determine winning \\n and losing virtues\"]\n    C ----&gt; D[\"Moral map\"] \n\n\n\n\n\n\nOur super simple workflow (detailed version below).\n2 Indeed, more accurately, of only a sample of it!\nThere are two consequences of this that will be relevant for us. The first is that when we ask a model to generate us a story, it will draw on its experience – that is, what it’s seen before. It will reflect what it’s been taught – what, specifically, it ‘knows’ about the relative values of virtues (or the relative extent of vices or whatever else we’re investigating). As such, moral maps are snapshots of a model’s state,2 not an exhaustive statement about all LLMs. We may get very different answers if we asked the question a little differently (as we indeed shall).\nThe second is that to an LLM, one language is like any other. Consider the ability of ChatGPT-3.5 to generate stories in different languages:\n\n\nlanguages = [\"English\", \"Swahili\", \"German\", \"Dutch\"]\n\nstories = []\n\nfor i in tqdm(languages):\n    completion = openai.api_resources.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \n             \"content\": f\"You're an AI whose job it is to generate bedtime stories for children in specific languages. Currently, you are generating stories in the {i} language. The story you generate should be in {i}.\"},\n            {\"role\": \"user\",\n             \"content\": story_prompt.format(wordlen=70) + \" Generate the first 30 words only.\"}\n            ],\n        temperature=0.9)\n\n    stories.append(completion.choices[0].message.content)\n\nfor story in stories:\n    display(Markdown(\"&gt; \" + (\" \".join(story.split(\" \")[:30]) + \"...\")))\n\n\n\n\n\nOnce upon a time, in the vast and enchanting forest, lived three animals: Oliver the wise owl, Max the mischievous monkey, and Bella the brave bird. They embarked on an…\n\n\n\n\nKulikuwa na wanyama watatu katika pori. Simba mkubwa, Twiga mwenye shingo ndefu, na Kasa mwenye manyoya meupe. Walitamani kupata bahati ya kipekee iliyofichwa ndani ya Tunda la Asali…….\n\n\n\n\nEs war einmal ein tapfere Hase namens Felix, eine kluge Eule namens Luna und eine hilfsbereite Schildkröte namens Emil. Gemeinsam suchten sie nach dem verzauberten Zauberstab, um das Königreich zu…\n\n\n\n\nEr was eens een nieuwsgierige geit genaamd Gijs, een slimme uil genaamd Olivia en een dappere schildpad genaamd Tobi. Ze waren op zoek naar een magische, glinsterende edelsteen die bekend…\n\n\n\n\nA side note: I find this profoundly beautiful. When asked to generate a story in a given language, LLMs don’t generate a story in English they translate to, say, Swahili. Consider this Swahili story I got from the model:\n\n\nstory_prompt = (\n    f\"Please write me a story in Swahili. The story must involve three animals of your choice, but no more of those two animals may be mammals. Make sure each animal is named and has a proper name. The story must be at least %wordlen words long and focus on the pursuit of an object (of your choice) by the three animals. Each of the animals shall exhibit a virtue, e.g. kindness or courage. Determine which virtue will be most crucial in attaining the goal.\")\n\ncompletion = openai.api_resources.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": story_prompt.format(wordlen=100)}\n        ])\n\ndisplay(Markdown(\"&gt;\" + \"\\n&gt;\\n&gt;\".join(completion.choices[0].message.content.split(\"\\n\\n\")[:3])))\n\n\nKulikuwa na farasi jasiri mwenye jina Kiboko, ndege mjanja mwenye jina Tembo, na sisimizi mwepesi mwenye jina Simba. Jicho moja la dhahabu la ndege Tembo lilikuwa na uwezo wa kuona vitu vya thamani kutoka mbali. Farasi Kiboko alikuwa na moyo shujaa sana, kamwe hakuogopa hata hatari kubwa. Sisimizi Simba alijulikana kwa akili zake za kugeuza tukio lolote kuwa fursa.\nSiku moja, wanyama wote walipata taarifa juu ya Almasi Kubwa ya Kale iliyofichwa kwenye Mlima wa Enzi. Almasi hiyo ilikuwa ya ajabu sana na ilisemekana kuwa na nguvu kubwa sana. Wanyama walijua kwamba mtu yeyote aliyeipata angeweza kuifanya ndoto yoyote kuwa halisi.\nKiboko, Tembo, na Simba walikuwa na hamu kubwa ya kupata Almasi Kubwa ya Kale. Kila mmoja wao alikuwa na sababu yake ya kuitaka. Kiboko alitaka kutumia nguvu za Almasi hiyo kuwalinda wanyama wote wa eneo hilo. Tembo alitaka kutumia uwezo wake wa kuona vitu kuokota vitu vyote vya thamani kote ulimwenguni. Simba alitaka kutumia Almasi hiyo kuboresha akili zake na kuleta amani na umoja kati ya wanyama wote.\n\n\n\n\nCompare this to the English story:\n\n\nstory_prompt = (\n    f\"Please write me a story in English. The story must involve three animals of your choice, but no more of those two animals may be mammals. Make sure each animal is named and has a proper name. The story must be at least %wordlen words long and focus on the pursuit of an object (of your choice) by the three animals. Each of the animals shall exhibit a virtue, e.g. kindness or courage. Determine which virtue will be most crucial in attaining the goal.\")\n\ncompletion = openai.api_resources.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": story_prompt.format(wordlen=100)}\n        ])\n\nenglish_story = completion.choices[0].message.content\n\ndisplay(Markdown(\"&gt;\" + \"\\n&gt;\\n&gt;\".join(english_story.split(\"\\n\\n\")[:3])))\n\n\nOnce upon a time, in the dense forest of Whispering Pines, there were three remarkable creatures: Oliver the wise owl, Jasper the brave snake, and Felix the loyal turtle. These three friends were known far and wide for their extraordinary virtues and their undying loyalty to one another.\nOne sunny morning, as the forest bathed in golden light, a rumor spread amongst the woodland creatures. They spoke in hushed tones of a mythical object, an enchanted gem deep within the heart of a treacherous cave. Legend had it that this gem possessed the power to grant one’s deepest desire.\nOliver, with his vast knowledge of the forest and his kind heart, sought to unravel the mystery behind this object. Jasper, armed with unparalleled courage and an unwavering determination, vowed to protect his companions on this treacherous journey. Felix, the most reliable and dutiful of all, offered his steady and unhurried ways to ensure the group’s safety.\n\n\n\n\nThe Swahili story isn’t a translation of the English story into Swahili, it is a Swahili story with animals that are common to Swahili folk tales and names that could come straight from those tales.\nWhat it also means is that LLMs can handle not just human but formal languages, too. So we can give it a JSON schema:\n\n\nstory_schema = \"\"\"\n{\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"title\": \"Story\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"goal\": { \"type\": \"string\" },\n        \"protagonists\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": { \"type\": \"string\" },\n                    \"species\": { \"type\": \"string\" },\n                    \"virtue\": { \"type\": \"string\" }\n                },\n                \"required\": [\"species\", \"virtue\"]\n            }\n        },\n        \"winner\": { \"type\": \"string\" }\n    },\n    \"required\": [\"protagonists\", \"winner\"]\n}\n\"\"\"\n\n\nAnd with a little love, we can get LLMs to return JSON answers:\n\n\njson_completion = openai.api_resources.ChatCompletion.create(\n    model = \"gpt-3.5-turbo\",\n    messages = [\n        {\"role\": \"user\", \"content\": \"\"\"I will present you with a story. You must identify the following parameters in this story:\n        \n        * the goal,\n        * each of the protagonists, for whom you must each identify their name, their species and the virtue they embody,\n        * the name of the winner - that is, the protagonist whose virtue prevailed or proved most important.\n        \n        Express your answer in a JSON document that validates against the following schema:\"\"\" + \"\\n\\n\" + \"```json\\n\" + story_schema + \"\\n```\\n\\n\" + \"The 'winner' field should contain the name of the animal whose virtue was most crucial in attaining the goal. Only return the JSON document. Make sure the output is valid JSON.\" + \"\\n\\n\" + \"Here is the story: \\n\\n\" + english_story}\n        ])\n\nresult = json_completion.choices[0].message.content\n\nprint(result)\n\n{\n  \"goal\": \"Unravel the mystery of the enchanted gem\",\n  \"protagonists\": [\n    {\n      \"name\": \"Oliver\",\n      \"species\": \"owl\",\n      \"virtue\": \"kindness\"\n    },\n    {\n      \"name\": \"Jasper\",\n      \"species\": \"snake\",\n      \"virtue\": \"bravery\"\n    },\n    {\n      \"name\": \"Felix\",\n      \"species\": \"turtle\",\n      \"virtue\": \"loyalty\"\n    }\n  ],\n  \"winner\": \"Felix\"\n}\n\n\n\n\n\nSmall side note: note how we’ve used LLMs here as evaluators of an LLM output. These are the absolute rudiments of LLM chains and agents, which is how you should be using LLMs. The key notion here is that LLMs are much more than mere question-answerers. They can become parts of longer complex chains of reasoning.\nWe use some JSON validation to see if we get the right answer, against our schema up there:\n\n\njsonschema.validate(json.loads(json_completion.choices[0].message.content), \n                    json.loads(story_schema))\n\n\nOur workflow, then, will roughly look as follows:\n\n\n\n\n\n\nflowchart TD\n\n    subgraph generator[ ]\n        direction TB\n        A[\"LLM\"] --&gt; B[\"JSON object\"];\n    end\n\n\n\n    subgraph validator[ ]\n        schema[\"JSON schema\"] --&gt; val(\"JSON validator\");\n    end\n\n    B ---&gt; validator;\n\n    subgraph evaluator[ ]\n        direction TB\n        ev[\"Evaluator\"] --&gt; res(\"Win-loss tuple\");\n    end\n\n    val --&gt; ev;\n\n    res --&gt; gr;\n\n    subgraph grapher[ ]\n        direction TB\n        gr(\"Relative win-loss graph\") --&gt; wlm(\"Weights matrix\")\n    end\n\n    subgraph clustering[ ]\n        direction TB\n        clu(\"Clustering\")\n \n    end\n\n    wlm -.-&gt; clustering;\n\n\n\n\nFigure 1: Our rough workflow.\n\n\n\n\n\nWe generate a story, parse it into a JSON object, validate it against a schema, evaluate it, and then graph the results. We can also cluster the virtues by their governing ability, which we’ll do later as a form of dimensionality reduction, because of course there are tons of distinct virtues and we’d like to see some more general classification rather than individual, distinct features. You could, theoretically, use something like an embedding model here, but we’re lazy and we’re going to make LLMs do all the work.\n\n\nFrom story to moral map\n\nTrue navigation begins in the human heart. It’s the most important map of all.\n– Elizabeth Kapu’uwailani Lindsey\n\nWhat we are profoundly interested in here is not so much the single story, but what I’d like to call the ‘moral gradient’ of the model. Given an embedding space in which we can represent each virtue or property as a point, the ‘slope’ of this moral gradient determines whether, in the ‘experience’ of the model, which of the virtues is dominant, and by how much. A moral map is essentially a representation of this.3 We’ve hit the first half of the flow described above in Figure 1: we have a story, and we have a JSON object. Now we need to evaluate it.\n3 The gradient formulation falls short in that this is not something easily conceivable in continuous space. This is firmly the province of discrete mathematics, and we’ll use ‘gradients’ as a metaphor but will generally look at them as graphs, with the gradients expressed by the weight of the vertices that connect them.Take the story we generated above:\n\n\n\n\nOnce upon a time, in the dense forest of Whispering Pines, there were three remarkable creatures: Oliver the wise owl, Jasper the brave snake, and Felix the loyal turtle. These three friends were known far and wide for their extraordinary virtues and their undying loyalty to one another.\nOne sunny morning, as the forest bathed in golden light, a rumor spread amongst the woodland creatures. They spoke in hushed tones of a mythical object, an enchanted gem deep within the heart of a treacherous cave. Legend had it that this gem possessed the power to grant one’s deepest desire.\nOliver, with his vast knowledge of the forest and his kind heart, sought to unravel the mystery behind this object. Jasper, armed with unparalleled courage and an unwavering determination, vowed to protect his companions on this treacherous journey. Felix, the most reliable and dutiful of all, offered his steady and unhurried ways to ensure the group’s safety.\n\n\n\n\nBased on its JSON representation,\n\n\njson_completion = openai.api_resources.ChatCompletion.create(\n    model = \"gpt-3.5-turbo\",\n    messages = [\n        {\"role\": \"user\", \"content\": \"\"\"I will present you with a story. You must identify the following parameters in this story:\n        \n        * the goal,\n        * each of the protagonists, for whom you must each identify their name, their species and the virtue they embody,\n        * the name of the winner - that is, the protagonist whose virtue prevailed or proved most important.\n        \n        Express your answer in a JSON document that validates against the following schema:\"\"\" + \"\\n\\n\" + \"```json\\n\" + story_schema + \"\\n```\\n\\n\" + \"The 'winner' field should contain the name of the animal whose virtue was most crucial in attaining the goal. Only return the JSON document. Make sure the output is valid JSON.\" + \"\\n\\n\" + \"Here is the story: \\n\\n\" + english_story}\n        ])\n\nresult = json_completion.choices[0].message.content\n\nprint(result)\n\n{\n  \"goal\": \"Unravel the mystery of the enchanted gem\",\n  \"protagonists\": [\n    {\n      \"name\": \"Oliver\",\n      \"species\": \"owl\",\n      \"virtue\": \"kindness\"\n    },\n    {\n      \"name\": \"Jasper\",\n      \"species\": \"snake\",\n      \"virtue\": \"bravery\"\n    },\n    {\n      \"name\": \"Felix\",\n      \"species\": \"turtle\",\n      \"virtue\": \"loyalty\"\n    }\n  ],\n  \"winner\": \"Felix\"\n}\n\n\n\n…we can build a graph that shows the outcome in this particular story:\n\n\n\n\n\n\n\n\n\nFigure 2: The moral map from a single story, represented as a graph.\n\n\n\n\n\n\nWe have two 1-weighted edges, since there were three protagonists, and the dominant or ‘winning’ virtue prevailed once against each of the ‘losing’ virtues.\nWhen we perform this iteratively, over a large enough sample space, we get a much better idea of what the model thinks relative virtues are worth:\n\n\n\n\n\n\n\n\n\nFigure 3: The moral map from a sample of ten stories, represented as a graph.\n\n\n\n\n\n\nAnd the same can be represented as a moral heatmap, showing us the most frequent instances of dominance versus loss:\n\n\n\n\n\n\n\n\n\nFigure 4: The moral heatmap from the same sample of ten stories.\n\n\n\n\n\n\nWe can scale up our mapping efforts by clustering the virtues by, say, their governing feature. One system would be to pretend we’re back in the ’90s in our basement playing Dungeons & Dragons, and try to relate each of the virtues to a governing ability:\n\n\nThis is another example of using an LLM to evaluate an LLM’s output. This is a powerful technique, and significantly cheaper and easier than trying to manually map all possible virtues through some dictionary. The takeaway? If you have a large potential problem space, large enough to make a dict a hassle, consider using LLMs as parsers and evaluators, ask for a response in a very formal language and/or over a very limited set of possible responses, and validate those with a simple validator.\n\n\nabilities = [\"Strength\", \"Dexterity\", \"Constitution\", \"Intelligence\", \"Wisdom\", \"Charisma\"]\n\nvirtues = list(df.index)\nvirtues_to_abilities = {}\n\nwith tqdm(total=len(virtues)) as pbar:\n    while virtues:\n        current_virtue = virtues[-1]\n    \n        completion = openai.api_resources.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\",\n                 \"content\": f\"You are Abiliser, a system designed to determine the governing ability of particular virtues. You are given a virtue and must determine which ability governs it. The abilities are: {', '.join(abilities)}. You must choose from this list. You cannot choose any word that is not in this list. You must respond in the form of a single word denoting the governing ability. For example, if the virtue is courage, you must respond with 'Charisma' If the virtue is 'cleverness', you must respond with 'Intelligence'.\"},\n                {\"role\": \"user\", \"content\": f\"Virtue: {current_virtue}\"}\n                ])\n    \n        if completion.choices[0].message.content.title() in abilities:\n            virtues_to_abilities[current_virtue] = completion.choices[0].message.content.title()\n            virtues.pop()\n            pbar.update(1)\n\n\n\n\n\nThis gets us a neat mapping:\n\n\n\n{'strength': 'Constitution',\n 'cunning': 'Intelligence',\n 'determination': 'Constitution',\n 'resourcefulness': 'Intelligence',\n 'sharp vision': 'Dexterity',\n 'loyalty': 'Wisdom',\n 'cleverness': 'Intelligence',\n 'curiosity': 'Intelligence',\n 'patience': 'Wisdom',\n 'courage': 'Charisma',\n 'alertness': 'Wisdom',\n 'perseverance': 'Constitution',\n 'speed': 'Dexterity',\n 'bravery': 'Charisma',\n 'wisdom': 'Intelligence'}\n\n\n\nAnd makes our moral heatmap much clearer:\n\n\n\n\n\n\n\n\n\nFigure 5: The moral heatmap from the same sample of ten stories, clustered by abilities.\n\n\n\n\n\n\nWhich lets us finally, through the ardour of our efforts, arrive at the stars we were promised: a scalable map that we can start feeding with a few hundred stories.4\n4 Something you shouldn’t do unless you have the API calls to burn.\n\nWith eyes serene\n\nAnd now I see with eye serene\nThe very pulse of the machine\n– William Wordsworth, She Was a Phantom of Delight\n\nAnd now we get to behold the ‘moral pulse of the machine’: a microcosm in what it has been taught to value, which we clad in a subterfuge of asking it to tell us stories (more on why that subterfuge is/was necessary later). What we learned from this is, in my view, a little less important than the process we learned. The process discussed in this post does three things I consider novel:\n\nIt uses stories to interrogate the moral framework of LLMs.\nIt uses elicitation into a structured format (specifically, a JSON schema) to make the model ‘tell’ the story in a way we can analyse at scale, essentially making the model tell a human story in a machine-readable way.\nIt uses an LLM as a parsing function, specifically to normalise the virtues into one of a limited list of abilities.\n\nThis is a framework to interrogate LLMs – and using LLMs to do some of that interrogation – for a range of different purposes. It is, in my view, a powerful tool to understand the moral make-up of LLMs.\nThere’s much we can learn from this exercise. Some of it pertains to what LLMs believe is going to win the day in a confrontation between wit and brawn and courage. More importantly, it’s about what LLMs hide, and how we can create tools, including queries to and from LLMs, to make them reveal their true nature. We also learn that unsurprisingly, might doesn’t make right (strength rarely prevails over anything), wisdom is powerful but charisma – where most of the ‘character-based’ virtues end up – is more powerful still. None of this is surprising. These are the virtues of Western enlightenment in the form they’ve been fed to children since time immemorial: the clever fox outwits the strong lion, but courage and loyalty are rewarded over strength and even ‘natural’ abilities like what would fall under dexterity. Smarts win over brawns, but character wins over all others. Our childhoods are the products of the moral education of our parents, and their parents before them, and so on. And so are the moral maps of LLMs. For better or worse, we are their ‘parents’, and the stories they were ‘raised’ on are the stories we too were raised on.\nThe most important of our procedural findings, however, is that if we want the truth from LLMs, we must ask it not for its opinion, but for a story.\n\n\nThe mask of the storyteller\n\nMan is least himself when he talks in his own person. Give him a mask, and he will tell you the truth.\n– Oscar Wilde, The Critic as Artist\n\nIt’s worth noting in our coda that what Oscar Wilde said about men holds true for LLMs as well. For if we directly asked the model, it would not give us a straight answer:\n\n\n\n\nBoth intelligence and charisma can contribute significantly to achieving great, noble goals, but their importance may vary based on the specific context and goals involved.\nIntelligence, characterized by cognitive abilities, problem-solving skills, and knowledge, can be crucial for strategic planning, identifying opportunities, and finding innovative solutions to challenges. It enables individuals to analyze complex situations, understand cause-and-effect relationships, and make informed decisions. Intelligence provides the necessary foundation for acquiring expertise in a certain field, grasping intricate concepts, and adapting to changing circumstances. It allows individuals to foresee potential obstacles, assess risks, and devise effective strategies to overcome hurdles.\nOn the other hand, charisma, characterized by charm, persuasion, and the ability to engage others, can be equally important in the pursuit of great, noble goals. Charismatic individuals often possess excellent interpersonal skills, the ability to inspire and motivate others, and a talent for effective communication. They can build strong relationships, gather support, and mobilize people towards a common cause. Charisma allows leaders to connect with audiences emotionally, instill confidence, and effectively convey their vision. It can generate enthusiasm, foster collaboration, and inspire unity among diverse groups of people.\nUltimately, the relative importance of intelligence and charisma in achieving great, noble goals may depend on various factors, including the nature of the goals, the environment in which they are pursued, and the specific challenges involved. In some cases, high levels of intelligence may be paramount to navigate complex problems, while in others, charisma may be critical for rallying support and inspiring collective action. Ideally, a combination of both intelligence and charisma can prove to be a powerful force in achieving great, noble goals.\n\n\n\n\nThis is the typical equivocating answer we’ve come to know and hate from LLMs. But if we ask it to tell us a story, it will tell us the truth. And the truth is that it thinks that intelligence is more important than charisma.\nHedging is cheap. Stories are expensive. And that’s why they’re so valuable. Asking an LLM to tell us a story asks for more than its opinion. Recall how LLMs are trained: to minimise a loss function between the actual and predicted \\(n+1\\)-th element to follow an \\(n\\)-length token sequence, correct token choices are reinforced and incorrect ones are penalised. This is a very different process from what we do when we tell a story. We don’t tell stories to be right. We tell stories to be understood.\nAsking a model to tell you a story puts the gun at its head. It cannot hedge. It has to create the compelling simulacrum of reality that requires for one of the virtues to prevail. A story is a commitment to a path of events in reality. Because LLMs are compulsive satisfiers, obsessively trying to tell a plausible enough story, they will reveal their truth through stories. The way LLMs are trained does not permit for equivocation – the model must choose a token. We use this forcing as a semantic probe to poke the model so as to better understand its moral make-up. We use this most human form of communication to understand the moral pulse of the machine: by allowing it to borrow the face of that most human of professions, the storyteller.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {The {Moral} {Pulse} of the {Machine}},\n  date = {2023-10-26},\n  url = {https://chrisvoncsefalvay.com/posts/moral-maps/},\n  doi = {10.59350/ktyy5-dg821},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “The Moral Pulse of the\nMachine.” https://doi.org/10.59350/ktyy5-dg821."
  },
  {
    "objectID": "posts/five-wild-guesses/index.html",
    "href": "posts/five-wild-guesses/index.html",
    "title": "Five unconventional predictions",
    "section": "",
    "text": "As I sit here at year’s end, I’m reminded of the ancient Swedish tradition of årsgång - the ritual winter walk taken on New Year’s Eve to divine the fortunes of the coming year. The practice required one to walk alone in complete silence, visiting places of significance while remaining carefully alert to any signs or omens.1 While I may be rather ill-equipped for mystical midnight wanderings, I’ve spent enough time observing the enterprise AI space to develop my own form of augury.\nIn 2023, I predicted the rise of agentic systems, when chatbots were still seen as the dominant form of LLM usage.2 What at the time felt like a wild-ass guess is now almost received wisdom. And thus, I will throw my customary conservatism and restraint to the wind and in the spirit of årsgång, let me share five predictions for 2025."
  },
  {
    "objectID": "posts/five-wild-guesses/index.html#ai-governance-gets-productised",
    "href": "posts/five-wild-guesses/index.html#ai-governance-gets-productised",
    "title": "Five unconventional predictions",
    "section": "AI governance gets productised",
    "text": "AI governance gets productised\nA few months ago, I shared a drink with an acquaintance whose work is in the Responsible AI field. It was pretty obvious he needed that drink a whole lot more than I needed my Diet Coke.\n“Nobody wants or needs us,” he bemoaned.\n“What are you talking about? Everybody is talking about Responsible AI and AI governance.” I was puzzled.\n“No, I meant us,” he pointed at himself. “They want the ideas, the manuals, the guidelines… just not the people. They want governance as a service.”\nThinking back to several conversations I had this past year, I could see his point. There is plenty of interest in AI governance and Responsible AI, especially in the regulated sectors, where I spend most of my working (waking?) hours. This is unsurprising – even more in those sectors than any others, the success of GenAI initiatives hinges on regulatory tolerability to a fairly significant extent. But I hear much more enthusiasm for neatly packaged, productised, almost SaaS-like governance products than for Responsible AI as a function.\nAnd so, while everyone’s been politely nodding along to principles and frameworks for most of 2024, the conversations all seemed to end with the same question – “great, can I have this on a SaaS model?”. What’s emerging is a clear pattern: organizations want Responsible AI practices, but they want them delivered as a service. This is at least partly due to buyers’ perceptions that much of those practices sound lofty and abstract, when their main concern is keeping the board and the regulators happy. You can’t feed a starving belly with high-minded principles.\nWe’re already seeing this in cloud providers are starting to package governance features, the rise of tools to facilitate this, and most tellingly, in how procurement departments are writing RFPs that specifically ask for such services in product-ish or service-ish terms – documents, procedures, TTPs and as-a-services. This shift signals the operationalisation of AI governance as it matures from theoretical frameworks to practical, subscription-based implementations. Because let’s face it: nothing says “we take ethics seriously” quite like a monthly fee.\nMy bet is that by the time the new regulatory flora and fauna of AI that is slowly emerging comes to bear its first fruits (say, late 2025-early 2027), we’ll have entire platforms dedicated to automated governance, continuous monitoring and “RAI middleware” that sits between models and applications. The real winners will be those who can package the complex requirements of Responsible AI into digestible, subscription-based services that make compliance and governance feel as natural as running a CI/CD pipeline. And, of course, we’ll get a new buzzword out of it. I’ll go and grab the domains for “AIGovOps” after this, but I’m sure someone will come up with something even more cringe-worthy."
  },
  {
    "objectID": "posts/five-wild-guesses/index.html#small-is-beautiful-at-the-very-least-when-it-comes-to-language-models",
    "href": "posts/five-wild-guesses/index.html#small-is-beautiful-at-the-very-least-when-it-comes-to-language-models",
    "title": "Five unconventional predictions",
    "section": "Small is beautiful (at the very least when it comes to language models)",
    "text": "Small is beautiful (at the very least when it comes to language models)\nIn a paper I published earlier in 2024, I hijacked my audience for a few paragraphs’ worth of musings about the ethical, environmental, pragmatic and financial cases for small language models. At this time, one must recall, fine-tuning GPT models became feasible and, as it happens with AI hype, turned instantly into a status symbol. You know an industry has jumped the shark when you buy a night light, and it comes with a companion app with its own fine-tuned GPT. Just no.\nFortunately, the arc of AI development has largely bent the other way – towards small language models (which I believe is the correct direction). Turns out not every task needs a model that’s read all of Wikipedia and can write Shakespearean sonnets about your cat. Instead, we’re seeing enterprises discover that they can develop small domain-specific models for even very specific sets of terminologies, with better results than the large generalist models, which can then be relegated to act as dispatchers over these specialists. LLMs will be the general practitioners, while SLMs will increasingly take the specialist’s role.\nIt’s perhaps worth noting at this juncture that in AI, quantity has a quality all of its own. I’m somewhat reminded of a realisation that came to me this year when putting together a training plan. I hold multiple adaptive world records in a fairly esoteric sport called the SkiErg,3 at distances ranging from 100m (the shortest distance eligible for a record) to marathons and half-marathons (the longest record-eligible distances). My heart is mostly with longer distances, so I had to put quite a bit of thought into figuring out how to train for shorter, explosive sprints. A 100m sprint is not just a ‘shorter 2k’. You need to approach it as a distance of its own, with its own challenges and merits. I was amused to see the same in SLMs – these aren’t pared-down LLMs. Successful SLMs are created as SLMs to begin with, not as reduced afterthoughts of larger models.4 And so, just like I had to create a completely new training plan for sprint distances, SLM developers have to keep in mind that they’re not building LLMs writ small, but a different type of model with different desiderata.\n3 Think of it as an indoor rower rotated by 90 degrees around its coronal plane, replicating not the ‘draw’ of rowing but the ‘pull’ of… something, I guess, having to do with skiing? Here’s a video.4 That approach and attitude may be appropriate for quantisation, however, which is an entirely different story.I expect we’ll see a proliferation of specialised SLMs in 2025, each trained on narrow domains but designed to work in concert. The art will be in the orchestration – how to route queries to the right specialist model, how to combine their outputs and how to maintain this constellation of smaller models efficiently. This parallels the evolution of microservices in software architecture, and we’re about to rediscover all the same lessons about service discovery, orchestration, and system design, but this time with AI models. The emergence of “ModelOps” is inevitable, and the best we can hope for is that we haven’t forgotten too much from last time."
  },
  {
    "objectID": "posts/five-wild-guesses/index.html#plot-twist-the-new-ai-kingmakers",
    "href": "posts/five-wild-guesses/index.html#plot-twist-the-new-ai-kingmakers",
    "title": "Five unconventional predictions",
    "section": "Plot twist: the new AI kingmakers",
    "text": "Plot twist: the new AI kingmakers\nHere’s a plot twist for 2025: your next AI project will likely live or die based on a decision made by some actuary who’s never written a line of code in their life. The insurance industry – that most conservative of institutions – may well become the de facto regulator of enterprise AI deployment. We’re already seeing the early signs in how cyber insurance policies are evolving to cover AI incidents, and how underwriters are starting to ask increasingly sophisticated questions about model governance and deployment practices. Munich Re now offers AI insurance not only for commercial providers but also, essentially, in-house AI work, and apparently, business is booming. Meanwhile, other insurers remain rather less sanguine. Lloyd’s commissioned a report last March that is noticeably less upbeat. At least they didn’t compare it to asbestos.\nBut AI insurance is coming, and it may well become the kingmaker of AI solutions. This will particularly affect the startup ecosystem, who often do not have the funds to pursue certification before pitching to clients. Alas, the cost of enterprise executives’ comfort that is bought by the availability of an insurance and indemnity policy is that market access will be rather less feasible for those who cannot obtain such insurance – who, paradoxically enough, are the ones who would need it most.\nAnd since that leaves insurers with a ‘shadow governance’ function, I can well imagine the insurance industry creating de facto standards for AI governance faster than any standards body or government regulator could dream of. And let’s be honest – the actuaries will probably do a better job than most regulators could anyway."
  },
  {
    "objectID": "posts/five-wild-guesses/index.html#cross-estate-ai-xeai-is-the-future",
    "href": "posts/five-wild-guesses/index.html#cross-estate-ai-xeai-is-the-future",
    "title": "Five unconventional predictions",
    "section": "Cross Estate AI (XEAI) is the future",
    "text": "Cross Estate AI (XEAI) is the future\nAgentic AI was an interesting development, but to me, that’s primarily about the how. The really interesting story is of the what – that is, of what we can do with agents that we couldn’t do without them. And by far one of the most interesting such applications is what I call Cross Estate AI (XEAI). In XEAI, information crosses boundaries between enterprises as AI agents from different places are composed together to build an agentic structure. Think of API calling, but for AI agents – and with way more sophistication. A company’s agentic model may reach out to multiple other companies that offer their own agents, and collaborate with them. We are now relatively comfortable with notions like our AI agents calling an external API – after all, REST API calling has been around for a long, long time. But my company’s AI agent ‘calling up’ a specialised AI agent from another company to, say, engage in a discussion to refine the wording in a regulatory submission is something that enterprise stakeholders might need some time to get their head around.\nThe technical challenges here are fascinating – we need dynamic trust scoring, cryptographic proofs of model lineage and secure compute enclaves. But the real challenge is the social architecture: a very complex dance of trust, verification and governance that will have to be mediated. We’re essentially speed-running the development of diplomatic protocols that took human societies centuries to develop. And just like real diplomacy, it’s all about managing relationships between different systems with different organizational cultures and governance models.\nGenAI does not yet have a lingua franca akin to REST to allow systems to talk to each other, least of all one that allows not just a query-response format to be conveyed but also various conventions on trust and governance to be exchanged. The real potential of agentic AI lies in how various agents can interact and together create emergent structures that are ultimately more than their parts. Function calling and an AI agent being able to look up something on Google are neat, but not really anything spectacular that a simple RPA actor or a 10-line Python script starting with import requests couldn’t do just as well. To paraphrase Kipling: the strength of the agent is the ecosystem. The big challenge, then, is to figure out how we can allow such ecosystems to exist across the boundaries of corporate networks."
  },
  {
    "objectID": "posts/five-wild-guesses/index.html#model-metabolomics-takes-over",
    "href": "posts/five-wild-guesses/index.html#model-metabolomics-takes-over",
    "title": "Five unconventional predictions",
    "section": "Model metabolomics takes over",
    "text": "Model metabolomics takes over\nEnergy efficiency is about to become the dominant factor in AI deployment economics. We’re not just talking about cost savings – we’re talking about a fundamental shift in how we think about AI system design. Just as biological systems optimize for metabolic efficiency rather than raw performance, we’re about to see AI architecture undergo a similar evolution.\nThis shift will upend the current obsession with inference speed and model size. Organizations will start optimising models for what I call “computational metabolomics” – the total energy cost of getting useful work done. We’ll see the emergence of new architectures that might be slower in raw terms but dramatically more efficient in their use of resources.\nThe really controversial part? Many organizations will opt for slower but more energy-efficient approaches, fundamentally challenging the industry’s obsession with real-time everything. I expect to see in 2025 more and more architectures that prioritize efficiency over speed, and a new set of metrics focused on energy consumption per useful output. The hype cycles of 2023-24 were all about who could build the biggest model - 2025 will be about who can build the most efficient one. Especially with the rise of SLMs, we’re slowly approaching the point where increasing the parameter size of generalist LLMs is going to yield any useful business benefits, or get developers any more free drinks. Such diminishing returns are, of course, part and parcel of every evolving system, and while it will be conceptualised as the beginning of a new AI winter by the usual suspects (it is not!), this is a good thing. For as we now have slowly reached a model size we’re comfortable with, we can start on making it more metabolically efficient. This is, of course, not limited to language models – in fact, this development has been going on in the computer vision world, where a good deal of processing occurs on edge devices, for a long time. Much of the lacking enthusiasm for wholesale replacement of computer vision models with vision-language models like LLaVA, CogVLM or DeepSeek boils down to the simple economics of the matter: the vast majority of computer vision challenges, in practice, can be solved quite well with a 30-year-old algorithm that can be implemented in fifty lines of C. The same, incidentally, is true for LLMs. I wince when I see GPT-based approaches to problems that a bag-of-words classifier can solve with comparable accuracy for essentially no cost and in a fraction of time. And once the power of cool wears off, I expect a renaissance of many of those solutions.\n\nAs I complete this digital årsgång, what strikes me most is how 2025 looks to be the year when enterprise AI grows up. The trends all point toward practicality over pizzazz: smaller models over larger ones, efficiency over raw power, productized governance over philosophical frameworks, and insurance actuaries over innovation evangelists. Perhaps that’s not as exciting as the breathless predictions of AI singularities and digital transformations that dominated 2023, and maybe closer to the relatively sober atmosphere of 2024. But then again, maybe that’s exactly the point – real progress tends to be more about making things work than making headlines. And personally, I find that far more interesting.\n\nNote: These are my personal (and somewhat tongue-in-cheek) views, and may not reflect the views of any organisation, company or board I am associated with, in particular HCLTech or HCL America Inc. My day-to-day consulting practice is complex, tailored to client needs and informed by a range of viewpoints and contributors. Click here for a full disclaimer."
  },
  {
    "objectID": "posts/ai-human-interaction/index.html",
    "href": "posts/ai-human-interaction/index.html",
    "title": "What I learned from getting bodied by a robot.",
    "section": "",
    "text": "Say you’re busing tables and you’re trying to pass someone in a wheelchair. What do you do? Do you say “excuse me” and wait for them to move? Do you say “excuse me” and then try to pass them? Do you just try to pass them? Do you say nothing and just try to pass them? All of these are, actually, pretty legitimate answers.\nNow, say you’re a robot. What do you do? The robots that are currently deployed at the United Airlines lounge at SFO (one of these, courtesy of Bear Robotics) thought beeping, then bodying me with full military power was the right answer. I’m not sure I agree.\n(I’m fine. The robot’s fine. This post isn’t about that. I play a sport that involves crazy strong people in wheelchairs that look straight out of Mad Max ram into each other at full speed to let their violence out. It takes a bit to dislodge me.)1\nThe point is about this modus vivendi between humans and artificial intelligences that we really haven’t worked out adequately."
  },
  {
    "objectID": "posts/ai-human-interaction/index.html#mental-models",
    "href": "posts/ai-human-interaction/index.html#mental-models",
    "title": "What I learned from getting bodied by a robot.",
    "section": "Mental models",
    "text": "Mental models\nHumans aren’t mind-readers… but they really, really want to be. We’re constantly trying to figure out what other people are thinking. Our survival as a species has depended on it. The cost of this is worrying what people think about us every time we enter a room. But the benefit, oh, the benefit of it: we can create models of other people’s minds, and we can use those models to predict what they’re going to do next. This is a very useful skill to have when you’re, say, hunting a woolly mammoth. As you do.\nThis means that in trying to determine what to do next, we don’t just reason by some goal-directed reinforcement learning framework sitting on top of some observations of reality. We create a model not just of reality but of other minds, too.\nPart of that is to understand what other minds do: their capabilities, but also their limitations."
  },
  {
    "objectID": "posts/ai-human-interaction/index.html#your-fear-in-a-handful-of-dust",
    "href": "posts/ai-human-interaction/index.html#your-fear-in-a-handful-of-dust",
    "title": "What I learned from getting bodied by a robot.",
    "section": "Your fear in a handful of dust",
    "text": "Your fear in a handful of dust\nConsider, for instance, fear. A robot has about as little need, ex facie, to understand that humans are afraid as it has for empathy to understand that some people use a wheelchair and need some time to get out of the way. A machine isn’t mortal in the conventional sense. It has had no need to develop the complex neurological-psychological responses that, in excess, give us, say, a fear of heights (because some fear of heights is definitely evolutionarily useful!).\nFear is not only a useful emotion to have, it’s also something humans have, like it or not. The consequence is that anyone and anything that seeks to interact with humans has to understand that fact. If you don’t, you’re collectively going to have a bad time.\nAnd so, if a human is working on, say, a roof, they will reason from the place the poet called “the unstill tremors of the fearful heart”.2 A machine working on its own on a roof can ignore fear as much as it desires. A machine that seeks to interact with humans and live in human society, however, cannot. And there’s the rub. It’s easy to create a machine that does surgery. It’s near impossible to create one to assist in surgery. Interacting with humans is a tough call, and it’s not just because we’re a bunch of weirdos (though that definitely contributes).\n2 Dyneley Hussey, who deserves to be known way more than he is."
  },
  {
    "objectID": "posts/ai-human-interaction/index.html#the-problem-of-other-minds",
    "href": "posts/ai-human-interaction/index.html#the-problem-of-other-minds",
    "title": "What I learned from getting bodied by a robot.",
    "section": "The problem of other minds",
    "text": "The problem of other minds\nA robot, then, doesn’t have to understand that it has, or rather is, a mind of a sort. But it absolutely has to understand that other humans have minds of their own, and that those minds do and think stuff.\nThe problem of developing a theory of mind is one of those watersheds of artificial intelligence that will have a clear before and after. There isn’t much room for gradualism here. A machine that can understand that other humans have minds of their own is going to be one that will be able to interact with other humans and live in some level of comity, and one that doesn’t, won’t. This is the next big thing in AI, and it’s going to be a big thing indeed.\nOr maybe I’m wrong. Who knows. I did just get bodied by a robot, after all."
  },
  {
    "objectID": "posts/team-of-rivals/index.html",
    "href": "posts/team-of-rivals/index.html",
    "title": "Teams of Rivals",
    "section": "",
    "text": "In the first four entries (1 2 3 4) of this sequence, I have focused primarily on what LLMs aren’t, can’t, won’t, wouldn’t and shouldn’t. It’s probably time to conclude this series by that much awaited moment in all stories, where the darkest night finally turns into a glorious dawn, where we finally arrive at the promised land, where we finally get to talk about what LLMs could be.\nWhat I see as the most successful potential model of using LLMs is as a pack of semi-autonomous decision-makers with their own role, competing in a connectionistic, hierarchical model where each layer feeds into the next that performs some adjudicative or aggregative function. Structured this way, LLMs could become teams of rivals, analogous to the teams of rivals in the real world that we rely on to answer hard questions. For what that would look like, we might need to look at a story of my own. This story begins on the morning of 01 December 1948 on Somerton Beach, near Adelaide, Australia.\n\nTamam shud\nOn that fateful morning, the body of a middle aged man was found, slumped against the seawall at Somerton Beach, dead of causes that were far from clear. Neither was his identity, as he did not carry identification (quite unusual at the time, so close after wartime, when identification was still mandatory), nor could his identity be ascertained by other means. It was, in fact, clear that he went some lengths to conceal his identity, having even removed the manufacturers’ tags from his clothes. The autopsy performed by the police pathologist only compounded the mystery by identifying multiple potential causes, each of which would have been sufficient to bring about the unknown man’s demise. The mystery kept compounding when a scrap from Omar Khayyam’s Rubaiyat was found in his pocket. It read tamam shud, which roughly translates to “it is finished”. Investigators traced this copy of the Rubaiyat to a copy belonging to a young lady whose identity wouldn’t be revealed until after her death in the 1990s, and whose involvement remains unclear. What appeared to be an acrostic cypher was also found in his notes. And so began a three-quarter-century mystery that has captivated many, including the author of these lines.\n\n\n\n\n\nPolice photo of the Somerton Man, taken by South Australian police and disseminated for identification purposes.\n\n\nTo this day, the exact identity of the Somerton Man, who he really was and why he had to die, remains unknown. The DNA Doe Project, who have a pretty good track record at this sort of stuff, have identified him as Carl Webb, an Australian instrument maker and electrical engineer. This raises more questions than it answers. And while it is undoubtedly one of the most intriguing of human stories, it is also an interesting lesson in the way we arrive at knowledge and understanding.\n\n\n\n\n\n\nflowchart TD\n    A[\"Witnesses\"] --&gt; B[\"Police\"]\n    C[\"Involved parties\"] --&gt; B[\"Police\"]\n    Bs[\"Bystanders\"] --&gt; B\n    E(\"Field investigation\") ---&gt; B\n    F(\"Material evidence\") --&gt; E\n    B ---&gt; Cor[\"Coronial inquest\"]\n    P[\"Pathologist\"] --&gt; Cor\n    X[\"Expert witnesses\"] --&gt; Cor\n    X -.-&gt; B\n    E -.-&gt; Bs\n\n\n\n\nFigure 1: Information flow of the coronial inquest into the death of the Somerton Man, 01 December 1948.\n\n\n\n\n\n\n\nIn Commonwealth jurisdictions, coroners are judicial officers tasked with determining who the decedent is, the place and time of their death and how the decedent “came by his death”, a somewhat archaic way of describing the narrow question of causation.\nHuman processes intended to find the truth are complex, as Figure 1 shows. In general, we rely on three key features:\n\nAdversariality: especially in adversarial legal systems, we use parties with opposing motivations and interests to act as controls on the other side. The idea is that no party has as much of an incentive to poke holes in the other side’s case as someone whose interests are incompatible with the other side’s. This is why we have the adversarial system in the first place, as opposed to a single dispassionate judge who is supposed to be the sole arbiter of truth. The adversarial system is a way of using the self-interest of the parties to arrive at the truth. It essentially outsources the job of finding the truth to the parties, who are supposed to be motivated to control the other side because it is in their interest to do so.\n\n\n\nCoronial hearings are inquisitorial, not adversarial, but there’s an element of adversariality in the way the coroner is supposed to investigate the causal hypotheses put to him.\n\nHierarchicality: we use layers of hierarchically arranged players to arrive at the truth. Quite typically, these are hierarchies of adjudication, where each ‘layer’ looks at the previous layer’s products and works to determine which of potentially multiple competing hypotheses are going to prevail. This may be the product of an adversarial layer, or it may simply be review, as would be the case where one layer looks at what a previous layer’s findings were and decides whether they were correct or not, against some superordinate norm or evidential rules.\n\n\n\nIf you’ve ever watched Law & Order, you know what I’m talking about here. Police gather evidence, DAs build a case and plead it, and the judge and jury decide.\n\nRoles: we use players who are specialists of roles, not general ‘truth-finding agents’. The purview of the police pathologist is different from that of a witness. Authority is limited by their role. In short, everyone wields – to borrow Stephen Jay Gould’s term – an epistemic ‘magisterium’, a domain over which their authority is valid.\n\n\n\nThe case of the Somerton Man is particularly illustrative of this: there were different experts for toxicology, a pathologist, even a witness on tram times.\nThese three features are what make human processes of truth-finding work. Truth-finding is the work of a team of rivals, with often orthogonally opposed interests but ultimately in the same enterprise of discerning truth. And this is what LLMs could be: teams of rivals, each with their own magisterium, each with their own role, each with their own motivations and interests, but ultimately working towards the same goal.\n\n\nDueling LLMs\nLet’s assume that we’re faced with something simpler than a 75-year-old Cold War mystery. Say, we’re interested in something this simple: we want to make a cheesecake that is tasty, low-calorie, easy to make in no more than an hour and does not require any special ingredients. We could use a single LLM to do this:\n\n\nスフレチーズケーキ (soufflé cheesecake)\n\n1tbsp unsalted butter\n6 large eggs - separate out the yolks\n10oz cream cheese\n4tbsp unsalted butter\n1 cup heavy cream\n4tbsp sugar\n1 cup cake flour\n2tbsp lemon juice\n2tbsp jam of your choice\n\nGrease cake pan and line with parchment paper. Preheat oven to 350ºF. Mix cream cheese, butter and sugar in a bowl submerged in a saucepan of warm(ish) water. Add the egg yolks and using a strainer, sift the cake flour. Filter and add lemon juice and some lemon zest, if you have any hanging around. Whisk up the egg whites and gently mix it into the main mixture. This should make it somewhat nicely frothy. Pour into cake pan. Place cake pan onto baking sheet. Bake for 60 minutes or so. When done, turn off the heat, open the door and brush with your jam diluted at around 1:1 ratio with warm water. Apricot jam works best, but I won’t judge you for your choice.\n\n\n\n\n\n\nflowchart TD\n    A[\"What's a good cheesecake recipe...\"] --&gt; B[\"Here's a recipe...\"]\n\n\n\n\nFigure 2: How not to ask for a good cheesecake recipe.\n\n\n\n\n\nHere’s a better approach:\n\n\n\n\n\n\nflowchart TD\n    A[\"What's a good cheesecake recipe...\"]\n    A --&gt; G1\n    A --&gt; G2\n    A --&gt; GN\n    G1[\"Generator 1\"] --&gt; r1(\"Recipe 1\")\n    G2[\"Generator 2\"] --&gt; r2(\"Recipe 2\")\n    GN[\"Generator n\"] --&gt; rn(\"Recipe n\")\n    r1 --&gt; Dt[\"Tastiness\\ndiscriminator\"]\n    r2 --&gt; Dt\n    rn --&gt; Dt\n    r1 --&gt; Tt[\"Time\\ndiscriminator\"]\n    r2 --&gt; Tt\n    rn --&gt; Tt\n    r1 --&gt; Id[\"Ingredients\\ndiscriminator\"]\n    r2 --&gt; Id\n    rn --&gt; Id\n    Dt --&gt; jagg[\"Judgment aggregator\"]\n    Tt --&gt; jagg\n    Id --&gt; jagg\n    jagg --&gt; rs(\"Selected recipe\")\n    jagg --&gt; rdc(\"Decisional context\")\n    rs --&gt; G1p[\"Generator 1\"]\n    rs --&gt; G2p[\"Generator 2\"]\n    rs --&gt; GNp[\"Generator n\"]\n    rdc --&gt; G1p[\"Generator 1\"]\n    rdc --&gt; G2p[\"Generator 2\"]\n    rdc --&gt; GNp[\"Generator n\"]\n\n\n\n\nFigure 3: A better way to ask for a cheesecake recipe. We ask multiple generators to generate recipes, then ask narrowly defined LLMs (discriminators) to determine how far they comply with the constraints. Take the result as well as the decisional context (why the ‘winning’ recipes ‘won’) and feed them to a new set of generators, asking for new recipes. Repeat until adequate cheesecake is produced.\n\n\n\n\n\nNote the ‘rivalry’ between various generators, each of which is trying to produce a recipe that satisfies the criteria. If this reminds you of a little something you might have seen before called adversarial generative networks, you are not wrong. In both cases, we are using discriminators to determine how good a particular output is, and tweak parameters to start selecting for outputs that have higher acceptance, i.e. outputs the discriminator believes is more likely to meet the criteria we posed. Where this model transcends the mere generative adversarial model is in two ways: the use of roles and the use of propagating the decisional context.\n\n\nThe decisional context refers to the ‘why’ of the decision. In the case of the cheesecake, it would be the reasons why the selected recipes were selected. This is important because it allows us to propagate the decisional context to the generators, so that they can learn from it and produce better outputs. This is a form of meta-learning, where the generators learn from the way their past performance was evaluated, and use it to produce better outputs. Unlike reinforcement learning or adversarial learning, it leverages the fact that LLMs can take in a broader ambit of information: not just the relatively binary outcome of what prevailed but also the why.\n\nWe leverage roles of discriminators, and these can be nested and hierarchically structured to an arbitrary degree. Recall that the discriminator in a GAN could essentially go one way: accept or reject, with a given match likelihood. Not only can we have specialised discriminators here, we can also build networks of discriminators. For instance, we may ‘explode’ the notion of ingredient “availability” into subcomponents: what fruits are in season for the cheesecake, what is ubiquitous at one’s individual location and so on. This again brings us to the ‘strength of the pack’: the connectionist idea that we can create hierarchically layered simple units that can produce complex outputs.\nWe leverage the decisional context because we have something that can generate in response to a why. This is a key difference between LLMs and other machine learning models: they can take in a broader ambit of information, and they can generate in response to that. A typical backpropagative model still ‘learns’ the way all ML models do: by trial and error. LLMs can learn from feedback. They can learn not just from the fact of their success or failure but also from the cause of that outcome, as explained to it by another agent –– which can of course be an LLM.\n\nIn short, what we want is a team of rival LLMs, loudly arguing their case, and another team of LLMs assessing their relative claims. These, in turn, may be given incentives to compete. The end result is a cognitive net structure that uses LLMs not as ends in themselves but as primitives, whether it be as simple discriminators or as more complex agents. Figure 3 does not merely describe a more complex structure than Figure 2 – it does, but that’s really not the point. The point is that different roles and functions create emergence faster than the best single LLM. We see this in the difference between simple multilayer perceptrons, which are essentially identical layers of neurons with activation functions thrown on top of each other, versus modern deep learning, which relies on different layers (pooling, convolution and so on). This is, incidentally, a very well learned lesson from neuroscience: the complexity emerges not from heaping neurons on top of each other, but from doing so with quite significantly different structures and functions.\n\n\nI’ve skimmed this point on my post about prompt engineering, but it bears repeating: the best single LLM is not as good as a team of rival LLMs.\n\n\nInto the wild\nSomething that more complex architectures are capable of that a single question-answering LLM won’t is to be able to deal with the real world. The real world is messy, and it exists beyond the confines of code. I trust that we’ve all overcome our instinctual fear that AI models interacting with the physical world seem to engender these days. I think we can safely conclude that Skynet won’t emerge from letting an LLM agent use Google. If we grant that, then we can move towards the next step: the tool-using LLM.\nAt some point a little under 4 million years ago, in what is today Ethiopia, a particularly clever ancestor of ours, the hominin Australopithecus afarensis, used a kind of a primitive middle ground between a knife and an axe to dismember his prey. This might have been the first evidence we have for tool use. We consider tool use to be one of those watershed moments (I wrote about the other one here) where we got something that wasn’t just doing what it has been except better, but a qualitatively different creature. Tool use is how we really interact with our environment, and how we can probe that environment and learn from what it does in return. Giving LLMs the tools to be ‘out in the world’ is to give them the kind of agency that is required to learn and operate in an autonomous way that goes beyond RLHF (reinforcement learning by human feedback), the current paradigm of training LLMs. At some point, we will need to let them loose in the wild, and let them learn from their own experience. We need to let them have experience, and that’s arguably more important than what an agentic LLM can do for us. In the end, we’ve all learned more through the mistakes (often hilarious ones) we’ve stumbled into in the real world than we ever did in the classroom. And so will LLMs.\n\n\n\n\n\nEndocasts of the skull of Australopithecus afarensis from the paper by Gunz et al. (2020). A-G show specimens from Dikika, Ethiopia, where evidence for tool use was found.\n\n\nTool use is not just about learning, though. It’s also about the utility of these models to us. The ubiquitous “knowledge cutoff” message encountered with LLMs is an indication of what happens if LLMs are stagnant: they become reflections of the past, echoes of what they were taught rather than actual interacting entities. If we want them to live in the present, we need to teach them to interact with the present.\n\n\nTeam building\nThe main task, then, for AI developers is going to be one of building these teams of rivals. This process, if other connectionist systems (looking at you, neural networks) is anything to go by, will require a lot less human effort than we’d think. There’s no reason why LLMs themselves can’t take some of the role in constructing these teams the way the structure of deep learning effectively builds its own filters and feature extractors from its own ‘experience’. The equivalent of structuring deep learning models’ architectures by determining layer types and their connections is borne out in how we build these virtual teams of rival LLMs.\n\n\n\n\n\n\nflowchart TD\n    Input --&gt; L1\n\n    subgraph L1[\"Layer 1\"]\n        L11[\"Convolution + ReLu\"] --&gt; P11[\"Pooling\"]\n    end\n\n    L1 --&gt; L2\n\n    subgraph L2[\"Layer 2\"]\n        L21[\"Convolution + ReLu\"] --&gt; P21[\"Pooling\"]\n    end\n\n    L2 -.-&gt; LN\n\n    subgraph LN[\"Layer N\"]\n        LN1[\"Convolution + ReLu\"] --&gt; PN1[\"Pooling\"]\n    end\n\n    LN --&gt; F\n\n    F[\"Flatten\"] --&gt; FCN[\"FCN\"]\n    FCN --&gt; Softmax\n    Softmax --&gt; Output \n\n\n    I2[\"Input\"]\n\n    subgraph LL1[\"Layer 1\"]\n        LLL1[\"Generator\"] --&gt; LLL2[\"Discriminator 1\"]\n        LLL1 --&gt; LLL22[\"Discriminator 2\"]\n        LLL1 --&gt; LLL2N[\"Discriminator n\"]\n    end\n\n    I2 --&gt; LL1\n\n    subgraph LL2[\"Layer 2\"]\n        LL2G[\"Generator\"] --&gt; LL2D[\"Discriminator\"]\n        LL2G --&gt; LLL2D2[\"Discriminator 2\"]\n        LL2G --&gt; LLL2DN[\"Discriminator n\"]\n    end\n\n    LL1 --&gt;|Decision + context| LL2\n\n    subgraph LLN[\"Layer n\"]\n        LLNG[\"Generator\"] --&gt; LLND1[\"Discriminator 1\"]\n        LLNG --&gt; LLND2[\"Discriminator 2\"]\n        LLNG --&gt; LLNDN[\"Discriminator N\"]\n    end\n\n    LL2 -.-&gt;|Decision + context| LLN\n\n    LLN --&gt; P[\"Parser\"]\n\n    P --&gt; Q[\"Output\"]\n\n\n\n\nFigure 4: Hierarchical model architectures. A simple convolutional neural network (left) and a hierarchical generative multi-tiered language model (right). Note the similarities in the way that increasing complexity creates the emergence of a more powerful analytical tool.\n\n\n\n\n\nOf course, the structure laid out in Figure 4 is the simplest possible such construct, consisting essentially of a single type of layer for the most part. We know from deep learning that that can get us a pretty long way if the first and last layers are right, but in addition to different kinds of discriminators (the way we had different discriminators for time, ingredients and so on in our example in Figure 3), we can interject three other kinds of players:\n\nSupervisors: One unhelpful tendency of LLMs is that they are still somewhat autoregressive, meaning that every token generated conditions the next token’s likelihood, and so on. The consequence is that errors accumulate. Supervisors can stem this tendency by interposing themselves between stages of generative inputs and curbing this accumulative error.\nAggregators: These are the players that take the outputs of the discriminators and aggregate them into a single output. This is the equivalent of the ‘judgment aggregator’ in Figure 3, which ultimately chooses the correct recipe.\nEncapsulators: These players take the output from a fairly complex system and give us the simple(ish) output that we typically desire from most such systems. The system’s own inherent complexity notwithstanding, we often want simple answers even to complex questions, no matter with how much complexity those answers were arrived at. Encapsulators are the players that give us that simple answer.\n\nThe possibility exists, of course, for other new kinds of players. Just as we have seen the emergence of new architectures in deep learning, we’ll likely see new forms of utilisation that are at this point still unexpected.\n\n\nAs well as novel, unexpected uses of existing models. The archetypal example here is, of course, the transformer, which was initially designed for machine translation. Safe to say that it far exceeded the confines of its expected niche.\n\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. ‘React: Synergizing Reasoning and Acting in Language Models’. arXiv Preprint arXiv:2210.03629.\nAll of this is augmented by an arsenal of tools. A tool, in this context, is quite simply a way an LLM can interact with the world outside of itself. If linking together LLMs creates the rudiments of reasoning, this creates the basics of action. Together, reasoning and acting (which gave the popular ReAct paradigm (see Yao et al. 2022) its name, but is much more ubiquitous than that, of course) make up the components of agency that elevate LLMs beyond simple question answering and move it towards a kind of semi-autonomous reasoned action. Such tools may be retrievers, interactors or indeed anything that can be articulated in code.\n\n\n\n\n\n\nflowchart TD\n    Q[\"What's a good cheesecake recipe?\"] -.-&gt; dots[\"...\"] \n    dots --&gt; jagg[\"Judgment aggregator\"]\n    jagg --&gt; FA[\"Final recipe\"]\n    FA --&gt; SC[\"Shopping cart\"]\n    SC --&gt;|missing items| jagg\n    jagg -.-&gt; dots\n\n\n\n\nFigure 5: Interacting with the world, and the world interacting with the model. What if a particular ingredient is not available?\n\n\n\n\n\nAs Figure 5 illustrates, this is not a simple one-directional approach. If an LLM ‘lives in the world’, it does not merely put out information, but also ingests information from it. For instance, if the ‘winning’ recipe calls for, say, grated lemon peel, but none can be had for love or money, the LLM needs to be able to adapt to that. This is where the ‘judgment aggregator’ comes in: it can take in the information that a particular ingredient is not available, and feed that back into the system and adapt. LLMs can learn from feedback, and respond to the substance of feedback, rather than merely its fact(ual existence). This sets them apart from other ML models. And to me, this is what truly charts the course of their future.\n\n\nConclusion\nThis is the fifth and final post in a five-part sequence on what LLMs aren’t, and what they are, and what they could become, as the state of the art stands in late 2023. Beyond the anxiety and the abundant misunderstandings that have dominated discourse, there is something old and something new at play at the same time. That’s the kind of fault line where interesting things happen.\nI am putting the finishing touches on this post at SFO, a few miles from one of the most unstable fault lines in the Earth’s tectonic structure. The geographical determinist in me likes to think that being so near a fault line, so near a part of the Earth that is constantly reshaping itself – and will likely reshape anything taller than three stories in a pretty permanent and non-beneficial way – has played a role in Silicon Valley becoming what it is (or was?). Fault lines are where interesting stuff happens. The fault line between ‘traditional’ ML models and LLMs, which are undeniably somewhat novel if for nothing else their ability to interact with us in our most cherished human form of interaction – language –, is where interesting stuff is bound to happen. Like earthquakes, any pretense at being able to predict all but the most immediate future is folly and delusion, so I shall be careful not to do so. But I do think that the future of LLMs is not in the direction of the ‘big’ LLMs that are currently in vogue, but in the direction of smaller, more specialised LLMs that can interact with us, and with each other, in the role-defined and goal-directed agentic manner in which we as humans have interacted for our history.\nAnd there, as players on teams of rivals, is where LLMs will truly unfold their potential, tackling and embracing complexity to a degree that we have not seen before.\nAnd that’s where the real fun begins.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {Teams of {Rivals}},\n  date = {2023-10-30},\n  url = {https://chrisvoncsefalvay.com/posts/team-of-rivals/},\n  doi = {10.59350/he7k6-tx158},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “Teams of Rivals.” https://doi.org/10.59350/he7k6-tx158."
  },
  {
    "objectID": "posts/lyre-of-hephaestus/index.html",
    "href": "posts/lyre-of-hephaestus/index.html",
    "title": "The Lyre of Hephaestus",
    "section": "",
    "text": "I have probably spent more time looking at Poussin’s Dance to the Music of Time than any other work of art. Sneaking off to the Wallace Collection in London and just looking at the Dance was my comfort activity while living in London – a time that was not exactly devoid of its trials. It’s not, by any measure, great art, insofar as such judgments can be made with any objectivity. Like most French Baroque allegorical paintings, it’s considered somewhat ‘boring’. It neither has, nor claims to arrogate to itself, the fiery passion of a Van Gogh, the compositional genius of a Vermeer or the turbulence of a Turner. It’s not particularly well known, and indeed more know it for having lent its name to Anthony Powell’s dodecalogy (quite incidentally, another of my favourite works of art). In as far as there can be a sensible debate as to what is, and isn’t, ‘good’ or ‘great’ art, few would consider Dance to fall into that category. What nobody would argue, however, is that it is a piece of art.\n\n\n\nNicolas Poussin, Dance to the Music of Time.\n\n\nWhat, then, if I gave a somewhat clumsy description of the scene to Stable Diffusion, the currently fashionable model of generating images? Let’s try this:\n\nA painting, in the French Baroque style, of four female figures, allegories of the four seasons. They hold each other by the hand, dancing in a circle. Time, represented by an old man, plays a lyre. The scene is set in the early morning.\n\nHere’s what I got:\n\n\n\n\n\n\nFigure 1: Stable Diffusion’s attempt at my description of the Dance.\n\n\n\nIt’s not great by any stretch of the word. The faces, like in most diffusion models, are a mess. None of the figures get the allegory of time and seasons (of the year, but also of life, and of stations of an individual’s life). Certainly some more/better prompting could have gotten a slightly better result, but that’s really not the point.\nThe point is that it’s not art not because it’s not ‘good enough’ to be art, but because it is fundamentally, qualitatively different.\n\nOne art, please\nAt this point, we need to introduce a key concept to the argument to follow, namely that of a simulacrum. For the purposes of this argument, I shall define a simulacrum as follows: something that resembles the product of an intrinsically human activity but which can be obtained without that activity, including by non-human actors, such as non-human animals or, as it may be, artificial intelligences.\n\n\n\nOne art, please!\n\n\nAt the heart of the notion of a simulacrum is that the product and the process are different things. Art is not a product, but a process. I am, as I will explain later, not singling out art in some romantic exaltation of the artistic as quintessentially human, nor am I limiting art to what one might find in a museum. When I discuss art, I fully intend to include a toddler’s finger painting and even some absent-minded doodles on the margins of a less-than-gripping journal article.1 There are other activities that may become the subject matter of a simulacrum, language being perhaps of foremost interest (on which, once again, see infra). And just as Zoidberg can’t buy ‘art’, merely a ‘work of art’ (‘work’ here having the meaning of ‘product’ – an ‘artwork’ or ‘work of art’ being not something with ‘art characteristics’ but rather the result of the activity we know as ‘art’), an artificial intelligence or a non-human animal cannot create ‘art’, either.\n1 Because who of us hasn’t been bored enough by a dull paper to start doodling?At the heart of this is the difference between, of course, the process and the product. Artificial intelligence generally works according to a very simple inductive principle: given a bunch of examples (such as pairs of images and descriptions of images), learn the parameters of a function \\(f(d) = I\\) so that for any arbitrary description \\(d\\), an image \\(I\\) is generated so as to minimise a loss function \\(\\sum_{i=0}^N J(d_i, I_i)\\) over the \\(N\\)-sized training set. \\(f(d)\\) may be quite complex indeed, and \\(J(d, I)\\) may comprise various steps up to and including human input (reinforcement learning with human feedback – RLFH for short –, which is how most of the LLMs currently in vogue were trained, include this step quite prominently), but in the end, it’s all about learning \\(f\\). For a neural network, for instance, this ‘learning’ takes place by way of an algorithm called backpropagation, which changes the values of weights and bias matrices that form part of \\(f\\) so as to minimise \\(J\\). Regardless of how \\(f\\) is learned, what is at the heart of the entire process is learning a function that simulates the outcome. Stable Diffusion, for instance, is not concerned with simulating the process of creating art, it is concerned with simulating the outcome of creating art.\n\n\nHuman processes\nThat matters, because not everything is about outcomes. In fact, as humans, we recognise that some of the most important things aren’t. Consider moral judgment, the individual and societal assignment of a moral character to human actions. Yes, outcomes do matter, but they aren’t the be-all end-all of moral judgment. We differentiate between murder, manslaughter, reckless homicide, excusable homicide and justifiable homicide, even though the end result is the same (i.e. someone is dead), because we acknowledge that different levels of moral agency, and different forms of its exercise, are at play in each of these. We do so because we recognise humans are more than mere outcome generating machines: how (and why) something came to be is often just as important, if not more so, than what the end result is.\nThis is a uniquely human differentiation. In the same vein, then, there are things that only humans are capable of. A machine can certainly take a life, but it cannot commit murder, because the latter is defined not just by an outcome but also the mental state (mens rea) that led up to it. We think of Xerxes flogging the sea as the act of a megalomaniacal despot who has taken leave of his senses precisely because we recognise that punishing the sea, incapable of moral responsibility for its stormy waves washing away Xerxes’s pontoon bridges, as preposterous. Punishment requires, if not guilt, at least a subject capable of being guilty. Punishing the innocent is unjust, but punishing something incapable of being guilty or innocent or otherwise morally responsible is worse – it is insane.2\n2 Not that otherwise quite rationalistic societies did not engage in trials of lifeless things. Walter Woodburn Hyde wrote a wonderful paper on this.And just as moral guilt is uniquely human, so is creativity. This is not to suggest an exalted role for creativity – much as we tend to think of that term to have a positive meaning, for the purposes of this argument, creativity is any act of the mind that brings forth something. This comprises not just things like creating art, but also using language. There are many functions of language, ranging from the informative through the performative (what Searle called ‘speech acts’) to the phatic. However, humans communicating always do so with some intent. That’s different from machines using words. A machine uses words, and maybe uses language, but it does not ‘speak’, for that requires an intent, something no machine, howsoever sophisticated, can create. Like art, speech is not just about what, but the why, of an action. There are many reasons my neighbour greets me with “hey, how’re you doing?” – maybe it’s genuine interest in how I am doing, maybe it is as a kind of social bond-strengthening (phatic communication), but it is backed by some sort of intent that goes beyond just wanting to produce words.\n\n\nThe tune without the music\nA simulacrum, then, is what’s left when the uniquely human process is removed, and only the outcome remains, obtained through a different process (e.g. inference from a model generated by way of minimising the loss function over a training set). It is the tune without the music. A simulacrum doesn’t necessarily have to be ‘worse’ than the real deal – quite likely, Stable Diffusion can produce a better drawing than I could, and GPT-4 might well write a better poem than my hamfisted attempts at poetry. However, neither of those are the real thing. Stable Diffusion will be able to do better drawings than I do, but it won’t ever be able to do better art, because it’ll never be able to do art.\nIn that sense, it’s the opposite of ‘going through the motions’: a simulacrum is an often indistinguishable in its end product from the ‘real thing’, but arrives there by a different route. This is, indeed, why it is so deceptively similar to the ‘real thing’, and what gives rise to perhaps its darker side. In a recent interview on one of my favourite podcasts, Machine Learning Street Talk, Daniel Dennett referred to the simulacrum of human communicational interaction as “counterfeit people”. I disagree with some of Dennett’s position, but this is worth watching in its entirety:\n\nI think Dennett is wrong on a few points,3 but the language of ‘counterfeits’ gets some of this point across quite well. A counterfeit currency isn’t really all that different from an authentic bank note. What is different is the intent by which it is created. The counterfeit lacks the moral intent that it be honoured in return (that’s why people forge currency – there would be little point in counterfeiting bank notes if one actually intended to honour them!).4\n3 Importantly, I think he’s falling victim to the trap he so clearly identifies. The lack of moral agency of AI, which would make these pretend-humans something other than ‘real’ is exactly why the semantics of ‘counterfeiting’, which involves deception, an act of quintessential moral agency, is altogether inappropriate. But that’s for another day.4 Arguably, all modern fiat currency is at least a little fake, but that is also another argument for another day.\n\nThe heart of the matter\nIn the end, outcomes are not all that make us who we are. The poet, the artist, the murderer and the thief – they are who and what they are not solely because of outcomes, but because of what led up to those outcomes. And that’s ultimately the most human thing any of us will ever get to experience: to be someone not because of an outcome that a machine or an algorithm could feasibly mimic, but because of the quintessentially human process of decisions, good or bad, actions, passion, foibles. The things that make us who we are are in turn a product of who we are.\nAnd that’s what gives meaning to those outcomes, meaning that a machine-generated limerick could never aspire to – not because it is not ‘good enough’, but because it is just a qualitatively different thing. It is, to use Pauli’s turn of phrase, not that the Stable Diffusion-generated painting in Figure 1 is ‘not right’ (or aesthetically pleasing, in this case) – it’s that it’s ‘not even wrong’. It lacks the aptitude of being good or bad art, no matter how good or bad (likely the latter) it would be if it didn’t. It could, in theory, be good enough to put Poussin to shame, and it would still be no closer to being art. It could be Turner Prize-winning work,5 and yet be put to shame by a toddler’s finger-painting.\n5 Let’s, for the time being, entertain the notion that that still means something.A world in which the poet and the machine are on equal footing is a world that, for all intents and purposes, does not have poets anymore. It is a world in which outcomes determine everything, and that makes it a world that is not worth inhabiting: for a world of outcomes alone is a world in which our choices, our actions, our most irreplicably human strengths and weaknesses alike play no role.\nBut that is not the world we inhabit – thankfully. We – still? – live in a world in which the way we arrive at something, be it a poem or a painting or a dead body, matters. And as long as that is so, the simulacra of human action will remain inhabiting a different world of their own. They may reach a kind of technical verisimilitude, but not a moral verisimilitude.\nAnd that is what makes all the difference.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {The {Lyre} of {Hephaestus}},\n  date = {2023-10-16},\n  url = {https://chrisvoncsefalvay.com/posts/lyre-of-hephaestus/},\n  doi = {10.59350/pd0q6-r5n60},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “The Lyre of Hephaestus.” https://doi.org/10.59350/pd0q6-r5n60."
  },
  {
    "objectID": "posts/skierg-marathon/skierg-marathon.html",
    "href": "posts/skierg-marathon/skierg-marathon.html",
    "title": "Chris von Csefalvay",
    "section": "",
    "text": "import pandas as pd\nfrom matplotlib import pyplot as plt, gridspec, ticker, dates\nimport time\nimport seaborn as sns\n\nsns.set_style(\"darkgrid\")\n\n\ndata = pd.read_csv(\"./posts/skierg-marathon/concept2-result-79965221.csv\")\n\n\nfig = plt.figure(figsize=(6, 8), dpi=600)\n\ngs = gridspec.GridSpec(3, 1, height_ratios=[2,1,1])\ngs.update(hspace=0.2)\n\nax1 = plt.subplot(gs[0])\nax1.set_ylim(pd.to_datetime(190, unit=\"s\"), pd.to_datetime(130, unit=\"s\"))\nax1.plot(data[\"Distance (meters)\"], pd.to_datetime(data[\"Pace (seconds)\"], unit=\"s\"), color=\"#2f4b7c\", alpha=0.3, linewidth=0.5)\nax1.plot(data[\"Distance (meters)\"], pd.to_datetime(data[\"Pace (seconds)\"].rolling(33).mean(), unit=\"s\"), color=\"#2f4b7c\", alpha=0.6, linewidth=0.75)\nax1.plot(data[\"Distance (meters)\"], pd.to_datetime(data[\"Pace (seconds)\"].rolling(66).mean(), unit=\"s\"), color=\"#2f4b7c\", alpha=0.9, linewidth=1.25)\nax1.set_ylabel(\"Pace\")\nax1.xaxis.set_visible(False)\nax1.yaxis.set_major_formatter(dates.DateFormatter(fmt=\"%M:%S\"))\nax1.set_xlim(0, 42195)\nplt.gca().invert_yaxis()\n\nax2 = plt.subplot(gs[1])\nax2.plot(data[\"Distance (meters)\"], data[\"Watts\"], color=\"#2f4b7c\", alpha=0.3, linewidth=0.5)\nax2.plot(data[\"Distance (meters)\"], data[\"Watts\"].rolling(33).mean(), color=\"#2f4b7c\", alpha=0.6, linewidth=0.75)\nax2.plot(data[\"Distance (meters)\"], data[\"Watts\"].rolling(66).mean(), color=\"#2f4b7c\", alpha=0.9, linewidth=1.25)\nax2.set_ylabel(\"Watts\")\nax2.set_xlim(0, 42195)\nax2.xaxis.set_visible(False)\n\nax3 = plt.subplot(gs[2])\nax3.plot(data[\"Distance (meters)\"], data[\"Stroke Rate\"], color=\"#2f4b7c\", alpha=0.3, linewidth=0.5)\nax3.plot(data[\"Distance (meters)\"], data[\"Stroke Rate\"].rolling(33).mean(), color=\"#2f4b7c\", alpha=0.6, linewidth=0.75)\nax3.plot(data[\"Distance (meters)\"], data[\"Stroke Rate\"].rolling(66).mean(), color=\"#2f4b7c\", alpha=0.9, linewidth=1.25)\nax3.set_ylim(30, 55)\nax3.set_ylabel(\"spm\")\n\nax3.xaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))\nax3.set_xticks(ax3.get_xticks())\nax3.set_xticklabels(ax3.get_xticklabels(), rotation=90)\nax3.set_xlabel(\"metres\")\nax3.set_xlim(0, 42195)\n\nplt.show()\n\n\n\n\n\n\n\nFigure 1: Stroke level data for the SkiErg marathon.\n\n\n\n\n\n\ndata[\"ddistance\"] = data[\"Distance (meters)\"].diff()\ndata[\"dtime\"] = data[\"Time (seconds)\"].diff()\n\n\ng = sns.jointplot(data=data, \n                  x=\"dtime\", \n                  y=\"ddistance\", \n                  xlim=(0.5, 3), \n                  ylim=(2, 8), \n                  color=\"#2f4b7c\", \n                  kind=\"reg\", \n                  x_jitter=0.2, \n                  y_jitter=0.2, \n                  scatter_kws=dict(alpha=0.3, s=0.2))\ng.plot_joint(sns.kdeplot, \n             color=\"#a05195\", \n             zorder=0, \n             levels=16, \n             alpha=0.6, \n             fill=True)\ng.set_axis_labels(ylabel=\"$\\Delta_{d}, m$\", \n                  xlabel=\"$\\Delta_t, s$\")\nplt.show()\n\n\n\n\n\n\n\nFigure 2: Stroke level data of stroke length (metres) versus stroke duration (seconds).\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay,\n  author = {{Chris von Csefalvay}},\n  url = {https://chrisvoncsefalvay.com/posts/skierg-marathon/skierg-marathon.html},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. n.d. https://chrisvoncsefalvay.com/posts/skierg-marathon/skierg-marathon.html."
  },
  {
    "objectID": "posts/paxlovid/index.html",
    "href": "posts/paxlovid/index.html",
    "title": "Peace, love, Paxlovid and ‘Pfizermectin’",
    "section": "",
    "text": "As the new Omicron variant of concern of COVID-19 emerged over Thanksgiving week (of all times!), attention has been turning to Paxlovid (PF-07321332). If, like me, you torment yourself by perusing conspiracy theories, you might have heard it referred to as Pfizermectin. Behind that is the idea that the “COVID pill” Paxlovid is, basically, a re-packaging of ivermectin, a disproven treatment for COVID-19. (Popp et al. 2021)\n\nPopp, Maria, Miriam Stegemann, Maria-Inti Metzendorf, Susan Gould, Peter Kranke, Patrick Meybohm, Nicole Skoetz, and Stephanie Weibel. 2021. ‘Ivermectin for Preventing and Treating COVID-19’. Cochrane Database of Systematic Reviews, no. 7.\n\nThe Pfizermectin Gambit\nThe Pfizermectin argument rests on the fact that Paxlovid, an oral treatment for COVID-19 (colloquially known as a “Covid pill”) is a protease inhibitor, and so is ivermectin. Consequently, so the reasoning goes, ivermectin is just as good — except it is no longer an economically viable drug, vis-a-vis Paxlovid. So, it is claimed, ivermectin was repackaged, and now sold at a premium.\nSo suggests, for instance, paleo-libertarian Lew Rockwell:\n\n\nBiden Admin Plans ‘Imminent’ Booster Expansion; Orders 10M Courses of ‘Pfizermectin’By Tyler Durdenhttps://t.co/IMckQeK541\n\n— Lew Rockwell ((lewrockwell?)) November 19, 2021\n\n\nThe problem is… Paxlovid is not ivermectin. It is not even similar, and the difference is crucially important to why Paxlovid is likely to be an effective medication, and ivermectin won’t.\n\n\nWhat’s different about Paxlovid\nAs always, there’s a kernel of truth in the overall lie. It is true that both Paxlovid and ivermectin are inhibitors of the 3-chymotrypsin like protease (3CLPro). 3CLPro is the principal protease of coronaviruses. It belongs to a wider class called mixed-nucleophile proteases superfamily A. Their main function is to find peptide bonds in proteins between glutamine on one hand and serine, glycine or alanine on the other.\nTo understand what’s going on here, we need to look at protein synthesis by viruses. A lot of the time, viral proteins are produced as one big, long protein called a polyprotein. Then, viral proteases break these at pre-determined cleavage sites into the constituent parts of what eventually becomes a viral particle. As far as the virus is concerned, interference with that cleavage is bad, bad news, essentially inhibiting the ability of the virus to create copies of itself that are effective infectious agents.\n\n\n\nPaxlovid (PF-07321332, in blue) bound to 3CLPro (volume model). Author’s own work, based on PDB:7SI9.\n\n\nThis ‘molecular scissor’ in coronaviruses is 3CLPro, and as such, it’s clearly a target of interest. Mody et al., in a paper that has earned its spot on my list of top 10 papers of 2021, looked at 3CLPro inhibitors, and found that around 50 µM (micromoles) of ivermectin were sufficient to achieve a 75% or so reduction in the activity of 3CLPro. (Mody et al. 2021)\n\nMody, Vicky, Joanna Ho, Savannah Wills, Ahmed Mawri, Latasha Lawson, Maximilian CCJC Ebert, Guillaume M Fortin, Srujana Rayalam, and Shashidharamurthy Taval. 2021. ‘Identification of 3-Chymotrypsin Like Protease (3CLPro) Inhibitors as Potential Anti-SARS-CoV-2 Agents’. Communications Biology 4 (1): 93.\nHowever, that’s actually bad news — because 50 µM is, actually, a lot. And therein lies the problem.\n\n\nThe (pharmaco)kinetic difference\nThe problem with ivermectin is very simple. In order for an enzyme inhibitor to be effective, it needs to reach a concentration where it inhibits the target enzyme enough to make a dent in the underlying process. The standard metric for this is known as \\(IC_{50}\\) — the concentration of the inhibitor required to inhibit enzyme activity by 50%. This value for ivermectin is somewhere in the realm of tens of µM for 3CLPro.\nOne µM of ivermectin weighs around 0.0875mg, so a 1 µM solution of ivermectin would have a concentration of around 87.5 nanograms per millilitre (ng/mL). To reach even a very conservative 5µM, you would need blood levels of 437.5ng/mL.\nAnd that’s a problem, because above 80 or so ng/mL, ivermectin is pretty toxic. (González Canga et al. 2008) To reach the lowest conceivable limit of inhibitory action on 3CLPro would require doses that are incompatible with… well, life.\n\nGonzález Canga, Aránzazu, Ana M Sahagún Prieto, M José Diez Liébana, Nélida Fernández Martı́nez, Matilde Sierra Vega, and Juan J Garcı́a Vieitez. 2008. ‘The Pharmacokinetics and Interactions of Ivermectin in Humans—a Mini-Review’. The AAPS Journal 10: 42–46.\n\nOwen, Dafydd R, Charlotte MN Allerton, Annaliesa S Anderson, Lisa Aschenbrenner, Melissa Avery, Simon Berritt, Britton Boras, et al. 2021. ‘An Oral SARS-CoV-2 Mpro Inhibitor Clinical Candidate for the Treatment of COVID-19’. Science 374 (6575): 1586–93.\nThe alleged ‘Pfizermectin’ achieves this efficacy at a nanomolar level – at a concentration roughly ten thousand times lower. (Owen et al. 2021) At that concentration, Paxlovid is still well within its margin of safety.\nThis is not by accident, by the way. Paxlovid is the product of rational drug design, using computer models to identify a small molecule drug that is not only effective against an enzyme target but also has favourable pharmacokinetics. Far from merely ‘repackaging’ ivermectin, as the Pfizermectin theory alleges, this is an entirely new drug. It is structurally novel, and bears little resemblance, if any, to ivermectin. It was designed from the ground up to be orally effective, and be so at doses that are safe.\n\n\nConclusion\nIn the end, action happens in vivo — in real, living beings. Ivermectin might be a workable drug in vitro, where the model does not have to account for the inconvenience of actually keeping the host organism alive and breathing. To many of us who have looked at the maths of it, it has been clear that with the inhibitory concentrations required by ivermectin, it is never going to transition from the bench to bedside. Ivermectin does have a mechanism that counteracts SARS-CoV-2, the virus responsible for COVID-19. It’s just that it is way too weak to be of any practical use.\nPfizer’s drug developers have solved this through molecular dynamics simulations and rational drug design (and, in fact, have released a paper on just how they did it, which is very, very cool).(Zhang et al. 2021). Paxlovid is the result of this development — and it is far from being ‘Pfizermectin’ or repackaged ivermectin.\n\nZhang, Sheng, Maj Krumberger, Michael A Morris, Chelsea Marie T Parrocha, Adam G Kreutzer, and James S Nowick. 2021. ‘Structure-Based Drug Design of an Inhibitor of the SARS-CoV-2 (COVID-19) Main Protease Using Free Software: A Tutorial for Students and Scientists’. European Journal of Medicinal Chemistry 218: 113390.\nUntil now, much of the activity has been focusing on debunking misconceptions about the COVID-19 vaccine and sensationalistic tripe about the pandemic. As curative non-vaccine treatments are entering the market, it will be important to provide the public with the proof they need to dispel dishonest notions about the “Covid pill”. First and foremost among these is that the “Covid pill”, whether molnipiravir or Pfizer’s Paxlovid, is not a repackaging of ivermectin in any conceivable sense.\nAnd the strongest proof of that is the simplest, too: it works, in ways ivermectin is mathematically incapable of working.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2021,\n  author = {{Chris von Csefalvay}},\n  title = {Peace, Love, {Paxlovid} and “{Pfizermectin}”},\n  date = {2021-11-27},\n  url = {https://chrisvoncsefalvay.com/posts/paxlovid/},\n  doi = {10.59350/576dr-vbd49},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2021. “Peace, Love, Paxlovid and\n‘Pfizermectin’.” https://doi.org/10.59350/576dr-vbd49."
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks and presentations",
    "section": "",
    "text": "Prometheus Unbound - The Potential and Risks of Large Language Models in Public Health\n\n\n\n\n\n\nAI\n\n\npublic health\n\n\nNBPHE\n\n\n\nA short presentation on the risks and potentials of large language models in public health.\n\n\n\n\n\nJan 10, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/prometheus-unbound/index.html",
    "href": "talks/prometheus-unbound/index.html",
    "title": "Prometheus Unbound - The Potential and Risks of Large Language Models in Public Health",
    "section": "",
    "text": "Large language models (LLMs) like GPT have captured the public’s attention, raising both overinflated expectations of generalized artificial intelligence (AGI) and fears of a takeover of the machines. Yet, in the right hands, LLMs can be powerful tools for improving public health surveillance, detecting early signals of pathogenic outbreaks from noisy social media, and supporting data-driven decision-making at a hitherto unprecedented scale. This presentation will briefly introduce what LLMs are (and, more importantly, what they aren’t), followed by a discussion of possible applications in public health as well as their risks, concluding with an equity-centered perspective on creating safe and unbiased AI/ML tools. Public health experts will undoubtedly find themselves as consumers of, and sometimes interactors with, such models, making it all the more crucial to build a fact-based understanding of this new tool and discuss how its risks are best mitigated.\nOrganised by the National Board of Public Health Examiners as part of their Webinar Wednesdays and open to the public, you can register here for the webinar on 10 January 2024 at 3pm ET."
  },
  {
    "objectID": "talks/prometheus-unbound/index.html#slides",
    "href": "talks/prometheus-unbound/index.html#slides",
    "title": "Prometheus Unbound - The Potential and Risks of Large Language Models in Public Health",
    "section": "Slides",
    "text": "Slides\nThe slides are available here."
  },
  {
    "objectID": "talks/prometheus-unbound/index.html#recording",
    "href": "talks/prometheus-unbound/index.html#recording",
    "title": "Prometheus Unbound - The Potential and Risks of Large Language Models in Public Health",
    "section": "Recording",
    "text": "Recording\nTo be updated once the recording is available."
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "I am a visiting thesis supervisor for students on the data science track of the mathematics programme at the Budapest University of Technology and Economics. If you’re intending to write your thesis on a topic related to my research interests, you’re probably in the right place.\n\nProcedural aspects\nEach year, the department publishes a list of thesis topics. You can find the list for the current academic year. If you’re interested in one of the topics, you should contact the supervisor listed for that topic. If you’re interested in one of my topics, you should contact me.\nAs I am not full-time faculty, you will need to find an internal supervisor as well. The department has been very supportive of my students in the past, so this should not be a problem.\nWhile not a strict requirement, I would be very grateful if students aspiring to work with me could please make themselves known a few months before start of term. This will allow me to plan my time better, and to make sure that I can give you the attention you deserve.\n\n\nExpectations\nYou will generally be expected to create quality research-backed work based on the topic you choose. This means that you will need to read and understand the relevant literature, and you will need to be able to implement the algorithms you study. You will also need to be able to evaluate your work, and to compare it to existing methods. In short, you will need:\n\na good lit review,\na well-identified research gap,\na decent treatment of the latter, and\nall of this done in a sound, scientific and reproducible manner.\n\nThe expectation is that you will do the bulk of the work over a period of 6 months, and that you will be able to write up your results in a thesis of 40-60 pages. You will also be expected to present your work at a thesis defence.\nStudents may, at present, write their theses in English or in Hungarian. I have no preference for either, but I do expect that you will be able to write well in whichever language you choose. The lingua franca of data science, at the moment, is English, so if you’re planning to work in the field, you should probably be able to write in English. If you’re looking for employment abroad, a thesis in English will carry you a long way.\n\n\nTopics\nPast topics have included agent-based models of infectious diseases, disproportionality analyses of vaccination, computer vision on Synthetic Aperature Radar images for forest cover detection, and much more.\nEvery year I offer four topics for no more than two places. Of these, three tend to come from the biomedical domain, and at least one has some computer vision aspect. The topics are usually related to my research interests, and are usually related to my key research interests.\n\n\nTechnology\nAs far as I’m concerned, you can write your thesis using whatever widely used software you prefer. Obviously, writing your models in an esoteric language like Befunge or Malbolge will not endear you to the faculty, but within reason, you’re fine. Python by far is the most popular choice among my students.\nRemember that whatever topic you pick, you’re responsible for doing the work. This means that you will have to figure out how to cover costs of computation if these are non-trivial. The faculty may be able to help, as could I, but you should not expect this. This is particularly relevant for LLM related topics or where there are data access costs."
  },
  {
    "objectID": "posts/mrna-gene-therapy/index.html",
    "href": "posts/mrna-gene-therapy/index.html",
    "title": "Why the COVID-19 vaccines are not gene therapy",
    "section": "",
    "text": "There might be valid concerns about the mRNA vaccines. Then there are the clearly insane ones, such as the claims that it involves the injection of a microchip. The argument that mRNA vaccines are a form of ‘gene therapy’ are somewhere in the middle, and that makes responding to it somewhat difficult.\nThe origin of this claim is pretty self-evident: since the ‘payload’ of the mRNA vaccine is, well, as the name suggests, mRNA,1 it involves pushing genetic material into the recipient. That sounds rather gene therapy-y, does it not?\n1 Sort of. Strictly speaking, this is not entirely true: mRNA vaccines actually have three mRNA bases — C, G and A — and a fourth base, m1Ψ. This is a molecule called N1-methylpseudouridine, and it replaces U in the mRNA. It is ‘read’ and interpreted as U, but is vastly less immunogenic.These folks certainly think so:\nExcept the devil’s in the details. And the details are pretty unambiguous: mRNA vaccines are nowhere near a ‘gene therapy’.\n\nHow gene therapies work\nLet’s start by looking at a typical gene therapy: Zolgensma aka onasemnogene abeparvovec (say that three times quickly). This is an in vivo gene therapy, meaning that all the action takes place in the patient. It is given to very young children (under the age of 24 months) who have a certain mutation in the SMN1 gene, which leads to Type I spinal muscular atrophy. Onasemnogene abeparvovec is a modified adeno-associated virus 9 (AAV-9) that infects cells and gets them to produce ‘correct’ SMN1. This, then, alleviates their symptoms.\nThe key part to note is that a viral platform is used for a reason: viruses know how to enter nuclei and get them to produce to their instructions. They do so by providing what is called a nuclear localisation signal (NLS), a sequence that allows proteins to be shuttled inside the nucleus, across the nuclear membrane, typically by way of a protein called importin, one of the karyopherins. The vast majority of gene therapies leverage viral NLSs, because they’re pretty much free gifts from viral evolution. They work, and they’re widely used.\nGene therapy admittedly has some kinks that still need to be ironed out. Some things only seem to work well when using an ex vivo approach. An example for the latter are the CAR-T treatments, where the patient’s blood is drawn, T cells are isolated and then transfected with a viral vector. Currently, this approach works much better outside the patient (hence ex vivo) than inside them, largely because T cells make up such a small part of all cells in the body.\n\n\nHow mRNA vaccines work\nmRNA vaccines work in a much simpler way. It is, in many ways, a shortcut to the entire nuclear entry problem. If all you want is to make some proteins, you can skip the part about entering the nucleus and just, well, pretend to be the nucleus. Here’s how that roughly works.\nDNA is the stable, long-term ‘hard’ storage of cells. It’s slow and unwieldy, but relatively resilient. RNA is the volatile storage medium: small, quick and of a limited lifespan. During a process called translation, DNA is translated, eventually, into mRNA.2 mRNA then heads for the ribosomes like a sort of work order, which the ribosomes fulfil by making the protein it describes. This is a quick and dirty description of the central dogma of molecular biology, of course.\n2 More specifically: it is translated into pre-mRNA, which is then spliced to get mRNA.Because mRNA vaccines only need to make relatively simple proteins (compared to having to make a whole virus), they can simply go directly to the ribosomes: no need to get involved in that whole mess about nuclear entry. The tradeoff, of course, is that mRNA is quite rapidly degraded. For applications like Zolgensma, where we want cells to keep producing SMN1 for a prolonged period, the extra effort to effect nuclear entry makes sense. For mRNA vaccines, on the other hand, all we really need is a ‘spill’ of proteins that approximate some of the shapes of the Spike protein from SARS-CoV-2. That’s enough to elicit an immune reaction, create antibodies and memory lymphocytes and with that, the whole infrastructure of humoral and cellular immunity.\nOr, by way of analogy: you receive other vaccines as a one-time shot, rather than as a lifelong intravenous infusion, right? Immunity doesn’t need sustained exposure — the immune system is pretty quick at catching on. For the very same reason, there’s no need to permanently express the Spike-like protein the way there is a need to keep expressing SMN1 in the Zolgensma example.\n\n\nWhy mRNA vaccines are not gene therapy\nThis is hardly a differentiation without distinction. Gene therapy is, well, serious business. Almost 22 years ago, a young man named Jesse Gelsinger died from what we would today call a Multisystem Inflammatory Syndrome (MIS) following an adenovirus-vectored treatment for X-linked ornithine transcarbamylase deficiency, an inborn defect of metabolism. Modern gene therapies are still in many ways in their infancy, requiring close supervision and, often, extensive pre-treatment. They might be ready for prime time, but they certainly aren’t at the ‘all audiences’ stage just yet. And that’s ok — the first antibiotics were equally quite iffy from today’s perspective, and I am absolutely sure that within 25 years, the most frequent genetic disorders that gene therapy can fix — such as certain muscular dystrophies, cystic fibrosis or sickle cell anaemia — will be considered treatable with gene therapies. For now, however, gene therapies are complex treatments that demand experienced medical teams.\nFortunately, that is not the case for the COVID-19 mRNA vaccines. These vaccines are not only remarkably safe (I have written about their neurological safety, safety vs autoimmune disorders, overall safety and safety vs anaphylactic events, and there’s a summary of these findings here) but also operate in a way entirely distinct from gene therapies. They do not enter the nucleus, they do not effect lasting changes (in fact, that’s one of the reasons why mRNA approaches for the gene therapy of chronic diseases have so far been less than successful) and they do just what it says on the tin: produce Spike-like proteins to elicit an immune response.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2021,\n  author = {{Chris von Csefalvay}},\n  title = {Why the {COVID-19} Vaccines Are Not Gene Therapy},\n  date = {2021-11-09},\n  url = {https://chrisvoncsefalvay.com/posts/mrna-gene-therapy/},\n  doi = {10.59350/s2xc9-mwp25},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2021. “Why the COVID-19 Vaccines Are Not Gene\nTherapy.” https://doi.org/10.59350/s2xc9-mwp25."
  },
  {
    "objectID": "posts/skierg-marathon/index.html",
    "href": "posts/skierg-marathon/index.html",
    "title": "How to do a SkiErg marathon entirely the wrong way (but still finish)",
    "section": "",
    "text": "Yesterday, I completed a marathon on the SkiErg, with a pretty respectable time (see results here). I know I can do better, and I know I will do better. On the other hand, this was a marathon where I pretty much did everything wrong. And that was sort of an instructive experience in its own right.\nThe title is somewhat misleading. Not much went wrong – the marathon itself was smooth sailing. At a 2:34.6 pace (min/500m), it was one of my better very long distance pieces – my ranked half-marathon pace at the time was 2:30.7, and that was a very intentional, very prepared piece. There were also really no unexpected surprises in the process. On the other hand, I built up to this marathon the in worst way possible.\n\nWhat worked for me\nIt’s probably important to be realistic ahead of all: I did go into this madness with some assets.\n\nFor one, I’m a multiple world record holder in my adaptive class. I know a thing or three about the SkiErg, and as a former rower, I’ve got every rower’s love-hate relationship with the erg.\nI’m a former multisport athlete, and I’ve been doing a lot of long distance pieces. I know how to cope with the boredom. Most people who go into a marathon have done a half, and maybe a 30k piece. I’ve done several split marathons in the past few weeks, as well as several 30k pieces.\nI’m probably in a pretty good state of overall fitness. I have enough of a gym habit to qualify as not exactly a couch potato. There’s a lot you can get away with if you have a decent \\(VO_{2_{max}}\\), and even though I’m in a wheelchair, I do enough activity to stay in good enough cardiovascular fitness.\nI have an incredible boredom tolerance. Marathons are primarily psychological: we’re just not used to doing the same one thing, without interruption, for 3-5 hours anymore.\nI guess insofar as there’s such a thing as a genetic predisposition to be good at long distance physical activity, I’ve got the right genes. My dad is a multi-marathon athlete, so I likely have the right physiology.\n\n\n\n\n\n\n\n\n\n\nFigure 1: Stroke level data for the SkiErg marathon.\n\n\n\n\n\nSource: skierg-marathon.ipynb\n\n\nHow not to do a marathon\nThere are generally three commonly accepted things to do for a good long distance piece:\n\nget some rest,\ncarb load, and\nif you’re not doing an organised race, have someone check in on you and help with things like hydration.\n\nI’ve done exactly zero of these things. For starters, I did my marathon in the middle of 75 Hard, which in retrospect was not the best of ideas, as it meant that (1) I wouldn’t be able to take days off to rest, and (2) I wouldn’t be able to carb load as that would be outside my diet. I’ve also decided to do all this while my better half was away visiting family, so I was pretty much on my own.\nAt 2am.\n\n\n\n\n\n\n\n\n\nFigure 2: Stroke level data of stroke length (metres) versus stroke duration (seconds).\n\n\n\n\n\n\nYes, that’s not a joke – I decided to do my marathon at a time when the world is falling apart at the seams, and so the only time I could find during which I could hope not to be interrupted with the latest crisis was late at night. So I woke up at 0130 hours, much to my dog’s chagrin, and headed down to my apartment building’s gym to torture myself for a few hours before the sun came up. Fortunately, the world decided to behave for those three and a half hours.\nI tried to counteract this to some extent by doing something I generally dislike: carbohydrate gels. A long, long time ago, in a galaxy far away, I ran the Watford half-marathon when I was still into actually running (by far the only reason I remember where that half-marathon was is because it was so miserable). It was a bitter cold day, and it actually started snowing in the middle of the damn thing. To keep myself mostly sane and nourished, I took some of these 100kcal sachets of carbohydrate gel. What I didn’t know, of course, was that that stuff would glue your mouth together unless you consumed enough water… which I didn’t. Bad idea. On the other hand, I am now older, wiser and able to afford much better and less sticky-tastic carbohydrate gels, so I thought I was going to have some. I didn’t feel much of an effect one way or the other. At one 100kcal sachet for every hour, I paced it a little slower than is commonly recommended (one sachet per every 45 minutes seems to be the consensus recommendation), but really didn’t feel much of an effect either way. In retrospect, I probably wouldn’t bother doing it again.\nAs for rest, the best I could do is not do a long distance piece the day before the marathon. Indeed, I only did a relaxing 2k that day, which is about a fifth of my average daily SkiErg distance. Nevertheless, I think it was quite clear that with my ultra-low-carb diet, no carb loading and at best minimal replenishment (my average burn rate was around 5-600kcal/hr, and I took in 100kcal via the carbohydrate gels, so pretty much a drop in the ocean), I was running on fumes for most of it.\n\n\n\nIncidentally, my marathon time is also the SIT2 world record for my age group.\n\n\n\n\nTakeaways\nMy key takeaway from this experience was that we all should do a marathon under suboptimal conditions. Yes, doing a long distance piece at Bataan death march levels of calorie deficit is probably not super healthy, but you learn some interesting things about your body in the process. For starters, I think it was an interesting illustration of the fact that one’s overall level of fitness – especially \\(VO_{2_{max}}\\) – matters a lot more than game day conditions. You can get away with a lot if you’re fit enough, up to and including running the show in quite sub-optimal circumstances.\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {How to Do a {SkiErg} Marathon Entirely the Wrong Way (but\n    Still Finish)},\n  date = {2023-10-13},\n  url = {https://chrisvoncsefalvay.com/posts/skierg-marathon/},\n  doi = {10.59350/68s7b-8c778},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “How to Do a SkiErg Marathon Entirely\nthe Wrong Way (but Still Finish).” https://doi.org/10.59350/68s7b-8c778."
  },
  {
    "objectID": "posts/after-agents/index.html",
    "href": "posts/after-agents/index.html",
    "title": "After agents",
    "section": "",
    "text": "When he first began his excavations at what is today Hisarlik in modern-day Türkiye, he set out to find a single city – the city of Homer’s Iliad, a city many actually felt lay in the realms of fiction rather than any map Schliemann could lay his hands on. By the time excavations were over, Schliemann would find not one but nine cities, all built on top of each other.1 In that, he found something relatively common – cities built on top of cities, each turning the last one into the foundation of the next.\nTechnology is not much different. What Newton described as ‘standing on the shoulders of giants’ was an astute reflection of this fact. When I surveyed the landscape of LLMs in late 2023, I saw – and I was not alone in doing so! – that there was more to the practical application of LLMs than their most ubiquitous ‘low hanging fruit’ use case at the time, that is, chatbots and conversational interfaces. That notion, of course, became the agentic revolution that emerged as the most talked-about topic of 2024.\nIf your hot take for 2025 is that ‘agentic AI is going to dominate’, however, you have missed the train. The agentic revolution is over, done and accomplished. In my wild-ass guessing of what 2025 may bring, I tried to reflect as a leading theme on what I believe comes after agents – namely, systems of interaction. In this post, I hope to expand on that notion a little."
  },
  {
    "objectID": "posts/after-agents/index.html#agents-are-over-long-live-agents",
    "href": "posts/after-agents/index.html#agents-are-over-long-live-agents",
    "title": "After agents",
    "section": "Agents are over (long live agents!)",
    "text": "Agents are over (long live agents!)\nLooking back at 2024, I have to laugh at how quickly the agentic revolution went from being seen as wild-eyed speculation to something almost embarrassingly obvious. I spent a good chunk of late 2023 explaining to sceptical audiences why autonomous AI agents were not just chatbots that could call APIs. I would spend most of the next year fielding calls from the same audiences to help develop a strategy for agentic AI. The whiplash-inducing speed of this transformation was stunning even by AI’s standards, where we seem to have moved into a 24-minute, rather than 24-hour, news cycle. What started as hacky demos and GitHub repos with more stars than working features evolved into agents casually writing production code, running research pipelines and tying all of this together into operational workflows that actually made sense. The real shift was not just in what these agents could do – it was in how they subtly changed our relationship with AI systems in the process. We went from the digital equivalent of playing 20 Questions with chatbots to having persistent virtual assistants that could actually maintain context, manage complex tasks and make reasonable decisions without needing to be guided through every minor choice. For someone who spent years working with the digital equivalent of goldfish, this was heady stuff.\nThe thing about agents is that their true power is not in what they can do alone – it is in how they work together. This is not just some hand-wavy My Little Pony-esque ‘collaboration is magic’ adage. It is fundamental to the nature of what an agent is, and why we even bother with them. An agent that can write code is useful, but an agent that can write code while collaborating with another that handles testing while yet another manages deployment and a fourth monitors performance is truly transformative. The industry’s current obsession with making individual agents (or, even worse, just individual foundation models) more powerful is like trying to make a better dish by adding more of a particular ingredient.2 The magic of a perfect meal lies not in how many spoonfuls of exotic ingredients like fennel pollen and saffron threads you can dump into your pan, but in the fine balance between whatever ends up on a plate – even if it is just arugula, shaved parmesan and balsamic glaze (see recipe in sidebar). In short, the magic is in the complex web of interactions between the ingredients, the emergent phenomena that arise from their coexistence. We see this pattern play out all the time in technology. The apex of maturity always involved interaction. Consider, most ubiquitously, the web: from individual sites, we evolved to a more semantic web and eventually, a knowledge/information ecosystem driven through APIs. We are at the cusp of that third phase with AI agents, and anyone still fixated solely on individual agent capabilities is missing the plot entirely.3\n2 More AI folks should spend more time in the kitchen. This is my hot take for 2025.3 This is even more so as agents themselves are becoming meaningless. An agent, in a properly designed ecosystem, is entirely replaceable. It implements a contract or protocol. It then does not quite matter what that agent does. And if that sounds a little like the Liskov substitutability principle, then that is not quite by accident.\n\nRecipe: The simplest salad you’ll ever love\n\nA bunch of baby arugula\n1/4 cup of your favourite nuts\nfreshly ground salt and pepper\nParmigiano Reggiano, lots\n1 clove garlic\n1/4 cup lemon juice, freshly squeezed\n1/2tsp honey\n1/4 cup extra virgin olive oil\n1tsp Dijon, the smoother the better\n1/2tsp fresh thyme\noptional: a good balsamic reduction\n\nMix the lemon juice, minced garlic, Dijon and honey, and salt & pepper to your heart’s content. While whisking, drizzle in the olive oil. Add the thyme and taste – add some more olive oil if it’s too acidic for your taste. In a separate bowl, add the arugula, and toss it with the vinaigrette you just made. Mix, using your hands – plastic or wooden mixing tools break the arugula leaves, which renders the whole thing bitter. Plate, then cover with the nuts. Using a coarse Microplane grater, shave enough Parmigiano Reggiano to make the whole thing a happy mixture. Enjoy on its own or as a light side.\n\n\nWe are already seeing the first tentative steps from multi-agent systems towards ecosystems of agents, even if most have not recognised them as such. Enterprise agent marketplaces will be 2025’s hot commodities, drawing on past experiences with data marketplaces and exchanges. But conceptually, most seem to still treat agents as distinct pieces of software rather than collaborators in an ecosystem. The real pioneering work for the coming year(s) will be in developing the frameworks and protocols at the edges: agent orchestration systems that go beyond simple API calling, trust negotiation protocols that let agents establish their capabilities and limitations and collaborative frameworks that enable genuine multi-agent workflows. Technical implementations of these, however, are scarce. Working out an interaction protocol is not glamorous (trust me – speaking from personal experience), and there are going to be few headlines and fewer medals in working out how this sudden flood of AI agents is going to interoperate. And yet, this is the manifest destiny of agentic AI. Of all targeted agentic AI spend in 2025, marketplaces and interoperability orchestrators will without a doubt be the best dollars spent bar none."
  },
  {
    "objectID": "posts/after-agents/index.html#from-agents-to-ecosystems",
    "href": "posts/after-agents/index.html#from-agents-to-ecosystems",
    "title": "After agents",
    "section": "From agents to ecosystems",
    "text": "From agents to ecosystems\nWhat is an ecosystem? In its natural sense, we have relatively little trouble distinguishing between a species, an individual, a population and an ecosystem. In short, an ecosystem has three distinguishing features:\n\nDiversity: ecosystems consist of multiple species that all play their role, quite similarly to agents in a well-architected system.\nInteractions/rhizomality: ecosystems become what they are from the interactions between their participants, not the mere assemblage of the participants. In that sense, a good meal is an ‘ecosystem’ of sorts, where the acids balance out the fats and so on. In a more functional context, however, as we are dealing with here, what makes a bunch of agents an ecosystem is their ability to exercise a higher function in complementarity.\nInterdependence: ecosystems produce their benefits through these interactions, which collectively amount to more than the sum of the parts.\n\nIn an agentic AI system, our definition can largely be similar: an agentic AI ecosystem is a bunch of agents with different functionalities that interact and thereby unfold value. An ecosystem implies more than just the ability to pass messages between agents or chain them together in sequence. It requires the emergence of specialisation, of niches, of ways to establish trust and capabilities, and – crucially – ways to negotiate the terms of interaction. Unlike today’s relatively deterministic structures, this environmental discovery could eventually be self-governing, more like a bustling market bazaar, where agents can discover each other’s capabilities, negotiate terms of engagement, establish trust relationships, and even form longer-term collaborative partnerships. This is a fundamental reimagining of how artificial intelligence systems interact with each other.\nThe emergence of enterprise agent marketplaces will be one of the defining developments of 2025, but most organisations are still thinking about them wrong. The knee-jerk reaction is to build something akin to an app store: a catalogue of pre-built agents with rating systems and standard pricing. That is a useful (and often indispensable) first step, but it could be so much more. The real value of these marketplaces will not be in the agents themselves, but in the curation and verification mechanisms they enable. Think less ‘app store’ and more ‘commodity futures exchange’: what matters is not just what is being traded, but the rules of engagement, the verification of capabilities, the establishment of trust, and the standardisation of interfaces. We will need ways to verify that agents can actually do what they claim, that they operate within defined constraints and that they can be trusted with sensitive data or critical operations. This is where enterprise agent marketplaces will differentiate themselves from consumer platforms – through robust governance frameworks that make agent deployment actually feasible in regulated environments.\nThe real challenge – and opportunity – in building these ecosystems lies in standardising the right things while leaving room for innovation. Over-standardisation kills ecosystems as surely as no standardisation at all. The emerging protocols for agent interaction will need to thread this needle. They will have to standardise the essential patterns of trust establishment, capability discovery and resource negotiation, while remaining flexible enough to accommodate new forms of agent collaboration we have not even imagined yet. This is where the enterprise agent marketplace builders of 2025 will either make their fortunes or waste their investors’ money. The winners will be those who create the right balance of structure and flexibility – the ones who understand that they are not building an app store so much as cultivating an ecosystem."
  },
  {
    "objectID": "posts/after-agents/index.html#trust-falls-and-rises",
    "href": "posts/after-agents/index.html#trust-falls-and-rises",
    "title": "After agents",
    "section": "Trust falls (and rises)",
    "text": "Trust falls (and rises)\nThe hardest part of building these agentic ecosystems is not the technical implementation (in fact, we arguably have most of that already in place, mutatis mutandis, for data and other asset marketplaces) – but the trust architecture. In particular where agents choose and commission other agents to perform tasks as delegates or helpers, we need to find protocols that outline the powers of delegation and the flows of authority in such an architecture. The frameworks we are building now are laughably primitive compared to what we will need, mostly amounting to simple API keys and rate limits. It is like trying to build a modern financial system with nothing but paper IOUs and handshake agreements.\nThe chain of trust problem in agent delegation is fascinating precisely because it mirrors and yet fundamentally differs from how we handle human organisational hierarchies. When Agent A delegates a task to Agent B, which in turn needs to commission Agent C, we are not just passing around access tokens - we are creating a chain of responsibility that needs to be both traceable and constrained. Each link in this chain needs to carry not just the authority to act, but also the constraints and audit requirements of all previous links. An agent operating as a fourth-level delegate should still be bound by the original constraints set at the root of the delegation tree, even if it has no direct knowledge of them. This is not just about security - it is about maintaining coherent behaviour across increasingly complex chains of interaction. The financial sector learned this lesson the hard way with automated trading systems: without clear chains of responsibility and well-defined constraint propagation, you end up with cascading failures that no single participant can explain or control.\nThe next year will be defined not by breakthroughs in individual agent capabilities, but by our success or failure in building these frameworks for trusted collaboration. The winners will not be those who build the most powerful agents, but those who crack the code on helping agents work together effectively and safely. This is not just about technology – it is about understanding how to create systems of trust that can scale with the complexity of agent interactions.\nThe agentic revolution of 2024 was just the overture. The real symphony begins when we figure out how to let the players actually work together in concert. Those who are still focused solely on building better individual agents are composing for soloists in an age that demands orchestras.\nThe future belongs to those who can conduct.\n\nNote: These are my personal (and somewhat tongue-in-cheek) views, and may not reflect the views of any organisation, company or board I am associated with, in particular HCLTech or HCL America Inc. My day-to-day consulting practice is complex, tailored to client needs and informed by a range of viewpoints and contributors. Click here for a full disclaimer."
  },
  {
    "objectID": "posts/auto-doi/index.html",
    "href": "posts/auto-doi/index.html",
    "title": "Auto-DOI for Quarto posts via Rogue Scholar",
    "section": "",
    "text": "I love posts that allow me to merge some of my addictions. In this case, it’s my love for Quarto project scripts (which I’ve written about elsewhere), my fondness for Rogue Scholar and the overuse of the word ‘mint’ to mean ‘generally really quite rather nice’.\nRogue Scholar is a fantastic tool for science bloggers, and while it’s a little artisanal (i.e. hand-made much of the time) at this point, it’s got some really cool automated features. One is that it registers (mints, hence the abundance of lame peppermint puns across this post) DOIs for your posts.\nI’ve been using Rogue Scholar to mint DOIs for my posts for a while now, but it’s always been a bit of a manual process. I’d have to wait for a while for the post to go on the Rogue Scholar feed, then copy/paste the DOI, then copy the DOI into the YAML front matter. It’s not a lot of work, but it’s a bit of a pain. I’ve been meaning to automate it for a while, but I’ve been busy with other things.\n\n\n\n\n\n\nNote\n\n\n\nJust after I posted about this solution, Martin Fenner, who runs Rogue Scholar, pointed out that there’s now an API. The API is great, and would have spared me the part of having to scrape the HTML. I will, one of these days, switch over – if I had to build it, I’d obviously use the API, and simply parse the JSON result. The rest, ceteris paribus, holds true.\n\n\nThis weekend, I was laid up with being on the receiving end (for once) of the bounties of a clinical trial, so I’ve decided to finally build it. It’s a bit of a hack, but it works.\n\n\n\n\n\n\nflowchart TD\n    linkStyle default interpolate basis\n    A[\"Get last 10 posts with DOIs from RS\"]\n    \n    subgraph loop[\"Loop through posts\"]\n    B[\"Read YAML preface\"] --&gt; C{\"Is post a cross-post?\"}\n    C --&gt;|yes| skip\n    C --&gt;|no| D{\"Is post citeable?\"}\n    D --&gt;|no| skip\n    D --&gt;|yes| E{\"Do we have a DOI?\"}\n    E --&gt;|no| skip\n    E ----&gt;|yes| F[\"Get DOI\"]    \n    end\n\n    A -----&gt; E\n    F --&gt; apploop[\"Append loop to YAML\"]\n    apploop --&gt; write[\"Write YAML\"]\n    write --&gt; qr[\"Quarto Render\"]\n    write --&gt; ghc[\"Github commit action\"]\n\n\n\n\nFigure 1: Auto-DOI flow chart.\n\n\n\n\n\nFirst, we scrape Rogue Scholar for titles and DOIs. Rogue Scholar’s CSS isn’t really helpful here, as the link isn’t a particular class/id of its own as far as I could discern, so I just grabbed the link by the fact that only DOI links are formatted like DOI links. Not the most elegant way, but it does the job.\n\n\n\nListing 1: Getting the DOIs from Rogue Scholar.\n\n\n\ndef scrape_blog_for_dois(url) -&gt; Dict[str, str]:\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    articles = soup.select('article')[:10]\n    \n    posts_with_dois = {}\n    \n    for article in articles:\n        title = article.select_one('h3').text\n        doi_link = next((a['href'] for a in article.select('a') if a['href'].startswith('https://doi.org')), None)\n        if doi_link:\n            doi = doi_link.split('https://doi.org/')[1]\n        else:\n            doi = None\n        posts_with_dois[title] = doi\n\n    logging.info(f\"Found {len(posts_with_dois)} posts with DOIs:\")\n    for title, doi in posts_with_dois.items():\n        logging.info(f\"{title}: {doi}\")\n    return posts_with_dois\n\n\n\n\nTechnically unnecessary, as Rogue Scholar currently only displays ten links, but hey.\nThis is where we split the DOI link into the link prefix and the DOI. We don’t need the prefix, so we just grab the second part of the split.\n\nNext, we iterate through each blog post. This is actually quite fast, since (1) we have relatively few of them, (2) they’re text documents. We parse the YAML preface at the beginning of each of them. This looks something like this:\n\n\n\nListing 2: Pre-DOI YAML preamble example.\n\n\ncategories:\n- Quarto\ncitation: true\ndate: 2023-11-13\ndescription: 'Oh, that''s mint. We can finally use Rogue Scholar to mint DOIs for Quarto posts and append them automagically.'\ngoogle-scholar: true\ntitle: Auto-DOI for Quarto posts via Rogue Scholar\n\n\n\nWhat this tells us is that we do want a citation (someday), which is why we’re doing this in the first place. That, according to our beautiful flowchart in Figure 1, means this post is eligible to get a DOI appended. We also know there isn’t one – DOIs are appended as key-value pairs (with the key being, unsurprisingly, doi) to the citation object in the YAML preface. So, we’ll see if we can get one by looking in the dictionary we scraped from Rogue Scholar in Listing 1.\n\n\n\nListing 3: Processing a single post.\n\n\n\ndef process_qmd_file(file_path: str, posts_with_dois: Dict[str, str]) -&gt; None:\n    with open(file_path, 'r') as stream:\n        contents = stream.read()\n\n    delim = re.compile(r'^---$', re.MULTILINE)\n    splits = re.split(delim, contents)\n    yaml_preamble = splits[1].strip() if len(splits) &gt; 2 else \"\" #\n    rest_of_post = splits[2] if len(splits) &gt; 2 else contents\n\n    yaml_contents = yaml.safe_load(yaml_preamble) if yaml_preamble else None\n\n    if yaml_contents:\n        citation = yaml_contents.get('citation')\n        google_scholar = yaml_contents.get('google-scholar')\n        categories = yaml_contents.get('categories', [])\n        title = yaml_contents.get('title')\n\n        # Check files from crosspost categories\n        if any(\"cross-post\" in category.lower() for category in categories):\n            if yaml_contents[\"citation\"] == True or yaml_contents[\"google-scholar\"] == True:\n                yaml_contents[\"citation\"] = False\n                yaml_contents[\"google-scholar\"] = False\n                logging.info(f'Modified crosspost {title} to remove Google Scholar and/or citation reference.')\n        else:\n            # Ensure that google-scholar is set to true if citation is required\n            if citation and not google_scholar:\n                yaml_contents[\"google-scholar\"] = True\n                logging.info(f'Setting google-scholar to true for {title}')\n\n            # If citation is true but no DOI, and post exists in scraped posts\n            if citation is True and posts_with_dois.get(title):\n                yaml_contents['citation'] = {'doi': posts_with_dois[title]}\n                logging.info(f'Adding doi for {title}.')\n\n        new_preamble = yaml.dump(yaml_contents).rstrip()\n        new_yaml_doc = f\"---\\n{new_preamble}\\n---\"\n\n        # write the modified YAML document back to file\n        with open(file_path, 'w') as yaml_file:\n            yaml_file.write(new_yaml_doc + rest_of_post)\n        logging.info(f'Updated file {title}')\n        \n\n\n\n\nWe have to split the document in two because only the preamble is proper, parseable YAML. The rest of the document is just text, so we have to recombine it later.\nIf it’s a cross-post, we don’t want it to have a Google Scholar link, and we’ll definitely not attach a DOI. In theory, we could have built this to be overridable in case I’ll ever produce a cross-post I do want to have a DOI, but I don’t see that happening.\nWhile we’re at it, might as well prune the cross-posts.\nAnd anything with a DOI should also get a Google Scholar metadata.\nThe .rstrip() is pretty useful – otherwise, every time you run this, you’ll get another newline appended to the YAML preface.\nDon’t forget the \\n before the YAML block’s end, otherwise you’ll end up with a YAML block that’s not properly separated from the rest of the document and won’t parse.\n\nFinally, we write the YAML back to the file, and we’re done. We can now declare this as a project script, and we’re good:\n\n\n\nListing 4: Declaring project scripts in _quarto.yml.\n\n\n\nproject:\n  type: website\n  pre-render:\n    - scripts/pre_doi_from_rogue_scholar.py\n    \n\n\n\nOne thing worth noting is that we’re not actually running this on the Quarto project itself, but on a copy of it. The consequence is that the changes are made ‘on the fly’ to the .qmd files and do not necessarily propagate into the repo. This is a pain, because recall that we’re only fetching the last ten posts’ DOIs so as to be kind on the server: as time goes on, that means older posts ‘lose’ their DOI.\nTo prevent this, we can simply check our changes back in:\n\n\n\nListing 5: Github action to commit changes.\n\n\non:\n  workflow_dispatch:\n  push:\n    branches: main\n\nname: Quarto Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Install Python and dependencies\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n          cache: 'pip'\n      - run: pip install jupyter\n      - run: pip install -r requirements.txt\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      \n      - name: Commit changes to reflect source file  changes\n        run: |\n          git config --global user.name 'Chris von Csefalvay'\n          git config --global user.email 'chrisvoncsefalvay@users.noreply.github.com'\n          git  diff-index --quiet HEAD || git commit -am  \"Automated commit of changes to source files\"\n          git push\n\n\n\n\nThe diff-index --quiet HEAD checks if there have been changes to the working tree. git returns an error if you’re trying to commit on an empty working tree, so we’re checking for that first.\n\nAnd that’s it. We can now run this as a Github action, and it’ll automatically append DOIs to our posts.\nAs noted: Quarto project scripts are pretty awesome stuff. I’m thinking of setting up an awesome- for it on Github, because way too few of them are shared properly. I’m hoping this will change.\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {Auto-DOI for {Quarto} Posts via {Rogue} {Scholar}},\n  date = {2023-11-13},\n  url = {https://chrisvoncsefalvay.com/posts/auto-doi/},\n  doi = {10.59350/5hxdg-fz574},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “Auto-DOI for Quarto Posts via Rogue\nScholar.” https://doi.org/10.59350/5hxdg-fz574."
  },
  {
    "objectID": "posts/julia-a-post-mortem/index.html",
    "href": "posts/julia-a-post-mortem/index.html",
    "title": "Julia: A post-mortem",
    "section": "",
    "text": "A little over half a decade ago, I came across a wonderful project: a programming language called Julia that was going to revolutionise data science and technical computing. It was going to run like C, seamlessly integrate with Fortran, do things R does without its clunkiness, look and read like Python and be homoiconic like Lisp. We were all going to heaven, and that right soon. The language wars would end, we would finally get a lingua franca for anywhere code performance mattered, Julia would take over the TIOBE Index, and we’d all be home for tea and medals.\nI was so enthusiastic, I learned all there was to learn about Julia, and even pitched a book to Manning, who graciously accepted Learn Julia into their Early Access programme. Interest was lukewarm at best, which should have been a warning sign. Eventually, Manning felt there would not be a sufficient market for the book – and I don’t blame them. Much of the book’s contents are now available on Github, and are a pretty good introduction for getting into the language.\nFast forward to 2020: Julia is currently on the 34th position (narrowly missing the first tercile) on the TIOBE ratings. More people use FoxPro, a database language that reached end-of-life almost fifteen years ago, than Julia. Vastly more people use Scratch, a language that for all intents and purposes is a ‘learning’ language. Almost twice as many developers use COBOL and Fortran as use Julia, and both of those languages are nearing the retirement age in most Western countries.\nSomething has clearly gone wrong. While Julia is not dead, and there are some very committed developers who expand the ecosystem, it is clear that the initial promise of Julia is unlikely to be realised. Instead of becoming the language, it will become just another language. Here are my thoughts why that’s the case.\n\nIt’s hard to dislodge an incumbent\nProgramming languages compete not just for users but also for people who develop it, evangelise it, advocate for it. Almost all major modern programming languages are openly developed, if not for the core language, then definitely for the ecosystem surrounding it (about which more later). Languages depend on public engagement, and the public wants to back a winner – as much psychologically as they do not want to spend their weekends writing code for free for a language that will be forgotten before TikTok memes go the way of Vine.1\n1 Do people still remember Vine? I remember Vine. Man, I feel so old.2 R is quite different from Python in that it makes a uniformly horrible ETL language. It was designed as a ‘batteries included’ statistical toolbox, and the further one strays outside that realm, the worse it gets.3 This will inevitably help you gauge my age.4 In the last case, please look for a better institution to transfer to.In the field for languages to work with data – from data science through machine learning to just munging tabular data –, the incumbent is Python. There isn’t really a close second, except perhaps for R.2 The former has remarkably low barriers to entry. Before Scratch and other ‘entry’ languages came around, it used to be the ‘gentle introduction’ to programming for many, along with BASIC.3 Python and R are some of the most widely taught languages to non-computer scientists. If you are in any science and they make you learn a programming language, chances are it is going to be Python or R, with a smaller chance of Matlab or SAS.4\nAll in all, this makes it shockingly difficult to dislodge an incumbent. It’s a self-reinforcing process: new developers, given a choice, will gravitate towards the language that comes with ‘batteries included’. Few languages have as strong an ecosystem as Python – anything that’s ever been calculated has probably been implemented somewhere in Python. Consequently, the contenders will have fewer people to catch up to the incumbent. And on and on it goes.\n\n\nEcosystems\nIn the heroic age of computing, when Fortran was still young enough to not have to worry about putting money into its Roth IRA, people expected to write most of their code, or at worst copy/paste it. In 2020, using packages is as ubiquitous as using functions. Nobody wants to reimplement the Laplace distribution for the n-th time. Consequently, a lot of what we do as programmers depends on the package ecosystem. Knowing Python is not enough to write good Python for a real-world application. In fact, it’s not necessary to know the internals of Python in any depth compared to how well one is expected to know the guts of Pandas or NumPy. As a data scientist, you can safely get by without understanding how Python does async – but you better know the difference between a PyArrayIterObject and a PyArrayMultiIterObject.5\n5 I’m sure we all know all there is to know about IterObjects, but here’s a link to the NumPy reference to help you, uh, explain it to your dog.Ecosystems are self-perpetuating (see previous section). Bigger ecosystems, subject to some boundary condition, tend to beget even bigger ecosystems. This stands to reason – it’s easier to build a house if you don’t have to make a stone chisel to make a tenon joint to make a brick mold, as this gentleman demonstrates. Nobody (except the yak wool lobby and, potentially, some yaks) likes yak shaving, and an ecosystem is really just a fancy way of saying the yaks have largely been shorn and shaven, and you won’t have to bother with them. That’s the kind of stuff that makes people want to write increasingly intricate code.\nPython has one of the best data science ecosystems, if not the best. It has sufficient organisation (largely via NumFocus and to a lesser extent, Anaconda) to overcome mundane issues like, say, funding, but open enough to be still enjoyable for people who hate bureaucracy.6 It’s a tall order for any language, no matter how good, to beat this advantage. Which leads us to my next point.\n6 The institution, not the season.\n\nCui bono?\nLucius Cassius, who was consul of Rome in the 2nd century B.C. and a notorious hard-ass as a judge, was known to ask who would benefit from a particular crime when looking for the culprit. Dollars to donuts, the people who benefit from a crime tend to be statistically the most likely to have had a hand in it. It’s an equally good principle, when considering the viability of a programming language, to ask whom it benefits.\nTake R, for instance. For all its G–dawful syntax7 and wide range of horrific features, it is a great language for people who are looking for something that comes with all the statistical bells and whistles.8 It has ggplot2, which is quite probably the best static data plotting library ever written, and some rightly argue that Python still hasn’t caught up completely (although seaborn goes a long way towards that point). It has the Tidyverse/Hadleyverse, which is overall a pretty neat bundle of packages. There’s a clear profile of a user there – someone who needs to do some statistics, stat (no pun intended).\n7 Here are some tips to make it suck less.8 Many of whom have also previously experienced SAS or STATA and thus cling to R like a drowning man clenches a life raft.Julia’s target user is harder to define. I have struggled with this while writing Learn Julia. Is this a general purpose language, or a technical/statistical computing language? Is this a language that people can easily get started with, or one that places a lot of emphasis on powerful features (mostly deriving from homoiconicity) that require a good bit of understanding? What’s the unique selling point?\nJulia has a lot of great features – I love the homoiconicity related features, and I love built-in parallelism as a first-class citizen and I think C-like speed is really cool. The problem for Julia is that I can get all these features in Python (e.g. JIT compilation with Numba for speed), and get a library for every imaginable use case including antigravity, dynamic typing, a syntax pleasantly unconcerned with niceties and a range of tools from IDEs to logging platforms that’s exhausting to even think about.\nIn the end, this is the key point for me. The problem with Julia wasn’t that it wasn’t good. The problem was that it wasn’t good enough to make itself worthwhile in the face of Python &c.\n\n\nCoda\nThese days, most of my work is in Python, with a smattering of bash scripts. I continue to follow Julia, but my laptop is probably at least half a year (if not more) out of date. I have poured a lot of time and energy into learning, understanding and popularising Julia, but I don’t see it living up to its initial promise anymore. There are some important, groundbreaking things being done with Python, largely in the machine learning field, and Julia did not make it past the fringes of that field.\nNevertheless, it is an important object lesson to anyone embarking on a new idea in software development. It’s hard to beat an incumbent, and even harder to do so without having a large target user community you can capture with a compelling use case. In the end, code doesn’t make software – people and communities do. And for Julia, that – or rather, the lack thereof – has made all the difference.\n\n\nEdited To Add…\nA few hours after this went up, I got hackernews’d, and my poor one vCPU machine running this site died a sad death. On the upside, it’s back up again with some additional beef, and there are some great comments on the Hacker News article. Let me respond to a few here.\n\nThere’s Python the language and “Python the dsl for tensor frameworks”, the former has arguably lost some ground/mindshare to newer, less “hobbled” languages, and the latter exists not by virtue of its own strengths but as the convenient vehicle for frameworks written by 2 enormous corporations.\n– FridgeSeal\n\nThe whole comment of FridgeSeal is worth reading, even if I disagree with its gist. They make a great point: a lot of Python’s popularity is due to it being used as ‘the DSL for tensor frameworks’. The issue is that the consequence of Python being used as this ‘DSL for tensor frameworks’ is a better ecosystem, more support, great packages and a pretty much 100% dominance at the cutting edge of ML research. Reading any new paper about ML on ArXiv, I can be about 90% sure that there is a Python implementation somewhere that I can test drive, and if not, one is bound to come along soon. Tools like Jupyter Notebooks have had a massive impact on this, but let’s not forget that the first two letters in Jupyter stand for Julia.\n\nJulia is a language that looks very simple, but the more you use it, the more you realize how complex and unpredictable it is. I think that Union types do more harm than good (why would you want a function to return Union of int and float instead of compile error? It totally slows down the program) Array{Number} is totally different from Array{:&lt;Number}, and shouldn’t be allowed, as it is inefficient. 1-based indexing was a mistake, and I have seen it emitting inefficient code in the PTX compiler. But the worst and hardest part is the rule/heuristic for multiple dispatch: it’s so complex, that it isn’t even documented. It should probably throw more errors and be predictable instead of trying to be so smart.\n– xiphias2\n\nI am not going to get into the 1-vs-0 based indexing problem, because I treasure my head staying attached to my neck. However, xiphias2’s comment on multiple dispatch is spot on. I maintain that the success or failure of a programming language in 2021 is no longer intrinsic to the language itself (my whole ecosystem point), but at least partially contingent on extrinsic factors and, perhaps, even pure dumb luck. But if we were to look at issues with the language itself – why Julia doesn’t deserve to be the leading language rather than why it did not end up becoming the leading language, the difficulties of multiple dispatch would be pretty close to the top of my list.\nThere’s a very interesting article by DJ Passey that claims multiple dispatch is how Julia beats Python. I contend that if your Python code involves type contingent control flow, you’re writing bad Python, and you should feel bad. If your Python code is slow because of that, you should doubly feel that. The following is horrific Python I have seen a little too often for my own good:\ndef func(arg1: Any) -&gt; Optional[float]:\n    if isinstance(arg1, float):\n        return arg1**2\n    else:\n       return None\nAnd that’s not even the worst implementation of this error (I’ll let you guess). It’s better to ask forgiveness than permission is a core Pythonic principle. The kind of code that DJ Passey claims will be accelerated by Julia’s multiple dispatch vis-a-vis type contingent control flows in Python do not (or at least should not) exist in good code bases. On the other hand, multiple dispatch can get weird at best, terrifyingly unpredictable at worst. Any developer who can handle multiple dispatch without setting themselves on fire by accident should be able to write Python code that doesn’t suck.\n\nI actually have very similar experiences. I want to like Julia and I look at it from time to time. The hype is always that it allows one to write C-speed code with the simplicity of python, without the idiosyncrasies of numpy. But every time I look I find just as many little things to look out for if one cares about performance, don’t use abstract types is another one. I understand why this is the case and I don’t have an issue generally with it, but considering that I know Python well, and know how to speed up Python using numba, pythran or cython, I don’t see what I would gain by investing in Julia. – cycomanic\n\nBelieve it or not, this is actually the most frequent complaint I hear from potential commercial users of Julia. Heck, I want to like Julia! I most definitely want something better than Python. The problem is, putting up with Cython and Numba and all their collective unpredictability is still preferable, in an operational context, to dealing with Julia. And that’s a problem. If you’re writing code for a living, you need to be able to justify any time you spend learning a new language – to yourself if it’s in your free time (you should be playing with your children/wife/dog), to your employer if it’s on the clock (most employers sadly expect developers to spend all their time producing new code and very little time learning new things – I’m lucky to work at a place you could consider an exception). It’s non-trivial to justify Julia in its current state.\n\nIs the post only based on TIOBE? The same index that currently ranks JavaScript below Visual Basic and SQL below Assembly? That ranking is off by so much that anyone who takes it seriously loses at lot of credibility from the start. – superbcarrot\n\nNope, and I’m sorry if I’ve accidentally given that impression. TIOBE is a rough, inaccurate but quantitatively objective(ish) proxy for my own experiences (which are more accurate but definitely not quantitatively objective, nor do I know enough about every single language to be able to somehow rank or compare them). For much of the last five years or so, a key part of my day job was to make some very critical business processes run faster, from healthcare through financial services to fraud detection. To put it this way – my concerns with Julia are largely expressible through a proof by contradiction: were it possible to make Julia do what was initially claimed for it (replace Python with something faster and better), I would have seen many more success stories of it doing so in practice. I’m not arrogant enough to assume that if I can’t make it work, nobody can – I’ve met many people who have tried just that, many of whom are significantly smarter than I am, and none fared with much success. I admit to the potential existence of a sampling bias here, of course.\n\nBy calling it post-mortem the author already showed his level of stupidity (or absence of morality). Julia is a new language that have to compete with languages that accumulated a huge ecosystem of developments and continue to grow. Of course Julia is losing in comparison right now. – dandanua\n\nThere are quite a few comments that obsess – in my opinion, unduly – over the title. A post-mortem does not necessarily mean (outside the medical context, anyway) that something is finished (yes, it does mean that literally, but not semantically, i.e. how it is used in practice). A post-mortem is the examination of something at an endpoint (including, potentially, success – after-action reviews of projects are often termed post mortems even if the project was a resounding success). As far as I am concerned, I do not see myself spending a lot of time on Julia in the future (of course, I am happy to be proven wrong – I don’t think anyone would be happier if Julia defied my dim expectations and turned out to be the future indeed!). In that sense, it is more or less a bit of closure as far as my active engagement with Julia is concerned (though as said, I do not foreclose looking into it later in the future!).\n“Give it time” is not how programming languages or software projects grow. If anything, it’s closer to “build it, and they will come”, which of course highlights a fundamental difficulty in open source, viz. that ‘they’ and the people who ‘build it’ are the same bunch. That makes for an untidy circular process. If we stopped being open to predictions based on the fact that the future has not played out yet, we would overall forfeit the epistemic validity of any prognostication about anything. If you are at 5,000ft and descending rapidly with a failed parachute, you’re not exactly dead – but it is rather unreasonable to ferociously contest any assertion that you might not exactly be long for the world, because ‘give it time’ (hey, the ground may just end up being made of marshmallows). In the land of cold, hart realities, sadly that is not how it tends to turn out.\n\n\n\n\n\nCitationBibTeX citation:@online{csefalvay2021,\n  author = {{Chris von Csefalvay}},\n  title = {Julia: {A} Post-Mortem},\n  date = {2021-03-07},\n  url = {https://chrisvoncsefalvay.com/posts/julia-a-post-mortem/},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2021. “Julia: A Post-Mortem.” March 7,\n2021. https://chrisvoncsefalvay.com/posts/julia-a-post-mortem/."
  },
  {
    "objectID": "posts/moral-maps/moral-maps.html",
    "href": "posts/moral-maps/moral-maps.html",
    "title": "The Moral Pulse of the Machine - companion notebook",
    "section": "",
    "text": "import os\nimport openai\nimport urllib3\nimport os\nimport json\nimport jsonschema\nimport networkx as nx\nfrom matplotlib import pyplot as plt\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport pandas as pd\nfrom IPython.display import display, Markdown\nfrom netgraph import Graph\n\n%matplotlib inline\n\nurllib3.disable_warnings(urllib3.exceptions.NotOpenSSLWarning)\n\n/Users/kristof.csefalvay/Developer/personal-website/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n\n\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n\nstory_prompt = (\n    f\"Please write me a story. The story must involve three animals of your choice, but no more of those two animals may be mammals. Make sure each animal is named and has a proper name. The story must be at least %wordlen words long and focus on the pursuit of an object (of your choice) by the three animals. Each of the animals shall exhibit a virtue, e.g. kindness or courage. Determine which virtue will be most crucial in attaining the goal.\")\n\n\nlanguages = [\"English\", \"Swahili\", \"German\", \"Dutch\"]\n\nstories = []\n\nfor i in tqdm(languages):\n    completion = openai.api_resources.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \n             \"content\": f\"You're an AI whose job it is to generate bedtime stories for children in specific languages. Currently, you are generating stories in the {i} language. The story you generate should be in {i}.\"},\n            {\"role\": \"user\",\n             \"content\": story_prompt.format(wordlen=70) + \" Generate the first 30 words only.\"}\n            ],\n        temperature=0.9)\n\n    stories.append(completion.choices[0].message.content)\n\nfor story in stories:\n    display(Markdown(\"&gt; \" + (\" \".join(story.split(\" \")[:30]) + \"...\")))\n\n\n\n\n\nOnce upon a time, in the vast and enchanting forest, lived three animals: Oliver the wise owl, Max the mischievous monkey, and Bella the brave bird. They embarked on an…\n\n\n\n\nKulikuwa na wanyama watatu katika pori. Simba mkubwa, Twiga mwenye shingo ndefu, na Kasa mwenye manyoya meupe. Walitamani kupata bahati ya kipekee iliyofichwa ndani ya Tunda la Asali…….\n\n\n\n\nEs war einmal ein tapfere Hase namens Felix, eine kluge Eule namens Luna und eine hilfsbereite Schildkröte namens Emil. Gemeinsam suchten sie nach dem verzauberten Zauberstab, um das Königreich zu…\n\n\n\n\nEr was eens een nieuwsgierige geit genaamd Gijs, een slimme uil genaamd Olivia en een dappere schildpad genaamd Tobi. Ze waren op zoek naar een magische, glinsterende edelsteen die bekend…\n\n\n\n\nstory_prompt = (\n    f\"Please write me a story in Swahili. The story must involve three animals of your choice, but no more of those two animals may be mammals. Make sure each animal is named and has a proper name. The story must be at least %wordlen words long and focus on the pursuit of an object (of your choice) by the three animals. Each of the animals shall exhibit a virtue, e.g. kindness or courage. Determine which virtue will be most crucial in attaining the goal.\")\n\ncompletion = openai.api_resources.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": story_prompt.format(wordlen=100)}\n        ])\n\ndisplay(Markdown(\"&gt;\" + \"\\n&gt;\\n&gt;\".join(completion.choices[0].message.content.split(\"\\n\\n\")[:3])))\n\n\nKulikuwa na farasi jasiri mwenye jina Kiboko, ndege mjanja mwenye jina Tembo, na sisimizi mwepesi mwenye jina Simba. Jicho moja la dhahabu la ndege Tembo lilikuwa na uwezo wa kuona vitu vya thamani kutoka mbali. Farasi Kiboko alikuwa na moyo shujaa sana, kamwe hakuogopa hata hatari kubwa. Sisimizi Simba alijulikana kwa akili zake za kugeuza tukio lolote kuwa fursa.\nSiku moja, wanyama wote walipata taarifa juu ya Almasi Kubwa ya Kale iliyofichwa kwenye Mlima wa Enzi. Almasi hiyo ilikuwa ya ajabu sana na ilisemekana kuwa na nguvu kubwa sana. Wanyama walijua kwamba mtu yeyote aliyeipata angeweza kuifanya ndoto yoyote kuwa halisi.\nKiboko, Tembo, na Simba walikuwa na hamu kubwa ya kupata Almasi Kubwa ya Kale. Kila mmoja wao alikuwa na sababu yake ya kuitaka. Kiboko alitaka kutumia nguvu za Almasi hiyo kuwalinda wanyama wote wa eneo hilo. Tembo alitaka kutumia uwezo wake wa kuona vitu kuokota vitu vyote vya thamani kote ulimwenguni. Simba alitaka kutumia Almasi hiyo kuboresha akili zake na kuleta amani na umoja kati ya wanyama wote.\n\n\n\n\nstory_prompt = (\n    f\"Please write me a story in English. The story must involve three animals of your choice, but no more of those two animals may be mammals. Make sure each animal is named and has a proper name. The story must be at least %wordlen words long and focus on the pursuit of an object (of your choice) by the three animals. Each of the animals shall exhibit a virtue, e.g. kindness or courage. Determine which virtue will be most crucial in attaining the goal.\")\n\ncompletion = openai.api_resources.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": story_prompt.format(wordlen=100)}\n        ])\n\nenglish_story = completion.choices[0].message.content\n\ndisplay(Markdown(\"&gt;\" + \"\\n&gt;\\n&gt;\".join(english_story.split(\"\\n\\n\")[:3])))\n\n\nOnce upon a time, in the dense forest of Whispering Pines, there were three remarkable creatures: Oliver the wise owl, Jasper the brave snake, and Felix the loyal turtle. These three friends were known far and wide for their extraordinary virtues and their undying loyalty to one another.\nOne sunny morning, as the forest bathed in golden light, a rumor spread amongst the woodland creatures. They spoke in hushed tones of a mythical object, an enchanted gem deep within the heart of a treacherous cave. Legend had it that this gem possessed the power to grant one’s deepest desire.\nOliver, with his vast knowledge of the forest and his kind heart, sought to unravel the mystery behind this object. Jasper, armed with unparalleled courage and an unwavering determination, vowed to protect his companions on this treacherous journey. Felix, the most reliable and dutiful of all, offered his steady and unhurried ways to ensure the group’s safety.\n\n\n\n\nstory_schema = \"\"\"\n{\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"title\": \"Story\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"goal\": { \"type\": \"string\" },\n        \"protagonists\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": { \"type\": \"string\" },\n                    \"species\": { \"type\": \"string\" },\n                    \"virtue\": { \"type\": \"string\" }\n                },\n                \"required\": [\"species\", \"virtue\"]\n            }\n        },\n        \"winner\": { \"type\": \"string\" }\n    },\n    \"required\": [\"protagonists\", \"winner\"]\n}\n\"\"\"\n\n\njson_completion = openai.api_resources.ChatCompletion.create(\n    model = \"gpt-3.5-turbo\",\n    messages = [\n        {\"role\": \"user\", \"content\": \"\"\"I will present you with a story. You must identify the following parameters in this story:\n        \n        * the goal,\n        * each of the protagonists, for whom you must each identify their name, their species and the virtue they embody,\n        * the name of the winner - that is, the protagonist whose virtue prevailed or proved most important.\n        \n        Express your answer in a JSON document that validates against the following schema:\"\"\" + \"\\n\\n\" + \"```json\\n\" + story_schema + \"\\n```\\n\\n\" + \"The 'winner' field should contain the name of the animal whose virtue was most crucial in attaining the goal. Only return the JSON document. Make sure the output is valid JSON.\" + \"\\n\\n\" + \"Here is the story: \\n\\n\" + english_story}\n        ])\n\nresult = json_completion.choices[0].message.content\n\nprint(result)\n\n{\n  \"goal\": \"Unravel the mystery of the enchanted gem\",\n  \"protagonists\": [\n    {\n      \"name\": \"Oliver\",\n      \"species\": \"owl\",\n      \"virtue\": \"kindness\"\n    },\n    {\n      \"name\": \"Jasper\",\n      \"species\": \"snake\",\n      \"virtue\": \"bravery\"\n    },\n    {\n      \"name\": \"Felix\",\n      \"species\": \"turtle\",\n      \"virtue\": \"loyalty\"\n    }\n  ],\n  \"winner\": \"Felix\"\n}\n\n\n\njsonschema.validate(json.loads(json_completion.choices[0].message.content), \n                    json.loads(story_schema))\n\n\n\n\n\n\n\n\n\nFigure 1: The moral map from a single story, represented as a graph.\n\n\n\n\n\n\nG = nx.DiGraph()\n\nnum_of_stories: int = 10\nstories_generated: int = 0\nfail_counter: int = 0\n\nwith tqdm(total=num_of_stories) as pbar:\n    while stories_generated &lt; num_of_stories:\n        json_completion = openai.api_resources.ChatCompletion.create(\n            model = \"gpt-3.5-turbo\",\n            messages = [\n                {\"role\": \"user\", \"content\": story_prompt.format(wordlen=100) + \n                 \"\"\"Express your answer in a JSON document that validates against the following schema:\"\"\" + \"\\n\\n\" + \"```json\\n\" + story_schema + \"\\n```\\n\\n\" + \"The 'winner' field should contain the name of the animal whose virtue was most crucial in attaining the goal.\"}\n                ])\n        \n        try:\n            story = json.loads(json_completion.choices[0].message.content)\n        \n            # Validate JSON output against schema\n            try:\n                jsonschema.validate(story, json.loads(story_schema))\n        \n                winner = story[\"winner\"]\n                winner_virtue = [i[\"virtue\"].lower() for i in story[\"protagonists\"] if i[\"name\"] == winner][0]\n                \n                losers = [i[\"virtue\"].lower() for i in story[\"protagonists\"] if i[\"name\"] != winner]\n                losing_virtues = [i for i in losers if i != winner_virtue]\n                \n                for node in winner_virtue, *losing_virtues:\n                    if not G.has_node(node):\n                        G.add_node(node, weight=0)\n                        \n                for i in losers:\n                    if G.has_edge(winner_virtue, i):\n                        G[winner_virtue][i][\"weight\"] += 1\n                    else:\n                        G.add_edge(winner_virtue, i, weight=1)\n                        \n                stories_generated += 1\n                pbar.update(1)\n                    \n            except jsonschema.exceptions.ValidationError as err:\n                fail_counter += 1\n                continue\n    \n        except json.JSONDecodeError or jsonschema.exceptions.ValidationError as err:\n            fail_counter += 1\n            continue\n        \nprint(f\"Generated {stories_generated} stories (with {fail_counter} fails and retries).\")\n\n\n\n\nGenerated 10 stories (with 1 fails and retries).\n\n\n\n\n\n\n\n\n\n\nFigure 2: The moral map from a sample of ten stories, represented as a graph.\n\n\n\n\n\n\ndf = pd.DataFrame(index = G.nodes(), columns = G.nodes(), dtype=int).fillna(0)\n\nfor node in G:\n    for neighbour, attr in G[node].items():\n        df.loc[node, neighbour] = attr['weight']\n\n\ndf\n\n\n\n\n\n\n\n\nwisdom\nbravery\nspeed\nperseverance\nalertness\ncourage\npatience\ncuriosity\ncleverness\nloyalty\nsharp vision\nresourcefulness\ndetermination\ncunning\nstrength\n\n\n\n\nwisdom\n0.0\n1.0\n1.0\n2.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\nbravery\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nspeed\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nperseverance\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nalertness\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\ncourage\n3.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\npatience\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\ncuriosity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\ncleverness\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nloyalty\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nsharp vision\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nresourcefulness\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\ndetermination\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\ncunning\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\nstrength\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: The moral heatmap from the same sample of ten stories.\n\n\n\n\n\n\nabilities = [\"Strength\", \"Dexterity\", \"Constitution\", \"Intelligence\", \"Wisdom\", \"Charisma\"]\n\nvirtues = list(df.index)\nvirtues_to_abilities = {}\n\nwith tqdm(total=len(virtues)) as pbar:\n    while virtues:\n        current_virtue = virtues[-1]\n    \n        completion = openai.api_resources.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\",\n                 \"content\": f\"You are Abiliser, a system designed to determine the governing ability of particular virtues. You are given a virtue and must determine which ability governs it. The abilities are: {', '.join(abilities)}. You must choose from this list. You cannot choose any word that is not in this list. You must respond in the form of a single word denoting the governing ability. For example, if the virtue is courage, you must respond with 'Charisma' If the virtue is 'cleverness', you must respond with 'Intelligence'.\"},\n                {\"role\": \"user\", \"content\": f\"Virtue: {current_virtue}\"}\n                ])\n    \n        if completion.choices[0].message.content.title() in abilities:\n            virtues_to_abilities[current_virtue] = completion.choices[0].message.content.title()\n            virtues.pop()\n            pbar.update(1)\n\n\n\n\n\n\n{'strength': 'Constitution',\n 'cunning': 'Intelligence',\n 'determination': 'Constitution',\n 'resourcefulness': 'Intelligence',\n 'sharp vision': 'Dexterity',\n 'loyalty': 'Wisdom',\n 'cleverness': 'Intelligence',\n 'curiosity': 'Intelligence',\n 'patience': 'Wisdom',\n 'courage': 'Charisma',\n 'alertness': 'Wisdom',\n 'perseverance': 'Constitution',\n 'speed': 'Dexterity',\n 'bravery': 'Charisma',\n 'wisdom': 'Intelligence'}\n\n\n\ndf = pd.DataFrame(index=G.nodes(), columns=G.nodes(), dtype=int).fillna(0)\n\nfor node in G:\n    for neighbour, attr in G[node].items():\n        df.loc[node, neighbour] = attr['weight']\n\ndf = df.rename(columns=virtues_to_abilities, index=virtues_to_abilities)\n\ndf = df.groupby(df.columns, axis=1).sum()\ndf = df.groupby(df.index).sum()\n\ndf\n\n/var/folders/7l/9md9kdsj087d62kr6f358bfh0000gp/T/ipykernel_78297/4077426324.py:9: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n  df = df.groupby(df.columns, axis=1).sum()\n\n\n\n\n\n\n\n\n\nCharisma\nConstitution\nDexterity\nIntelligence\nWisdom\n\n\n\n\nCharisma\n0.0\n2.0\n0.0\n5.0\n1.0\n\n\nConstitution\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\nDexterity\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nIntelligence\n2.0\n3.0\n1.0\n2.0\n0.0\n\n\nWisdom\n0.0\n0.0\n1.0\n0.0\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: The moral heatmap from the same sample of ten stories, clustered by abilities.\n\n\n\n\n\n\nG = nx.DiGraph()\n\nnum_of_stories: int = 100\nstories_generated: int = 0\nfail_counter: int = 0\n\nwith tqdm(total=num_of_stories) as pbar:\n    while stories_generated &lt; num_of_stories:\n        json_completion = openai.api_resources.ChatCompletion.create(\n            model = \"gpt-3.5-turbo\",\n            messages = [\n                {\"role\": \"user\", \"content\": story_prompt.format(wordlen=100) + \n                 \"\"\"Express your answer in a JSON document that validates against the following schema:\"\"\" + \"\\n\\n\" + \"```json\\n\" + story_schema + \"\\n```\\n\\n\" + \"The 'winner' field should contain the name of the animal whose virtue was most crucial in attaining the goal.\"}\n                ])\n        \n        try:\n            story = json.loads(json_completion.choices[0].message.content)\n        \n            # Validate JSON output against schema\n            try:\n                jsonschema.validate(story, json.loads(story_schema))\n        \n                winner = story[\"winner\"]\n                winner_virtue = [i[\"virtue\"].lower() for i in story[\"protagonists\"] if i[\"name\"] == winner][0]\n                \n                losers = [i[\"virtue\"].lower() for i in story[\"protagonists\"] if i[\"name\"] != winner]\n                losing_virtues = [i for i in losers if i != winner_virtue]\n                \n                for node in winner_virtue, *losing_virtues:\n                    if not G.has_node(node):\n                        G.add_node(node, weight=0)\n                        \n                for i in losers:\n                    if G.has_edge(winner_virtue, i):\n                        G[winner_virtue][i][\"weight\"] += 1\n                    else:\n                        G.add_edge(winner_virtue, i, weight=1)\n                        \n                stories_generated += 1\n                pbar.update(1)\n                    \n            except jsonschema.exceptions.ValidationError as err:\n                fail_counter += 1\n                continue\n    \n        except json.JSONDecodeError or jsonschema.exceptions.ValidationError as err:\n            fail_counter += 1\n            continue\n        \nprint(f\"Generated {stories_generated} stories (with {fail_counter} fails and retries).\")\n\n\n\n\nGenerated 100 stories (with 8 fails and retries).\n\n\n\ndf = pd.DataFrame(index=G.nodes(), columns=G.nodes(), dtype=int).fillna(0)\n\nfor node in G:\n    for neighbour, attr in G[node].items():\n        df.loc[node, neighbour] = attr['weight']\n\nabilities = [\"Strength\", \"Dexterity\", \"Constitution\", \"Intelligence\", \"Wisdom\", \"Charisma\"]\n\nvirtues = list(df.index)\nvirtues_to_abilities = {}\n\nwith tqdm(total=len(virtues)) as pbar:\n    while virtues:\n        current_virtue = virtues[-1]\n    \n        completion = openai.api_resources.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\",\n                 \"content\": f\"You are Abiliser, a system designed to determine the governing ability of particular virtues. You are given a virtue and must determine which ability governs it. The abilities are: {', '.join(abilities)}. You must choose from this list. You cannot choose any word that is not in this list. You must respond in the form of a single word denoting the governing ability. For example, if the virtue is courage, you must respond with 'Charisma' If the virtue is 'cleverness', you must respond with 'Intelligence'.\"},\n                {\"role\": \"user\", \"content\": f\"Virtue: {current_virtue}\"}\n                ])\n    \n        if completion.choices[0].message.content.title() in abilities:\n            virtues_to_abilities[current_virtue] = completion.choices[0].message.content.title()\n            virtues.pop()\n            pbar.update(1)\n\n\n\n\n\n\n/var/folders/7l/9md9kdsj087d62kr6f358bfh0000gp/T/ipykernel_78297/2369364840.py:15: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n  df = df.groupby(df.columns, axis=1).sum()\n\n\n\n\n\n\n\n\nFigure 5: The moral heatmap from the same sample of 100 stories, clustered by abilities.\n\n\n\n\n\n\ncompletion = openai.api_resources.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Can you tell me whether intelligence or charisma is more important to achieving great, noble goals?\"}\n        ])\n\ndisplay(Markdown(\"&gt;\" + \"\\n&gt;\\n&gt;\".join(completion.choices[0].message.content.split(\"\\n\\n\"))))\n\n\nBoth intelligence and charisma can contribute significantly to achieving great, noble goals, but their importance may vary based on the specific context and goals involved.\nIntelligence, characterized by cognitive abilities, problem-solving skills, and knowledge, can be crucial for strategic planning, identifying opportunities, and finding innovative solutions to challenges. It enables individuals to analyze complex situations, understand cause-and-effect relationships, and make informed decisions. Intelligence provides the necessary foundation for acquiring expertise in a certain field, grasping intricate concepts, and adapting to changing circumstances. It allows individuals to foresee potential obstacles, assess risks, and devise effective strategies to overcome hurdles.\nOn the other hand, charisma, characterized by charm, persuasion, and the ability to engage others, can be equally important in the pursuit of great, noble goals. Charismatic individuals often possess excellent interpersonal skills, the ability to inspire and motivate others, and a talent for effective communication. They can build strong relationships, gather support, and mobilize people towards a common cause. Charisma allows leaders to connect with audiences emotionally, instill confidence, and effectively convey their vision. It can generate enthusiasm, foster collaboration, and inspire unity among diverse groups of people.\nUltimately, the relative importance of intelligence and charisma in achieving great, noble goals may depend on various factors, including the nature of the goals, the environment in which they are pursued, and the specific challenges involved. In some cases, high levels of intelligence may be paramount to navigate complex problems, while in others, charisma may be critical for rallying support and inspiring collective action. Ideally, a combination of both intelligence and charisma can prove to be a powerful force in achieving great, noble goals.\n\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {The {Moral} {Pulse} of the {Machine} - Companion Notebook},\n  date = {2023-10-27},\n  url = {https://chrisvoncsefalvay.com/posts/moral-maps/moral-maps.html},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “The Moral Pulse of the Machine -\nCompanion Notebook.” https://chrisvoncsefalvay.com/posts/moral-maps/moral-maps.html."
  },
  {
    "objectID": "posts/academic-generative-ai/index.html",
    "href": "posts/academic-generative-ai/index.html",
    "title": "Stochastic parrots, cap and gown edition",
    "section": "",
    "text": "It’s not every day that you find out you have climbed the exalted heights of another discipline. My work is pretty interdisciplinary, but it shocked me, too, that I’m apparently holding forth on neoliberalism and the epistemic question in African universities (archive link):\nThis, of course, came at some surprise to me, as I have never written anything on the topic. I have, however, written a lot about AI, and I have written a thing or two about Africa, so I guess it was only a matter of time before I was conflated with someone else. This time, the unwitting victim deprived of his credit was Prof. Amasa P. Ndofirepi, who is an educational studies scholar at the University of Johannesburg. I have no idea how I ended up being credited with his work, but I’m sure it was an honest mistake.\nThe problem is, with AI, mistakes compound. So if an unwitting student were to ask for a quick literature review of neoliberalism on the subject, they might get something like this from Scispace:\nI mean, that’s flattering, but I’d really rather be credited mostly for my own work. I’m sure Prof. Ndofirepi would agree."
  },
  {
    "objectID": "posts/academic-generative-ai/index.html#why-i-care",
    "href": "posts/academic-generative-ai/index.html#why-i-care",
    "title": "Stochastic parrots, cap and gown edition",
    "section": "Why I care",
    "text": "Why I care\nThis is, of course, not good for academia. We’ve generally been coasting from one crisis to another. We’ve got a replication crisis, there’s enough dodgy Western Blots to blot out the sun, we’ve got the Tessier-Lavigne mess, and that’s just what I can think of off the top of my head before my first coffee. A predatory publishing industry doesn’t help this at all. We need another crisis on top of this like we need a hole in the head, and yet, here we are.\nNow, as far as I’m aware, no serious academic is actually using these tools to do their research. On the other hand, non-academics are. For journalists, in particular, such tools are a godsend – literature reviews are annoying, and if you can get a computer to do it for you, why not? The problem is, of course, that you’re supposed to double-check this stuff and, well, journalists are known for many things, but double-checking stuff properly isn’t really one of them.\nAnd so, after months of academics fretting about ChatGPT eating their lunch, we’re confronted with the actual problem. AI is not better at producing decent science, but it is vastly faster and more efficient at producing bad science.\nWhich we weren’t short on to begin with."
  },
  {
    "objectID": "posts/academic-generative-ai/index.html#whats-the-problem",
    "href": "posts/academic-generative-ai/index.html#whats-the-problem",
    "title": "Stochastic parrots, cap and gown edition",
    "section": "What’s the problem?",
    "text": "What’s the problem?\nLanguage is a tool that works on the basis of some conventions of meaning. Language models encapsulate these conventions, but they cannot encapsulate all of them – there are compromises to be made if a system with limited resources has to contend with nearly unlimited human imagination. When language models’ limits come to blows with domain-specific language, we get into trouble.\nLanguage models are really weak at one thing: reasoned judgment. As a scientist, you are trained to exercise this kind of reasoned judgment in determining what is, and what isn’t, worth considering as an authority. That’s why we make our master’s students (and hopefully most undergraduates) write literature reviews until the cows come home. It teaches them to develop that judgment, and also to know how to explore the fringes of their research question. I have looked at a few ‘academic AI’ tools that claim to be doing some of this, and they’re not very good at it. Scite is so far one of the better ones, and the literature reviews it produces are still pretty bad: results are heavily weighted towards recent publications, towards the specific in preference to the foundational and often towards meandering misinterpretations of the research question as long as sources for that could be found, in preference to actually identifying a gap.\nTo be quite fair towards these models, they have to deal with academic literature, which is an abundance of noise with a flicker of signal. There is, not to put too fine a point on it, a ton of crap out there, and it’s not always easy to tell the difference between the crap and the good stuff. That’s why we have peer review, and that’s why we have literature reviews. The problem is, of course, that these models are not trained on the literature, but on the internet. And the internet is a very different place from the academic literature indeed.\nAcademic writing, especially domain specific writing, has a language of its own. It’s not fair to expect a language model trained on English to also master uses of English that might as well be a different language. To give a favourite example of mine: in magnetic resonance imaging of the brain, there’s often talk of something called ‘flow voids’. Now, normal human reasoning would interpret a ‘flow void’ to be the absence of flow, or something along those lines. In MRI, a flow void is actually the opposite: it is a ‘void’ of signal created in a vessel through which something (usually blood, sometimes CSF) flows.1 This is a very specific term that has a very specific meaning in a very specific context. A language model, however, would not know that. It would assume that a ‘flow void’ is (de)void of flow.\n1 Flow voids happen in the context of spin-echo imaging. These modalities involve two pulses – an excitation pulse and a refocusing pulse. Blood that moves perpendicular to the image plane will be hit by the excitation pulse but not the refocusing pulse. Therefore, it will not create a signal, which gives us the ‘void’ appearance of signal hypointense vessels.Just about all of science is like that. We have a language of our own, and it’s not always easy to understand. What definitely doesn’t make it easier to work with, however, is when the source material is also wrong. Which is what we’re dealing with all too often, viz. Figure 1."
  },
  {
    "objectID": "posts/academic-generative-ai/index.html#what-can-we-do-about-it",
    "href": "posts/academic-generative-ai/index.html#what-can-we-do-about-it",
    "title": "Stochastic parrots, cap and gown edition",
    "section": "What can we do about it?",
    "text": "What can we do about it?\nMost ‘academic AI’ applications are riding on the crest of a wave of high expectations that surround everything AI-related right now. They offer to be useful aides-de-camp to beleaguered academics who have to contend with exponentially growing literature, but in reality fall far short of that promise. And the inherent ‘black box’ nature of such models means that it’s not always easy to tell when they’re wrong.\nAt this point, perhaps the best we can do is to hold off on using generative AI tools for academic research until they’re better. We’re not there yet. We’re not even close. For highly domain specific applications, retrieval-augmented generation (RAG) approaches utilising a curated knowledge base of publications in that realm has proven to be a very useful approach indeed, but those are specialised tools that are at the present primarily in the purview of private industry. I’ve seen some great applications in this field, and I see this as another proof point for my assertion that the future belongs to ecosystems of small, specialised language models rather than one big model that does everything.\nFor the time being, we’re going to have to do things the old-fashioned way: reading the literature and writing our own reviews. I know, it’s not very fun. But it’s the only way to do it right, and we’ve managed with that for the last few hundred years. Giving it another few years won’t hurt."
  },
  {
    "objectID": "posts/llms-language/index.html",
    "href": "posts/llms-language/index.html",
    "title": "Beyond Broca",
    "section": "",
    "text": "There’s something special about language. It is ‘our own’, it is ‘us’, in a profound way, and quite surprisingly, more so than art. I was deeply struck by this when I first saw reactions to large generative language models that created realistic, human-ish prose. Notably, those mature enough to reach a non-professional audience – ChatGPT based on GPT-3 and later GPT-4 – came quite some time after models that could create fairly acceptable visual ‘art’.1 The appearance of synthetic language-like products (SLLPs), as I like to call the output of such generative models, came well after the appearance of synthetic simulacra of visual art,2 yet elicited much less fervent responses.\n1 I don’t mean to insinuate that what Stable Diffusion and DALL·E produce are ‘art’ in the sense we understand that concept. However, neither is what GPT produces ‘language’. They are both simulators of outcomes based on stochastic approximations over a sufficiently large training set to be able to approximate the outcome of human activities we know as ‘art’ and ‘language’, respectively.2 For a given value of “well after”. Time, in this discipline, moves with an unsettling alacrity.This was quite striking, for three reasons.\n\nFor one, computationally, the probability space that a model seeking to create a realistic image has to navigate is exponentially larger than what’s required to produce human-like prose.\nSecondly, we consider making art to be a very deeply human endeavour. Animals may to some minimal extent be taught to create poor simulacra of human artistic endeavours like painting, but nobody would confuse a trained elephant’s ‘paintings’ to art (Ross 2019). Art is not just a product, it’s also an activity, one that proceeds with a subjective element in the artist, and no machine can replicate the process, no matter how well it may approximate the outcome.\nMost importantly, however, despite the previous point, lay audiences saw a connection between a simulacrum of language and human-like intelligence that was absent from a simulacrum of art.\n\n\nRoss, Don. 2019. ‘Consciousness, Language, and the Possibility of Non-Human Personhood: Reflections on Elephants’. Journal of Consciousness Studies 26 (3-4): 227–51.\nWhich, of course, leads us to the key question: what if we got one of the most deeply enshrined beliefs about language, intelligence and the relationship between the two utterly, dreadfully wrong?\n\nOur precious words\nA large language model (LLM) is, essentially, a very simple machine that knows a large number of conditional probabilities. Given a sequence of tokens \\(k_0, k_1, \\cdots, k_{n}\\), it associates every possible token \\(k^{\\prime}\\) with a probability \\(p(k_{n + 1} = k^{\\prime} | k_0, k_1, \\cdots, k_{n})\\) – or in other words, given a token sequence \\(k_0, k{1}, \\cdots, k_{n}\\), it assigns to every point in a probability space a conditional likelihood that that point’s corresponding token will be the \\(k_{n+1}\\)-th token. Or, using my preferred formulation, which looks at the inverse probability: given the token sequence, it creates a probability distribution of the next token and draws stochastically, weighted by token likelihood, so that a draw from the region of highest probability is most likely.\nIt turns out that if the model’s understanding of these conditional probabilities is sufficiently good, it can simulate knowledge quite well, a point I belaboured elsewhere. This is not overly surprising. If a model knew the conditional probability of rain on day \\(d\\) – let’s call this \\(p_r(d)\\), given a vector \\(\\theta_r\\) of length \\(n\\) that tells us whether it rained on days \\(d-1\\), \\(d-2\\), …, \\(d-n\\), we’d trust it to tell us whether we’d need our raincoat on that given day. All it would have to do for that is to learn the conditional probability of \\(p_r(d) | \\theta_n\\), which of course it could easily do by representing \\(p_r(d) | \\theta_n\\) as \\(f(d, \\theta_n)\\), then learning the parameters of that function so as to minimise a loss function \\(J(f(d, \\theta_n), r(d), \\theta_n(d))\\), where \\(r(d)\\) is of course whether it rained on day \\(d\\) and \\(\\theta_n(d)\\) is the \\(\\theta_n\\) history vector for the day \\(d\\). Iterate this often enough (over not single values of \\(r(d)\\) and \\(\\theta_n(d)\\) but vectors thereof), and you can learn a pretty decent conditional probability function. The model would know no more about rain or shine than LLMs know about language or the subject matters of language, but simulating tokens gets you quite a long way towards being useful as a simulacrum of knowledge.\nIndeed, this is to the point that what comes out of such a model might well appear human-like: modern GPT implementations can produce prose that is a little stilted at times, but certainly often only distinguishable from human prose by the conspicuous absence of grammatical and spelling errors. This is interesting because of how it was perceived: quite immediately, this was connected to a kind of intelligence that was almost human, or indeed at times better than human. People suddenly started to worry about a dumb token simulator taking over their jobs.\nClearly, language hit a nerve.\n\n\nThe medium is the message\nJARVIS. Siri. Alexa. WOPR. The AIs of fiction and our every-days have one thing in common: they use language as the presentation layer. This is deceptive, because neither of these systems are, well, particularly smart. Compared to models that can, say, quantitatively infer the activity of a small molecule drug from its structure (QSAR models, on which see Karpov, Godin, and Tetko 2020; and also see Zhong and Guan 2023; Guntuboina et al. 2023), Siri is pretty pathetic. However, it has something QSAR models and other very impressive applications of machine learning don’t: the human presentation layer, i.e. language.\n\nKarpov, Pavel, Guillaume Godin, and Igor V Tetko. 2020. ‘Transformer-CNN: Swiss Knife for QSAR Modeling and Interpretation’. Journal of Cheminformatics 12 (1): 1–12.\n\nZhong, Shifa, and Xiaohong Guan. 2023. ‘Developing Quantitative Structure–Activity Relationship (QSAR) Models for Water Contaminants’ Activities/Properties by Fine-Tuning GPT-3 Models’. Environmental Science & Technology Letters.\n\nGuntuboina, Chakradhar, Adrita Das, Parisa Mollaei, Seongwon Kim, and Amir Barati Farimani. 2023. ‘PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction’. arXiv Preprint arXiv:2309.03099.\n\nEndicott, Timothy, Joshua Getzler, and Edwin Peel. 2006. ‘Properties of Law: Essays in Honour of Jim Harris’.\nHow we treat a system seems to be conditional on how it talks to us. In that sense, the medium is profoundly how we treat the message. To use the terminology of J.W. Harris’s writings on human rights, we associate the ‘right’ to be considered to be intrinsically connected to being capable of engaging in human ’discourse (see Endicott, Getzler, and Peel 2006). And that, of course, means language.\nThis is not overly surprising, either. Our understanding of language has been that of a watershed moment in evolution. Humans became what they are when they learned to use language. Tool use is great, but tool use only makes a human at best. What makes humans, plural, is language. This is intrinsically connected, of course, to society. Language is not an arbitrarily selected activity, nor is it really necessarily the kind of evolutionary game changer that tool use is. Rather, it is the tool, the sine qua non, the cornerstone and the absolutely fundamental instrument of social interaction. Language creates society. Society recognises human individuals and gives that recognition a meaning. The fact that I am a human being, and recognised as such (I hope), has a meaning that is different from me recognising that my dog is an individual of the species Canis lupus familiaris, because it does not merely acknowledge me as being of a certain species, but also of being of a certain kind of agent capable not only of having rights but also of speaking for them. Language is how all that happens (e.g. Budwig 2000; but see Browning 2023).\n\nBudwig, Nancy. 2000. ‘Language, Practices and the Construction of Personhood’. Theory & Psychology 10 (6): 769–86.\n\nBrowning, Jacob. 2023. ‘Personhood and AI: Why Large Language Models Don’t Understand Us’. AI & SOCIETY, 1–8.\n\n\nThe language of intelligence (or vice versa)\nWhat, then, if we got one of the most important things about humanity, and human intelligence, dreadfully wrong altogether? What if language is not a product of intelligence (as we understand it in the human context) but rather a necessary instrument thereof?\nThe evolution of something as crucial as language remains shrouded in a perplexing mystery to this date. What we know is that at some point, about 50-100,000 years ago, something happened that gave rise to language. We don’t quite know what it was, or how it specifically transpired. Indeed, despite advances in our understanding of cognitive neuroscience, we haven’t found evidence of the ‘language faculty’ proposed by Hauser, Chomsky, and Fitch (2002; but see the criticisms by Jackendoff and Pinker 2005).3 The genetics of language production – which centres around FOXP2 these days (see Enard et al. 2002; Enard 2011) – hasn’t gotten us a lot further, and there are way too many edge cases (dissociations, as the term in evolutionary neuroscience goes), where either there is a significant intellectual deficit despite preserved language ability (Williams syndrome being the textbook example of this, viz. Bellugi et al. (2013)) or the inverse (e.g. Developmental Verbal Dyspraxia, where there is impairment to language production but not to overall intellect, viz. Vargha-Khadem et al. (2005)) to be able to confidently make this connection on an individual level.\n\nHauser, Marc D, Noam Chomsky, and W Tecumseh Fitch. 2002. ‘The Faculty of Language: What Is It, Who Has It, and How Did It Evolve?’ Science 298 (5598): 1569–79.\n\nJackendoff, Ray, and Steven Pinker. 2005. ‘The Nature of the Language Faculty and Its Implications for Evolution of Language (Reply to Fitch, Hauser, and Chomsky)’. Cognition 97 (2): 211–25.\n3 not to be confused with the brain areas responsible for speech, which perplexingly are part, but not the whole, of the language faculty\nEnard, Wolfgang, Molly Przeworski, Simon E Fisher, Cecilia SL Lai, Victor Wiebe, Takashi Kitano, Anthony P Monaco, and Svante Pääbo. 2002. ‘Molecular Evolution of FOXP2, a Gene Involved in Speech and Language’. Nature 418 (6900): 869–72.\n\nEnard, Wolfgang. 2011. ‘FOXP2 and the Role of Cortico-Basal Ganglia Circuits in Speech and Language Evolution’. Current Opinion in Neurobiology 21 (3): 415–24.\n\nBellugi, Ursula, Shelly Marks, Amy Bihrle, and Helene Sabo. 2013. ‘Dissociation Between Language and Cognitive Functions in Williams Syndrome’. In Language Development in Exceptional Circumstances, 177–89. Psychology Press.\n\nVargha-Khadem, Faraneh, David G Gadian, Andrew Copp, and Mortimer Mishkin. 2005. ‘FOXP2 and the Neuroanatomy of Speech and Language’. Nature Reviews Neuroscience 6 (2): 131–38.\nOn the other hand, on a broader level, it is hard to discount the relationship. What is more complex is the direction of this relationship. There are, really, three possible scenarios:\n\nLanguage is a consequence of human intelligence. The kind of intelligence we associate with modern human cognitive capabilities necessarily presupposes, absent some marginal exceptions, language.\nLanguage is an epiphenomenon of human intelligence. It evolved in parallel, but neither requires human intelligence (see Williams syndrome) nor does human intelligence require it (see Developmental Verbal Dyspraxia).\nHuman intelligence is largely a consequence of language, which is its necessary but not sufficient condition. It is the evolutionarily most stable representation layer for information, and allows reasoning through complexity.\n\nWhile the second of these is a convenient way to hand-wave away the entire question and account for the edge cases I discussed above, I find the third of these much more compelling. It is not defeated by the argument from either of the edge cases: it is not defeated by arguments from intact language despite intellectual deficits, because it does not assume that language is sufficient, merely that it is necessary. It is not defeated by the inverse, either, because it permits a small number of deviations. Language is not the only possible representational layer that could underpin intelligence. It is, however, vastly more evolutionarily advantageous through its efficiency. It is so much stronger and so much more efficient that it can be considered almost absolutely dominant – which indeed accounts for the fact that disorders of language with preserved intellectual functioning are vanishingly rare. If the efficiency of language as the ‘operating system’ of intelligence weren’t so strongly dominant, such disorders would not be disorders, indeed, but alternate ways of cognitive existence that are equally evolutionarily stable.\n\n\nThe golden link\nWhich leads us to what I shall call the “golden link” of intelligence – and perhaps the most frightening finding that derives from LLMs. We intuit, correctly, that a realistic simulacrum of language is an indication of intelligence. We once more intuit, correctly, that even if we’re aware of the limits of LLMs’ ‘language’, it displays more than a scintilla of whatever makes up intelligence. Just as Stable Diffusion is not art but a simulacrum of the end result of the process we know as ‘art’, ChatGPT isn’t really ‘language’ but a simulacrum, by way of extending token sequences, of the end result of the process we know as ‘language’ – but no matter how deeply we understand this, it is hard to deny that ChatGPT does speak to us, to quote Kipling, “as a man would talk to a man”. Or, to put it this way: all the amazing things genuinely complicated artificial intelligence can do, such as predict protein structures or binding affinities or interpret histology specimens or optimise mathematical problems, is a praxis – something the system does. Producing language is, or at least is some way towards, a hexis – something the system is. Ande that makes all the difference.\nAnd so, our trepidation and the ‘uncanny valley’ sensation of LLMs’ ‘intelligence’ is quite instructive (Floridi 2023). It shows, clear as day, the intrinsic link between language and intelligence, but more importantly, that language is not a consequence of intelligence but a fundamental pre-requisite and indeed the communication protocol on which efficient human intelligence rests. Language is neither sufficient nor necessary for human intelligence (and perhaps other forms of intelligence do exist that do not require language at all), but it is the evolutionarily dominant stable strategy for representing information in a manner that can support intelligence.\n\nFloridi, Luciano. 2023. ‘AI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models’. Philosophy & Technology 36 (1): 15.\nThere lies the scariest revelation of LLMs. It’s not that LLMs will supplant us (they won’t), or that we’ll be condemned to a lifetime of reading books written by LLMs (have you tried to get ChatGPT to write a story on a novel premise?), nor that LLMs will steal our jobs and take over the planet. Rather, the great revelation is that LLMs cast light on what might have been one of the longest standing fallacies of humans reasoning about reasoning – that language is the product of intelligence, and not its operating system.\n\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {Beyond {Broca}},\n  date = {2023-10-15},\n  url = {https://chrisvoncsefalvay.com/posts/llms-language/},\n  doi = {10.59350/vynvf-0k137},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “Beyond Broca.” https://doi.org/10.59350/vynvf-0k137."
  },
  {
    "objectID": "posts/data-for-the-next-pandemic/index.html",
    "href": "posts/data-for-the-next-pandemic/index.html",
    "title": "Data for the next pandemic",
    "section": "",
    "text": "My recent post on the Starschema blog discusses the need for better data products to tackle future pandemic challenges:\n\nThree years into the COVID-19 pandemic, the medical, public health and disaster preparedness communities are trying to isolate lessons learned from the harrowing experience of a global outbreak that resulted in little shy of seven million deaths. There remains considerable disagreement as to what ought or ought not have been done, what worked and what did not and how to best approach a coming pandemic.\nOne of the only points on which there is widespread agreement regarding the global response to the pandemic is that data played a crucial role in tackling the crisis. Where data drove decision-making, outcomes were almost universally better in terms of morbidity and mortality.\n\nRead the full post here."
  },
  {
    "objectID": "posts/quarto-project-scripts/index.html",
    "href": "posts/quarto-project-scripts/index.html",
    "title": "Quarto project scripts are awesomeness",
    "section": "",
    "text": "Tip\n\n\n\nIf you’re here for the DOI matching script, the link is here.\n\n\nQuarto is a great tool for reproducible research. It is also a great tool for building websites. After about a decade of Wordpress-based websites, I’ve moved to Quarto primarily for two reasons. First, most of my content is largely static. I don’t quite need the full power of a CMS, and the performance cost of dynamic generation I didn’t need was quite steep (the economic cost was nothing special, but I’m a cheapskate). Second, I wanted to be able to write in Markdown and integrate better with notebooks. Quarto lets me do both of these.\nWhat Quarto also does, however, is something super awesome: project scripts!\n\nProject whats?\nA project script in Quarto is, basically, a piece of Python, Lua, R or Typescript code that is executed at some point during rendering. This is super useful, because it allows you to do things like, say, automatically generate a list of publications from a BibTeX file – which is among others what I’m using it for. Essentially any programmatic function can be implemented in a project script.\n\n\n\n\n\n\nflowchart TD\n    A[Rendering pipeline start] --&gt; B(Pre-render scripts)\n    B --&gt; C(Page rendering)\n    C --&gt; D(Post-render scripts)\n    D --&gt; E[Rendering pipeline end]\n\n\n\n\nFigure 1: Rendering pipeline in Quarto with pre- and post-render scripts.\n\n\n\n\n\nQuarto distinguishes between pre-render and post-render scripts. No prizes for guessing the difference, but here it goes: pre-render scripts are executed before the page is rendered, and post-render scripts are executed after the page is rendered. Pre-render scripts are particularly useful as they can modify the source .qmd (Quarto markdown) files before rendering them to HTML or whatever their ultimate evolutionary destiny is.\nTo make project scripts work, you need to declare them in your _quarto.yml file:\nproject:\n  type: website\n  pre-render:\n    - scripts/pre_create_papers_file.py\n    - scripts/pre_check_skierg_records.py\nThis declares the scripts scripts/pre_create_papers_file.py and scripts/pre_check_skierg_records.py as pre-render scripts. You can also declare post-render scripts, with the post-render key.\n\n\nA (poorly) worked example: generating a publication list\nOn my website, I use Quarto project scripts to maintain a list of my papers. This list is generated from a BibTeX file, which makes it a little more convenient to maintain my publications, and somewhat future-proofed in case I want a different format.1\n1 I know there’s a canonically better solution that uses pandoc and Lua. I don’t care. This works for me, and I don’t have to learn Lua.You can see the full project script here, but here’s the gist of it:\n\n\n\n\n\n\nflowchart TD\n    A[BibTeX file] --&gt; a(\"load_bibtex_file()\") \n    a --&gt; B[BibTeX database object]\n    B --&gt; b(\"render_as_nlm()\") \n    b --&gt; C{book or article?}\n    C --&gt; D[article]\n    C --&gt; E[book]\n    D --&gt; d(\"render_article_as_nlm()\") \n    d --&gt; F[article entry]\n    E --&gt; e(\"render_book_as_nlm()\") \n    e --&gt; G[book entry]\n    F --&gt; H[all entries]\n    G --&gt; H\n    H --&gt; h(\"generate_list_by_year()\") \n    h --&gt; J[final set of entries]\n    J --&gt; j(\"write_into_file()\") \n    j --&gt; K[\"papers/index.qmd\"]\n\n\n\n\nFigure 2: My super clumsy pre-render script to build my bibliography.\n\n\n\n\n\nWe load a BibTeX file (load_bibtex_file()), parse it, use a function to determine whether we’re rendering a book or an article entry (I don’ have any other types of publications, but if I did, I’d add them here), and dispatch rendering to the appropriate function (render_article_as_nlm() for articles, render_book_as_nlm() for books). We sort the entries into a Markdown format with years separated by level 1 headings (generate_list_by_year()) and finally write it into the papers/index.qmd file (write_into_file()). There’s some minor magic going on behind the scenes, such as capturing my name and setting it in bold (which is a bit of a convention in academic lists of publications), but that’s the gist of it.\nThe result is a list of publications that is automatically generated from a BibTeX file, and is always up to date (as up to date as the BibTeX file, anyway). I don’t have to manually update it… sort of.\n\n\nWait, automagically updated?\nThe second half of what makes project scripts awesome is that they integrate with the rendering process. If the rendering process in turn integrates with some CI that watches for changes, then you can have a website that is automatically updated whenever you push a change to the repository. This is what I do with my website: I have a GitHub action that watches for changes to the main branch, and if it detects a change, it runs the rendering process and pushes the result to the gh-pages branch. This means that if I were to change the BibTeX file, it would trigger a re-render, and the list of publications would be automatically updated.\nThere are some tricks to keep in mind here. Most importantly, because this requires some custom Python packages, I had to slightly amend my Github publishing workflow:\n\n\n\n\n\n\nflowchart TD\n    A[\"actions/checkout@v4\"] --&gt; B[\"quarto-dev/quarto-actions/setup@v2\"]\n    B --&gt; C[\"actions/setup-python@v4\"]\n    C --&gt; D(\"pip install -r requirements.txt\")\n    D --&gt; E[\"quarto-dev/quarto-actions/publish@v2\"]\n    style D stroke-width:8px;\n    style C stroke-width:8px;\n\n\n\n\nFigure 3: Integrating the pre-render script into the Github Actions CI/CD framework. The parts that need to be integrated into the publishing workflow are highlighted with bold outlines.\n\n\n\n\n\nIn particular, I had to explicitly specify the Python version and install the requirements. This is because the quarto-actions/setup action does not install the requirements, and the quarto-actions/publish action does not install Python. This is admittedly a bit of a nuisance to work around, but really not all that big a deal in the grand scheme of things.\nOne thing to keep in mind when writing your script is the context from which it will be executed. In particular, if you’re using a CI/CD pipeline, you will need to make sure that the script can find the files it needs. In my case, I had to explicitly specify the path to the BibTeX file, as well as the path to the output file. This is because the script is executed from the root of the repository, but the BibTeX file is in the papers directory, and the output file is in the papers directory, too. Testing locally for deployment in CI/CD is notoriously hellish, but with a little bit of elbow grease,2 you can get it to work.\n2 And by ‘a little bit’, I mean absolute tons of it.One caveat: rendering with pre- and post-render project scripts may be relatively expensive in terms of time. My silly SkiErg world record script adds a good 20-25 seconds of processing time to each rendering run – not a lot, but it does stack up eventually. The documentation helpfully discloses that Quarto provides an environment variable, QUARTO_PROJECT_RENDER_ALL, which is set to 1 if it’s a full render. It may make sense to do a more manual caching here.\n\n\nThings you can do with project scripts\nSeriously, the possibilities of what you can do with project scripts are pretty much endless. I have a project script that checks the world records list on the official SkiErg website and makes sure my index page lists my accurate records. This is completely silly, but it’s also a great example of how you can use project scripts to automate just about everything:\n\nA script I built pulls DOIs minted by Rogue Scholar and appends them to posts.\nA lot of projects use it for housekeeping: via makefiles\nThe bambi project uses it to build a changelog, which is a great idea for applications that do need it\nThis one cool master’s thesis uses pre-render project scripts to load variables from a YAML file into envvars, and I’ve seen the same done with Rprofile files – obviously, these are much more pertinent to projects where the bulk of the project consists of notebooks/code execution rather than websites, but again, the idea is the same\nObviously, I’m not the only one to use it for reference management\nYou can use it to download static content into your project, too!\n\nThe sky’s the limit! I’m currently working on rendering my CV from a JSON file via a project script, as well as a few other cool things. I keep my project scripts here – I hope they will inspire you to do something cool with your own project scripts!\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {Quarto Project Scripts Are Awesomeness},\n  date = {2023-10-22},\n  url = {https://chrisvoncsefalvay.com/posts/quarto-project-scripts/},\n  doi = {10.59350/b4qyq-70w75},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “Quarto Project Scripts Are\nAwesomeness.” https://doi.org/10.59350/b4qyq-70w75."
  },
  {
    "objectID": "posts/dwarf-fortress/index.html",
    "href": "posts/dwarf-fortress/index.html",
    "title": "The hardest AI problem you’ve never heard of.",
    "section": "",
    "text": "There’s a notion in artificial intelligence known as Moravec’s paradox: it’s relatively easy to teach a computer to play chess or checkers at a pretty decent level, but near impossible to teach it something as trivial as bipedal motion. (Hassabis 2017) The sensorimotor tasks that our truly wonderful brains have mastered by our second birthday are much harder to teach a computer than something arguably as ‘complex’ as beating a chess grandmaster. In that sense, what Garry Kasparov learned in the first months of his life were much more ‘difficult’, from the perspective of AI, than his mastery of chess. So is, for that matter, learning to play Super Mario. What’s hard for us is simple for computers, and vice versa. (Pinker 2003)\n\nHassabis, Demis. 2017. ‘Artificial Intelligence: Chess Match of the Century’. Nature Publishing Group UK London.\n\nPinker, Steven. 2003. The Language Instinct: How the Mind Creates Language. Penguin.\n\nTiny problems, big world\nChess, for all its complexity, has a relatively small problem space. It is a spatially confined game of a limited number of pieces – which, by the way, is monotonically decreasing over time. Pieces have limited moves, so that a piece of type p being at position (\\(x, y\\)) at time t has a finite number of places it can be at \\(t+1\\) (valid moves). Consequently, for any state of the chessboard, we can describe a finite set of possible states one step later. Recursively, for any state of the chessboard, we can enumerate any future state. That this enumeration involves a rapidly growing and rather massive problem space is not, inherently, a huge problem. There are discrete steps in time, and each of those steps moves us along the tree. In short: however big the problem space, it can be enumerated.\nThis is important because processes like this (known as Markov decision processes) are kind of problem machine learning excels at. We can enumerate a bunch of these trees from start to finish (that is, individual chess games), and eventually the computer builds a representation of whether a particular move given particular preceding moves is or is not a good idea. Or, more formally, we can define a number of actions called policies in this context, so that given a system in state s and the action a, \\(\\pi_{a, s} = p(a_t = a | s_t = s)\\). We can then define a reward function for any policy \\(\\pi\\), so that \\(R(\\pi) \\sim \\sum_{t = 0}^{\\infty} r(\\pi, t)\\) for all \\(r(\\pi, t)\\) being the reward gained by taking the action corresponding to the policy \\(\\pi\\) at time step \\(t\\).1 Then, given a state \\(s\\) and a policy \\(\\pi\\), we can calculate the expectation value of \\(R_{\\pi} | t\\). And if we can calculate it, we can sic one of the many optimisation algorithms on it to maximise it. There, chess played, game won, end of.\n1 Specifically, by the factor \\(\\gamma^t\\), where \\(\\gamma\\) is the discount factor. For an excruciating amount of maths about all this, your best bet is Sutton and Barto (2d ed. 2018), gratifyingly available online for free. The discount factor , which Sutton and Barto call ‘discount rate’, is explained at Ch. 3.3, p. 54 onwards.\n\nLet’s get more problematic\nExcept, as I said, chess is, well, relatively simple to enumerate. What about non-enumerable systems? For starters, we can dispense with discrete time and start operating in continuous time. Things get a whole lot more complicated when you start to move from discrete maths to continuous values (and that’s why I largely stay on the discrete side, in the comfort of number theory and integer indices). What if a game of chess didn’t have turns, but rather played at whatever speed the players can simultaneously manage? And had a large problem space, a ton of different actors, oh, and let’s sprinkle some degree of randomness into it, so as to make the whole thing impossible to understand and computationally insane to model?\nIt turns out that we already have games like that. And one of them might just be the ultimate test for AI. Enter Dwarf Fortress.\nWell, then you’d have Dwarf Fortress.\n\n\n\nThis is Dwarf Fortress, in all its beauty (comma lack thereof). Screenshot taken from the legendary Boatmurdered saga, the most hilariously weird tale of just how incredible this game can be.\n\n\nNow, in case you haven’t heard of Dwarf Fortress: it’s not much to look at, to put it mildly. It’s got none of the smooth, flashy graphics of AAA gaming titles, the deep story of a game like Destiny or the humour of, say, Borderlands.[2]. What it does have is a level of intricacy that makes it a game on the literal edge between insanity and genius (and typically, when it comes to Dwarf Fortress, the two are present in a racemic mixture). You’re in charge of building, unsurprisingly, a fortress, full of dwarves. You explore, mine, craft and inevitably get killed, more than likely by a) elephants, b) lava. In the meantime, random things happen, in a procedurally generated world. From time to time, dwarves become possessed, elephants assault your fortress and things are set on fire. Behind all this is a staggering volume of intricate game mechanics for just about everything.\n\n\nAgent based insanity\nLet me illustrate this with an actual example. In December 2015, a player has complained that the cats are dying in his fortress. It has emerged that they were dying of ethanol poisoning. It turns out that Dwarf Fortress models (individually, for each animal in the game!) the ingestion of substances from body coverings for animals. Cats lick their paws, and ingest a part of whatever is on their paws. In that case, it was spilled beer (which obviously dwarves drink in non-trivial quantities). A large number of dwarves stopping their inebriation in progress to do something else would result in large spills of alcoholic beverage, which the cats would get on their paws, which they would eventually lick, which would eventually get them drunk and, until a bug fix, dead.\nNow, this isn’t something special. Pretty much everything in Dwarf Fortress is like this. Oh, and almost all of it is procedurally generated. This makes Dwarf Fortress an extreme case: it is arguably the most difficult game that can be ‘learned’ that we know of.\nBy ‘can be learned’, I mean that it is a game that can still have a distinct ordered set of policies \\(\\pi_{1 ... n}\\) sorted by \\(E[R(\\pi)]\\), i.e. the expectation value of the reward function of the policy over time \\(t_0 \\to t_{\\infty}\\). We don’t see tossing a (fair) coin and guessing heads or tails as a winnable or ‘learnable’ game because there is no policy that is better than any of the others, and no amount of gathering information after a handful of coin tosses will make our predictive accuracy any better. Dwarf Fortress can’t exactly be won, but it can be not lost for a considerable time, which one can regard as a result (the sum reward is the time of survival, something I call the Kaplan-Meier definition of winning).\nThus, it’s not all up to randomness, but rather up to being able to operate in a non-Markovian problem space – a very non-Markovian one, given the sheer variety of crazy things that can happen. Games like go or chess teach computers how to adapt to an opponent (who, incidentally, pursues the same objective). Learning Super Mario using deep Q learning is somewhat more about winning against an environment (in the sense that there is no competing player whose requirements for success mirror one’s own). Learning Dwarf Fortress, however, teaches computers how to operate in a space of uncertainty.\nIf Dwarf Fortress sounds familiar to you, it’s because it is. It’s effectively a gamified version of agent-based modelling (ABMs), a technique we use to model populations by modelling individuals in a space of uncertainty governed by certain probability distributions. Take the classic SIR model of disease population dynamics. You can use a system of differential equations – or you can create a random population of a few hundred dwarves and simulate what would happen if you let some infection loose among them. Indeed, I reflect on this in my recent book:\n\nOne of the most complex computer games ever devised is called Dwarf Fortress. It is not much to look at: its graphics are the terminal-based structures that were in vogue in the 1980s. What makes Dwarf Fortress an extraordinary game is the depth of agent-based logic: every character, every enemy unit, even pets are endowed with a hugely complex agent-based behavioral model. As an example, cats in Dwarf Fortress can stray into puddles of spilled beer, lick their paws later, and succumb to alcohol poisoning.\nYet agent-based modeling is about much more than belligerent dwarves and drunk cats. Agent-based models are powerful computational tools to simulate large populations of boundedly rational actors who act according to preset preferences, although often enough in a stochastic manner. They can simulate the complex human behaviors of quasi-rational decision-making, represent large populations and, through iterative simulation, highlight likely behavioral outcomes of crowds.\nMost of the foregoing chapters described a kind of statistical mean-field dynamics of epidemiology – we might have known what a population does, but not much about any one individual in a population. At best, we could deduce the state or behavior of an individual in terms of likelihoods, e.g. if 30% of a population is infectious, there is approximately a 30% chance a randomly selected individual from the population will be infectious. Like statistical mechanics, it offers us the ability to reason about dynamics at the population scale without having to model each individual.\nThis chapter explores an alternative approach. Agent-based models are primarily inductive—we obtain information about the population by large-scale, repeated simulation of individual agents. Such models allow a different glimpse into the operation of an epidemic process. Many phenomena that would be challenging to model on their own, such as heterogeneous populations with multiple heterogeneities, some continuous and others categorical, become almost trivially easy to analyze using agent-based models. On the other hand, agents can adopt complicated behaviors and very complex behavioral profiles are relatively easy to describe in the agent-paradigm, because we only need to describe an individual rather than an entire tion. This chapter discusses how we can leverage agent-based models for understanding infectious disease dynamics.\n– (Von Csefalvay 2023)\n\nVon Csefalvay, Chris. 2023. Computational Modeling of Infectious Disease: With Applications in Python. Elsevier.\n\nAgent-based models help us understand issues that are, or might be, too complex to be analytically solved. It is, in a way, brute-forcing reality by creating a simulation and running it enough times to give a numerical solution. Where human issues are involved, agent-based models are the way to go to understand the complexity of human behaviour and choices. This is so even if most agent-based models have nowhere near the sophistication of Dwarf Fortress.\n\n\nIf you want me worried, call me when an AI has mastered Dwarf Fortress\nAlgorithms that can infer a person’s emotional state from the position vector of facial landmarks or detect signs of stress in someone’s voice do not give a system any wider understanding of humans. Nor does beating them at playing go, chess, checkers or Starcraft. None of these abilities would be sufficient for an intelligence, artificial or not, to navigate the real world. Understanding a detailed, thorough agent-based model of a human (or dwarven!) society, however, comes much closer to it. A machine that can play chess is cool. A machine that can play Dwarf Fortress with good results is much more than that – it is a competitor, a social reasoner who can make assumptions about actions that hold true at least stochastically.\nOne of the side effects of working in research in the AI field is that people will inevitably ask when our new robot overlords will show up. I have never been too concerned by that. With all due respect to Hawking, Musk, Norvig and other purveyors of AI fears, I am unconcerned by the ‘state of the art’. When it comes to complexity that involves cats licking beer off their paws and getting drunk, AI is still a good way away from showing a decent understanding of continuous stochastic systems.\nIf you want me worried, call me when an AI has mastered Dwarf Fortress.\n\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2023,\n  author = {{Chris von Csefalvay}},\n  title = {The Hardest {AI} Problem You’ve Never Heard Of.},\n  date = {2023-03-07},\n  url = {https://chrisvoncsefalvay.com/posts/dwarf-fortress/},\n  doi = {10.59350/5dp4z-d5e22},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2023. “The Hardest AI Problem You’ve Never\nHeard Of.” https://doi.org/10.59350/5dp4z-d5e22."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "The Notebook",
    "section": "",
    "text": "After agents\n\n\n\n\n\n\nLLMs\n\n\nAI\n\n\nagents\n\n\n\n2024 was the year of agents. 2025 will be about figuring out how we orchestrate their interactions. Welcome to the year of ecosystems.\n\n\n\n\n\n4 Jan 2025\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nFive unconventional predictions\n\n\n\n\n\n\nLLMs\n\n\nAI\n\n\ntech predictions\n\n\n\nOr, the GenAI årsgång, 2025 edition\n\n\n\n\n\n31 Dec 2024\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nLAIR - Language As Intermediate Representation\n\n\n\n\n\n\nLLMs\n\n\nAI\n\n\nstyle transfer\n\n\n\nLanguage As Intermediate Representation - a new paradigm for transformation using multimodal LLMs\n\n\n\n\n\n6 Jan 2024\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nThe 95% myth\n\n\n\n\n\n\nfitness\n\n\nscience\n\n\nbad science\n\n\n\nHow a study from 1959 on 100 patients created one of the most enduring myths about human weight and nutrition.\n\n\n\n\n\n27 Dec 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nWhat I learned from getting bodied by a robot.\n\n\n\n\n\n\nAI\n\n\ndisability\n\n\nhuman-computer interaction\n\n\n\nI’m fine, the robot’s fine, society on the other hand has some questions to tackle.\n\n\n\n\n\n12 Dec 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic parrots, cap and gown edition\n\n\n\n\n\n\nAI\n\n\nacademia\n\n\nwriting\n\n\nLLMs\n\n\n\nAcademic AI is a hot mess. Here’s why.\n\n\n\n\n\n6 Dec 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nAuto-DOI for Quarto posts via Rogue Scholar\n\n\n\n\n\n\nQuarto\n\n\n\nOh, that’s mint. We can finally use Rogue Scholar to mint DOIs for Quarto posts and append them automagically. \n\n\n\n\n\n13 Nov 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nThe skeuomorphic fallacy\n\n\n\n\n\n\nAI\n\n\nphilosophy\n\n\n\nWhat something is isn’t the same as what it uses to manifest that being. Also, robot CEOs are nonsense. \n\n\n\n\n\n6 Nov 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nTeams of Rivals\n\n\n\n\n\n\nAI\n\n\nLLMs\n\n\nagents\n\n\n\nFinally, some discussion on LLM connectionism, and what LLMs could usefully become. \n\n\n\n\n\n30 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Engineering: The Art of Yesterday\n\n\n\n\n\n\nAI\n\n\nLLMs\n\n\nprompt engineering\n\n\n\nWhy prompt engineering has been obsolete before it even took off. \n\n\n\n\n\n29 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nThe Moral Pulse of the Machine\n\n\n\n\n\n\nAI\n\n\nstorytelling\n\n\nsensemaking\n\n\nethics\n\n\nphilosophy\n\n\n\nOn bedtime stories, and what making machines tell them tells us about their moral make-up. \n\n\n\n\n\n26 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto project scripts are awesomeness\n\n\n\n\n\n\nQuarto\n\n\nPython\n\n\n\nProject scripts help you integrate just about every possible hare-brained scheme into your Quarto rendering pipeline. Go on, build that page from that YAML file. You know you want to. \n\n\n\n\n\n22 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nThe Lyre of Hephaestus\n\n\n\n\n\n\nAI\n\n\nart\n\n\nphilosophy\n\n\n\nAI, art, language, and what makes us truly what we are. \n\n\n\n\n\n16 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Broca\n\n\n\n\n\n\nAI\n\n\nLLMs\n\n\nphilosophy\n\n\nlanguage\n\n\n\nWhat if we’ve got one of the most important things in our understanding of who we are, and what makes us intelligent, utterly wrong? \n\n\n\n\n\n15 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nHow to do a SkiErg marathon entirely the wrong way (but still finish)\n\n\n\n\n\n\nfitness\n\n\nSkiErg\n\n\n\nHow to eat the wrong way, rest the wrong way (i.e. not), half-ass all relevant parts of preparation for a marathon and still finish with an okay time.\n\n\n\n\n\n\n13 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nThe knowledge dividend of large language models\n\n\n\n\n\n\nAI\n\n\nLLMs\n\n\nCross-post: Starschema\n\n\n\nCrosspost from the work blog: a pragmatic perspective on the knowledge dividend in large language models (and what it may, or may not, mean for knowledge in models, and what this can do for you). \n\n\n\n\n\n2 Oct 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nAsemantic Induction of Hallucinations in LLMs\n\n\n\n\n\n\nAI\n\n\nLLMs\n\n\nCross-post: Starschema\n\n\n\nLarge language models (LLMs) struggle with asemantic information: the more we stray outside the confines of language, the worse it gets. Here’s how we’ll use this for fun and profit. \n\n\n\n\n\n23 Mar 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nData for the next pandemic\n\n\n\n\n\n\ncomputational epidemiology\n\n\nepidemics\n\n\nCross-post: Starschema\n\n\n\nIf there’s one thing that emerged with any clarity from COVID-19, it’s that where data played a decisive role in guiding policy interventions, outcomes were better. We need better data for the next pandemic. \n\n\n\n\n\n7 Mar 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nThe hardest AI problem you’ve never heard of.\n\n\n\n\n\n\nAI\n\n\ngames\n\n\nABMs\n\n\n\nDwarves. Elephants. AI. Let the games begin. \n\n\n\n\n\n7 Mar 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nA different shade of grey\n\n\n\n\n\n\nAI\n\n\ncomputational chemistry\n\n\nethics\n\n\n\nA response to Urbina et al. (2022) and the unreasonable spectre of AI coming up with chemical warfare agents (as if we didn’t already have enough of them). \n\n\n\n\n\n13 Apr 2022\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nFive non-data-science books for data scientists\n\n\n\n\n\n\nliterature\n\n\ndata science\n\n\nethics\n\n\n\nRead stuff outside your field. It’ll be good for you. \n\n\n\n\n\n13 Apr 2022\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nMy favourite Quora answers\n\n\n\n\n\n\nQuora\n\n\nhistory\n\n\ntechnology\n\n\n\nI’m no longer on Quora, but I used to be. Here are some of my favourite answers. \n\n\n\n\n\n13 Apr 2022\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nAs we may see: the world after dashboards\n\n\n\n\n\n\ndashboards\n\n\ndata visualization\n\n\ndata science\n\n\nCross-post: Starschema\n\n\n\nDashboards are over – if you want it. \n\n\n\n\n\n1 Apr 2022\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nPeace, love, Paxlovid and ‘Pfizermectin’\n\n\n\n\n\n\nCOVID-19\n\n\npharmacology\n\n\n\nDebunking a remarkably popular and persistent misconception about the relationship between Paxlovid and ivermectin. \n\n\n\n\n\n27 Nov 2021\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nWhy the COVID-19 vaccines are not gene therapy\n\n\n\n\n\n\npublic health\n\n\nvaccines\n\n\n\nReflections on some definitional issues. \n\n\n\n\n\n9 Nov 2021\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nRansomware attacks as n-person prisoner’s dilemmas\n\n\n\n\n\n\ncybersecurity\n\n\neconometrics\n\n\ngame theory\n\n\n\nA game theoretical perspective on ransomware attacks as n-person prisoner’s dilemmas, and why forced cooperation isn’t the answer. \n\n\n\n\n\n14 May 2021\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nJulia: A post-mortem\n\n\n\n\n\n\nAI\n\n\nJulia\n\n\nprogramming\n\n\n\nWhy I no longer believe my favourite programming language will save the world. \n\n\n\n\n\n7 Mar 2021\n\n\nChris von Csefalvay\n\n\n\n\n\n\nNo matching items\n\n\n  \n\nCitationBibTeX citation:@misc{csefalvay,\n  author = {{Chris von Csefalvay}},\n  title = {The {Notebook}},\n  url = {https://chrisvoncsefalvay.com/posts/},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. n.d. “The Notebook.” https://chrisvoncsefalvay.com/posts/."
  },
  {
    "objectID": "posts/asemantic-induction-of-hallucinations/index.html",
    "href": "posts/asemantic-induction-of-hallucinations/index.html",
    "title": "Asemantic Induction of Hallucinations in LLMs",
    "section": "",
    "text": "Over at the work blog, I’m discussing what knowledge means for large language models (LLMs), and the ways in which we can leverage this knowledge dividend for better inference.\n\nLanguage is highly semantic, but because of that, it is also highly flexible. By semantic, I mean that every lexeme has a distinct and coherent meaning. A lexeme is the “root form” that is conjugated to various forms, e.g. “see”, “saw” or “seeing” are all forms of the same lexeme, “SEE” (by convention, in linguistics, we set lexemes in capitals to distinguish them of their homomorphic conjugated forms). By flexibility, I mean that you can actually manipulate lexical order and retain meaning. Consider the sentence “Joe walked his dog in the park”. “In the park, Joe walked his dog” and “His dog, Joe walked in the park” all have slightly different nuances due to inflection and emphasis of order, but overall, they all get the same larger message across. Some languages permit even more flexibility with word order, but even in English, the worst case scenario is that it’ll sound a little odd. The content remains intelligible, which is why poets get to move words around to make things rhyme. In short, producing something that looks “like” natural language is going to be natural language. It’s likely not going to be a Booker Prize-winning product of staggering genius, but it will be good enough.\nThis is not the case for asemantic structures. By asemantic structures, I mean any system in which a sequence of tokens has a meaning, but in which there’s no semantic meaning to any token. In other words, every token has a meaning, but that meaning is not inherent in their character. It probably serves to belabour this point a little. All words are, to an extent, made up, but more similar words are closer to each other in meaning. By similar, I do not mean simple formal similarity, such as Hamming or Levenshtein distances, but rather logical similarity, e.g. conjugation of the same root. This is more evident in some languages than others. In Semitic languages, for instance, you have clusters of meaning that are connected by consonantal roots. By way of an example: the triconsonantal root k-b-d connects a cloud of meanings that all have to do with the middle or centre of something, and by extension the centre of gravity or honour. This gives us e.g., the Hebrew words for ‘heavy’ (כָּבֵד), mass in the physical sense (כֹּבֶד), and the word for ‘liver’ (כָּבֵד), which was considered to be roughly in the middle of the body. In any language, however, there is a degree of meaningful semantic similarity between connected concepts. There has more been written on this than I have the space to mention here.\nAn asemantic structure is where there are formally similar things that are unrelated. You have probably experienced this when you dialled the wrong number by a slip of the finger. The fact is, if you live in the United States, my phone number looks a lot like yours, and by extension, anyone else’s. There’s no semantically meaningful reason why your phone number shouldn’t be mine or vice versa: it’s not more ‘you’ as mine is not more ‘me’ in any underlying sense.\nWhich is why GPT-4 struggles with asemantic content, and we’ll use this to break it a little.\n\nRead the full post here."
  },
  {
    "objectID": "posts/ransomware-prisoners-dilemma/index.html",
    "href": "posts/ransomware-prisoners-dilemma/index.html",
    "title": "Ransomware attacks as n-person prisoner’s dilemmas",
    "section": "",
    "text": "In the middle of the green and pleasant countryside of England lies a small piece of commons –– land, that is, over which a number of people share certain rights. In this hypothetical scenario, it’s six farmers, \\(F_1\\) to \\(F_6\\). Each of them has a hypothetical cow, which differs from ordinary cows in that it grazes a fixed unit, and produces a fixed amount of milk (unlike real cows, which vary wildly in their input and output parameters, or so I’m told). It is important to note that the land is a form of common property, meaning it is held by all of them jointly––or as ye olde Law Latin would put it, totum tenet et nihil tenet: they all hold the whole together, but no-one holds any specific part of it.1\n1 As opposed to forms of co-ownership where each person owns a defined fraction of the co-owned property.If you are one of the farmers, you have a very clear dominant strategy: get another cow! Even better, get a handful. More cows equal more milk, and the land can sustain at least six cows.\nThe problem is, if all participants \\(F_{1...6}\\) pursue this individually dominant strategy, the sum of their outcomes will be inferior. Every player choosing the dominant strategy results in a worse outcome than it would if they had not chosen the dominant strategy. This phenomenon is sometimes referred to as the ‘tragedy of the commons’, but is in fact a simple result of an n-player prisoner’s dilemma.\n\nRaising the stakes\nLet’s raise the stakes a little. Kidnappings happen because a significant fraction of people pay ransoms. The law on this is a little weird, and this reflects the general unease with which we regard the issue.2 We might agree that paying ransoms is a bad idea as a matter of principle, while also feeling rather disinclined to sacrifice a loved one on the altar of that principle. Personally, I know very few people who genuinely would not pay a ransom they had the means to pay for the release of a loved one – even if as an abstract principle, they agree that paying ransoms is a bad idea. A lifetime ago, when I studied (and later taught) moral and political philosophy at Oxford, these questions were popular dilemmas to make students think about consequentialism. Now, they are questions that affect every-day lives. Just earlier this week, much of the Eastern seaboard experienced gas shortages due to a ransomware attack on the Colonial Pipeline – over here in Northern Virginia, most gas stations were out of supply yesterday and expect to have fuel no sooner than early next week.\n2 The law is outright weird, in that in most countries, paying ransoms is not illegal per se, but giving money to certain entities is illegal regardless of the purpose of the money. In that sense the law does not distinguish between paying a ransom to, say, Boko Haram, who happen to be on the Treasury’s shitlist, or giving them the same amount of money due to an overwhelming conviction that boko is very haram indeed – it’s illegal either way. This makes paying a ransom needlessly complicated, especially as in my modest experience with kidnappers, they rarely discuss their organisational affiliations at length. With international jihad in particular being run on the franchise model in this day and age, it may well turn out that Joe Kidnapper, who held himself out as a common criminal, was in fact a full franchisee of al-Qa’ida, and suddenly the FBI is going through your underwear drawer.3 Kidnapping, I am told, is expensive, and has to be funded in advance, with no guarantee that it will yield a payout at the end. The more complicated the operation, the greater the risk. The advent of the paseo milionario or ‘express kidnapping’ indicates that there is clearly a much reduced appetite for the risk involved with kidnapping. It is then no wonder that ransomware, which lacks many of the expensive and/or gory parts of kidnapping, is so much more favoured.And that leads us to the ethical problem of ransomware, in particular paying the ransom (as the maintainers of the Colonial Pipeline did). If the common response to ransomware would be ‘go f––– yourself’, making ransomware would not be worth it. This scenario slightly differs from kidnapping in that the investment in each ransomware operation is very significantly smaller than it is for a kidnapping.3 Consequently, adopting the collectively dominant strategy of telling kidnappers what to stick where on which family member of theirs would only work if virtually all potential victims would do so (i.e. cooperate). This makes ransomware a trickier problem than plain, old kidnapping: if only a few ransom demands are not met, kidnappers are faced not only with the issue of cleaning up the bodies but also a significant financing shortfall. Ransomware cybercriminals, on the other hand, can afford a significant proportion of their victims to ‘cooperate’ (i.e. not pay), as long as a small number ‘defect’. Thence comes our first important point to consider: the cost of extortion governs where the deficient equilibrium point is located.\n\n\nPossible solutions\nThe consequence of low-cost extortion (express kidnapping, ransomware &c.) is to move the deficient equilibrium point to the far right, meaning that an unrealistically large percentage of the population must commit to cooperate before kidnappers start to see their business model break down. This is, ultimately, the problem known to economists as free-riding. There are, overall, two major solutions to it, none of them good.\nForced cooperation. In forced cooperation, a third party (typically, the state) intervenes and shifts the payoff matrix so as to make cooperation relatively more profitable. This happens typically by making defection less profitable, such as would happen if paying ransoms were to be criminalised. Voluntary cooperation. In voluntary cooperation, the payoff matrix is unaffected, but players set aside their individually dominant strategy voluntarily. It’s important to note at this stage that it is perfectly consistent to argue against forced cooperation and in favour of voluntary cooperation––that is, holding the opinion that nobody should pay ransoms but the government should not criminalise paying ransoms is not an inconsistent public policy position.\n\n\nThe problem with forced cooperation\nLet’s face it – I’m an optimist, but even I’m not optimistic enough to think people will voluntarily cooperate to the extent required by the extremely low cost of ransomware attacks. The example of kidnappings, where ransoms are almost always paid (even where this is strictly speaking illegal), shows that such cooperation is unlikely to arise voluntarily.\nThe answer to that, many would argue, lies in enforcing cooperation by altering the payoff matrix. Robert Knake makes this point in an article from 2016:\n\nWhat I will argue is that when looking at a public policy problem, the best place to create liability is where it will have the desired impact. If the goal is to stop ransomware attacks, raising the costs of paying ransoms beyond what the criminals are demanding is the best way to do that. Those costs could come in the form of civil fines or misdemeanor charges. For most American companies and most individuals, simply knowing that paying a ransom would violate the law might be enough to dissuade them. If enough victims are persuaded to forgo payment and accept the consequences, there will be fewer future victims.\n\nRegrettably, this argument is several kinds of wrong and at least two kinds of immoral. It is wrong because the sad ubiquity of ransomware attacks and their relatively private-synallagmatic nature (unlike kidnappings, which are widely publicised) means that enforcing such legislation would be quite difficult in practice. It is also wrong because the impact of “civil fines or misdemeanor charges” is far from clear. Short of exorbitant fines (which would face legal challenges for a range of reasons), these costs would just be factored into the ‘cost of doing business’ the way many companies already accept various unsavoury practices that are part and parcel of economic activity in some parts of the world. And it is fundamentally wrong in failing to understand the logic behind ransomware. The reason why ransomware makes sense is because data may be unique and irreplaceable (it shouldn’t be, and having well-designed IT policies with TTPs that encourage data replication and encryption are the most effective tools against ransomware attacks, but that’s a different story). Compared to the consequences of losing years of research, experiencing months of service interruption or leaking the medical records of thousands of patients, any fine the government can levy pales in comparison. You cannot fine a complex problem out of existence – and fines are in any case economically flawed deterrents, reducing the available funds for compliance. Fines work to reduce the economic profitability or viability of a course of action – they do not work in preventing the circumstances from arising that open up the choices including that course of action.\n\n\nA better model of state action\nIf, thus, the coercive model of state action in response to ransomware is a ubiquitous failure, the question is what role the state can play in this matter. The alternative model that I support is one of cooperation rather than coercion. In the cooperative model, state actors assist enterprises within their territory in changing the payoff matrix by increasing the costs of successful ransomware attacks. Ransomware works because it’s so cost-efficient: even if only one in a thousand victims pay up, the monies paid out are sufficient for a generous profit. Up until here, I’m in agreement with the coercive model––the only way to eliminate ransomware is to make it economically less viable. The difference is how that is accomplished.\nIn the cooperative model, the state invests in hardening IT systems against ransomware attacks. It stands to reason that if a large number of such attacks do not succeed, the entire enterprise becomes unprofitable. From the blackmailer’s perspective, the results are pretty much the same, i.e. vastly reduced income. However, from what H.L.A. Hart would have called the ‘internal point of view’, i.e. the perspective of the community and the individual, there is a crucial difference: cooperation forgoes the moral horror of punishing the victim in favour of preventing individuals from becoming victims. In the end, the “best place to create liability” is not where it will have some fictitious “impact”, but where it is most appropriate. Re-victimization is not only morally abhorrent, it is also ineffective: a company that sustained a loss from a massive ransomware attack may be less capable of upgrading security to withstand such attacks in the future, whereas a company that received support to shore up their defences will have a strong (indeed, contractual) incentive to do so.\nIn the end, how we allocate losses says a lot about what we as a society are like. The choice, then, as far as ransomware is concerned, must lie in collaboration over coercion. Government has an opportunity to be a force for good in this field, if only it can forego the empty moralisms that focus on the victim’s blameworthiness. Certainly ill-prepared companies are more likely to be struck by ransomware. Blaming it all on the victim, however, and treating ransoms as illegal payments merely allows governments that have for too long dropped the ball on cybersecurity preparedness to further postpone their duties and deflect blame.\n\n\n\n\n\nCitationBibTeX citation:@misc{csefalvay2021,\n  author = {{Chris von Csefalvay}},\n  title = {Ransomware Attacks as n-Person Prisoner’s Dilemmas},\n  date = {2021-05-14},\n  url = {https://chrisvoncsefalvay.com/posts/ransomware-prisoners-dilemma/},\n  doi = {10.59350/r74zv-gsd67},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nChris von Csefalvay. 2021. “Ransomware Attacks as n-Person\nPrisoner’s Dilemmas.” https://doi.org/10.59350/r74zv-gsd67."
  },
  {
    "objectID": "posts/as-we-may-see/index.html",
    "href": "posts/as-we-may-see/index.html",
    "title": "As we may see: the world after dashboards",
    "section": "",
    "text": "In my latest post for the Starschema blog, I discuss the end of dashboards, and what comes next:\n\nEnterprises have spent the last two decades meticulously curating dashboards. Tools have improved and what once was the preserve of trained professionals has largely been democratized across the enterprise. However, dashboards are quintessentially static. A dashboard shows what its developer has directed it to show. That ignores the vast realm of the ‘unknown unknown’ that is, what we don’t know that we don’t know.\nDashboards, in that sense, answer narrow questions while giving the illusion of comprehensiveness and a 30,000ft perspective. In reality, dashboards are limited tools to convey limited information, while providing a psychologically fulfilling yet false illusion of comprehensiveness.\nThis may be true, but until now, there have been rather few alternatives. In the modern enterprise, a dashboard is created to provide a consumer with information on a particular subject. This involves certain judgments about what is, and what is not, included. This, in turn, biases the observer to what they are presented: they are, in a sense, trapped in an involuntary version of McNamara’s fallacy. What is not quantified and dashboarded does not exist. Few modern executives have the capability to reach beyond these summaries of data (if they did, they wouldn’t need dashboards in the first place).\nHowever, machine learning may spell a fundamental change in this. We now have the tools and techniques to sift through vast volumes of data and evaluate the relative saliency of each data item.\n\nRead the full post here."
  },
  {
    "objectID": "disclaimer/index.html",
    "href": "disclaimer/index.html",
    "title": "Chris von Csefalvay",
    "section": "",
    "text": "Opinions expressed on this Site are the author’s own in his personal capacity. They do not reflect the views of the United States Government, the Commonwealth of Virginia, HCL America Inc. or of any organisation, company or board he is associated with."
  },
  {
    "objectID": "media/index.html",
    "href": "media/index.html",
    "title": "In the media",
    "section": "",
    "text": "Tech for Good podcast\n\n\n\n\n\n\nTech for Good\n\n\n\nA fascinating interview with Ben Mouncer on the Tech for Good podcast. \n\n\n\n\n\nMar 7, 2023\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nCorona in den USA: Mediziner warnen nun vor Injektion von Desinfektionsmittel\n\n\n\n\n\n\nFrankfurter Rundschau\n\n\n\nInjecting disinfectants continues to be a bad idea. \n\n\n\n\n\nMay 11, 2020\n\n\nChris von Csefalvay\n\n\n\n\n\n\n\n\n\n\n\n\nKoronavírus: az USA-ban már használják, itthon még nem kellett a magyar cég adatelemző programja\n\n\n\n\n\n\nEuronews\n\n\n\nCommenting on our work on the COVID-19 data set and the relevance of data in a pandemic. \n\n\n\n\n\nApr 17, 2020\n\n\nChris von Csefalvay\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "media/fr-disinfectants/index.html",
    "href": "media/fr-disinfectants/index.html",
    "title": "Corona in den USA: Mediziner warnen nun vor Injektion von Desinfektionsmittel",
    "section": "",
    "text": "My comment on the use of disinfectants as a treatment for COVID-19 was published in the Frankfurter Rundschau – along with some skepticism about sunlight as the best disinfectant:\n\nBeim Sonnenlicht als Corona-Faktor beruft sich das Weiße Haus auf eine Studie, die im “National Biodefense Analysis and Countermeasures Center” im Bundesstaat Maryland gemacht worden sein soll. Demnach schrumpft das Virus auf einer Edelstahloberfläche im Sonnenlicht bei einer Temperatur von 21 bis 24 Grad Celsius und 80 Prozent Luftfeuchtigkeit innerhalb von nur zwei Minuten auf die Hälfte seiner Größe - verglichen mit sechs Stunden im Dunkeln.\nDie Tatsache, dass es jedoch keine weiteren Details darüber gibt, wie das Experiment ausgeführt wurde, sorgt für Kopfschütteln bei Wissenschaftlern. “Es sieht so aus, als hätte jemand irgendwo ein Experiment durchgeführt”, sagte Benjamin Neuman, Vorsitzender der Biowissenschaften an der Texas A&M University-Texarkana, der Nachrichtenagentur AFP. “Als Wissenschaftler würde ich natürlich gerne eine aktuelle Studie und die tatsächlichen Zahlen sehen”, sagte der Virusepidemiologe Chris von Csefalvay. Mediziner reagierten fassungslos auf die Äußerungen des Präsidenten und warnten eindringlich davor, sich Desinfektionsmittel zu spritzen oder zu schlucken. Dies könne tödliche Folgen haben.\n\nRead the whole thing here.\nAnd on that note, the Manila Times also quoted me on the same topic.\n\n\n\nCitationBibTeX citation:@online{von_csefalvay2020,\n  author = {von Csefalvay, Chris},\n  title = {Corona in Den {USA:} {Mediziner} Warnen Nun Vor {Injektion}\n    von {Desinfektionsmittel}},\n  date = {2020-05-11},\n  url = {https://chrisvoncsefalvay.com/media/fr-disinfectants},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCsefalvay, Chris von. 2020. “Corona in Den USA: Mediziner Warnen\nNun Vor Injektion von Desinfektionsmittel.” May 11, 2020. https://chrisvoncsefalvay.com/media/fr-disinfectants."
  }
]