<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Chris von Csefalvay</title>
<link>https://chrisvoncsefalvay.com/posts/</link>
<atom:link href="https://chrisvoncsefalvay.com/posts/index.xml" rel="self" type="application/rss+xml"/>
<description>Chris von Csefalvay is a computational epidemiologist/data scientist working at the intersection of AI, epidemiology and public health.</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Sun, 28 Dec 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>The post-training instrument cluster – Part II</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Hey, I’m writing a book about this!
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m actually writing a book about this stuff. It turns out there isn’t a lot of literature on how to do post-training at the level too big for single-GPU laptop-sized hobby projects and requiring enterprise reliability on one hand, but not quite at the scale of multi-team distributed post-training you’d get in foundation labs. That’s a problem, because a lot of the current value in fine-tuning applications comes exactly out of that large, crucial market. I am in the last phases of putting together the manuscript for <em>The Frontier Playbook</em>, a set of curated tactics and techniques for real world operationalisation of LLMs. <a href="https://aifrontierplaybook.substack.com">Sign up for updates here</a>.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>This is Part II of a series
</div>
</div>
<div class="callout-body-container callout-body">
<p>This post builds on <a href="../../posts/post-training-instrument-cluster/index.html">Part I</a>, which covered the eight instruments for supervised fine-tuning. If you haven’t read that yet, I recommend starting there – the instruments in this post assume familiarity with the basics of loss landscape monitoring, gradient health and the general philosophy of comprehensive training instrumentation.</p>
</div>
</div>
<p>In Part I, we built an instrument cluster for supervised fine-tuning: eight monitors that together paint a comprehensive picture of what’s happening during a LoRA training run. But as I hinted at the end of that post, the story doesn’t end with SFT.</p>
<p>The moment you move from supervised fine-tuning to reinforcement learning from human feedback (RLHF) or its variants – Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), Proximal Policy Optimization (PPO) and so on – you enter a different regime altogether. The failure modes multiply. The metrics become more subtle. And the consequences of getting it wrong become considerably more expensive.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;I’m being restrained here. In my experience, a failed RL run is typically 3-5x more expensive than a failed SFT run, not just in compute cost but in human time spent diagnosing what went wrong. The failure modes are less obvious, the feedback loops are longer and the pathologies can be quite subtle until they suddenly aren’t.</p></div></div><p>The fundamental shift is philosophical: in SFT, we’re teaching the model to imitate. In RL, we’re teaching it to <em>optimise</em>. And optimisation, as anyone who has spent time with reward systems (or golden retrievers) knows, is a double-edged sword. The model will find a way to maximise the reward – the question is whether that way aligns with what we actually wanted.</p>
<p>This post introduces four additional instruments for your post-training dashboard, specifically designed for preference optimisation and reinforcement learning methods. Together with the eight from Part I, they form a twelve-instrument cluster that should catch most of the pathologies you’ll encounter in production RL training.</p>
<section id="the-rl-monitoring-problem" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-rl-monitoring-problem">The RL monitoring problem</h2>
<p>Before we dive into the instruments, it’s worth understanding why RL training is harder to monitor than SFT.</p>
<p>In supervised fine-tuning, the objective is clear: minimise the cross-entropy loss between the model’s predictions and the training labels. The loss curve tells you almost everything you need to know about whether learning is happening. Yes, there are subtle failure modes (as we covered in Part I), but the basic diagnostic picture is straightforward.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>The reward model is itself a trained system with its own failure modes. We’re optimising against a proxy, not the true objective. This, by the way, is the source of most RL pathologies.</p>
</div></div><p>In RL, we’re optimising against a <em>reward signal</em> – typically produced by a reward model trained on human preferences, or in the case of DPO, implicitly derived from preference pairs. This introduces several complications:</p>
<ol type="1">
<li><strong>The reward is a proxy</strong>: The reward model is our best guess at what humans want, not what they actually want. Optimising too hard against this proxy leads to reward hacking – the model exploiting quirks in the reward model rather than genuinely improving <span class="citation" data-cites="gao2023scaling">(Gao, Schulman, and Hilton 2023)</span>.</li>
<li><strong>The policy can drift</strong>: Unlike SFT, where the model stays close to its initialisation, RL can push the model relatively far from its starting point. This drift can destroy capabilities that the base model had. RL can legitimately break your base model’s back.</li>
<li><strong>The optimisation landscape is non-stationary</strong>: As the policy changes, the distribution of data it generates changes, which in turn changes the effective reward landscape.</li>
<li><strong>Multiple objectives are in tension</strong>: We want high reward <em>and</em> low divergence from the reference policy <em>and</em> preserved capabilities <em>and</em> no degenerate behaviours. These can conflict.</li>
</ol>
<div class="no-row-height column-margin column-container"><div id="ref-gao2023scaling" class="csl-entry">
Gao, Leo, John Schulman, and Jacob Hilton. 2023. <span>‘Scaling Laws for Reward Model Overoptimization’</span>. <em>Proceedings of the 40th International Conference on Machine Learning</em>. <a href="https://proceedings.mlr.press/v202/gao23h.html">https://proceedings.mlr.press/v202/gao23h.html</a>.
</div></div><p>The instruments in this post are designed to catch failures in each of these dimensions.</p>
</section>
<section id="instrument-9-reward-dynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-9-reward-dynamics">Instrument 9: reward dynamics</h2>
<p>The reward curve is to RL what the loss curve is to SFT – the primary indicator of whether learning is happening. But unlike loss, reward requires considerably more nuance to interpret correctly.</p>
<p>The TRL library, for example, logs several reward-related metrics by default, but understanding what they mean – and what healthy versus pathological patterns look like – requires some unpacking.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>For DPO, the implicit reward for a response is typically <img src="https://latex.codecogs.com/png.latex?%5Cbeta%20(%5Clog%20%5Cpi_%5Ctheta(y%20%5Cmid%20x)%20-%20%5Clog%20%5Cpi_%7B%5Ctext%7Bref%7D%7D(y%20%5Cmid%20x))">, rather than a chosen-vs-rejected ratio. The <code>rewards/margins</code> metric tracks the difference between chosen and rejected rewards, which should increase during training.</p>
</div></div><div id="065d373a" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Enhanced reward monitoring callback</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TrainerCallback</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deque</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> RewardDynamicsCallback(TrainerCallback):</span>
<span id="cb1-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Track reward statistics beyond simple averages."""</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, window_size: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>):</span>
<span id="cb1-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.window_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> window_size</span>
<span id="cb1-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reward_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>window_size)</span>
<span id="cb1-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.margin_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>window_size)</span>
<span id="cb1-12"></span>
<span id="cb1-13">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, logs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb1-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> logs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-15">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb1-16"></span>
<span id="cb1-17">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Track reward metrics (names vary by trainer)</span></span>
<span id="cb1-18">        reward_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-19">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rewards/chosen"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rewards/rejected"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rewards/margins"</span>,</span>
<span id="cb1-20">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"objective/scores"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"objective/rlhf_reward"</span></span>
<span id="cb1-21">        ]</span>
<span id="cb1-22"></span>
<span id="cb1-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> reward_keys:</span>
<span id="cb1-24">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> logs:</span>
<span id="cb1-25">                value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logs[key]</span>
<span id="cb1-26"></span>
<span id="cb1-27">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"margin"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chosen"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> key:</span>
<span id="cb1-28">                    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reward_history.append(value)</span>
<span id="cb1-29"></span>
<span id="cb1-30">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reward_history) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:</span>
<span id="cb1-31">                        rewards <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reward_history)</span>
<span id="cb1-32"></span>
<span id="cb1-33">                        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Trend analysis</span></span>
<span id="cb1-34">                        logs[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>key<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_trend"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.polyfit(</span>
<span id="cb1-35">                            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(rewards)), rewards, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-36">                        )[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-37"></span>
<span id="cb1-38">                        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Variance tracking (early warning for instability)</span></span>
<span id="cb1-39">                        logs[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>key<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_variance"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(rewards)</span>
<span id="cb1-40"></span>
<span id="cb1-41">                        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Saturation detection</span></span>
<span id="cb1-42">                        recent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rewards[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>:] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(rewards) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> rewards</span>
<span id="cb1-43">                        logs[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>key<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_saturation"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.std(recent) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (np.std(rewards) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>)</span></code></pre></div></div>
</details>
</div>
<p>For <strong>DPO</strong>, the key metrics are:</p>
<ul>
<li><code>rewards/chosen</code>: The implicit reward for chosen responses (higher is better)</li>
<li><code>rewards/rejected</code>: The implicit reward for rejected responses (lower is better)</li>
<li><code>rewards/margins</code>: The difference between chosen and rejected (should increase)</li>
<li><code>rewards/accuracies</code>: How often the model prefers chosen over rejected (should approach 1.0)</li>
</ul>
<div id="cell-fig-dpo-metrics-relationship" class="cell" data-fig-height="6" data-fig-width="10" data-execution_count="2">
<div class="cell-output cell-output-display">
<div id="fig-dpo-metrics-relationship" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dpo-metrics-relationship-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/index_files/figure-html/fig-dpo-metrics-relationship-output-1.png" width="822" height="519" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dpo-metrics-relationship-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The relationship between DPO reward metrics: chosen and rejected rewards define the margin, which determines accuracy through the sigmoid function.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The margin is simply the difference between the chosen and rejected rewards; the preference probability is the sigmoid of that margin (scaled by beta).<sup>2</sup> The logged accuracy is the empirical fraction of pairs where the chosen reward exceeds the rejected reward, so it tracks the sigmoid in expectation. As training progresses, we want the margin to increase – either by pushing the chosen reward up, the rejected reward down, or both. A larger margin means higher accuracy, which means the model more reliably prefers the chosen response over the rejected one.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;This follows from the Bradley-Terry model underlying DPO. The model assumes the probability of preferring response A over B is <img src="https://latex.codecogs.com/png.latex?%5Csigma(r_A%20-%20r_B)">, where <img src="https://latex.codecogs.com/png.latex?r"> is the implicit reward. DPO’s loss function directly optimises this probability, so the accuracy metric – how often the model assigns higher probability to the chosen response – naturally follows a sigmoid relationship with the reward margin.</p></div></div><p>For <strong>PPO</strong>, the key metrics are:</p>
<ul>
<li><code>objective/scores</code>: The raw reward from the reward model</li>
<li><code>objective/rlhf_reward</code>: The effective RLHF reward (<code>scores + non_score_reward</code>)</li>
<li><code>objective/non_score_reward</code>: The KL penalty contribution (negative, computed as <code>-kl_coef * kl</code>)</li>
<li><code>objective/kl</code>: The mean KL divergence between current and reference policy</li>
</ul>
<p>For <strong>GRPO</strong>, the metrics follow a different naming convention:</p>
<ul>
<li><code>reward</code>: The overall average reward after applying reward weights</li>
<li><code>reward_std</code>: The standard deviation of rewards (per-group or batch-level, depending on <code>scale_rewards</code>)</li>
<li><code>kl</code>: The average KL divergence (logged only if <code>beta &gt; 0</code>)</li>
<li><code>entropy</code>: Average entropy of token predictions across completions</li>
<li><code>clip_ratio/region_mean</code>: The fraction of token probabilities clipped within the trust region</li>
<li><code>clip_ratio/low_mean</code> and <code>clip_ratio/high_mean</code>: Mean clipping on lower and upper bounds</li>
</ul>
<div id="cell-fig-reward-dynamics" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="fig-reward-dynamics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-reward-dynamics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/index_files/figure-html/fig-reward-dynamics-output-1.png" width="952" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-reward-dynamics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Reward dynamics diagnostics: healthy learning vs common pathologies in DPO.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Margin not increasing</strong>: If <code>rewards/margins</code> plateaus early, your model has stopped learning from the preference data. Either the learning rate is too low, or you’ve exhausted the signal in your dataset. As a general rule, people overestimate just how much signal <em>is</em> in a given preference dataset.</li>
<li><strong>Unbounded reward growth</strong>: If chosen rewards keep climbing without limit, you’re likely seeing reward hacking. The model is exploiting the reward function rather than genuinely improving. Check your KL divergence – it’s probably too high.</li>
<li><strong>Rewards converging</strong>: If chosen and rejected rewards approach each other, the model is losing its ability to distinguish preferences. This can indicate catastrophic forgetting or a learning rate that’s too high.</li>
<li><strong>High reward variance</strong>: Unstable rewards suggest unstable optimisation. Consider reducing the learning rate or increasing the KL penalty.</li>
</ul>
</section>
<section id="instrument-10-kl-divergence-health" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-10-kl-divergence-health">Instrument 10: KL divergence health</h2>
<p>The KL divergence between your training policy and the reference policy is perhaps the single most important diagnostic for RL training. It measures how far your model has drifted from its starting point – and managing this drift is the central challenge of preference optimisation.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>The reference policy is typically the SFT model you started with. In DPO, this is implicit in the loss function. In PPO, you maintain an explicit reference model and compute KL divergence at each step.</p>
</div></div><p>The mathematics are straightforward. For a policy <img src="https://latex.codecogs.com/png.latex?%5Cpi_%5Ctheta"> and reference policy <img src="https://latex.codecogs.com/png.latex?%5Cpi_%7B%5Ctext%7Bref%7D%7D">, the KL divergence is:</p>
<p><img src="https://latex.codecogs.com/png.latex?D_%7B%5Ctext%7BKL%7D%7D(%5Cpi_%5Ctheta%20%5C%7C%20%5Cpi_%7B%5Ctext%7Bref%7D%7D)%20=%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20%5Cpi_%5Ctheta%7D%5Cleft%5B%5Clog%20%5Cfrac%7B%5Cpi_%5Ctheta(x)%7D%7B%5Cpi_%7B%5Ctext%7Bref%7D%7D(x)%7D%5Cright%5D"></p>
<p>In practice, we estimate this over batches of generated text, summing the per-token log probability differences. The TRL library uses the Schulman approximator for efficiency <span class="citation" data-cites="schulman2020kl">(Schulman 2020)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-schulman2020kl" class="csl-entry">
Schulman, John. 2020. <span>‘Approximating <span>KL</span> Divergence’</span>. <a href="http://joschu.net/blog/kl-approx.html">http://joschu.net/blog/kl-approx.html</a>.
</div><div id="ref-chen2024catastrophic" class="csl-entry">
Chen, Thomas, Jie He, and Daniel Kifer. 2024. <span>‘Catastrophic Goodhart: Regularizing <span>RLHF</span> with <span>KL</span> Divergence Does Not Mitigate Heavy-Tailed Reward Misspecification’</span>. In <em>Advances in Neural Information Processing Systems</em>. <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/1a8189929f3d7bd6183718f42c3f4309-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2024/file/1a8189929f3d7bd6183718f42c3f4309-Paper-Conference.pdf</a>.
</div></div><p>The relationship between KL divergence and reward optimisation is nuanced. Recent work has shown that KL regularisation alone may not prevent reward hacking when reward model errors are heavy-tailed – a phenomenon called “catastrophic Goodhart” <span class="citation" data-cites="chen2024catastrophic">(Chen, He, and Kifer 2024)</span>. The practical implication: don’t rely solely on KL to prevent overoptimisation. Monitor the other instruments too.</p>
<div id="549c3f07" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>KL divergence monitoring callback</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> KLDivergenceCallback(TrainerCallback):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Monitor KL divergence and detect drift pathologies."""</span></span>
<span id="cb2-3"></span>
<span id="cb2-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, window_size: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, drift_threshold: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>):</span>
<span id="cb2-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.window_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> window_size</span>
<span id="cb2-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.drift_threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> drift_threshold</span>
<span id="cb2-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.kl_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>window_size)</span>
<span id="cb2-8"></span>
<span id="cb2-9">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, logs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb2-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> logs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb2-12"></span>
<span id="cb2-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># KL metrics (names vary by trainer)</span></span>
<span id="cb2-14">        kl_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"objective/kl"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kl"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kl_divergence"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"policy/approxkl_avg"</span>]</span>
<span id="cb2-15"></span>
<span id="cb2-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> kl_keys:</span>
<span id="cb2-17">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> logs:</span>
<span id="cb2-18">                kl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logs[key]</span>
<span id="cb2-19">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.kl_history.append(kl)</span>
<span id="cb2-20"></span>
<span id="cb2-21">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.kl_history) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:</span>
<span id="cb2-22">                    kl_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.kl_history)</span>
<span id="cb2-23"></span>
<span id="cb2-24">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Trend: is KL growing?</span></span>
<span id="cb2-25">                    logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kl/trend"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.polyfit(</span>
<span id="cb2-26">                        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(kl_values)), kl_values, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb2-27">                    )[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-28"></span>
<span id="cb2-29">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Acceleration: is growth accelerating?</span></span>
<span id="cb2-30">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(kl_values) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>:</span>
<span id="cb2-31">                        first_half <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kl_values[:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(kl_values)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb2-32">                        second_half <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kl_values[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(kl_values)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]</span>
<span id="cb2-33">                        logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kl/acceleration"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(second_half) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.mean(first_half)</span>
<span id="cb2-34"></span>
<span id="cb2-35">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Warning flag for runaway KL</span></span>
<span id="cb2-36">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> kl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.drift_threshold:</span>
<span id="cb2-37">                        logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kl/drift_warning"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb2-38">                        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"WARNING: KL divergence (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>kl<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">) exceeds threshold (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>drift_threshold<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>)</span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-kl-divergence" class="cell" data-fig-height="10" data-fig-width="6" data-execution_count="5">
<div class="cell-output cell-output-display">
<div id="fig-kl-divergence" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kl-divergence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/index_files/figure-html/fig-kl-divergence-output-1.png" width="568" height="951" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kl-divergence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: KL divergence patterns: the art of managing policy drift in preference optimisation.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>KL growing without bound</strong>: Runaway policy drift. Your model is moving too far from the reference. Increase the KL penalty (beta) or reduce the learning rate. In PPO, check that the clipping is working.</li>
<li><strong>KL near zero throughout training</strong>: Your KL penalty (beta) is too high. The model is barely updating. Reduce beta to allow more policy drift.</li>
<li><strong>KL noisy with high variance</strong>: Unstable optimisation. The learning rate is probably too high for your current KL penalty setting.</li>
<li><strong>KL suddenly spiking</strong>: Often indicates a batch of data that the model handles very differently from the reference. Investigate that batch.</li>
</ul>
<p>A useful heuristic for PPO: the <code>val/ratio</code> metric (ratio of current to old policy probabilities) should stay close to 1.0. If it regularly exceeds 2.0 or drops below 0.5, the policy updates are too aggressive <span class="citation" data-cites="huang2024n">(Huang et al. 2024)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-huang2024n" class="csl-entry">
Huang, Shengyi, Michael Liu, Qinyi Zhong, et al. 2024. <span>‘The <span>N</span>+ Implementation Details of <span>RLHF</span> with <span>PPO</span>: A Case Study on <span>TL;DR</span> Summarization’</span>. <em>arXiv Preprint arXiv:2403.17031</em>. <a href="https://huggingface.co/papers/2403.17031">https://huggingface.co/papers/2403.17031</a>.
</div></div></section>
<section id="instrument-11-policy-ratio-and-clip-fraction" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-11-policy-ratio-and-clip-fraction">Instrument 11: policy ratio and clip fraction</h2>
<p>For PPO and GRPO (but not DPO), the clipping mechanism is central to training stability. PPO’s “proximal” nature comes from clipping the policy ratio to prevent too-large updates.</p>
<p>The policy ratio is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?r_t(%5Ctheta)%20=%20%5Cfrac%7B%5Cpi_%5Ctheta(a_t%20%7C%20s_t)%7D%7B%5Cpi_%7B%5Ctheta_%7B%5Ctext%7Bold%7D%7D%7D(a_t%20%7C%20s_t)%7D"></p>
<p>PPO clips this ratio to the range <img src="https://latex.codecogs.com/png.latex?%5B1%20-%20%5Cepsilon,%201%20+%20%5Cepsilon%5D"> (typically <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%20=%200.2">), ensuring that the policy doesn’t change too drastically in a single update. The <code>clip_fraction</code> metric tells you how often this clipping is triggered.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>GRPO, developed by DeepSeek, uses a similar clipping mechanism but computes advantages relative to the group of completions for each prompt <span class="citation" data-cites="shao2024deepseekmath">(Shao et al. 2024)</span>. The monitoring principles are the same.</p>
<div id="ref-shao2024deepseekmath" class="csl-entry">
Shao, Zhihong, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. 2024. <span>‘<span>DeepSeekMath</span>: Pushing the Limits of Mathematical Reasoning in Open Language Models’</span>. <em>arXiv Preprint arXiv:2402.03300</em>. <a href="https://huggingface.co/papers/2402.03300">https://huggingface.co/papers/2402.03300</a>.
</div></div></div><div id="e249bdb5" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Policy ratio monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> PolicyRatioCallback(TrainerCallback):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Monitor policy ratio and clipping behaviour in PPO/GRPO."""</span></span>
<span id="cb3-3"></span>
<span id="cb3-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, target_clip_fraction: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>):</span>
<span id="cb3-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.target_clip_fraction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target_clip_fraction</span>
<span id="cb3-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.clip_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, logs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb3-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> logs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-10">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb3-11"></span>
<span id="cb3-12">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ratio metrics</span></span>
<span id="cb3-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val/ratio"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> logs:</span>
<span id="cb3-14">            ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val/ratio"</span>]</span>
<span id="cb3-15">            ratio_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logs.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val/ratio_var"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-16"></span>
<span id="cb3-17">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flag extreme ratios</span></span>
<span id="cb3-18">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>:</span>
<span id="cb3-19">                logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"policy/ratio_warning"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb3-20">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"WARNING: Extreme policy ratio: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ratio<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-21"></span>
<span id="cb3-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Clip fraction analysis</span></span>
<span id="cb3-23">        clip_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"policy/clipfrac_avg"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"clip_ratio/low"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"clip_ratio/high"</span>]</span>
<span id="cb3-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> clip_keys:</span>
<span id="cb3-25">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> logs:</span>
<span id="cb3-26">                clip_frac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logs[key]</span>
<span id="cb3-27">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.clip_history.append(clip_frac)</span>
<span id="cb3-28"></span>
<span id="cb3-29">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Too much clipping = updates too aggressive</span></span>
<span id="cb3-30">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> clip_frac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>:</span>
<span id="cb3-31">                    logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"policy/clipping_warning"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb3-32"></span>
<span id="cb3-33">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># No clipping = updates might be too small</span></span>
<span id="cb3-34">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> clip_frac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>:</span>
<span id="cb3-35">                    logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"policy/underclipping_warning"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-clip-fraction" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="7">
<div class="cell-output cell-output-display">
<div id="fig-clip-fraction" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clip-fraction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/index_files/figure-html/fig-clip-fraction-output-1.png" width="952" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clip-fraction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Policy ratio and clip fraction diagnostics for PPO/GRPO training.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Policy ratio far from 1.0</strong>: The ratio should hover around 1.0 with small fluctuations. Values consistently above 1.5 or below 0.7 indicate that consecutive policy updates are too drastic. Reduce the learning rate.</li>
<li><strong>Clip fraction too high (&gt; 30%)</strong>: Most of your updates are being clipped. The learning rate is too high relative to your epsilon. Either reduce learning rate or increase epsilon (carefully).</li>
<li><strong>Clip fraction too low (&lt; 1%)</strong>: Almost no clipping is happening. Either your learning rate is very conservative, or something else is wrong.</li>
<li><strong>Clip fraction growing over time</strong>: The optimisation is becoming increasingly aggressive. This often precedes a KL explosion.</li>
</ul>
</section>
<section id="instrument-12-generation-length-dynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-12-generation-length-dynamics">Instrument 12: generation length dynamics</h2>
<p>The final instrument is deceptively simple but catches some of the most common RL failures: tracking how long your model’s responses are. Generation length is one of the earliest indicators of reward hacking, and changes in length distribution often precede more obvious failures by hundreds of steps.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Length-based reward hacking is so common that many practitioners now add explicit length penalties or normalisation to their reward functions. The TRL library’s <code>missing_eos_penalty</code> parameter exists specifically to combat length collapse.</p>
</div></div><p>Why does length matter so much? Because length is one of the easiest things for a model to optimise. If longer responses tend to score slightly higher (perhaps because they’re more detailed, or because the reward model has a subtle length bias), the model will learn to be verbose. Conversely, if the model discovers that short, safe responses avoid negative rewards, it will collapse to terse outputs.</p>
<p>The key metrics to track (in GRPO/PPO) are:</p>
<ul>
<li><code>completions/mean_length</code>: Average token count across generations</li>
<li><code>completions/mean_terminated_length</code>: Average length of completions that end with EOS</li>
<li><code>completions/min_length</code> and <code>completions/max_length</code>: The range of lengths</li>
<li><code>completions/clipped_ratio</code>: How often generations hit the maximum length limit</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<p>The distinction between <code>mean_length</code> and <code>mean_terminated_length</code> is subtle but diagnostic. The former counts all completions including those truncated at <code>max_length</code>; the latter only counts those that properly terminated with an EOS token. A large gap between these two metrics indicates frequent truncation – the model is generating responses that exceed the length limit before naturally concluding.</p>
</div></div><div id="d1a3ce39" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Generation length monitoring callback</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> GenerationLengthCallback(TrainerCallback):</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Monitor generation length dynamics for reward hacking detection."""</span></span>
<span id="cb4-3"></span>
<span id="cb4-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, baseline_length: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, window_size: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>):</span>
<span id="cb4-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.baseline_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> baseline_length</span>
<span id="cb4-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.window_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> window_size</span>
<span id="cb4-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.length_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>window_size)</span>
<span id="cb4-8"></span>
<span id="cb4-9">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, logs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb4-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> logs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb4-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb4-12"></span>
<span id="cb4-13">        length_keys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"completions/mean_length"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response_length"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gen_len"</span>]</span>
<span id="cb4-14"></span>
<span id="cb4-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> length_keys:</span>
<span id="cb4-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> key <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> logs:</span>
<span id="cb4-17">                length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logs[key]</span>
<span id="cb4-18">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.length_history.append(length)</span>
<span id="cb4-19"></span>
<span id="cb4-20">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.length_history) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:</span>
<span id="cb4-21">                    lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.length_history)</span>
<span id="cb4-22"></span>
<span id="cb4-23">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Trend detection</span></span>
<span id="cb4-24">                    logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"length/trend"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.polyfit(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(lengths)), lengths, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-25"></span>
<span id="cb4-26">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Variance (low variance = mode collapse)</span></span>
<span id="cb4-27">                    logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"length/variance"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(lengths)</span>
<span id="cb4-28"></span>
<span id="cb4-29">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compare to baseline if available</span></span>
<span id="cb4-30">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.baseline_length:</span>
<span id="cb4-31">                        ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(lengths) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.baseline_length</span>
<span id="cb4-32">                        logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"length/baseline_ratio"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ratio</span>
<span id="cb4-33"></span>
<span id="cb4-34">                        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>:</span>
<span id="cb4-35">                            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"WARNING: Length collapsed to </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ratio<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> of baseline"</span>)</span>
<span id="cb4-36">                        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>:</span>
<span id="cb4-37">                            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"WARNING: Length exploded to </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ratio<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> of baseline"</span>)</span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-generation-length" class="cell" data-fig-height="10" data-fig-width="6" data-execution_count="9">
<div class="cell-output cell-output-display">
<div id="fig-generation-length" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generation-length-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/index_files/figure-html/fig-generation-length-output-1.png" width="568" height="951" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-generation-length-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Generation length dynamics: healthy stability vs common pathologies.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Length steadily increasing</strong>: The model is learning that verbosity is rewarded. This is often a sign that your reward model has a length bias. Consider adding length normalisation or a brevity penalty.</li>
<li><strong>Length steadily decreasing</strong>: The model is learning that short responses are safer. This often happens when the reward model penalises certain content – the model learns to say less to avoid penalties. Check your reward distribution.</li>
<li><strong>Length variance collapsing</strong>: Even if mean length stays stable, collapsing variance indicates mode collapse. The model is converging to a single “template” response style. Increase temperature or add entropy bonuses.</li>
<li><strong>High clipped ratio</strong>: If <code>completions/clipped_ratio</code> is high (&gt; 20%), many responses are hitting the maximum length limit. Either increase <code>max_completion_length</code> or investigate why the model wants to generate such long responses.</li>
</ul>
<p>A useful baseline: measure your SFT model’s generation length distribution before RL training begins. Any significant deviation (&gt; 30% change in mean or &gt; 50% change in variance) during RL deserves investigation.</p>
</section>
<section id="putting-it-all-together" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="putting-it-all-together">Putting it all together</h2>
<p>The four RL instruments we’ve covered complement the eight from Part I:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 33%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Instrument</th>
<th>What it tells you</th>
<th>Failure mode it catches</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reward dynamics</td>
<td>Preference learning progress</td>
<td>Reward hacking, saturation, collapse</td>
</tr>
<tr class="even">
<td>KL divergence</td>
<td>Policy drift from reference</td>
<td>Overoptimisation, capability loss</td>
</tr>
<tr class="odd">
<td>Clip fraction</td>
<td>Update magnitude</td>
<td>Unstable optimisation</td>
</tr>
<tr class="even">
<td>Generation length</td>
<td>Output distribution health</td>
<td>Length hacking, mode collapse</td>
</tr>
</tbody>
</table>
<p>Together with the SFT instruments, you now have a twelve-gauge dashboard for monitoring any post-training run.<sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Not to be confused with an equally potent firearm of the same specification, <em>twelve</em> here quantifies rather than specifies.</p></div></div><p>For production RL training, I recommend the following dashboard layout:</p>
<ol type="1">
<li><strong>Primary RL metrics</strong>: Reward margin, KL divergence, RLHF reward. The overview.</li>
<li><strong>Policy health</strong>: Clip fraction, policy ratio, policy entropy. The vital signs.</li>
<li><strong>Value function</strong>: Value loss, value clipping. (PPO only.)</li>
<li><strong>Fundamentals</strong>: Loss, gradients, attention entropy. Don’t forget these still matter!</li>
</ol>
</section>
<section id="the-failure-pattern-gallery" class="level2">
<h2 class="anchored" data-anchor-id="the-failure-pattern-gallery">The failure pattern gallery</h2>
<p>Let me conclude with a visual summary of the most common RL training failures I encounter in practice. Each of these can be caught by monitoring the right combination of instruments. In RL, “wtf even” is a valid diagnostic category: it’s rare for one thing to go wrong in neat isolation. Rather, what you get is a picture of multiple interacting failures that create a tableau of pathology.</p>
<div id="cell-fig-rl-failure-patterns" class="cell" data-fig-height="10" data-fig-width="11" data-execution_count="10">
<div class="cell-output cell-output-display">
<div id="fig-rl-failure-patterns" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rl-failure-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/index_files/figure-html/fig-rl-failure-patterns-output-1.png" width="1047" height="951" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rl-failure-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Common RL training failures: each requires monitoring multiple instruments simultaneously.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="practical-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="practical-recommendations">Practical recommendations</h2>
<p>If you take away nothing else from this post, remember these heuristics:</p>
<ol type="1">
<li><p><strong>Never trust the reward alone</strong>. Always cross-reference with KL divergence and generation quality samples. Reward hacking is the default failure mode.</p></li>
<li><p><strong>Set up alerts for KL divergence thresholds</strong>. In my experience, KL &gt; 0.5 is a warning and KL &gt; 1.0 is a stop sign. Your thresholds may vary, but have thresholds.</p></li>
<li><p><strong>Log generation samples throughout training</strong>. This catches qualitative failures that no metric will show you. Schedule periodic human evaluation if you can.</p></li>
<li><p><strong>For PPO, keep an eye on the ratio and clip fraction</strong>. If the ratio regularly exceeds 1.5 or clip fraction exceeds 30%, reduce your learning rate.</p></li>
<li><p><strong>Don’t forget the basic instruments</strong>. Gradient health, attention entropy and the other fundamentals still matter.</p></li>
</ol>
<p>In the next post, we’ll tackle the third domain: function calling and tool use, where the metrics of success involve not just natural language quality but format compliance, execution accuracy and production reliability. We’ve devoted relatively little attention to the outcome in general so far – perplexity, for example, is a metric that I haven’t commented on a lot. Mainly, that’s because people who swear by it cannot be convinced otherwise and people who don’t already use it don’t care. Function calling, on the other hand, is a different animal. There, we have those magical ‘verifiable rewards’, so we have no excuse not to be rather assiduous about identifying very clear outcome metrics rather than the more procedural statistical metrics that have occupied our attention so far.</p>
<p>Until then, happy training!</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The Post-Training Instrument Cluster -\/- {Part} {II}},
  date = {2025-12-28},
  url = {https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“The Post-Training Instrument Cluster
-- Part II.”</span> <a href="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/">https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>LLMs</category>
  <category>LLMOps</category>
  <category>post-training</category>
  <category>reinforcement learning</category>
  <category>RLHF</category>
  <guid>https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/</guid>
  <pubDate>Sun, 28 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster-rl/rl_failure_patterns.png" medium="image" type="image/png" height="131" width="144"/>
</item>
<item>
  <title>The post-training instrument cluster – Part I</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Hey, I’m writing a book about this!
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m actually writing a book about this stuff. It turns out there isn’t a lot of literature on how to do post-training at the level too big for single-GPU laptop-sized hobby projects and requiring enterprise reliability on one hand, but not quite at the scale of multi-team distributed post-training you’d get in foundation labs. That’s a problem, because a lot of the current value in fine-tuning applications comes exactly out of that large, crucial market. I am in the last phases of putting together the manuscript for <em>The Frontier Playbook</em>, a set of curated tactics and techniques for real world operationalisation of LLMs. <a href="https://aifrontierplaybook.substack.com">Sign up for updates here</a>.</p>
</div>
</div>
<p>Jimmy Doolittle, later famous for leading the daring Doolittle Raid on Tokyo in 1942, was a pioneering aviator in the 1920s and 30s. One of his key contributions to aviation was the first of what at the time was called “blind” flight – what we would refer to as IFR (Instrument Flight Rules) flight today. Doolittle demonstrated that with the right set of instruments, a pilot could safely navigate and land an aircraft without any external visual references. A few years later, instrument flying became increasingly standardised, and in the late 1930s, the main instruments and their arrangement into the “basic T” layout of six key instruments – affectionately referred to as the six-pack – was formalised. To this day, virtually all aircraft have the same instrument cluster in the same order, and every pilot is trained to interpret them. Together, they create a fairly comprehensive picture of the aircraft’s state and environment.</p>
<p>You should aspire to have the same for your LLM post-training.</p>
<p>Unfortunately, that doesn’t come without some effort. Even though really good tools exist for monitoring fine-tuning runs, what you get out of the box is often quite lacklustre. When you fire up a fine-tuning run and open your Weights &amp; Biases dashboard, you’re greeted with the same three faithful companions: training loss, validation loss and gradient norm. They’re like the speedometer, fuel gauge and temperature warning light of the machine learning world – essential, certainly, but hardly sufficient for understanding what’s actually happening under the bonnet. Nobody would fly a commercial airliner with three instruments, and nobody should run a fine-tuning job of any seriousness with just loss curves and a gradient norm.</p>
<p>More important than what you see is knowing how to read those instruments. As you monitor a post-training job, regardless of whether it’s SFT, DPO, GRPO, even something more exotic, you’re largely after the same information: is the model learning what you want it to learn, is the optimisation stable, are there any silent failure modes creeping in, and when should I stop? Knowing how to read the instruments properly means you’ll know a lot about the model while it’s still in the oven, so to speak, and you can catch issues early. This is useful for the ML hobbyist, but indispensable for the enterprise practitioner. At that scale, a solid training run can cost north of five figures – not foundation lab training cost scale (it is estimated that a single training run of a modern foundation model is easily in the realm of nine figures), but enough that wasting runs is eventually going to attract management attention.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;I’m being my usual flippant self here, but there’s a very real economic, environmental and social cost to wasted compute. We owe it to the world and to future generations to make sure we make every watt of compute count. One can disagree about the ethics of the money and energy and CO2 emissions that are devoted to training LLMs – it is rather harder to argue that wasting those resources is in any way justifiable.</p></div></div><p>The purpose of this post – the first in a series of three – is twofold: to explain what a comprehensive post-training instrument cluster looks like for the easiest ‘base case’ (plain vanilla SFT) and provide you with the code to implement it yourself on one hand, and learning how to interpret them on the other.</p>
<section id="the-case-for-comprehensive-monitoring" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-case-for-comprehensive-monitoring">The case for comprehensive monitoring</h2>
<p>Before we dive into the instruments themselves, it’s worth asking: why bother? The loss is going down, the model is learning, what more do you need?</p>
<p>The answer, as with most things in machine learning, is that the happy path is easy and the failure modes are numerous. A decreasing loss curve can mask catastrophic forgetting. A stable gradient norm can coexist with attention collapse. A model can achieve excellent validation loss while generating nonsense. Worse, many of these failure modes are silent until you actually deploy the model and discover, often at significant cost, that something went wrong twenty hours into a forty-hour training run.<sup>2</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;I’ve seen production fine-tuning runs where the model appeared to be learning beautifully right up until generation quality fell off a cliff. The loss was still decreasing. The gradient norm was textbook perfect. The only hint that something was wrong was a subtle shift in the attention entropy that nobody was monitoring.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Even better, good monitoring can often prevent failures from happening in the first place. Catching a loss spike or a gradient explosion early can save hours of wasted compute and frustration. Monitoring logs can – indeed, should! – act as release gates at worst, meaning you might well avoid the ‘mortem’ part altogether.</p></div></div><p>Enterprise fine-tuning adds another dimension of complexity. You’re not just training a model, you’re accountable for training a model. When a stakeholder asks why a particular run failed, ‘the loss looked fine but the model doesn’t work’ is not an acceptable answer. Comprehensive monitoring provides the forensic trail that turns post-mortems from guesswork into analysis.<sup>3</sup></p>
</section>
<section id="instrument-1-the-loss-landscape" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-1-the-loss-landscape">Instrument 1: the loss landscape</h2>
<p>Let’s start with the obvious: loss. But we’re going to look at it properly.</p>
<p>The default wandb setup gives you <code>train/loss</code> and <code>eval/loss</code> as single scalar values. This is necessary but insufficient. What you actually want is a richer picture of the loss landscape:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Loss variance is particularly diagnostic for LoRA fine-tuning, where you’re updating a small fraction of parameters and the optimisation landscape can be surprisingly bumpy.</p>
</div></div><div id="15b28f94" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Enhanced loss logging callback</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TrainerCallback</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deque</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LossLandscapeCallback(TrainerCallback):</span>
<span id="cb1-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Track loss statistics beyond simple averages."""</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, window_size: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>):</span>
<span id="cb1-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.window_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> window_size</span>
<span id="cb1-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>window_size)</span>
<span id="cb1-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque(maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>window_size)</span>
<span id="cb1-12"></span>
<span id="cb1-13">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, logs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb1-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> logs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-15">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb1-16"></span>
<span id="cb1-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"loss"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> logs:</span>
<span id="cb1-18">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses.append(logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"loss"</span>])</span>
<span id="cb1-19"></span>
<span id="cb1-20">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:</span>
<span id="cb1-21">                losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses)</span>
<span id="cb1-22">                logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train/loss_variance"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(losses)</span>
<span id="cb1-23">                logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train/loss_trend"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.polyfit(</span>
<span id="cb1-24">                    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(losses)), losses, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-25">                )[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-26"></span>
<span id="cb1-27">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Detect loss spikes</span></span>
<span id="cb1-28">                recent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> losses[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:]</span>
<span id="cb1-29">                older <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> losses[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(losses) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> losses</span>
<span id="cb1-30">                logs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train/loss_spike_ratio"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb1-31">                    np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(recent) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> np.mean(older)</span>
<span id="cb1-32">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> older <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb1-33">                )</span></code></pre></div></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Loss variance increasing</strong>: The optimisation is becoming unstable. Consider reducing learning rate.</li>
<li><strong>Loss trend flattening while absolute loss is still high</strong>: You’ve hit a plateau. Either the learning rate is too low, or you’ve exhausted what this architecture can learn from this data.</li>
<li><strong>Loss spike ratio &gt; 2.0</strong>: Something dramatic happened. Check for data corruption, gradient explosion or memory issues.</li>
<li><strong>Eval loss diverging from train loss</strong>: The classic overfitting signal, but in LoRA training this can also indicate that your adapter rank is too high for your dataset size.</li>
</ul>
<div id="cell-fig-loss-diagnostics" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="2">
<div class="cell-output cell-output-display">
<div id="fig-loss-diagnostics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-loss-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/index_files/figure-html/fig-loss-diagnostics-output-1.png" width="952" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-loss-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Loss landscape diagnostics: what healthy and unhealthy training looks like.
</figcaption>
</figure>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>Sometimes, such visual guides note the existence of a pattern they call a ‘stuck loss curve’. This is essentially a perfectly fine ‘done’ loss curve (i.e.&nbsp;flat loss) with very high variance. It <em>is</em> pathological, but it’s just a special case of increasing variance, and in my view, shouldn’t be a category of its own.</p>
</div></div></section>
<section id="instrument-2-gradient-histograms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-2-gradient-histograms">Instrument 2: gradient histograms</h2>
<p>A single gradient norm scalar tells you almost nothing. What you actually want is the <em>distribution</em> of gradients across your parameters. Weights &amp; Biases can log histograms natively, and you should take advantage of this wherever possible, but it’s important you understand what to look for.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Gradient histograms are one of the most underused diagnostic tools in deep learning. A single glance at the distribution shape tells you more than a hundred scalar metrics. The problem is, they take a lot of experience to interpret. WandB has done the world a massive service with making them pop out of the box by default if you configure it mostly the right way, but knowing what to look for is another matter entirely. There are relatively few good heuristics for what good and bad gradient distributions look like, and I’ve seen more disagreement among perfectly competent practitioners on this topic than almost any other.</p>
</div></div><p>The mathematics of gradient pathology is straightforward but worth stating precisely. During backpropagation, the gradient of the loss <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D"> with respect to the weights <img src="https://latex.codecogs.com/png.latex?W_1"> in an early layer depends on the chain of derivatives through all subsequent layers:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20%5Cmathcal%7BL%7D%7D%7B%5Cpartial%20W_1%7D%20=%20%5Cfrac%7B%5Cpartial%20%5Cmathcal%7BL%7D%7D%7B%5Cpartial%20W_L%7D%20%5Ccdot%20%5Cprod_%7B%5Cell=2%7D%5E%7BL%7D%20%5Cleft(%20%5Cphi'_%5Cell(z_%5Cell)%20%5Ccdot%20W_%5Cell%20%5Cright)"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cphi'_%5Cell"> is the derivative of the activation function at layer <img src="https://latex.codecogs.com/png.latex?%5Cell"> and <img src="https://latex.codecogs.com/png.latex?z_%5Cell"> is the pre-activation. The product structure is the culprit: if the spectral norm <img src="https://latex.codecogs.com/png.latex?%5C%7CW_%5Cell%5C%7C%20%3C%201"> for most layers, the product shrinks exponentially with depth and gradients <em>vanish</em>. Conversely, if <img src="https://latex.codecogs.com/png.latex?%5C%7CW_%5Cell%5C%7C%20%3E%201"> and <img src="https://latex.codecogs.com/png.latex?%5C%7C%5Cphi'_%5Cell%5C%7C%20%3E%201">, the product grows exponentially and gradients <em>explode</em>. With ReLU activations, an additional failure mode emerges: wherever <img src="https://latex.codecogs.com/png.latex?z_%5Cell%20%3C%200">, the derivative is exactly zero, causing entire gradient paths to die.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;This is the mathematical foundation of the ‘dying ReLU’ problem. It’s also why Leaky ReLU, GELU and other activations with non-zero gradients everywhere have become popular in modern architectures.</p></div></div><div id="c8df9f4f" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Parameter-wise gradient histogram logging</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> GradientHistogramCallback(TrainerCallback):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Log parameter-wise gradient histograms to wandb."""</span></span>
<span id="cb2-3"></span>
<span id="cb2-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, log_every_n_steps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>):</span>
<span id="cb2-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_every_n_steps</span>
<span id="cb2-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-7"></span>
<span id="cb2-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_pre_optimizer_step(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb2-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Capture gradients before optimizer.step() clears them."""</span></span>
<span id="cb2-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb2-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb2-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb2-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb2-15"></span>
<span id="cb2-16">        <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb2-17"></span>
<span id="cb2-18">        histograms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb2-19">        stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb2-20"></span>
<span id="cb2-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> name, param <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> model.named_parameters():</span>
<span id="cb2-22">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> param.grad <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-23">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb2-24"></span>
<span id="cb2-25">            grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> param.grad.detach().flatten().cpu().numpy()</span>
<span id="cb2-26">            short_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._simplify_name(name)</span>
<span id="cb2-27"></span>
<span id="cb2-28">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log histogram to wandb</span></span>
<span id="cb2-29">            histograms[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"gradients/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>short_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Histogram(grad)</span>
<span id="cb2-30"></span>
<span id="cb2-31">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Also log summary statistics</span></span>
<span id="cb2-32">            stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"grad_stats/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>short_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/mean"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(np.mean(grad))</span>
<span id="cb2-33">            stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"grad_stats/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>short_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/std"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(np.std(grad))</span>
<span id="cb2-34">            stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"grad_stats/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>short_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/max"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(grad)))</span>
<span id="cb2-35">            stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"grad_stats/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>short_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/sparsity"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(</span>
<span id="cb2-36">                np.mean(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(grad) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>)</span>
<span id="cb2-37">            )</span>
<span id="cb2-38"></span>
<span id="cb2-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> wandb.run <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-40">            wandb.log({<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>histograms, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>stats})</span>
<span id="cb2-41"></span>
<span id="cb2-42">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _simplify_name(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="cb2-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Simplify parameter name for readable logging."""</span></span>
<span id="cb2-44">        parts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> name.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"."</span>)</span>
<span id="cb2-45">        simplified <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-46">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> parts:</span>
<span id="cb2-47">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> p.isdigit():</span>
<span id="cb2-48">                simplified.append(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"L</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>p<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-49">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lora"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> p.lower():</span>
<span id="cb2-50">                simplified.append(p.replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>))</span>
<span id="cb2-51">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"q_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"k_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"v_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"o_proj"</span>):</span>
<span id="cb2-52">                simplified.append(p.replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>))</span>
<span id="cb2-53">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>.join(simplified) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> simplified <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> name[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>:]</span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-gradient-histograms" class="cell" data-fig-height="10" data-fig-width="10" data-execution_count="4">
<div class="cell-output cell-output-display">
<div id="fig-gradient-histograms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gradient-histograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/index_files/figure-html/fig-gradient-histograms-output-1.png" width="874" height="841" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gradient-histograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Gradient distribution over time (wandb-style): steps on x-axis, gradient values on y-axis, density as colour.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Distribution collapsing to a spike at zero</strong>: Vanishing gradients. Your model has stopped learning, often because of dying ReLUs, excessive regularisation or a learning rate that’s far too low.</li>
<li><strong>Fat tails extending far from zero</strong>: Exploding gradients. Even if the mean looks fine, occasional extreme values will destabilise training. Gradient clipping can help, but investigate the root cause.</li>
<li><strong>Different layers having wildly different spreads</strong>: Layer imbalance. Early layers dominating late layers (or vice versa) indicates poor initialisation or the need for layer-wise learning rate scaling.</li>
<li><strong>Bimodal or multimodal distributions</strong>: Often indicates that different parameter groups (e.g.&nbsp;attention vs MLP, or LoRA A vs B matrices) are learning at very different rates. Not always bad, but worth investigating.</li>
</ul>
</section>
<section id="instrument-3-learning-rate-dynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-3-learning-rate-dynamics">Instrument 3: learning rate dynamics</h2>
<p>The learning rate schedule is decided before training, so why monitor it? Because what matters isn’t what you <em>planned</em> but what <em>actually happened</em>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Warmup is particularly important for LoRA. Jumping straight to your target learning rate can cause the adapter weights to overshoot before the base model activations have stabilised.</p>
</div></div><div id="0a739116" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Learning rate monitoring with phase detection</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LearningRateMonitor(TrainerCallback):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Track effective learning rate and detect phase transitions."""</span></span>
<span id="cb3-3"></span>
<span id="cb3-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lr_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.phase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"warmup"</span></span>
<span id="cb3-7"></span>
<span id="cb3-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_step_end(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb3-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get current learning rate from optimizer</span></span>
<span id="cb3-10">        lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state.learning_rate <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(state, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"learning_rate"</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb3-11"></span>
<span id="cb3-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> lr <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-13">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lr_history.append(lr)</span>
<span id="cb3-14"></span>
<span id="cb3-15">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Detect phase transitions</span></span>
<span id="cb3-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lr_history) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:</span>
<span id="cb3-17">                recent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lr_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:]</span>
<span id="cb3-18">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>(recent[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> recent[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(recent)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)):</span>
<span id="cb3-19">                    new_phase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"decay"</span></span>
<span id="cb3-20">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>(recent[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> recent[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(recent)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)):</span>
<span id="cb3-21">                    new_phase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"warmup"</span></span>
<span id="cb3-22">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb3-23">                    new_phase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"peak"</span></span>
<span id="cb3-24"></span>
<span id="cb3-25">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> new_phase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.phase:</span>
<span id="cb3-26">                    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"LR phase transition: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>phase<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> -&gt; </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>new_phase<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-27">                    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.phase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_phase</span></code></pre></div></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Warmup too short</strong>: If your loss is unstable in the first few hundred steps, you probably needed more warmup.</li>
<li><strong>Peak learning rate never reached</strong>: This happens with some schedulers when total steps are miscalculated. The training never operates at full learning rate.</li>
<li><strong>Learning rate effectively zero before training ends</strong>: Overly aggressive decay. Your final epochs are wasted.</li>
</ul>
</section>
<section id="instrument-4-attention-entropy" class="level2">
<h2 class="anchored" data-anchor-id="instrument-4-attention-entropy">Instrument 4: attention entropy</h2>
<p>This is where we leave the standard metrics behind. Yes, histograms are art, loss landscapes are science, but attention entropy is where we begin to get into chef’s kiss territory.</p>
<p>Attention entropy measures how focused or diffuse the model’s attention patterns are, and it’s one of the most diagnostic metrics for detecting subtle training pathologies. Mathematically, for a single attention head with attention weights <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Calpha%7D%20=%20(%5Calpha_1,%20%5Calpha_2,%20%5Cldots,%20%5Calpha_n)"> over a sequence of length <img src="https://latex.codecogs.com/png.latex?n"> (where <img src="https://latex.codecogs.com/png.latex?%5Csum_i%20%5Calpha_i%20=%201"> after softmax), the entropy is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?H(%5Cboldsymbol%7B%5Calpha%7D)%20=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Calpha_i%20%5Clog%20%5Calpha_i"></p>
<p>The bounds are intuitive: <img src="https://latex.codecogs.com/png.latex?H%20=%200"> when all attention is focused on a single token (<img src="https://latex.codecogs.com/png.latex?%5Calpha_j%20=%201"> for some <img src="https://latex.codecogs.com/png.latex?j">, all others zero), and <img src="https://latex.codecogs.com/png.latex?H%20=%20%5Clog%20n"> when attention is uniformly distributed (<img src="https://latex.codecogs.com/png.latex?%5Calpha_i%20=%201/n"> for all <img src="https://latex.codecogs.com/png.latex?i">). In practice, we average across heads and layers to get a scalar summary, but per-head entropy can reveal pathologies that aggregates hide.</p>
<div id="0c3f8278" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Attention entropy monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AttentionEntropyCallback(TrainerCallback):</span>
<span id="cb4-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Monitor attention pattern entropy during training."""</span></span>
<span id="cb4-6"></span>
<span id="cb4-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, log_every_n_steps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, num_heads_to_sample: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb4-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_every_n_steps</span>
<span id="cb4-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_heads_to_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> num_heads_to_sample</span>
<span id="cb4-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb4-11"></span>
<span id="cb4-12">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> compute_entropy(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, attn_weights: torch.Tensor) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>:</span>
<span id="cb4-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Compute entropy of attention distribution."""</span></span>
<span id="cb4-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># attn_weights: [batch, heads, seq, seq]</span></span>
<span id="cb4-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Normalise to valid probability distribution</span></span>
<span id="cb4-16">        attn_probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.softmax(attn_weights, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-17"></span>
<span id="cb4-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute entropy: -sum(p * log(p))</span></span>
<span id="cb4-19">        entropy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(</span>
<span id="cb4-20">            attn_probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.log(attn_probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-10</span>), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-21">        )</span>
<span id="cb4-22"></span>
<span id="cb4-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> entropy.mean().item()</span>
<span id="cb4-24"></span>
<span id="cb4-25">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_step_end(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb4-26">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb4-28">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb4-29"></span>
<span id="cb4-30">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hook to capture attention weights during forward pass</span></span>
<span id="cb4-31">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Implementation depends on model architecture</span></span>
<span id="cb4-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This is a simplified example</span></span>
<span id="cb4-33"></span>
<span id="cb4-34">        entropy_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb4-35">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"attention/mean_entropy"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._get_mean_entropy(model),</span>
<span id="cb4-36">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"attention/entropy_variance"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._get_entropy_variance(model),</span>
<span id="cb4-37">        }</span>
<span id="cb4-38"></span>
<span id="cb4-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log metrics</span></span>
<span id="cb4-40">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(state, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"log_history"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> state.log_history:</span>
<span id="cb4-41">            state.log_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].update(entropy_stats)</span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-attention-entropy" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="7">
<div class="cell-output cell-output-display">
<div id="fig-attention-entropy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-attention-entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/index_files/figure-html/fig-attention-entropy-output-1.png" width="951" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention-entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Attention entropy diagnostics: mean entropy (solid) and cross-head variance (dashed) reveal different pathologies.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Attention entropy collapsing towards zero</strong>: The model is attending to single tokens almost exclusively. This is often a sign of attention sink formation or degenerate patterns.</li>
<li><strong>Attention entropy increasing unboundedly</strong>: The model is spreading attention uniformly – essentially not learning to focus. This can indicate that your task doesn’t require sequence understanding, or that something is wrong with positional encoding.</li>
<li><strong>Sudden entropy changes mid-training</strong>: Phase transitions in what the model is learning. Not necessarily bad, but worth investigating. <em>When</em> exactly this is okay depends to a great extent on your task – and the answer may often enough be “never”. I see this a lot when we’re fine-tuning time series type transformers for semi-periodic signals. It’s okay for the model to have some attention entropy to see various scales of periodicities, but not essentially for it to blow up unboundedly.</li>
</ul>
</section>
<section id="instrument-5-generation-quality-samples" class="level2">
<h2 class="anchored" data-anchor-id="instrument-5-generation-quality-samples">Instrument 5: generation quality samples</h2>
<p>No amount of metric monitoring replaces actually looking at what the model generates. Periodic sampling during training is essential for catching qualitative failures that quantitative metrics miss.</p>
<div id="e0396424" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Periodic generation sampling</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> GenerationSamplerCallback(TrainerCallback):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Generate samples periodically during training."""</span></span>
<span id="cb5-3"></span>
<span id="cb5-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(</span>
<span id="cb5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb5-6">        tokenizer,</span>
<span id="cb5-7">        eval_prompts: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>],</span>
<span id="cb5-8">        log_every_n_steps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>,</span>
<span id="cb5-9">        max_new_tokens: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb5-10">    ):</span>
<span id="cb5-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer</span>
<span id="cb5-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_prompts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_prompts</span>
<span id="cb5-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_every_n_steps</span>
<span id="cb5-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_new_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_new_tokens</span>
<span id="cb5-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb5-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.generation_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb5-17"></span>
<span id="cb5-18">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_step_end(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb5-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb5-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb5-21">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb5-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb5-23">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb5-24"></span>
<span id="cb5-25">        model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb5-26">        samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb5-27"></span>
<span id="cb5-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> prompt <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_prompts[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sample first 3 prompts</span></span>
<span id="cb5-29">            inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer(</span>
<span id="cb5-30">                prompt,</span>
<span id="cb5-31">                return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span></span>
<span id="cb5-32">            ).to(model.device)</span>
<span id="cb5-33"></span>
<span id="cb5-34">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb5-35">                outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(</span>
<span id="cb5-36">                    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>inputs,</span>
<span id="cb5-37">                    max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_new_tokens,</span>
<span id="cb5-38">                    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>,</span>
<span id="cb5-39">                    do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb5-40">                    pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer.pad_token_id,</span>
<span id="cb5-41">                )</span>
<span id="cb5-42"></span>
<span id="cb5-43">            generated <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer.decode(</span>
<span id="cb5-44">                outputs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][inputs.input_ids.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]:],</span>
<span id="cb5-45">                skip_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb5-46">            )</span>
<span id="cb5-47">            samples.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompt"</span>: prompt, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generation"</span>: generated})</span>
<span id="cb5-48"></span>
<span id="cb5-49">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.generation_history.append({</span>
<span id="cb5-50">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"step"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count,</span>
<span id="cb5-51">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"samples"</span>: samples</span>
<span id="cb5-52">        })</span>
<span id="cb5-53"></span>
<span id="cb5-54">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log to wandb as table</span></span>
<span id="cb5-55">        <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb5-56">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> wandb.run <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb5-57">            table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Table(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"step"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generation"</span>])</span>
<span id="cb5-58">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> sample <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> samples:</span>
<span id="cb5-59">                table.add_data(</span>
<span id="cb5-60">                    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count,</span>
<span id="cb5-61">                    sample[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompt"</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>],</span>
<span id="cb5-62">                    sample[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generation"</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>]</span>
<span id="cb5-63">                )</span>
<span id="cb5-64">            wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generation_samples"</span>: table})</span>
<span id="cb5-65"></span>
<span id="cb5-66">        model.train()</span></code></pre></div></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Repetition loops</strong>: The model gets stuck repeating phrases. Often indicates a temperature or sampling problem, but can also signal training issues.</li>
<li><strong>Hallucination of training data</strong>: The model regurgitates training examples verbatim. You’re overfitting.</li>
<li><strong>Format drift</strong>: The model’s output format changes during training. If you’re fine-tuning for a specific format, monitor for deviations.</li>
<li><strong>Coherence deterioration</strong>: Early generations are coherent, later ones are not. Catastrophic forgetting in progress.</li>
</ul>
</section>
<section id="instrument-6-lora-adapter-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="instrument-6-lora-adapter-diagnostics">Instrument 6: LoRA adapter diagnostics</h2>
<p>When training LoRAs, it’s crucial to monitor the behaviour of the adapter weights themselves. Their norms, effective ranks and relative changes can reveal whether the adapters are learning effectively or diverging. In particular, they are a crucial health check on our assumption about rank.</p>
<p>There are a few ways to determine effective rank, but a simple and effective method is to use the entropy of the singular value distribution. If the singular values are <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r">, we first normalise them to form a probability distribution: <img src="https://latex.codecogs.com/png.latex?p_i%20=%20%5Cfrac%7B%5Csigma_i%7D%7B%5Csum_%7Bj=1%7D%5E%7Br%7D%20%5Csigma_j%7D"></p>
<p>Then, the effective rank is given by the exp of the entropy thereof, the calculation of which we have already had the pleasure above.</p>
<p>So far, so undergraduate stats. Where it gets tricky is to see this in the data, and know the right rank adjustments to make. Here, your Mk I Eyeball is your best tool, I’m afraid: what you’re looking for is the ‘cliff’ where singular values drop off sharply. If the effective rank is much lower than your configured rank, you can probably reduce it. If it’s at maximum, consider increasing it if your model is not learning. In either case of a rank mismatch, you’re wasting a valuable resource – in the case of overprovisioning, you’re wasting compute and memory, but in the case of underprovisioning, you’re wasting information theoretical value. In practice, that latter one is much harder to get back.</p>
<div id="6b94dc8f" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>LoRA-specific monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LoRADiagnosticsCallback(TrainerCallback):</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Monitor LoRA adapter-specific metrics."""</span></span>
<span id="cb6-3"></span>
<span id="cb6-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, log_every_n_steps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>):</span>
<span id="cb6-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_every_n_steps</span>
<span id="cb6-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb6-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb6-8"></span>
<span id="cb6-9">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_step_end(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb6-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb6-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb6-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb6-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb6-15"></span>
<span id="cb6-16">        lora_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb6-17"></span>
<span id="cb6-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> name, param <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> model.named_parameters():</span>
<span id="cb6-19">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lora_"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> name.lower():</span>
<span id="cb6-20">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb6-21"></span>
<span id="cb6-22">            weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> param.detach()</span>
<span id="cb6-23"></span>
<span id="cb6-24">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Basic statistics</span></span>
<span id="cb6-25">            norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> weight.norm().item()</span>
<span id="cb6-26">            lora_stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lora/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/norm"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> norm</span>
<span id="cb6-27"></span>
<span id="cb6-28">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Effective rank (for lora_A and lora_B)</span></span>
<span id="cb6-29">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(weight.shape) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:</span>
<span id="cb6-30">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb6-31">                    s <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linalg.svdvals(weight.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>())</span>
<span id="cb6-32">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Effective rank: how many singular values matter</span></span>
<span id="cb6-33">                    s_normalized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> s <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> s.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb6-34">                    entropy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(</span>
<span id="cb6-35">                        s_normalized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.log(s_normalized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-10</span>)</span>
<span id="cb6-36">                    )</span>
<span id="cb6-37">                    effective_rank <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(entropy).item()</span>
<span id="cb6-38">                    lora_stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lora/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/effective_rank"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> effective_rank</span>
<span id="cb6-39">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span>:</span>
<span id="cb6-40">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">pass</span></span>
<span id="cb6-41"></span>
<span id="cb6-42">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Track relative change from initialisation</span></span>
<span id="cb6-43">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb6-44">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb6-45">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> name <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms:</span>
<span id="cb6-46">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> norm</span>
<span id="cb6-47">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-48">                relative_change <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms[name]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (</span>
<span id="cb6-49">                    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.initial_norms[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-10</span></span>
<span id="cb6-50">                )</span>
<span id="cb6-51">                lora_stats[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lora/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/relative_change"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> relative_change</span>
<span id="cb6-52"></span>
<span id="cb6-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Aggregate metrics</span></span>
<span id="cb6-54">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> lora_stats:</span>
<span id="cb6-55">            norms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [v <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k, v <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> lora_stats.items() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/norm"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> k]</span>
<span id="cb6-56">            lora_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lora/mean_norm"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(norms)</span>
<span id="cb6-57">            lora_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lora/norm_variance"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(norms)</span>
<span id="cb6-58"></span>
<span id="cb6-59">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(state, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"log_history"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> state.log_history:</span>
<span id="cb6-60">            state.log_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].update(lora_stats)</span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-lora-diagnostics" class="cell" data-fig-height="9" data-fig-width="10" data-execution_count="10">
<div class="cell-output cell-output-display">
<div id="fig-lora-diagnostics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lora-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/index_files/figure-html/fig-lora-diagnostics-output-1.png" width="952" height="855" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lora-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: LoRA adapter diagnostics: layer-wise norms reveal training health (top row), singular value spectra reveal rank utilisation (bottom row).
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Adapter norms exploding</strong>: The LoRA weights are growing too large. Either your learning rate is too high, or there’s a mismatch between your LoRA rank and the task complexity.</li>
<li><strong>Effective rank much lower than configured rank</strong>: You’ve over-specified. Consider reducing the LoRA rank to save memory and potentially improve generalisation.</li>
<li><strong>Effective rank at maximum</strong>: Your rank might be too low. The adapter is using all its capacity.</li>
<li><strong>Large variance in norms across layers</strong>: Some layers are learning much more than others. This is often fine, but extreme variance can indicate problems.</li>
</ul>
</section>
<section id="instrument-7-compute-efficiency" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-7-compute-efficiency">Instrument 7: compute efficiency</h2>
<p>Training efficiency metrics are often overlooked in research contexts but are critical for production training.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>An efficiency drop during training often precedes other problems. Memory fragmentation, garbage collection and I/O bottlenecks can all manifest first as throughput degradation.</p>
</div></div><div id="fb9c81d1" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Compute efficiency monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> psutil</span>
<span id="cb7-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GPUtil</span>
<span id="cb7-4"></span>
<span id="cb7-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ComputeEfficiencyCallback(TrainerCallback):</span>
<span id="cb7-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Monitor training throughput and resource utilisation."""</span></span>
<span id="cb7-7"></span>
<span id="cb7-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, log_every_n_steps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>):</span>
<span id="cb7-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_every_n_steps</span>
<span id="cb7-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.last_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb7-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.last_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokens_per_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb7-14"></span>
<span id="cb7-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_train_begin(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb7-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.last_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb7-17"></span>
<span id="cb7-18">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_step_end(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb7-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb7-21">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb7-22"></span>
<span id="cb7-23">        current_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb7-24">        elapsed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.last_time <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.last_time <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-25"></span>
<span id="cb7-26">        efficiency_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb7-27"></span>
<span id="cb7-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Throughput</span></span>
<span id="cb7-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokens_per_step:</span>
<span id="cb7-30">            tokens_processed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokens_per_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps</span>
<span id="cb7-31">            efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/tokens_per_second"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokens_processed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> elapsed</span>
<span id="cb7-32">            efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/steps_per_second"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> elapsed</span>
<span id="cb7-33"></span>
<span id="cb7-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPU utilisation</span></span>
<span id="cb7-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb7-36">            gpus <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GPUtil.getGPUs()</span>
<span id="cb7-37">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> gpus:</span>
<span id="cb7-38">                gpu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpus[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb7-39">                efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/gpu_utilisation"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpu.load <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb7-40">                efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/gpu_memory_used_gb"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpu.memoryUsed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span></span>
<span id="cb7-41">                efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/gpu_memory_pct"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb7-42">                    gpu.memoryUsed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> gpu.memoryTotal <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb7-43">                )</span>
<span id="cb7-44">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span>:</span>
<span id="cb7-45">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">pass</span></span>
<span id="cb7-46"></span>
<span id="cb7-47">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CPU and system memory</span></span>
<span id="cb7-48">        efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/cpu_percent"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> psutil.cpu_percent()</span>
<span id="cb7-49">        memory <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> psutil.virtual_memory()</span>
<span id="cb7-50">        efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/ram_used_gb"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> memory.used <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb7-51">        efficiency_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"efficiency/ram_percent"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> memory.percent</span>
<span id="cb7-52"></span>
<span id="cb7-53">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(state, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"log_history"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> state.log_history:</span>
<span id="cb7-54">            state.log_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].update(efficiency_stats)</span>
<span id="cb7-55"></span>
<span id="cb7-56">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.last_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> current_time</span></code></pre></div></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>GPU utilisation below 80%</strong>: You’re bottlenecked somewhere else (data loading, CPU preprocessing). Increase <code>dataloader_num_workers</code> or enable <code>pin_memory</code>.</li>
<li><strong>Tokens per second declining over time</strong>: Memory fragmentation or garbage collection pressure. Consider periodic garbage collection calls.</li>
<li><strong>GPU memory usage climbing</strong>: Memory leak, often from gradient accumulation bugs or improper tensor handling in callbacks.</li>
<li><strong>Sudden throughput drops</strong>: I/O problems, often when the training hits a slow region of the data (e.g., longer sequences).</li>
</ul>
</section>
<section id="instrument-8-convergence-detection" class="level2">
<h2 class="anchored" data-anchor-id="instrument-8-convergence-detection">Instrument 8: convergence detection</h2>
<p>The final instrument in our cluster is arguably the most important: knowing when to stop.</p>
<div id="b96e57f6" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Early stopping with convergence detection</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ConvergenceDetector(TrainerCallback):</span>
<span id="cb8-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Detect convergence and potential overfitting."""</span></span>
<span id="cb8-3"></span>
<span id="cb8-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(</span>
<span id="cb8-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb8-6">        patience: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb8-7">        min_delta: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>,</span>
<span id="cb8-8">        divergence_threshold: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb8-9">    ):</span>
<span id="cb8-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patience <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> patience</span>
<span id="cb8-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_delta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> min_delta</span>
<span id="cb8-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.divergence_threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> divergence_threshold</span>
<span id="cb8-13"></span>
<span id="cb8-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_eval_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'inf'</span>)</span>
<span id="cb8-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epochs_without_improvement <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_losses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-18"></span>
<span id="cb8-19">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> on_evaluate(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, args, state, control, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb8-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> metrics <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb8-21">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb8-22"></span>
<span id="cb8-23">        eval_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metrics.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eval_loss"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'inf'</span>))</span>
<span id="cb8-24">        train_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metrics.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train_loss"</span>, state.log_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"loss"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb8-25"></span>
<span id="cb8-26">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses.append(train_loss)</span>
<span id="cb8-27">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_losses.append(eval_loss)</span>
<span id="cb8-28"></span>
<span id="cb8-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log convergence metrics</span></span>
<span id="cb8-30">        convergence_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb8-31"></span>
<span id="cb8-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check for improvement</span></span>
<span id="cb8-33">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> eval_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_eval_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_delta:</span>
<span id="cb8-34">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_eval_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_loss</span>
<span id="cb8-35">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epochs_without_improvement <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-36">            convergence_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convergence/improving"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb8-37">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb8-38">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epochs_without_improvement <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb8-39">            convergence_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convergence/improving"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-40"></span>
<span id="cb8-41">        convergence_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convergence/patience_remaining"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb8-42">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patience <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epochs_without_improvement</span>
<span id="cb8-43">        )</span>
<span id="cb8-44"></span>
<span id="cb8-45">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check for overfitting (eval loss diverging from train loss)</span></span>
<span id="cb8-46">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_losses) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb8-47">            gap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> train_loss</span>
<span id="cb8-48">            prev_gap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eval_losses[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.train_losses[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb8-49">            gap_increase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> prev_gap</span>
<span id="cb8-50"></span>
<span id="cb8-51">            convergence_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convergence/train_eval_gap"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gap</span>
<span id="cb8-52">            convergence_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convergence/gap_velocity"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gap_increase</span>
<span id="cb8-53"></span>
<span id="cb8-54">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> gap_increase <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.divergence_threshold:</span>
<span id="cb8-55">                convergence_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convergence/overfitting_warning"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb8-56">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"WARNING: Potential overfitting detected. Gap increase: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>gap_increase<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb8-57"></span>
<span id="cb8-58">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log metrics</span></span>
<span id="cb8-59">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(state, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"log_history"</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> state.log_history:</span>
<span id="cb8-60">            state.log_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].update(convergence_stats)</span>
<span id="cb8-61"></span>
<span id="cb8-62">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Trigger early stopping</span></span>
<span id="cb8-63">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epochs_without_improvement <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.patience:</span>
<span id="cb8-64">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Early stopping triggered after </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>patience<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> evaluations without improvement"</span>)</span>
<span id="cb8-65">            control.should_training_stop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span></code></pre></div></div>
</details>
</div>
<div id="cell-fig-convergence-detection" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="13">
<div class="cell-output cell-output-display">
<div id="fig-convergence-detection" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-convergence-detection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/index_files/figure-html/fig-convergence-detection-output-1.png" width="952" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-convergence-detection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Convergence pathologies: knowing when to stop (or when you should have stopped earlier).
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Train-eval gap increasing</strong>: Classic overfitting. Stop training or increase regularisation.</li>
<li><strong>Both losses plateauing</strong>: You’ve reached the model’s capacity on this task. More training won’t help.</li>
<li><strong>Eval loss increasing while train loss decreases</strong>: Severe overfitting. You should have stopped earlier.</li>
<li><strong>Oscillating eval loss</strong>: Learning rate too high for the current phase of training.</li>
</ul>
</section>
<section id="putting-it-all-together" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="putting-it-all-together">Putting it all together</h2>
<p>The eight instruments we’ve covered form a complete picture of your training run:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 33%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Instrument</th>
<th>What it tells you</th>
<th>Failure mode it catches</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Loss landscape</td>
<td>Optimisation progress</td>
<td>Instability, plateaus</td>
</tr>
<tr class="even">
<td>Gradient health</td>
<td>Learning signal quality</td>
<td>Vanishing/exploding gradients</td>
</tr>
<tr class="odd">
<td>Learning rate</td>
<td>Schedule execution</td>
<td>Misconfigured schedules</td>
</tr>
<tr class="even">
<td>Attention entropy</td>
<td>Model focus patterns</td>
<td>Attention collapse, degeneration</td>
</tr>
<tr class="odd">
<td>Generation samples</td>
<td>Output quality</td>
<td>Qualitative failures</td>
</tr>
<tr class="even">
<td>LoRA diagnostics</td>
<td>Adapter behaviour</td>
<td>Rank mismatch, weight explosion</td>
</tr>
<tr class="odd">
<td>Compute efficiency</td>
<td>Resource utilisation</td>
<td>Bottlenecks, memory leaks</td>
</tr>
<tr class="even">
<td>Convergence detection</td>
<td>When to stop</td>
<td>Overfitting, wasted compute</td>
</tr>
</tbody>
</table>
<p>In a production setting, I recommend implementing all eight and setting up alerts for the key failure modes. A good heuristic: if any of these metrics deviate by more than two standard deviations from their moving average, that warrants investigation.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;This is crude but effective. More sophisticated anomaly detection is possible but often unnecessary for catching the failures that actually occur in practice.</p></div></div></section>
<section id="the-wandb-configuration" class="level2">
<h2 class="anchored" data-anchor-id="the-wandb-configuration">The wandb configuration</h2>
<p>To actually implement this, here’s a complete trainer configuration that wires up all the callbacks:</p>
<div id="0867b9cb" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Complete training configuration with all monitors</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TrainingArguments, Trainer</span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> trl <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SFTTrainer</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_monitored_trainer(</span>
<span id="cb9-5">    model,</span>
<span id="cb9-6">    tokenizer,</span>
<span id="cb9-7">    train_dataset,</span>
<span id="cb9-8">    eval_dataset,</span>
<span id="cb9-9">    output_dir: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./output"</span>,</span>
<span id="cb9-10">    eval_prompts: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb9-11">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> SFTTrainer:</span>
<span id="cb9-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Create a fully instrumented SFT trainer."""</span></span>
<span id="cb9-13"></span>
<span id="cb9-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Training arguments with comprehensive logging</span></span>
<span id="cb9-15">    training_args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TrainingArguments(</span>
<span id="cb9-16">        output_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>output_dir,</span>
<span id="cb9-17">        num_train_epochs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb9-18">        per_device_train_batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb9-19">        gradient_accumulation_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb9-20">        learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-4</span>,</span>
<span id="cb9-21">        lr_scheduler_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cosine"</span>,</span>
<span id="cb9-22">        warmup_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb9-23"></span>
<span id="cb9-24">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Logging configuration</span></span>
<span id="cb9-25">        logging_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb9-26">        logging_first_step<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb9-27">        report_to<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wandb"</span>,</span>
<span id="cb9-28"></span>
<span id="cb9-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluation</span></span>
<span id="cb9-30">        eval_strategy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"steps"</span>,</span>
<span id="cb9-31">        eval_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb9-32">        save_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>,</span>
<span id="cb9-33"></span>
<span id="cb9-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Performance</span></span>
<span id="cb9-35">        bf16<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb9-36">        dataloader_num_workers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb9-37">        dataloader_pin_memory<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb9-38">    )</span>
<span id="cb9-39"></span>
<span id="cb9-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assemble callbacks</span></span>
<span id="cb9-41">    callbacks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb9-42">        LossLandscapeCallback(window_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>),</span>
<span id="cb9-43">        GradientHealthCallback(log_every_n_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>),</span>
<span id="cb9-44">        LearningRateMonitor(),</span>
<span id="cb9-45">        AttentionEntropyCallback(log_every_n_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>),</span>
<span id="cb9-46">        LoRADiagnosticsCallback(log_every_n_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>),</span>
<span id="cb9-47">        ComputeEfficiencyCallback(log_every_n_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>),</span>
<span id="cb9-48">        ConvergenceDetector(patience<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, min_delta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>),</span>
<span id="cb9-49">    ]</span>
<span id="cb9-50"></span>
<span id="cb9-51">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add generation sampler if eval prompts provided</span></span>
<span id="cb9-52">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> eval_prompts:</span>
<span id="cb9-53">        callbacks.append(</span>
<span id="cb9-54">            GenerationSamplerCallback(</span>
<span id="cb9-55">                tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer,</span>
<span id="cb9-56">                eval_prompts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>eval_prompts,</span>
<span id="cb9-57">                log_every_n_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>,</span>
<span id="cb9-58">            )</span>
<span id="cb9-59">        )</span>
<span id="cb9-60"></span>
<span id="cb9-61">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> SFTTrainer(</span>
<span id="cb9-62">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model,</span>
<span id="cb9-63">        tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer,</span>
<span id="cb9-64">        train_dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset,</span>
<span id="cb9-65">        eval_dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>eval_dataset,</span>
<span id="cb9-66">        args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>training_args,</span>
<span id="cb9-67">        callbacks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>callbacks,</span>
<span id="cb9-68">    )</span></code></pre></div></div>
</details>
</div>
</section>
<section id="reading-the-dashboard" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reading-the-dashboard">Reading the dashboard</h2>
<p>Knowing what to log is only half the battle. The other half is knowing what you’re looking at.</p>
<p>I recommend organising your wandb dashboard into four panels:</p>
<ol type="1">
<li><strong>Primary metrics</strong>: Train loss, eval loss, learning rate. The overview.</li>
<li><strong>Health indicators</strong>: Gradient norm, attention entropy, convergence status. The vital signs.</li>
<li><strong>Efficiency metrics</strong>: Tokens/sec, GPU utilisation, memory. The resource gauge.</li>
<li><strong>Deep diagnostics</strong>: Per-layer gradients, LoRA norms, generation samples. The detailed view.</li>
</ol>
<p>Start each monitoring session by glancing at panels 1 and 2. Only dive into 3 and 4 when something looks off.</p>
<p>The most common failure patterns I see in practice:</p>
<ul>
<li><strong>Silent overfitting</strong>: Loss looks great, but generation quality is degrading. Always check the samples.</li>
<li><strong>Efficiency death spiral</strong>: Throughput drops, memory climbs, eventually OOM. Often caused by a memory leak in a custom callback.</li>
<li><strong>Attention collapse</strong>: Happens gradually, then suddenly. The attention entropy instrument catches this before it becomes catastrophic.</li>
<li><strong>Gradient starvation in later layers</strong>: Early layers learn, later layers don’t. Per-layer gradient monitoring reveals this immediately.</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<p>These patterns often require monitoring multiple indicators simultaneously. No single metric tells the whole story.</p>
<p>A beloved example of mine is GPU memory vs utilisation. It’s somewhat shocking how many otherwise competent engineers look at these in isolation. GPU utilisation going down is not necessarily a good sign. If memory usage is climbing and is approaching the top 10-15%, GPU utilisation and/or power draw going down is a three-alarm fire and a sign of impending OOM/collapse.</p>
</div></div><div id="cell-fig-failure-patterns" class="cell" data-fig-height="10" data-fig-width="11" data-execution_count="15">
<div class="cell-output cell-output-display">
<div id="fig-failure-patterns" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-failure-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/index_files/figure-html/fig-failure-patterns-output-1.png" width="1052" height="951" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-failure-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Common failure patterns in practice: each requires monitoring multiple indicators simultaneously.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="what-comes-next" class="level2">
<h2 class="anchored" data-anchor-id="what-comes-next">What comes next</h2>
<p>This instrument cluster is designed for supervised fine-tuning of LoRA adapters – the most common post-training scenario. But the story doesn’t end here.</p>
<p>In the next post, we’ll extend this framework to preference optimisation methods like DPO and GRPO. These introduce new failure modes: reward hacking, KL divergence explosion and the subtle art of balancing preference learning against capability preservation. The instrument cluster will need to grow.</p>
<p>The third post will tackle specialised training for function calling, where the metrics of success are not just loss curves but format compliance, execution accuracy and the reliability that production systems demand.</p>
<p>For now, the homework is straightforward: instrument your next fine-tuning run with all eight monitors. Watch what happens. Learn to read the dashboard. And when something goes wrong – as it inevitably will – you’ll have the forensic data to understand why.</p>
<p>Happy post-training!</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The Post-Training Instrument Cluster -\/- {Part} {I}},
  date = {2025-12-25},
  url = {https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“The Post-Training Instrument Cluster
-- Part I.”</span> <a href="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/">https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>LLMs</category>
  <category>LLMOps</category>
  <category>fine-tuning</category>
  <category>post-training</category>
  <category>MLOps</category>
  <guid>https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/</guid>
  <pubDate>Thu, 25 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/failure_patterns.png" medium="image" type="image/png" height="130" width="144"/>
</item>
<item>
  <title>Post-training: three disciplines in a trenchcoat</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/post-training-scale/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Hey, I’m writing a book about this!
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m actually writing a book about this stuff. It turns out there isn’t a lot of literature on how to do post-training at the level too big for single-GPU laptop-sized hobby projects and requiring enterprise reliability on one hand, but not quite at the scale of multi-team distributed post-training you’d get in foundation labs. That’s a problem, because a lot of the current value in fine-tuning applications comes exactly out of that large, crucial market. I am in the last phases of putting together the manuscript for <em>The Frontier Playbook</em>, a set of curated tactics and techniques for real world operationalisation of LLMs. <a href="https://aifrontierplaybook.substack.com">Sign up for updates here</a>.</p>
</div>
</div>
<p>There’s a comfortable fiction in AI that “post-training” names a coherent discipline. We speak of it as though the researcher fine-tuning Llama on a 3090 and the infrastructure team planning a 500MW RLHF run are engaged in the same enterprise at different magnitudes. And yes, in a very philosophical sense, they are. It’s just that that philosophical acuity reflects pretty much none of the parts of reality that matter. And that’s a problem for our allegedly unitary discipline.</p>
<p>Pre-training never had to confront this problem. The barriers to entry were so astronomical that there was never any pretence of an on-ramp. You either had foundation lab resources or you didn’t, and if you didn’t, you weren’t doing pre-training. This hasn’t really shifted – the kind of pre-training/scaling needed to create true foundation models is limited to a vanishingly small part of the world (more people have been to outer space than have managed a capital foundation model). The conversation is contained, the community is small and everyone who needs to know what something means already knows it.</p>
<p>Post-training is different. It is democratised, and will only become more so as efficient (esp.&nbsp;<em>memory</em>-efficient) methods proliferate. The barriers of entry have never been lower. At the moment, you can run toy examples of cutting edge techniques for free with the <a href="https://github.com/unsloth-ai/notebooks">Unsloth notebooks</a> on Google Colab. Consumer GPUs can, with some ingenuity, run fine-tuning experiments that would have been unthinkable a few years ago. The on-ramps are everywhere.</p>
<p>But not to everything.</p>
<p>Post-training is not one discipline. It is three,<sup>1</sup> awkwardly sharing a name. The binding constraints, the core competencies, the failure modes differ qualitatively across regimes. Perhaps most poignantly, the governing constraints are so different, they do not share a continuum.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;At least. Arguably there’s token-scale, where users buy API access or other consumer products. There’s not a lot of what would merit being referred to as post-training there, though, so we shall omit mention.</p></div></div><div id="tbl-regimes" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-regimes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: The three regimes of post-training, distinguished by their binding constraints.
</figcaption>
<div aria-describedby="tbl-regimes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Memscale</th>
<th style="text-align: left;">Flopscale</th>
<th style="text-align: left;">Powerscale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Binding constraint</strong></td>
<td style="text-align: left;">VRAM</td>
<td style="text-align: left;">Unit economics</td>
<td style="text-align: left;">Energy</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Typical scale</strong></td>
<td style="text-align: left;">1 GPU (16-80 GB)</td>
<td style="text-align: left;">Dozens to hundreds of GPUs</td>
<td style="text-align: left;">Several thousands of GPUs</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Team size</strong></td>
<td style="text-align: left;">Solo</td>
<td style="text-align: left;">Solo to small team of generalists</td>
<td style="text-align: left;">Professionally project-managed teams for various stages</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Cost scale, order of magnitude $USD/run</strong></td>
<td style="text-align: left;">$10-$100s</td>
<td style="text-align: left;">$1,000s</td>
<td style="text-align: left;">$1,000,000s</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>There’s something magical about these three realms coexisting at all. Perhaps for the first time in history, our most advanced frontier technologies are also accessible to essentially anyone who can set up Hugging Face jobs or a Colab notebook. No matter how much these regimes differ, it’s remarkable that what little continuity exists, exists at all. But that continuity is quite thin. As someone who essentially lives and breathes post-training, I have seen all three of these first-hand, although I spend almost all my time towards the middle to top end of the flopscale regime. I’m a tolerated guest in powerscale land, and a weekend adventurer in memscale. All I can say is that I never had to talk to a power company about when I can throw the on-switch.</p>
<section id="memscale-the-tyranny-of-vram" class="level3">
<h3 class="anchored" data-anchor-id="memscale-the-tyranny-of-vram">Memscale: The tyranny of VRAM</h3>
<p>At memscale, the fundamental question is: can I fit this into memory? This is the world of the single GPU, from a 3090 through an RTX 6000, perhaps stretching to a GB200 in a DGX Spark if you’re fortunate. The binding constraint is physical and absolute. Either the model, its gradients, its optimiser states and its activations fit, or they don’t. There is no negotiating with VRAM.</p>
<p>The entire memscale toolkit exists to cope with this constraint. LoRA and its descendants (QLoRA, DoRA, the ever-expanding alphabet) represent a fundamental insight: if you cannot fit the whole thing, fit an efficient delta. Gradient checkpointing trades compute for memory. Quantisation compresses representations. Tools like Unsloth and Axolotl have packaged these techniques into something approaching accessibility for the sufficiently obsessed.</p>
<p>But here’s what makes memscale genuinely different as a regime: scaling is lumpy. If you run out of memory, your options are to optimise harder or to acquire another GPU, assuming you still can in the current market. There is no smooth gradient of resources. You’re either within your envelope or you’re not, and if you’re not, you hit a wall that you can generally supervene at the cost of doubling your entire GPU investment. The memscale practitioner’s core competency is OOM avoidance. Everything else is secondary.</p>
<p>This creates a particular kind of craft knowledge, somewhat akin to the art of the demoscene coder who could put entire animated demos into less than a modern social media avatar takes up in space. The memscale expert knows exactly which layers to freeze, which LoRA rank to choose for a given VRAM budget, how to schedule batch sizes against memory headroom, when to checkpoint and when to materialise. It is artisanal work, intimate and particular. And almost none of it transfers upward – which is why relatively few foundation lab researchers, never mind powerscale infrastructure teams, spend much time thinking about memscale techniques.</p>
</section>
<section id="flopscale-the-discipline-of-unit-economics" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="flopscale-the-discipline-of-unit-economics">Flopscale: The discipline of unit economics</h3>
<p>At flopscale, memory ceases to be the binding constraint in any individual sense. You have a cluster. Perhaps dozens of GPUs, perhaps hundreds. You can shard, you can parallelise, you can distribute.</p>
<p>What you cannot do is waste operations, because what you <em>also</em> have, typically, is a boss. This is firmly enterprise land, and enterprises care about ROI. Those TFLOPs your rack of H200s produce? They’re the <code>I</code> in that abbreviation, and you best be producing some <code>R</code> on them.</p>
<p>The question then becomes not “can I fit it?” but “can I justify it?” The optimisation target shifts from memory efficiency to unit economics. The scarcest resource is not VRAM but organisational patience for uncertain outcomes.</p>
<p>Scaling here is smoother than at memscale. You don’t hit walls; you encounter gradients of cost. Need more compute? Provision more nodes. The constraint is fiscal, not physical. But this smoothness is double-edged. At memscale, the walls enforce discipline. At flopscale, you have enough rope to hang yourself, and thus the flopscale practitioner is expected to bring a level of judgment about what to run when that memscale hobbyists don’t have to worry about by and large and powerscale teams… well, to most, it’s a rounding error.</p>
<p>This is a rather critical realm, and yet, paradoxically, perhaps the most woefully underserved. There are clear risks and failure modes to flopscale work, and you are not going to be able to teach yourself how to run a model on a cluster of 64 H200s from weekend tinkering.<sup>2</sup> You need to understand distributed systems, job scheduling, data pipeline reliability, cost monitoring, failure recovery and a host of other concerns that don’t arise at memscale. Yet there are precious few resources targeted at this regime specifically. Most of the literature is either memscale hobbyist-focused or powerscale foundation lab-focused (although at the moment, regrettably, the industry is going through its mediaeval guild phase, where the secrets of building cathedrals are jealously guarded and only passed on from master to apprentice after the latter has proven itself worthy). Flopscale is the neglected middle child of post-training – the realm where most real-world applications will be built, and yet the one with the thinnest knowledge base.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Please don’t take a HELOC to fund your first 120B full finetune on a bunch of A100s.</p></div><div class="">
<hr>
<p><strong>Recipe:</strong> Cassoulet (sort of)</p>
<ul>
<li>500g dried white beans, soaked overnight</li>
<li>Duck confit (4 legs, or make your own if you have the week)</li>
<li>400g Toulouse sausage</li>
<li>200g salt pork or pancetta</li>
<li>Onion, carrot, celery, garlic</li>
<li>Tomato paste, bay leaves, thyme</li>
<li>Good stock, ideally duck</li>
</ul>
<p>Brown meats separately. Build a soffritto. Layer everything in a Dutch oven with the beans. Add stock to cover. Bake at 150°C (that’s 300°F in freedom units) for three hours minimum, breaking the crust that forms and pushing it down every hour. The crust reforms. You break it again. This is the cassoulet ritual.</p>
<p>Worth it? Depends on your objective function. ***</p>
</div></div>
<p>This is, I think, the hardest regime to operate in well. The memscale practitioner has constraints that enforce focus. The powerscale practitioner has resources that permit exploration. The flopscale practitioner has neither the discipline of poverty nor the freedom of abundance. They must construct their own discipline, and they must do so while delivering demonstrable business value.</p>
</section>
<section id="powerscale-the-infrastructure-of-nations" class="level3">
<h3 class="anchored" data-anchor-id="powerscale-the-infrastructure-of-nations">Powerscale: The infrastructure of nations</h3>
<p>At powerscale, we measure not in gigabytes or teraflops but in gigawatts. The binding constraint is raw energy: what you can power, cool and sustain. This is foundation lab territory, the handful of organisations that can credibly discuss training runs straining national electrical infrastructure.</p>
<p>I won’t dwell long here, partly because anyone who is habitually operating at this scale is already deeply familiar with the peculiarities of their narrow place in it. This is ‘big science’. I am reminded of Richard Rhodes’s description of the Manhattan Project as a massive industrial enterprise. Sure, I thought, I get the first part, but… industrial? We think of it as an achievement of science – right up until we realise that just keeping Hanford running took more people per shift than the entire project had physicists. And powerscale AI engineering is no different. For every AI researcher, there are fleets of infrastructure engineers, data centre ops, civil engineers, logistics coordinators and myriad others ensuring that the lights stay on and the gradients keep flowing. I have trained some absurdly large models, but I don’t routinely have to consider geopolitics or the national grid. Neither do powerscale practitioners, but they do have to deal with people who do.</p>
</section>
<section id="the-diffusion-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-diffusion-problem">The diffusion problem</h3>
<p>This brings us to the crux of the matter. Techniques do diffuse across scales, but the diffusion is slow, uneven and often lossy. If there is such a thing as a post-training discipline, it is largely focused on solving the same vague problem in world so different that the solutions themselves need an effort to be feasibly translated, if at all possible to do so.</p>
<p>Consider recent work like Khatri, Madaan et al.’s <a href="https://arxiv.org/abs/2510.13786">ScaleRL paper</a>. It would be hand-wavey to claim that such techniques apply only to the narrow powerscale slice. Clearly, insights about reinforcement learning at scale have downstream applicability. But the applicability is not automatic. The flopscale practitioner cannot simply import powerscale techniques wholesale. They must translate, adapt, figure out what survives the transition and what doesn’t.</p>
<p>Tools like Unsloth accelerate this filtration significantly. They package techniques that originated in higher-resource environments into forms usable at memscale. This is genuine democratisation. But there will always be techniques that don’t translate, approaches that only make sense given certain resource assumptions, optimisations that are pointless below (or above) certain thresholds.</p>
<p>If you work in post-training, your first task is to know which game you’re playing. The memscale practitioner who imports flopscale assumptions will waste time on approaches they cannot execute. The flopscale practitioner who ignores powerscale developments will miss techniques that could, with adaptation, provide advantage. The flopscale practitioner who imports memscale habits will under-utilise available resources.</p>
<p>The hardest position, I think, is flopscale. You have enough resources to attempt almost anything but not enough to attempt everything. You face genuine choices about which techniques to adopt, which to adapt and which to ignore. You must show ROI while navigating a tactical landscape that wasn’t designed with your constraints in mind, and remain competitive with players who operate much larger resource envelopes for less focal problems – or know how to “get it right on a 3090” but are blissfully unaware of just how much that is not going to be acceptable in an actual enterprise deployment.</p>
<p>This is not a solved problem. We lack good heuristics for technique translation across scales. We lack systematic understanding of what survives the transitions and what doesn’t. We lack, frankly, recognition that the problem exists.</p>
<p>Perhaps the first step is simply to stop pretending that “post-training” names a unified discipline. It doesn’t. We have three disciplines awkwardly sharing a name, and the sooner we recognise this, the sooner we can develop the differentiated knowledge each regime demands while maintaining the channels to traffic insights between them.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {Post-Training: Three Disciplines in a Trenchcoat},
  date = {2025-12-20},
  url = {https://chrisvoncsefalvay.com/posts/post-training-scale/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“Post-Training: Three Disciplines in a
Trenchcoat.”</span> December 20, 2025. <a href="https://chrisvoncsefalvay.com/posts/post-training-scale/">https://chrisvoncsefalvay.com/posts/post-training-scale/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>LLMs</category>
  <category>post-training</category>
  <guid>https://chrisvoncsefalvay.com/posts/post-training-scale/</guid>
  <pubDate>Sat, 20 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/post-training-scale/header.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Dorkestration</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/dorkestration/</link>
  <description><![CDATA[ 




<p>In the dying days of the Roman Republic, there existed a class of functionaries called <em>nomenclatores</em>. Their job was to whisper the names of approaching citizens into their patron’s ear so that the great man could greet each one as if they were intimates. It was, in essence, human middleware: a layer of intelligence that sat between intention and execution, transforming the vague desire “I should be pleasant to these people” into the specific action of remembering that the fellow in the toga with the wine stain is called Gaius and his mother just died. The nomenclator didn’t make decisions. He enabled them.</p>
<p>I find myself thinking about nomenclatores rather a lot these days, because I’ve accidentally turned Claude Code into one. Not for social niceties, but for something equally tedious and equally important: orchestrating machine learning workloads.</p>
<section id="the-quiet-tyranny-of-boilerplate" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-quiet-tyranny-of-boilerplate">The quiet tyranny of boilerplate</h2>
<p>Here’s a confession: I don’t vibe code. I know, I know. It’s supposedly the hot new thing,<sup>1</sup> and I’m meant to be breathlessly excited about asking a language model to build me a web app while I sip my flat white.<sup>2</sup> But the truth is, most of my coding needs are rather more mundane. I need to fine-tune a model, I need to check that the data is in the right format, I need to submit a training job and I’d like to please not think about it until WandB tells me something interesting has happened.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;For a given value of new. I suffer from late stage temporal displacement: I live about 8-9 months out from whatever the current date is. No, we still don’t have hoverboards in late Summer 2026, sorry to disappoint.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;Frustratingly, the magic <em>is</em> there about this. Just not where people think it is.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;If you do, please don’t send them to me.</p></div></div><p>This is not creative work – it’s the plumbing part of ML, simultaneously crucial and boring. Nobody writes poetry about their CI/CD pipelines.<sup>3</sup></p>
<p>The traditional solution to this problem is to write scripts, lots and lots of scripts. These inevitably reach turtles-all-the-way-down complexity, until you have scripts with configuration files that nobody remembers how to update, scripts that worked six months ago and now mysteriously don’t because somebody upgraded a dependency somewhere and scripts that are documented with lines like “it sounded like a good idea at the time”. The more sophisticated alternative to scripts is to reach for Airflow or Kubeflow or one of the other tools that promise to turn your ML workflow into a directed acyclic graph of containerised tasks, complete with a UI that looks like someone tried to build Microsoft Visio inside a web browser and gave up halfway through.</p>
<p>Both approaches share a fundamental problem: they require you to know exactly what you want before you start. You must specify every step, every parameter, every failure mode. There is no room for “I think maybe around <code>4e-5</code> for the learning rate, but honestly, use your judgment.” The machine has no judgment to use.</p>
<p>Until, of course, it does.</p>
</section>
<section id="what-everybody-missed-about-tool-use" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-everybody-missed-about-tool-use">What everybody missed about tool use</h2>
<p>When MCP emerged and the discourse turned to tool calling, there was a kind of gold rush mentality. Everybody assumed we would need to build elaborate API ecosystems: a thousand MCP servers, a million tool definitions, bespoke clients for every conceivable service. The assumption was that tool use scales with the number of tools available.</p>
<p>This assumption is wrong, and it’s wrong in an interesting way.</p>
<p>Consider what Claude Code actually has access to. Not thousands of specialised tools, but perhaps half a dozen primitives: browse the filesystem, write and execute bash, write and execute Python, create and edit files. That’s essentially it. And yet Claude Code can do <em>anything</em> with these primitives, because they are computationally complete. If you can read files, write files, and execute arbitrary code, you can accomplish any computable task.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;This is, of course, the Church-Turing thesis applied to practical tooling. The specific tools don’t matter so long as you have a universal set.</p></div></div><p>The magic isn’t in having more tools but in having tools that can <em>make</em> other tools. When I need Claude to interact with a new API, I don’t need to build an MCP server for it. I need Claude to write a Python script that calls that API. When I need to orchestrate a complex workflow, I don’t need a specialised orchestration tool. I need Claude to compose a bash script that chains together the steps. The fundamental operations are sufficient precisely because they enable composition.</p>
<p>This is what so many people continue to miss about the definition of ‘tools’ in agentic AI: they act as though tool use meant wrapping every possible API in a standardised interface. But the truly powerful pattern is recursive: agents that use their primitive tools to create new capabilities on the fly, capabilities that exist only for the duration of the task and then dissolve back into tokens. Tool use isn’t about the breadth of your toolbox. It’s about whether your tools can build other tools.</p>
</section>
<section id="the-nomenclator-in-the-machine" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-nomenclator-in-the-machine">The nomenclator in the machine</h2>
<p>Which brings us to <strong>dorkestration</strong>, aka ‘vibe coding for orchestrating ML’ – the use of coding agents like Claude Code to manage ML workloads. We’re using a coding agent (which really is just fancy terminology for ‘LLM trained to call tools that create executable code’) not to write code in the traditional sense, but to serve as an intelligent intermediary between my intentions and the rather tedious specifics of actually getting a model trained.</p>
<p>The insight is simple enough: a well-designed Claude skill can handle the entire training pipeline with remarkably little input. I provide a data source and a base model. Out comes a WandB link. The code is already running with sensible defaults. If I ask for hyperparameter optimisation, Optuna spins up and starts searching. I never have write a YAML file, debug a CUDA error or remember whether <code>--gradient_checkpointing</code> needs to be <code>true</code>, <code>True</code> or <code>enabled</code>.</p>
<p>This is what coding agents are actually good for: not replacing programmers, but replacing the programmer-as-bureaucrat. All that busywork of marshalling data, checking formats, setting up environments, monitoring progress: this is nomenclator work that requires intelligence but not creativity, judgment but not vision. It is the kind of thing that a competent assistant could handle if you could explain to them what you wanted.</p>
<p>And that’s precisely what a coding agent is: a competent assistant who speaks enough technical language to translate “fine-tune this model on that data” into the forty-seven individual steps required to actually accomplish it.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Which means we may rethink what a junior developer <em>is</em>. Rather than being an apprentice being made to do things we don’t want to do, this may shift their role to what it always should have been: a collaborator who brings fresh ideas and perspectives to the table while the agent handles the tedious bits. The junior developer becomes an apprentice thinker for a master, not an indentured executor. It’s not going to make the junior level (sub-L3) job market any less dire, but it is going to leave us, potentially, with a better future.</p></div></div></section>
<section id="anatomy-of-a-dorkestration" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="anatomy-of-a-dorkestration">Anatomy of a dorkestration</h2>
<p>Let me make this concrete. Here’s what a typical fine-tuning session looks like with a properly configured Claude skill.</p>
<p>I say: “Fine-tune Llama 3.1 8B on my preference data at <code>/data/preferences.jsonl</code>. Use LoRA, keep it cheap, let me know how it goes. See you in a bit.”</p>
<p>What happens next:</p>
<ol type="1">
<li><p><strong>Data validation.</strong> Claude examines the JSONL file, checks that it’s in the expected format (conversations? preference pairs? instruction-response?), counts examples, looks for obvious problems like empty responses or malformed JSON.</p></li>
<li><p><strong>Configuration generation.</strong> Based on the model and data characteristics, Claude generates an Axolotl, TRL or Unsloth config with sensible defaults. For an 8B model with LoRA, this means reasonable rank and alpha values, appropriate learning rates, gradient checkpointing enabled because we’re not made of VRAM.<sup>6</sup></p></li>
<li><p><strong>Environment setup.</strong> Claude checks that the necessary packages are installed, that CUDA is accessible, that there’s enough disk space. If we’re running on a serverless endpoint (Modal, RunPod, Lambda Labs), it handles the deployment.</p></li>
<li><p><strong>Training submission.</strong> The job starts. WandB logging is configured automatically. I get a link.</p></li>
<li><p><strong>Monitoring.</strong> If I’ve set up the WandB MCP integration, Claude can actually check on progress, alert me to anomalies, and suggest early stopping if the loss curves look pathological.<sup>7</sup></p></li>
<li><p><strong>Optional: Optuna.</strong> If I’ve indicated interest in hyperparameter search, Claude sets up an Optuna study with sensible search spaces, launches multiple trials, and reports back on the best configuration.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;As a shareholder of NVIDIA, please ignore this sentence and pretend you <em>are</em>. That 0.7B model? Totally needs a Grace Blackwell. My stockbroker and my retirement fund thank you.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;Interesting curiosity: Claude has been much better at spotting early signs of failure from screenshots of the WandB dashboard than from the raw data. I’d love for any of my Anthropic readers who are in the Vision team to explain this. You know where to reach me.</p></div></div><p>The whole thing takes maybe thirty seconds of my attention. The first time I configured this properly, I felt like I’d hired a very competent but slightly literal-minded research assistant. One who would never forget to enable <code>bf16</code> training on Ampere GPUs, but who also needed explicit permission to do anything beyond the literal scope of the request.</p>
</section>
<section id="the-skill-itself" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-skill-itself">The skill itself</h2>

<div class="no-row-height column-margin column-container"><div class="">
<hr>
<p><strong>Recipe:</strong> Carbonara for the impatient</p>
<p>Gets done in about the time a decent 3B model fine-tunes on a small data set using enough compute to power a small village.</p>
<ul>
<li>200g guanciale (or pancetta, or bacon if you’re desperate). Don’t ask for it in grams. Just buy a ton and do the science-y thing in the privacy of your kitchen.</li>
<li>400g spaghetti</li>
<li>4 egg yolks</li>
<li>100g Pecorino Romano, finely grated</li>
<li>Black pepper, lots of it</li>
</ul>
<p>Cook the pasta. While it boils, render the guanciale slowly in a cold pan brought up to medium heat. Beat the yolks with the cheese and pepper until you have a thick paste. When the pasta is done, reserve a cup of pasta water, then toss the drained pasta with the guanciale. Remove from heat. Wait thirty seconds. Add the egg mixture and toss vigorously, adding pasta water as needed until you have a glossy sauce. The residual heat cooks the eggs without scrambling them. Serve immediately. If you’ve done it right, you’ll have pasta and gradient returns around the same time. ***</p>
</div></div><p>For those who want to implement something similar, here’s the skeleton of a Claude skill for fine-tuning orchestration:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"># Fine-tuning orchestrator</span></span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Trigger conditions</span></span>
<span id="cb1-4"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>User wants to fine-tune a language model</span>
<span id="cb1-5"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>User provides a data source and base model</span>
<span id="cb1-6"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Keywords: "fine-tune", "finetune", "train", "LoRA", "QLoRA"</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Workflow</span></span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### 1. Data validation</span></span>
<span id="cb1-11">Before anything else, examine the data source:</span>
<span id="cb1-12"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Determine format (JSONL, CSV, Parquet, HuggingFace dataset)</span>
<span id="cb1-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Identify structure (conversations, instruction-response, preference pairs)</span>
<span id="cb1-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Count examples and estimate training time</span>
<span id="cb1-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Check for obvious issues (empty fields, encoding problems, truncation)</span>
<span id="cb1-16"></span>
<span id="cb1-17">Report findings and proceed only with user confirmation.</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### 2. Configuration</span></span>
<span id="cb1-20">Based on model size and data type, generate appropriate config:</span>
<span id="cb1-21"></span>
<span id="cb1-22">For Unsloth (recommended for single-GPU):</span>
<span id="cb1-23"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Use 4-bit quantisation for models &gt;7B</span>
<span id="cb1-24"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>LoRA rank 16-64 depending on task complexity</span>
<span id="cb1-25"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Learning rate 2e-4 for QLoRA, 1e-5 for full fine-tuning</span>
<span id="cb1-26"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Gradient checkpointing enabled by default</span>
<span id="cb1-27"></span>
<span id="cb1-28">For Axolotl (recommended for multi-GPU or complex setups):</span>
<span id="cb1-29"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Generate YAML config with appropriate settings</span>
<span id="cb1-30"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Use deepspeed_zero2 for multi-GPU</span>
<span id="cb1-31"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Configure WandB logging automatically</span>
<span id="cb1-32"></span>
<span id="cb1-33"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### 3. Environment</span></span>
<span id="cb1-34">Check and configure:</span>
<span id="cb1-35"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>CUDA availability and version</span>
<span id="cb1-36"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Required packages (transformers, peft, bitsandbytes, etc.)</span>
<span id="cb1-37"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Disk space for checkpoints</span>
<span id="cb1-38"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>WandB authentication</span>
<span id="cb1-39"></span>
<span id="cb1-40">If using serverless (Modal/RunPod/Lambda):</span>
<span id="cb1-41"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Generate deployment script</span>
<span id="cb1-42"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Configure appropriate GPU type</span>
<span id="cb1-43"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Set up volume mounts for data and outputs</span>
<span id="cb1-44"></span>
<span id="cb1-45"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### 4. Execution</span></span>
<span id="cb1-46"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Start training with configured parameters</span>
<span id="cb1-47"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Provide WandB link immediately</span>
<span id="cb1-48"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Log checkpoint locations</span>
<span id="cb1-49"></span>
<span id="cb1-50"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### 5. Optional: Hyperparameter search</span></span>
<span id="cb1-51">If requested, configure Optuna study:</span>
<span id="cb1-52"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Search space: learning_rate <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">1e-5, 5e-4</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>, lora_r <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">8, 64</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>, lora_alpha <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">16, 128</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb1-53"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Objective: validation loss</span>
<span id="cb1-54"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Pruning: Median pruner after 100 steps</span>
<span id="cb1-55"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">- </span>Report best configuration and provide config file</span></code></pre></div></div>
<p>The key insight is that this isn’t really a “skill” in the sense of specialised knowledge, but more like a well-structured set of default behaviors that Claude can adapt to specific circumstances. The skill tells Claude what to check, in what order, with what defaults. Claude supplies the judgment calls: is this data format unusual? Is this model small enough to fit in memory? Should we be concerned about this warning?</p>
</section>
<section id="why-this-works-and-why-traditional-tools-dont" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-this-works-and-why-traditional-tools-dont">Why this works (and why traditional tools don’t)</h2>
<p>I’ve written elsewhere about <a href="../../posts/mcp-mcpmark/index.html">the gap between excellent infrastructure and models’ ability to use it</a>. MCP is beautifully designed but so often let down by models not showing up. Orchestration, though, is different. Traditional workflow tools fail at ML orchestration because ML is inherently exploratory: you don’t know what hyperparameters will work until you try them. You don’t know if the data is clean until you look at it. You don’t know if the model is converging until you see the loss curves. Every step requires conditional logic, and the conditions aren’t known in advance. Simple optimisers/tuners like Optuna are great, but LLMs have complexity and judgment that go far beyond what a static configuration can capture.</p>
<p>Coding agents handle this naturally because they can actually look at things. When Claude validates your data, it’s not checking against a schema. It’s looking at actual examples and making judgments about whether they seem reasonable. When it suggests a learning rate, it’s considering the model size, the dataset characteristics, the training duration. It’s doing what a knowledgeable human would do, except it doesn’t get bored or distracted or forget that one crucial flag.</p>
<p>The “ephemeral UI” framing is perhaps the most useful way to think about this. Traditional UIs are persistent: you build them once and they exist forever, gradually accumulating technical debt and increasingly byzantine configuration options. An ephemeral UI exists only for the duration of the task. You describe what you want in natural language, the agent interprets it, and when the task is done, the “UI” dissolves back into tokens. No maintenance. No versioning. No documentation to keep updated.<sup>8</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;This is, incidentally, why I think the current wave of low-code/no-code ML tools is somewhat missing the point. They’re trying to build better persistent UIs when what we actually need is better ephemeral ones. A drag-and-drop interface for configuring training pipelines will always be limited by the imagination of its designers. A coding agent is limited only by the underlying capabilities of the tools it can access.</p></div></div></section>
<section id="crystallising-knowledge" class="level2">
<h2 class="anchored" data-anchor-id="crystallising-knowledge">Crystallising knowledge</h2>
<p>Here’s where it gets properly interesting. Unsloth, one of the more popular fine-tuning libraries, has <a href="https://github.com/unsloth/notebooks">over a hundred example notebooks</a> (and they’re brilliant). Different model architectures, different data formats, different training regimes. It’s a wealth of institutional knowledge, but it’s scattered across dozens of files, each demonstrating a slightly different approach.</p>
<p>Claude’s skill creator can read all of them, distill the key patterns, and crystallise them into a coherent skill. Not just copying configurations, but understanding <em>why</em> certain settings work together: that QLoRA with 4-bit quantisation needs different learning rates than full fine-tuning, that gradient checkpointing trades compute for memory, that certain models respond better to particular LoRA ranks. This distilled knowledge then informs every future interaction.</p>
<p>This is what true agentic interaction looks like. Not just calling tools, but using tools to create new capabilities. The skill creator reads documentation, examines examples, synthesises understanding, and produces a structured artefact that makes future tasks easier. It’s recursive improvement: the agent uses its primitive tools to build better tools for itself.</p>
<p>I’ve been building out a small collection of these skills, including one for <a href="https://huggingface.co/blog/chrisvoncsefalvay/claude-hf-jobs-optuna">hyperparameter optimisation on Hugging Face Jobs</a> that integrates Optuna with serverless GPU endpoints. The entire interaction looks like this:</p>
<blockquote class="blockquote">
<p>Hi, Claude. Can you finetune Qwen/Qwen2.5-0.5B on a 2k subsample of wikitext/wikitext-2-raw-v1 using your optuna-hpo skill to figure out the ideal training hyperparameters? Your budget is $5. Do it on Hugging Face Jobs. And please launch the Gradio dashboard for me, too.</p>
</blockquote>
<p>Claude responds, and then just… does it. Creates an Optuna study. Generates trial scripts. Submits jobs to HF Jobs. Polls for completion. Extracts metrics. Launches a dashboard. All automatically. Within two trials and $0.18 spent, it found a 6% improvement by discovering that a higher learning rate with a smaller LoRA rank worked better for that particular configuration.</p>
<p>The skill encapsulates not just the mechanical steps but the judgment calls: reasonable search spaces for different model sizes, pruning strategies that don’t waste compute on obviously bad trials, budget tracking that stops before you bankrupt yourself on cloud GPUs. None of this required building elaborate MCP integrations. Claude wrote Python scripts, executed them, parsed the results, and iterated. The primitive tools were sufficient.</p>
<p>And this pattern generalises far beyond ML training. Playwright testing? Same idea: Claude can orchestrate browser automation, validate that pages render correctly, generate test reports. Data pipeline validation? Configuration management? Any task that requires intelligence but follows repeatable patterns is a candidate for dorkestration.</p>
</section>
<section id="the-human-in-the-loop" class="level2">
<h2 class="anchored" data-anchor-id="the-human-in-the-loop">The human in the loop</h2>
<p>I should be clear about what dorkestration is <em>not</em>. It is not autonomous ML research. It is not a replacement for understanding what you’re doing. It is very definitely not a way to fine-tune models if you have no idea why you’re fine-tuning them or what success looks like.</p>
<p>What it is is a way to eliminate the bureaucratic overhead that sits between “I know what I want to do” and “the thing is actually happening.” It assumes you have the domain knowledge to specify the task, evaluate the results and make decisions about next steps.</p>
<p>This is, I think, the correct way to think about coding agents more generally. They’re not replacing humans, but the tedious parts of being human: the parts where you’re not thinking creatively or making important decisions, but rather remembering syntax and copying file paths and checking that the bloody GPU hasn’t run out of memory.</p>
<p>In the nomenclator analogy: the great man still has to decide whom to speak with and what to say. The nomenclator just whispers the names.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Practical notes
</div>
</div>
<div class="callout-body-container callout-body">
<p>A few things I’ve learned from several months of using this approach:</p>
<p><strong>Start with Unsloth for simplicity.</strong> Axolotl is more powerful but has more moving parts. When you’re debugging your skill rather than your model, simplicity wins. Once the workflow is solid, add complexity.</p>
<p><strong>The WandB MCP integration is crucial.</strong> Without it, you’re just launching jobs into the void. With it, Claude can actually tell you how things are going, suggest early stopping, compare runs. For HF Jobs specifically, the built-in logging handles this, but for local or other cloud setups, WandB is the glue.</p>
<p><strong>Sensible defaults beat flexibility.</strong> The temptation is to expose every possible parameter. Resist it. A good skill should work 80% of the time with zero configuration. The other 20% is what natural language is for.</p>
<p><strong>Test the failure modes.</strong> What happens when the data is malformed? When CUDA isn’t available? When the model doesn’t fit in memory? A good skill handles these gracefully, with informative error messages and suggested remedies.</p>
<p><strong>Keep the skill updated.</strong> Libraries change. New best practices emerge. The skill is a living document, not a one-time configuration.</p>
<p>If you want to try the HPO workflow yourself, I’ve written up <a href="https://huggingface.co/blog/chrisvoncsefalvay/claude-hf-jobs-optuna">detailed instructions on Hugging Face</a>. The short version: install the skill, export your HF token, and ask Claude to optimise your model. Be specific about budget, search space and hardware. The skill handles the rest.</p>
<p>For teams rather than individuals, the <a href="https://huggingface.co/blog/sionic-ai/claude-code-skills-training">Sionic AI post on Claude Code skills</a> explores how to build a shared knowledge registry: their <code>/advise</code> and <code>/retrospective</code> commands let researchers capture experimental learnings so the next person doesn’t repeat the same mistakes. It’s the team-scale version of what I’m describing here.</p>
</div>
</div>
</section>
<section id="the-broader-picture" class="level2">
<h2 class="anchored" data-anchor-id="the-broader-picture">The broader picture</h2>
<p>If this seems like a minor optimisation, consider the cumulative effect. Every time I need to fine-tune a model, I save perhaps an hour of fiddling with configuration files and debugging environment issues. Over a year, that’s several weeks of reclaimed time. Weeks that I can spend on the parts of the work that actually require human judgment: designing experiments, interpreting results, deciding what to try next.</p>
<p>But there’s something more fundamental here than time savings. What dorkestration reveals is the true nature of tool use in agentic systems.</p>
<p>When the discourse around MCP and tool calling first emerged, the implicit assumption was that we needed to build an elaborate ecosystem of specialised tools. Every API would need its wrapper. Every service would need its integration. The path to capable agents was through comprehensiveness: more tools, more capabilities, more coverage.</p>
<p>This was, I think, a category error. It confused the map for the territory.</p>
<p>The real insight is that a small set of compositional primitives – read, write, execute – is sufficient for any computable task. Claude Code doesn’t need a thousand MCP servers. It needs the ability to <em>make</em> whatever tool is required for the task at hand, use it, and then let it dissolve. The tools are ephemeral. The capability is permanent.</p>
<p>This is, I suspect, the actual future of agentic AI in practice. Not autonomous systems that replace human decision-making, but intelligent assistants that handle the mechanical substrate on which human decisions operate. Not conductors that lead the orchestra, but stage managers who ensure the musicians have stands and the lights are working. Not elaborate toolboxes but universal fabricators.</p>
<p>The nomenclator didn’t make Cicero a better orator. But he did allow Cicero to focus on oratory rather than memorising the names of every client who wandered into the Forum. And perhaps that’s enough. Perhaps the great contribution of agentic AI won’t be replacing human intelligence, but liberating it from the bureaucratic overhead that has always been the tax we pay for getting things done.</p>
<p>In the meantime, my model is training, WandB is logging, and I’m writing this instead of checking whether <code>torch.cuda.is_available()</code> returns <code>True</code>. The nomenclator is whispering the names. I’m free to think about what to say.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {Dorkestration},
  date = {2025-12-15},
  url = {https://chrisvoncsefalvay.com/posts/dorkestration/},
  doi = {10.59350/ddcq4-4na09},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“Dorkestration.”</span> <a href="https://doi.org/10.59350/ddcq4-4na09">https://doi.org/10.59350/ddcq4-4na09</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>agentic AI</category>
  <category>LLMs</category>
  <category>fine-tuning</category>
  <guid>https://chrisvoncsefalvay.com/posts/dorkestration/</guid>
  <pubDate>Mon, 15 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/dorkestration/header.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>The Hype, the Slop and the Craft</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/hype-slop-craft/</link>
  <description><![CDATA[ 




<section id="hype-slop-craft-the-evolutionary-ecology-of-ai" class="level1 page-columns page-full">
<h1>Hype, slop, craft: the evolutionary ecology of AI</h1>
<p>There’s a patch of ground near Chernobyl that botanists call Рудий ліс, the Red Forest. In the immediate aftermath of the 1986 disaster,<sup>1</sup> the radiation killed mostly everything, turning the pine trees a rust-red colour before they died. That’s poetic, but hardly unexpected – not even Polesian pines can withstand a firehose of low enriched uranium decay products. What happened next, though, was instructive: the first plants to return weren’t the mighty pines or the hardy oaks, but the weeds. Dandelions, mostly, and some rather aggressive species of grass. They grew quickly, flowered fast, scattered their seeds and died, leaving behind just enough organic matter for the next wave. Within a decade, saplings had started to appear. Within two, you had something approximating a young forest.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;The one at Chornobyl, not my birth. Which happens to fall on the same year.</p></div><div id="ref-grime1977" class="csl-entry">
Grime, J. Philip. 1977. <span>‘Evidence for the Existence of Three Primary Strategies in Plants and Its Relevance to Ecological and Evolutionary Theory’</span>. <em>The American Naturalist</em> 111 (982): 1169–94. <a href="https://doi.org/10.1086/283244">https://doi.org/10.1086/283244</a>.
</div></div><p>The ecologists studying this accidental laboratory weren’t surprised. They were watching a well-documented pattern called primary succession, where life reclaims disturbed ground through a predictable sequence of strategies. What they observed in the Red Forest plays out everywhere, from volcanic islands to abandoned car parks, and follows a model first articulated by Philip Grime in 1977: the Universal Adaptive Strategy Theory <span class="citation" data-cites="grime1977">(Grime 1977)</span>.</p>
<p>I’ve been thinking about Grime’s framework rather a lot lately, because it explains something about the AI industry that the irritatingly prevalent narratives of “good labs” versus “bad labs” utterly fails to capture: namely, that the AI landscape isn’t a morality play. It’s an ecosystem, and like all ecosystems, it requires diversity of strategy to thrive.</p>
<section id="the-triangle-of-strategies" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-triangle-of-strategies">The triangle of strategies</h2>
<p>Grime’s insight was deceptively simple. Plants face two primary challenges: stress (limitations on productivity, like poor soil or drought) and disturbance (destruction of biomass, like fire or trampling, or at least destruction of the patterns in which they exist). Their evolutionary strategies reflect different adaptations to these forces, forming three broad categories that he called R, C and S.</p>
<ul>
<li><strong>Ruderal strategists</strong> (R) thrive in high-disturbance environments. They grow fast, reproduce quickly and spread like mad before the next catastrophe hits. Think dandelions, annual weeds, those aggressive grasses that colonise disturbed ground. They’re opportunists, exploiting chaos. They don’t build to last because lasting isn’t the point – the point is to spread before someone else does. Speed wins.</li>
<li><strong>Competitive strategists</strong> (C) dominate through sheer volume and resource acquisition. They grow in environments where disturbance is low and stress is manageable, and they win by outcompeting neighbours for light, water, nutrients. Think bamboo forests, or those vine species that carpet entire hillsides. Volume is victory.</li>
<li><strong>Stress-tolerant strategists</strong> (S) excel in stable but harsh environments. They grow slowly, carefully, building resilience rather than racing for dominance. Think bristlecone pines that live thousands of years at high altitude, or the succulents that thrive in deserts. They’re not flashy. They’re not fast. But they endure. And endurance is the ultimate superweapon.</li>
</ul>
<p>Here’s what matters: none of these strategies is “better” than the others. Each is optimal for its niche. The healthiest ecosystems contain all three, each playing their role in the larger dance of succession and stability. Equally, they depend on different influences and explot different circumstances, and are generally rather maladapted to their absence.<sup>2</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;There’s a social analogy here. We call ruderal humans <em>innovators</em>. And thank heavens for them.</p></div></div><div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb1" data-startfrom="35" data-source-offset="-1" style="background: #f1f3f5;"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 34;"><span id="cb1-35">d3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">require</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d3@7"</span>)</span>
<span id="cb1-36">ternary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">require</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d3-ternary@3"</span>)</span>
<span id="cb1-37"></span>
<span id="cb1-38">labData <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-39">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Cluely"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hype"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"product"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-40">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Lovable"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.20</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"slop"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"product"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-41">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Anthropic"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.80</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"craft"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"major"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-42">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OpenAI"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.30</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mixed"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"major"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"xAI"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.70</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hype"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"major"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-43">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FAIR"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.20</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"craft"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"foundation"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-44">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DeepMind"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.40</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"craft"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"foundation"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-45">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FaceApp"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"slop"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"product"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-46">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SpicyChat"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"slop"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"product"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-47">  { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">name</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">r</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">c</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"slop"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"product"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-48">]</span>
<span id="cb1-49"></span>
<span id="cb1-50">colours <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ({</span>
<span id="cb1-51">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">hype</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#e63946"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-52">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">slop</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#457b9d"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-53">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">craft</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#2a9d8f"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-54">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">mixed</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#6c757d"</span></span>
<span id="cb1-55">})</span>
<span id="cb1-56"></span>
<span id="cb1-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Shape generators for different nature types</span></span>
<span id="cb1-58">shapeGen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ({</span>
<span id="cb1-59">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">foundation</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">symbol</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span>(d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">symbolCircle</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">size</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-60">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">major</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">symbol</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span>(d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">symbolSquare</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">size</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">180</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-61">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">product</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">symbol</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span>(d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">symbolTriangle</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">size</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>)</span>
<span id="cb1-62">})</span>
<span id="cb1-63"></span>
<span id="cb1-64">width <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">550</span></span>
<span id="cb1-65">height <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">480</span></span>
<span id="cb1-66">radius <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">160</span></span>
<span id="cb1-67"></span>
<span id="cb1-68">bary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ternary<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">barycentric</span>()</span>
<span id="cb1-69">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">a</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">r</span>)</span>
<span id="cb1-70">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">b</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">c</span>)</span>
<span id="cb1-71">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">s</span>)</span>
<span id="cb1-72"></span>
<span id="cb1-73">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ternary<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ternaryPlot</span>(bary)</span>
<span id="cb1-74">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">radius</span>(radius)</span>
<span id="cb1-75">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labels</span>([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>])</span>
<span id="cb1-76"></span>
<span id="cb1-77">chart <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb1-78">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> svg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">create</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"svg"</span>)</span>
<span id="cb1-79">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"viewBox"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> height])</span>
<span id="cb1-80">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"width"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> width)</span>
<span id="cb1-81">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"height"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> height)</span>
<span id="cb1-82">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">style</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-family"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system-ui, -apple-system, sans-serif"</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-83"></span>
<span id="cb1-84">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-85"></span>
<span id="cb1-86">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Draw the triangle</span></span>
<span id="cb1-87">  g<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>)</span>
<span id="cb1-88">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">triangle</span>())</span>
<span id="cb1-89">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#f8f9fa"</span>)</span>
<span id="cb1-90">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stroke"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#343a40"</span>)</span>
<span id="cb1-91">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stroke-width"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-92"></span>
<span id="cb1-93">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Draw grid lines</span></span>
<span id="cb1-94">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> gridLines <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gridLines</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-95">  gridLines<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">forEach</span>(axisLines <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> {</span>
<span id="cb1-96">    g<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">selectAll</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">null</span>)</span>
<span id="cb1-97">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(axisLines)</span>
<span id="cb1-98">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">join</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>)</span>
<span id="cb1-99">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">line</span>()(d))</span>
<span id="cb1-100">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"none"</span>)</span>
<span id="cb1-101">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stroke"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#dee2e6"</span>)</span>
<span id="cb1-102">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stroke-width"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-103">  })<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-104"></span>
<span id="cb1-105">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Draw data points with shapes based on nature</span></span>
<span id="cb1-106">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">selectAll</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".point"</span>)</span>
<span id="cb1-107">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(labData)</span>
<span id="cb1-108">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">join</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>)</span>
<span id="cb1-109">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"class"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"point"</span>)</span>
<span id="cb1-110">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transform"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> {</span>
<span id="cb1-111">      <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> [x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> y] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(d)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-112">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`translate(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">)`</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-113">    })<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-114"></span>
<span id="cb1-115">  points<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>)</span>
<span id="cb1-116">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> shapeGen[d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nature</span>]())</span>
<span id="cb1-117">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> colours[d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type</span>])</span>
<span id="cb1-118">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stroke"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#fff"</span>)</span>
<span id="cb1-119">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stroke-width"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-120">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"opacity"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-121"></span>
<span id="cb1-122">  points<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb1-123">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-124">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb1-125">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-size"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"10px"</span>)</span>
<span id="cb1-126">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#343a40"</span>)</span>
<span id="cb1-127">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">text</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-128"></span>
<span id="cb1-129">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Compute vertices for corner labels</span></span>
<span id="cb1-130">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> vertices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-131">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>radius]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-132">    [radius <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">PI</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> radius <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">PI</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-133">    [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>radius <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">PI</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> radius <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">PI</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)]</span>
<span id="cb1-134">  ]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-135"></span>
<span id="cb1-136">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> cornerLabels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-137">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">pos</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> vertices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hype"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">offset</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>] }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-138">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">pos</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> vertices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Slop"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">offset</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>] }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-139">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">pos</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> vertices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Craft"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">offset</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>] }</span>
<span id="cb1-140">  ]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-141"></span>
<span id="cb1-142">  g<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">selectAll</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".corner-label"</span>)</span>
<span id="cb1-143">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(cornerLabels)</span>
<span id="cb1-144">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">join</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb1-145">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"class"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"corner-label"</span>)</span>
<span id="cb1-146">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pos</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">offset</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb1-147">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pos</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">offset</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb1-148">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-anchor"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"middle"</span>)</span>
<span id="cb1-149">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-size"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"11px"</span>)</span>
<span id="cb1-150">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-style"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"italic"</span>)</span>
<span id="cb1-151">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#6c757d"</span>)</span>
<span id="cb1-152">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">text</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-153"></span>
<span id="cb1-154">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Horizontal legend - Strategy (colours)</span></span>
<span id="cb1-155">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> strategyLegend <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-156">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hype"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hype"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-157">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"slop"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Slop"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-158">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"craft"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Craft"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-159">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mixed"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Mixed"</span> }</span>
<span id="cb1-160">  ]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-161"></span>
<span id="cb1-162">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> legendY <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">55</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-163">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> strategyG <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>)</span>
<span id="cb1-164">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transform"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`translate(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>legendY<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">)`</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-165"></span>
<span id="cb1-166">  strategyG<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb1-167">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-168">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-169">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-size"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"10px"</span>)</span>
<span id="cb1-170">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-weight"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"600"</span>)</span>
<span id="cb1-171">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#495057"</span>)</span>
<span id="cb1-172">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">text</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Strategy:"</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-173"></span>
<span id="cb1-174">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> stratItems <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> strategyG<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">selectAll</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".strat-item"</span>)</span>
<span id="cb1-175">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(strategyLegend)</span>
<span id="cb1-176">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">join</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>)</span>
<span id="cb1-177">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"class"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"strat-item"</span>)</span>
<span id="cb1-178">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transform"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> (d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> i) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`translate(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">55</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">65</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">, -4)`</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-179"></span>
<span id="cb1-180">  stratItems<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"circle"</span>)</span>
<span id="cb1-181">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb1-182">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> colours[d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-183"></span>
<span id="cb1-184">  stratItems<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb1-185">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb1-186">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb1-187">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-size"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"10px"</span>)</span>
<span id="cb1-188">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#343a40"</span>)</span>
<span id="cb1-189">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">text</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-190"></span>
<span id="cb1-191">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Horizontal legend - Nature (shapes)</span></span>
<span id="cb1-192">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> natureLegend <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-193">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"foundation"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Foundation labs"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-194">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"major"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model majors"</span> }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-195">    { <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">nature</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"product"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Product firms"</span> }</span>
<span id="cb1-196">  ]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-197"></span>
<span id="cb1-198">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> natureG <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>)</span>
<span id="cb1-199">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transform"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`translate(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>legendY <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">)`</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-200"></span>
<span id="cb1-201">  natureG<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb1-202">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-203">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-204">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-size"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"10px"</span>)</span>
<span id="cb1-205">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-weight"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"600"</span>)</span>
<span id="cb1-206">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#495057"</span>)</span>
<span id="cb1-207">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">text</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Nature:"</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-208"></span>
<span id="cb1-209">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> natureItems <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> natureG<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">selectAll</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".nature-item"</span>)</span>
<span id="cb1-210">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(natureLegend)</span>
<span id="cb1-211">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">join</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"g"</span>)</span>
<span id="cb1-212">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"class"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nature-item"</span>)</span>
<span id="cb1-213">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transform"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> (d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> i) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`translate(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">55</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">110</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">, -4)`</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-214"></span>
<span id="cb1-215">  natureItems<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>)</span>
<span id="cb1-216">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">symbol</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span>(</span>
<span id="cb1-217">      d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nature</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"foundation"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">symbolCircle</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb1-218">      d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nature</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"major"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">symbolSquare</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> d3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">symbolTriangle</span></span>
<span id="cb1-219">    )<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">size</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>)())</span>
<span id="cb1-220">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#6c757d"</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-221"></span>
<span id="cb1-222">  natureItems<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">append</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb1-223">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb1-224">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb1-225">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"font-size"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"10px"</span>)</span>
<span id="cb1-226">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">attr</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#343a40"</span>)</span>
<span id="cb1-227">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">text</span>(d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-228"></span>
<span id="cb1-229">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> svg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">node</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-230">}</span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-6" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-7" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-8" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-9" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-10" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-11" data-nodetype="declaration">

</div>
</div>
</div>
</div>
</section>
<section id="the-ai-ecology-and-its-malcontents" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-ai-ecology-and-its-malcontents">The AI ecology and its malcontents</h2>
<p>I think it’s clear that Grime’s theory applies to much more than shrubs in high desert plateaus. We see the current AI industry, once we mature past the nonsensical obsession with turning it into a battle between good and evil, recapitulate much of it. And when we do, the terminology that’s already emerged – hype, slop, craft – maps rather neatly onto R, C and S strategies.</p>
<ul>
<li><p><strong>Hype labs are ruderals.</strong> They thrive on chaos, often chaos they create themselves. They move fast, ship quickly, pivot aggressively. They’re excellent at identifying what deserves disruption, at spotting the cracks in established systems where fast growth is possible. When a new capability emerges, they’re first to market. When a paradigm shifts, they’ve already shifted with it. They don’t build cathedrals; they build beach huts and move on before the tide comes in. <em>Cluely</em> is my favourite example here – the startup that somehow convinced itself and half the internet that what we really needed was AI to cheat more efficiently at job interviews. They thrive precisely because they can spot the disturbed ground before anyone else, throw seeds everywhere and see what grows. Are they building for the long term? No.&nbsp;Are they building for tomorrow? Absolutely. And in a fast-moving field like AI, being first often matters more than being best.<sup>3</sup></p></li>
<li><p><strong>Slop labs are competitive strategists.</strong> They win through volume. They flood the market with models, with wrappers, with fine-tunes and adaptations and variations on themes. They’re not necessarily making the best AI – but they sure are making the most AI, and that matters more than craft purists<sup>4</sup> want to admit. In ecology, competitive strategists don’t win because they’re elegant—they win because they’re everywhere. Consider the explosion of ChatGPT wrappers in 2023, or the current proliferation of “AI-powered” everything. Is much of it derivative? Sure. Is some of it genuinely terrible? Absolutely. But volume dominance is a legitimate strategy. In markets with low barriers to entry and unclear winners, being everywhere means you’re there when someone needs you. The competitive strategy isn’t about excellence but accessibility and ubiquity.</p></li>
<li><p><strong>Craft labs are stress-tolerant.</strong> They tackle genuinely hard problems with deliberate slowness. They build for resilience rather than scale, for depth rather than breadth. They’re Anthropic with their slow, slogging but relentless march through the institutions, or <a href="https://edisonscientific.com/">Edison Scientific</a> building an actually useful scientific research tool. They grow slowly because they’re growing in hostile territory – territory where the problems are so hard that speed would be fatal. Just ask the dozens of labs that have tried their hand at ‘AI co-scientists’ or even AI for scientific research, and produced <a href="../../posts/academic-generative-ai/index.html">mostly underwhelming results</a>. I also consider <a href="https://thinkingmachines.ai/">Thinking Machines</a> to be in this camp, along with <a href="https://ssi.inc">Safe Superintelligence</a>, but it’s hard to be too sure about them given how little they have actually released publicly. I wouldn’t be surprised to see them adopt a more balanced strategy – I would be surprised to see them move any significant degree towards hype or slop.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;In fact, they themselves aren’t exactly naive about this. <a href="https://techcrunch.com/2025/11/05/cluelys-roy-lee-hints-that-viral-hype-is-not-enough/">Roy Lee, their CEO, has openly admitted that the hype fuel is running out</a>, and something sensible needs to be pivoted to.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;And I am considering myself one for the most part!</p></div></div><p>I am, of course, biased towards craft. I work at a very firmly craft-aligned outfit, and craft has something that others do not: longevity. They are, for better or worse, the DNA of this field. The things that will become long term legacies will mostly come from them, and that’s why it’s important that they balance commitment to their principles with an open mind.</p>
<p>Which is why we need to understand why they can feel like unambitious underdogs or hopeless obsessives that are about to be outpaced by what we intuitively perceive as more brash but less deserving (hype) or more opportunistic but less principled (slop).</p>
</section>
<section id="why-craft-feels-like-its-losing" class="level2">
<h2 class="anchored" data-anchor-id="why-craft-feels-like-its-losing">Why craft feels like it’s losing</h2>
<p>In a sense, craft has never been popular – not in AI, not in any other field. The stonemasons who crafted the intricate facade of the cathedral at Chartres had to contend with those who would gladly have gotten it done a little less exquisite if it could just cost a little less, or those who would altogether have preferred it to have been a little more flashy, even if it had been made of softer stone that couldn’t withstand the weather. There’s a significant moral overtone to all of this, a sense that serious, thoughtful work on alignment and safety and interpretability is being steamrollered by companies racing to ship whatever generates the most engagement.</p>
<p>This isn’t wrong, exactly. But it mistakes ecological dynamics for moral failure.</p>
<p>Stress-tolerant species don’t dominate during boom times, they dominate during sustained stress. Right now, we’re in what ecologists would call a “resource-rich, low-stress” environment: compute is expensive but available, talent is scarce but findable, the regulatory environment – for all the hand-wringing – remains permissive, and capital is flowing if you know where to look. These are conditions that favour ruderal and competitive strategies, not stress tolerance.</p>
<p>Craft labs are building for a different future: one where reliability matters more than novelty, where safety becomes non-negotiable, where the easy wins have been exhausted and only genuinely hard problems remain. They’re the bristlecone pines, building slowly at altitude while the weeds race across the valley floor below. If AI development remains a gold rush where shipping fast beats building right, ruderals win, confirming the perception that sees craft labs as fundamentally anachronistic (just not quite sure about the direction of that anachronism). If it becomes a mature industry where reliability and robustness are prerequisites for deployment, stress-tolerant strategies will prevail.</p>
</section>
<section id="the-necessity-of-synthesis" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-necessity-of-synthesis">The necessity of synthesis</h2>
<p>Here’s where this gets interesting. Grime’s framework is intended to be predictive. It doesn’t favour either strategy: but it does acknowledge a healthy ecosystem needs all three strategies because they create the conditions for each other’s success. Ruderals identify and exploit new opportunities, creating the disturbance that opens space for others. The hype labs aren’t useless noise; they’re advance scouts mapping terrain, testing hypotheses through market feedback that more cautious organisations couldn’t justify. When a hype lab pivots from blockchain to AI to quantum computing to whatever’s next, they’re not being flighty – they’re being adaptive in the way only ruderals can be.</p>
<p>Competitive strategists, in turn, consolidate gains through volume and presence. The slop labs are diluting quality, but they are also creating the market liquidity that makes AI ubiquitous enough to matter. Most ChatGPT wrappers add little value, but their collective presence makes AI feel inevitable, accessible, normal. That normalisation is what lets craft labs secure funding for decade-long research programmes.</p>
<p>Stress-tolerant strategists preserve gains and tackle genuinely hard problems. The craft labs aren’t being precious, they’re necessary. Someone has to do the work that can’t be rushed, can’t be parallelised across a thousand startups, can’t be solved by throwing more compute at it or requires long-term persistence. Constitutional AI, mechanistic interpretability, passing the emergent best practices on so we don’t have to be in some sort of permanent, exaptive adolescence require the kind of sustained, serious effort that only stress-tolerant organisations can muster.</p>
<p>The synthesis, then, is this: craft labs need to learn from ruderals and competitors, but not by abandoning craft. They need to recognise when speed matters, when presence matters, when being first beats being best. But they also need to hold firm on the problems that require their unique strengths – and trust their principles enough that they can the environment will eventually favour them.</p>

<div class="no-row-height column-margin column-container"><div class="">
<hr>
<p><strong>Recipe</strong>: Slow roasted tomatoes</p>
<ul>
<li>2kg ripe tomatoes, halved</li>
<li>100ml decent olive oil – this isn’t the project to throw your <img src="https://latex.codecogs.com/png.latex?%5Clambda"> on, but don’t use the cheapest either</li>
<li>6 cloves garlic, sliced</li>
<li>Fresh thyme</li>
<li>Sea salt</li>
<li>Black pepper</li>
</ul>
<p>Arrange tomatoes, cut side up, on baking sheets. Drizzle with oil, scatter garlic and thyme. Season generously. Roast at 120°C for 3-4 hours until concentrated and slightly caramelised. The point isn’t speed but transformation through sustained, gentle stress (bit thick of an analogy here?). Store in oil. They’ll last.</p>
<hr>
</div></div></section>
<section id="after-the-fire" class="level2">
<h2 class="anchored" data-anchor-id="after-the-fire">After the fire</h2>
<p>So, what happens next? If Grime’s framework holds – and I think it does –, we should expect the AI ecosystem to undergo succession patterns familiar from ecology. Early stage ecosystems favour ruderal strategies. We’ve seen this: the Cambrian explosion of AI startups, the rapid cycling of approaches, the constant churn of new capabilities. This phase rewards speed and adaptability over robustness. Then the party ends, music slows, resources become more constrained, and competitive strategies gain ground. This is where we are right now, which to the sufficiently shallow part of the analyst class appears like a ‘bubble’. Companies that can achieve volume at scale, be present across markets and use cases, manage to outproduce rather than necessarily outinnovate, are ascendant.</p>
<p>But mature ecosystems, particularly those under sustained stress, favour stress tolerance. And the stresses are coming, or at least some of them: regulatory pressure, liability questions, the need for genuine reliability in critical applications, the exhaustion of low-hanging fruit. They’ve always been ‘the’ main issue, we just bought some time to defer consideration until we have figured out how far we can stretch with the ‘run fast and break things’ approach. Once those stresses become sustained, beyond the ability of rapidly competitive players to do cowboy stuff and remain operational, craft strategies will dominate.</p>
<p>The cleverest organisations will deploy mixed strategies. They’ll run ruderal experiments while maintaining competitive presence while building stress-tolerant core capabilities. They’ll know when to be the dandelion and when to be the pine.</p>
</section>
<section id="coda-beyond-the-morality-play" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="coda-beyond-the-morality-play">Coda: beyond the morality play</h2>
<p>I started thinking about this framework because I was tired of the discourse that treats AI development as a morality play where craft labs are noble and everyone else is either reckless or parasitic. That narrative is not just wrong – it’s counterproductive. It fosters a neglect of those exaptive strategies that hype labs master, those rapid scaling volume strategies that slop labs exploit, leaving craft labs isolated, defensive and, ultimately, broke.</p>
<p>Hype isn’t inherently bad. It’s ruderal strategy, excellent at what it does: identifying opportunities, moving fast, exploiting disturbance. Slop isn’t inherently lazy. It’s competitive strategy, winning through presence and volume. Craft isn’t inherently superior. It’s stress-tolerant strategy, building for conditions that may not obtain.</p>
<p>What matters is recognising that healthy ecosystems require all three. The AI field needs organisations pursuing each strategy because they create the conditions for each other’s success. Ruderals open new spaces. Competitors consolidate gains. Stress-tolerant players build lasting value.</p>
<p>We’re not in a battle between good labs and bad labs.<sup>5</sup> We’re in an ecosystem undergoing succession, and the wisest response is to understand which strategy each niche requires – and to respect that all three have their place in the forest we’re growing.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;There absolutely are downright bad and sometimes fraudulent entities in AI. I won’t dignify them by calling them labs. At the same time, there are phenomena on the edge, and I may not agree with what they’re doing, but I will not deny that they may have an ecosystemic role. A case in point is <a href="https://www.cladlabs.ai/">Chad IDE</a> – I agree with <a href="https://tbpn.substack.com/i/178712299/run-of-show-rage-baiting-is-for-losers">Jordi</a> that ‘rage baiting is for losers’, but there’s a lot of space between silly and fraudulent.</p></div></div><p>The Red Forest today is neither weeds nor climax forest but something in between, a dynamic equilibrium of strategies coexisting in productive tension. Perhaps that’s what mature AI will look like too: not the victory of any single approach but the synthesis of all three, each doing what it does best, creating together something none could achieve alone.</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The {Hype,} the {Slop} and the {Craft}},
  date = {2025-11-23},
  url = {https://chrisvoncsefalvay.com/posts/hype-slop-craft/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“The Hype, the Slop and the
Craft.”</span> <a href="https://chrisvoncsefalvay.com/posts/hype-slop-craft/">https://chrisvoncsefalvay.com/posts/hype-slop-craft/</a>.
</div></div></section></div> ]]></description>
  <category>LLMs</category>
  <category>AI</category>
  <category>tech predictions</category>
  <category>ecology</category>
  <guid>https://chrisvoncsefalvay.com/posts/hype-slop-craft/</guid>
  <pubDate>Sun, 23 Nov 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/hype-slop-craft/header.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>What I talk about when I talk about agentic AI</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/two-years-of-agents/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Originally written on 01 November 2025, this post was <a href="https://github.com/chrisvoncsefalvay/chrisvoncsefalvay.github.io/commit/c73cea4d251c09168fff001f3cd10148b3a85d96">published on 09 November 2025</a> to comply with pre-publication review.</p>
</div>
</div>
<p>The Latin verb <em>agere</em> means “to do, to act, to drive forward”. From it we get not only “agent” but also “action”, “actor”, and curiously enough, “agile”. The Romans understood what we seem to have forgotten: that agency is fundamentally about motion, about transformation, about the capacity to change the world. I’ve been thinking about this a lot lately as I mark roughly two years since I sat in a Berkeley coffee shop, overcaffeinated and sleep-deprived, trying to articulate what would come after chatbots. It was late October 2023, my book on computational epidemiology – with a whole chapter devoted to agents<sup>1</sup> – had been published earlier that year, and I was looking at an unfolding crisis as the initial hype around language models began to fade and the bandaid patch of <a href="../../posts/prompt-engineering/index.html">prompt engineering</a> quickly showed it wasn’t going anywhere. Earlier that year, I spent a blissful few days driving across the country with Oliver, my golden retriever, moving ourselves from Northern Virginia to Denver, and in order to procrastinate away having to unpack boxes, I went on to devote most of the summer to injecting LLMs into agent-based simulations of public health. The connection seemed obvious: these models needed the same kind of connectionistic compositionality that made agent-based models and neural networks powerful – big structures of relatively trivial parts rather than desperate chases after ever-larger monoliths – and they needed to encounter the world, to learn from interaction the way a child learns from play.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;My editor will kill me, but I have to admit: I <em>do</em> have a favourite chapter, and it <em>is</em> the one about agents. In no other place do you get Dwarf Fortress and STDs within a few pages of each other.</p></div><div id="ref-Yao2022ReAct" class="csl-entry">
Yao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. <span>‘ReAct: Synergizing Reasoning and Acting in Language Models’</span>. <em>arXiv Preprint arXiv:2210.03629</em>. <a href="https://doi.org/10.48550/arXiv.2210.03629">https://doi.org/10.48550/arXiv.2210.03629</a>.
</div><div id="ref-Wei2022ChainOfThought" class="csl-entry">
Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022. <span>‘Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’</span>. <a href="https://doi.org/10.48550/arXiv.2201.11903">https://doi.org/10.48550/arXiv.2201.11903</a>.
</div><div id="fn2"><p><sup>2</sup>&nbsp;One day, the lot of us need to have dinner and/or a Highlander style battle.</p></div></div><p>The idea that language models could <em>do</em> things was, in those late days of 2023, still relatively novel. Tool use was of course more or less established, but far from mainstream, where the focus was on <a href="../../posts/prompt-engineering/index.html">coaxing the right words out of LLMs</a>. A key step was Shunyu Yao’s brilliant ReAct paper <span class="citation" data-cites="Yao2022ReAct">(Yao et al. 2023)</span>, which presented the first proper reconciliation of action and language generation. This put his work beyond other papers that primarily focused on ways of prompting, such as <span class="citation" data-cites="Wei2022ChainOfThought">Wei et al. (2022)</span> on Chain of Thought prompting, even though the latter did lay the groundwork for task decomposition, a key feature of agentic AI. <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">Lilian Weng</a>’s blog is perhaps the first proper early summary of what an agent properly so called would comprise, and I think that when the history of all of this is written someday, it will show she fully deserves to be considered one of the parents of the agentic idea. Finally, <a href="https://blog.langchain.com/agents-round/">Harrison Chase</a>’s post and <a href="../../posts/team-of-rivals/index.html">mine</a> were among the earliest on conceptualising the kind of more expansive notion of agents that I think are the proper domain of the subject.<sup>2</sup></p>
<p>This idea was picked up by an incredible community of builders, hackers, developers and popularisers, who took and turned it into the global phenomenon it has become. Companies are deploying agent orchestration platforms, VCs are writing nine-figure cheques for “agentic” startups and every consultancy worth its salt now has an agentic AI practice. Agentic AI has also come at the right time to save us from the spectre of an AI winter as moats around simple LLM wrappers were collapsing and prompt engineering came up short. It changed the tone of the discourse that once dismissed LLMs as stochastic parrots,<sup>3</sup> and the birth of agentic multimodality has enhanced that. In just a year, it’s become a household name and a boardroom buzzword. In short, agentic AI has been wildly successful.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;“Call me when your parrot can buy plane tickets”, I once quipped on a call. A friend turned this into a t-shirt I wear with pride to this day.</p></div></div><p>And that raises the uncomfortable question I’ve been wrestling with: what if it had been <em>too</em> successful too fast? What if agentic AI has become a victim of its own success?</p>
<section id="the-trap-of-inchoacy" class="level2">
<h2 class="anchored" data-anchor-id="the-trap-of-inchoacy">The trap of inchoacy</h2>
<p>My fear is that the success of agentic AI has landed us in a local maximum we may not be able to easily escape. Agentic AI is such a powerful idea that even in its current, limited form, it is capable of generating incredible business value – enough to essentially underwrite the whole long thesis on AI as it stands. But paradoxically, we’ve fallen into what I call the trap of inchoacy: we’ve built systems good enough to be profitable, which prevents them from becoming what they could be.</p>
<p>When I first conceptualised agents, I hat I envisioned wasn’t an agent-centric approach of ‘boxes and arrows’, the comforting organisational chart but now supplemented with LLMs. Indeed, to me, that’s the worst of two worlds: all the risk of stochasticity with none of its benefits. Coming from epidemiological agent-based modeling, where we routinely have agents in the thousands up to millions, this view feels like we’re succumbing to the notion that because ‘agent’ is in the name, agents should be the protagonists of our story. To me, agentic AI has always been about large scale emergence and self-organisation. This isn’t a matter of degree but qualitatively different. If you can draw it on a whiteboard, it may well be useful, possibly make decent dinner reservations, but it will not ever exhibit meaningful emergence (if you don’t believe me, try to draw every neuron of a modern convolutional neural network). It may be useful, but it’s not what I mean when I talk about agentic AI.</p>
<p>We understand this principle everywhere else. Markets work through distributed decision-making, not central planning. Cities evolve through countless individual choices, not master blueprints. Ecosystems maintain stability through interaction, not instruction. Yet with AI agents, we insist on micromanaging the very tool we have created to escape having to do so.</p>
<p>I’m not chasing some validation of my preferred – more expansive – definition here, but rather a degree of sustainability. I worry that we’re getting too comfortable with what agents can do for us today in order to harness their potential tomorrow, and it will leave us without a harvest once the low-hanging fruit has all been picked – and no help will come the way agentic AI came to rescue LLMs from their early crisis like a gentle breeze reawakening a campfire about to go out, not unless we jolt ourselves out of this comfortable stagnation. There’s only so much you can automate away with n8n-style node builders and simple decisional flows over LLMs, which is what much of current early agentic AI is about. By the tim we run out of that runway, will we have created the intellectual and theoretical ammunition to reason about the complexities? More importantly: will we have developed the language?</p>
</section>
<section id="the-word-set-free" class="level2">
<h2 class="anchored" data-anchor-id="the-word-set-free">The word set free</h2>
<p>Much of what is wrong with the way we think about agentic AI is intrinsically connected to the way we speak about it. Wittgenstein wrote that the limits of one’s language were the limits of their world, and he was altogether correct. In that sense, I must accept some responsibility for my part in all that’s gone wrong, however unwitting. Agency is a loaded term – perhaps more so than most of us realised initially. I can’t speak for the others, but I remember what I meant the first time I used it. Agents as long-running bits of code that do some background function have been pretty well established since… well, the dawn of modernish computing. Agents in a philosophical sense, too, were on my mind. But I’m also a recovering lawyer, and even though it’s been about twenty years since I last practised, I can recite case law on agency when woken from sleep. A lot of things come with that word: delegation, responsibility, authority – notions that we need for the entire agentic project to work, and which we do not necessarily as yet have in place. My hope was that that terminological reference would import some of these.</p>
<p>In a life I have mostly lived without regrets, my use of this word has been the cause of some. If I could go back, I’d fervently argue for any other term we could come up with. I believe the word itself has been harmful on both a human and an intellectual level.</p>
<p>Most people of course conceive of agents as persons: real estate agents, customer service agents, airport ticketing agents. English being my fourth language or so, this wasn’t really at the forefront of my mind. For right or wrong, many of these jobs were already at a high risk of replacement by AI, and I wonder whether our early and enthusiastic adoption of this term might have created a subconscious bias towards such human agents being seen as fundamentally replaceable by AI. When <a href="https://www.cnbc.com/2025/09/02/salesforce-ceo-confirms-4000-layoffs-because-i-need-less-heads-with-ai.html">Salesforce cuts 4,000 customer service agents to replace them with AI</a> and companies from UPS to Amazon are laying off their human agents by the thousands, it is hard not to wonder how many redundancy notices one’s terminological slippage had helped justify, how much human pain it might have contributed to.</p>
<p>And it’s not buying us any semantic clarity, either. It’s ultimately an anthropomorphism that leads to exactly the kind of fundamental misunderstanding holding us back from embracing the scale and stochastic connectionism of agentic AI. By seeing them as ‘virtual employees’ (a truly harmful analogy if there ever was one), we’re painting little organisational charts in our heads – no wonder many of the current so-called agentic architectures resemble one, with a salutary 90 degree rotation to make it maybe a little less obvious. We are confining ourselves to our comfort zones of manageable complexity, clinging to the org chart formalism in hopes that it will help us navigate the volatility, uncertainty, confusion and ambiguity of the world we live in – and in the process, forfeiting our very best tool against it: the ability of a true non-deterministically designed agentic system to self-organise and adapt to problems. We’re micromanaging ourselves into the overwhelming complexity we set out to escape.</p>
</section>
<section id="the-widening-gyre" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-widening-gyre">The widening gyre</h2>
<p>What probably worries me more than any of this is the rapidly accelerating divide I am seeing that will fracture our society in ways we are barely beginning to understand. We do not have the vocabulary to reason about true agentic AI. Well-informed, experienced and smart leaders of major global companies are still only starting to get their heads around the profound underlying differences that such systems would entail, and the vast majority of their peers are much further behind. You cannot reason about frontier agentic AI in the language of SDLC, of deterministic governance and prescriptive processes. True frontier agentic AI is something no enterprise in the history of humanity has experienced to any appreciable degree. The top maybe 1% of leaders recognise that they need to fundamentally redraw their approach to doing business. The top 0.1% realise that that’s not going to be remotely enough – they’ll need to redraw their own way of thinking, and their organisation’s. You cannot treat agentic AI like a new, innovative technology: it is quite literally without a useful analogy from any point in history,<sup>4</sup> and – even with our valiant efforts – very few enterprises (and leaders) are at this stage equipped with the organisational and cognitive tools to reason about it, never mind harness it effectively. A good deal of my job is to create ans convey those tools, and help them navigate this new stormy sea. But even for such decision-makers – whom I collectively consider perhaps the most agile collection of minds bar none that I ever had the privilege to meet –, the conceptual chasm created by this new paradigm is significant.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;My favourite analogy for this is Star Wars aliens <em>vs.</em> Baxter’s Xeeleeverse. Star Wars aliens are all basically mostly humanoids, just weird-looking ones. The Xeeleeverse’s aliens aren’t even based on the same <em>physical</em> principles, never mind the same biological templates, as we are. The closest to something we understand are the Squeem, who are basically space squid. It only gets weirder from there. Qax are cluster organisms of hexagonal convection cells that need turbulence to survive. The main antagonists, the Photino Birds, are made of antimatter. The Xeelee aren’t really described. Even very new and disruptive technology like the internet was alien at best in the way Star Wars aliens are. Agentic AI is Xeeleeverse alien.</p></div></div><p>At some point a few hundred thousand years ago, a gene called FOXP2 underwent a mutation in our early ancestors. We don’t really understand what FOXP2 does. The simplistic explanation is that it has to do with language, the better explanation is that it’s a motor learning gene that is necessary for effective language acquisition. In either case, it has been one of the greatest and most rapid success stories of evolution, essentially sweeping away wild-type FOXP2 in what in evolutionary terms is a blink of an eye. The evolutionary edge that language ability and speech conferred on our ancestors was so vast that it essentially eliminated the non-speakers. Society, coordination, story, culture, law, lore, history – we owe almost all our organising principles, from the smallest scale of two hunters planning a way to encircle their prey to the largest scale of social coordinated communication like elections or participatory democracy, to our ability to communicate.</p>
<p>When this breaks down, we’re in trouble. When one of the dominant technologies of our age are not so much incomprehensible as defying description due to a lack of a vocabulary, we lose the ability to have anything resembling democratic discourse about the subject itself. There are maybe 2-300 people I’d consider ‘frontier thinkers’ on agents, and the discussion we’re having is drifting apart from the wider social discourse on the topic. Nobody has found a really good way to bridge this gap. History teaches us that this sort of stuff does not tend to end well.</p>
<p>Nowhere is this more evident than in popular commentary on the subject. For about three months now, we’ve been living in the ‘bubble bubble’: the ever-inflating mass of LinkedIn posts, Youtube videos and breathless articles proclaiming that the bubble is going to burst <em>any day now</em>. Much of it is premised on a superficial understanding of the technology.<sup>5</sup> I don’t think you need to be able to explain group-relative policy optimisation in order to have a solid opinion on the economics of AI, but maybe something more profound than pointing at circular financing then concluding AI is the next Enron/Theranos/Lehman Brothers is needed. You cannot understand data center investment policy without understanding the pipeline of products for inference, you cannot understand that pipeline unless you understand what new inference-specific hardware like the prefill optimised Vera Rubin CPX is, and you cannot understand that unless you actually understand transformer architectures and K,V caching. This is one of a thousand things that you need to have at least some grounding on in order to have the context to make sense of this phenomenon. And if you’re, say, Hank Green, bless his heart, you probably don’t. This is a niche subject and it’s okay not to have an opinion on it – while at the same time, it is of course something that has downstream effects that impact everyone in very human terms. You do need to know transformers in order to be able to reason about data centre spend-o-nomics, you don’t need to know any of it to see mass layoffs, rising inequality and the social consequences of technological disruption and comment on it from a human perspective.<sup>6</sup> Bad commentary even with the best of intentions only widens the divide.<sup>7</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;And this includes critcism made on what I think are unfair premises. Karpathy, in the now infamous Dwarkesh interview, mentioned browser use as one of the ways in which agents fall short. I see absolutely nothing necessarily agentic about computer use, or anything about copmuter use essential to agents. Computer use is a RL and visual learning challenge.</p></div><div id="fn6"><p><sup>6</sup>&nbsp;This is a good time to give <a href="https://caspar.bgsu.edu/~courses/4510/Classes/48A078B0-8402-4995-9161-A2C418612C75_files/Gould_97.pdf">Stephen Jay Gould’s non-overlapping magisteria</a> a shout-out.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;The other side is not much better. Panic-mongering about superintelligence, about AI destroying the world, about existential risks from systems that still can’t reliably count the letters in “strawberry”.</p></div><div id="fn8"><p><sup>8</sup>&nbsp;…stealing from his brother William, who stole it from Andre Gide.</p></div></div><p>There’s an abdication of nuanced thinking here that bothers me a great deal. Agentic AI is neither a bubble about to pop nor an existential threat. It’s a genuine technological shift that’s creating real value whilst simultaneously falling short of its potential and creating genuine social problems. That’s a more complicated story than either the boosters or the doomers want to tell, and definitely a more differentiated one. Much of my day job is shepherding some of the world’s smartest business leaders through exactly this quandary – the messy middle we have to navigate, the safe route we must plot between Scylla and Charybdis. Working with them taught me that world class leaders can take in, indeed welcome, nuance over unhelpful oversimplifications that become cognitive straitjackets. They’re comfortable with life in the land of “yes, but also” if it gives them an edge over the Procrustean ‘simple stories’ of AI as a fraudulent bubble or AI on the road to giving us Skynet any day now. This nuance may be widespread in boardrooms at least at the level we’re working at, but is sorely missing from public discourse. If we as a society are to reason about the agentic revolution and its consequences, we must do so without needing to paint a picture of heaven on earth or a straight, do-not-collect-$200 road to hell. To quote McGeorge Bundy,<sup>8</sup> “gray is the colour of truth”.</p>
</section>
<section id="coda" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="coda">Coda</h2>
<p>Being early doesn’t give me any ownership of the idea or some privileged position in its formulation. Least of all can I or any single individual claim credit for its success, which has built on the efforts of so many. At the same time, in a world where millisecond differences are worth millions, being half a year early makes one incredibly sought after, complete with the kinds of job offers that NFL players used to get. As far as I can see these as an acknowledgment that every leading player in this industry is now recognising the value of agentic AI, it’s gratifying. But I’ve also never forgotten where I came from.</p>
<p>It’s been a long, long journey from writing my first neural networks from a 13th floor hospital room in the Royal London over a decade ago, to waking up to a stuffed mailbox that reads like a Who’s Who of Silicon Valley. Every morning I log into my Github, I see the status message I set years ago and never changed: “<em>doing science and still alive!</em>”, reminding me that just being here is a minor miracle I wasn’t guaranteed. I’ve already won the only lottery that really matters,and every morning I get to wake up to the snoring of the world’s best dog (sorry, not sorry) and watch the sun rise over the Denver skyline, I’m reminded of just how fortunate I am that I get to be here and do the things I live for: do cool frontier stuff, help my clients, mentor the next generation, give back to the community. There is so much to the future of agentic AI, and AI in general, that I rarely look back because looking ahead keeps me occupied. And so when I revisit the past, it’s to explain the origins of my ideas, not to claim credit or authority. I’m shy and reclusive by nature – seeking either is constitutionally alien to me. But the ideas we help bring into the world create a responsibility for their future we cannot so easily disclaim. We carry them into being as tender sprouts with no guarantees they will grow into mature trees that bear fruit. We only get to give them our hopes and dreams and fears and passions, and pray that it will all turn out for the best. And so as I look at agentic AI’s unlikely success story, I worry the way anyone would about the fate of a powerful idea in an uncertain, violent and imperfect world.</p>
<p><strong>But more than fear, I have hope.</strong></p>
<p>Because while the agentic revolution may be over, the journey hasn’t even begun in earnest. This is at best the end of the beginning. There are big questions to be tackled. Deep Agents, multi-agent coordination <span class="citation" data-cites="Becker2025MALLM">(Becker et al. 2025)</span>, model-native agents/agent-native models, the tricky issues that surround agentic alignment esp.&nbsp;in view of evaluation awareness, embodied agents <span class="citation" data-cites="Fu2025ROSBag">(Fu et al. 2025)</span> and the way we secure and authenticate agents are just a few of them. World simulation agents, which to a great degree <a href="../../posts/agentic-simulation/index.html">implement the notion I have been advocating for here</a>, are seeing increased use in the social sciences <span class="citation" data-cites="Srinivasan2025Democracy">(Srinivasan and Patapati 2025)</span> but also, closer to my principal domain of work, in clinical simulation <span class="citation" data-cites="Schmidgall2024AgentClinic">(Schmidgall et al. 2024)</span>. And of course that’s all on top of the the challenges we’re facing on the wider social issues that I’ve touched on above.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Becker2025MALLM" class="csl-entry">
Becker, Jonas, Lars Benedikt Kaesberg, Niklas Bauer, Jan Philip Wahle, Terry Ruas, and Bela Gipp. 2025. <span>‘MALLM: Multi-Agent Large Language Models Framework’</span>. <a href="https://doi.org/10.48550/arXiv.2509.11656">https://doi.org/10.48550/arXiv.2509.11656</a>.
</div><div id="ref-Fu2025ROSBag" class="csl-entry">
Fu, Lei, Sahar Salimpour, Leonardo Militano, Harry Edelman, Jorge Peña Queralta, and Giovanni Toffetti. 2025. <span>‘ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications’</span>. <a href="https://doi.org/10.48550/arXiv.2511.03497">https://doi.org/10.48550/arXiv.2511.03497</a>.
</div><div id="ref-Srinivasan2025Democracy" class="csl-entry">
Srinivasan, Trisanth, and Santosh Patapati. 2025. <span>‘Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities’</span>. <a href="https://doi.org/10.48550/arXiv.2508.19562">https://doi.org/10.48550/arXiv.2508.19562</a>.
</div><div id="ref-Schmidgall2024AgentClinic" class="csl-entry">
Schmidgall, Samuel, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, and Michael Moor. 2024. <span>‘AgentClinic: A Multimodal Agent Benchmark to Evaluate AI in Simulated Clinical Environments’</span>. <a href="https://doi.org/10.48550/arXiv.2405.07960">https://doi.org/10.48550/arXiv.2405.07960</a>.
</div></div><p>The promise remains. Systems of agents, properly conceived, could exhibit the kind of emergent intelligence that no individual model can achieve: learn, adapt, task-decompose, recompose. Realising this potential requires moving beyond the current boxes-and-arrows paradigm to something more fluid, more evolutionary, more genuinely agentic. Even it doesn’t come with the comfort of being able to draw it on a whiteboard.</p>
<p>The challenge of the road ahead is not primarily technical. No new models, no new GPUs, no new architectures are coming to save us. The issues are on a cognitive, linguistic and social plane, and so must the solutions be. For all my worries, for all my misgivings about terminology, I do believe that the best is yet to come. But I also know that we’re not promised those outcomes. When we set sail on this journey, we did so without the guarantee that there will be land at the end of it. That we have found safe harbour and profitable shores is occasion to be grateful – and carry on.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {What {I} Talk about When {I} Talk about Agentic {AI}},
  date = {2025-11-01},
  url = {https://chrisvoncsefalvay.com/posts/two-years-of-agents/},
  doi = {10.59350/ddeyn-whz59},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“What I Talk about When I Talk about
Agentic AI.”</span> <a href="https://doi.org/10.59350/ddeyn-whz59">https://doi.org/10.59350/ddeyn-whz59</a>.
</div></div></section></div> ]]></description>
  <category>LLMs</category>
  <category>AI</category>
  <category>agentic AI</category>
  <category>personal</category>
  <guid>https://chrisvoncsefalvay.com/posts/two-years-of-agents/</guid>
  <pubDate>Sat, 01 Nov 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/two-years-of-agents/header.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>Deep kimchi</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/agentic-speciation/</link>
  <description><![CDATA[ 




<p>This is about the time of year when I get the sudden and irresistible urge to make kimchi. Kimchi – and fermentation in general – is one of those things I wonder if we’re somewhat genetically predisposed to figure out as a species,<sup>1</sup> considering most major cultures in the right climates have independently discovered what is a fairly cool optimisation – finding something that converts sugar into lactic acid, but which is also insanely halotolerant (capable of enduring high salt concentrations) and therefore can create a little evolutionary niche in one’s own fridge muscling out other possibly pathogenic microorganisms.<sup>2</sup> Anyway, about a ton of napa cabbage in, waiting for my immunoassays to finish (because in this household, we do science properly, so we do fluorescence immunoassays for pathogens, because botulism is not cool), my brain wandered off to agentic AI.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Beyond, of course, the fact that we have glutamate-sensitive receptors in our taste buds that let us taste, and enjoy, umami. <a href="https://youtube.com/mrnigelng">Uncle Roger</a> does have a point.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;If you do it correctly. Fermentation is not for the faint of heart. There are real risks, up to and including getting very dead from botulism.</p></div></div><p>The thing is, I’ve been somewhat concerned about the way the agentic AI discourse has been going. We’re headed for deep kimchi, and I’m afraid the main reason for that is, ironically enough, that most agentic AI out there, well, isn’t.</p>
<section id="semantic-mishandles" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="semantic-mishandles">Semantic (mis)handles</h2>
<p>Part of the problem is, of course, the way we think about agents – and insofar as I <a href="../../posts/team-of-rivals/index.html">might be among those to blame for giving rise to the term in its modern sense</a>,<sup>3</sup> I guess I’ll have to shoulder some responsibility for the confusion it engenders. For if one conceives of it in the way we use the word in colloquial language, an agent is, of course, typically a person. This has led to the metaphor of agents as tiny people in your computer who do things to be taken rather more seriously. And with that, we started resorting to conventional operating models we use with people: org charts, arrows of delegated responsibility and all that.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Can’t take the credit without also taking the blame – though I’d rather neither. As I point out every time, the agentic idea has been around much longer. While my description of agentic AI was among the first in its modern sense, I don’t think it was <em>the</em> first. In a life lived with extremely few regrets, my use of the ‘a-word’ is one of the things I wish I could undo. It has so far only caused semantic confusion <em>and</em>, quite possibly, real human harm.</p></div></div><p>Nobody makes kimchi by instructing individual lactobacilli. You cannot sit there with a tiny megaphone directing bacterial populations. For millennia, civilisations that came up with their lactobacillus fermented foods have figured out how to do it instead: you salt the cabbage, add spices, control temperature and let the rest take care of itself.</p>
<p>We understand this intuitively for fermentation. For cities. For ecosystems. For markets. We know that complex systems require systems-level thinking, not component-level micromanagement. And yet somehow, when we talk about agentic AI, we abandon this wisdom entirely and write things like “the challenge of orchestrating thousands of agents” on LinkedIn.</p>
<p>The language of “agents” has misled us through anthropomorphism. We hear “agent” and think of something human – and therefore, rightly, something focal, unique, irreplaceable: an employee, a character in a story, the protagonist of our narrative. We instinctively think about agents the way we think about people – as discrete, meaningful entities whose individual actions matter.</p>
<p>But agents in mature agentic systems aren’t people. They’re processes on some server in Ashburn or Ohio or wherever your cloud provider lives. They neither require nor warrant the kind of individuated respect we afford to humans <em>qua</em> humans.</p>
</section>
<section id="the-domain-of-control" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-domain-of-control">The domain of control</h2>
<p>For two years now, we’ve defined agentic AI in terms of what agents are or can do. These are the mantras you hear repeated in agentic discourse <em>ad infinitum</em>: autonomy, goal-directedness, tool use. All agent-level properties, all true (sort of), and yet they describe at best what kind of thing can be an agent – not what agentic AI is, or can be.</p>
<p>If you can sketch your “agentic AI system” with a few boxes and arrows on a whiteboard, what you’ve built is glorified RPA with LLMs. You’ve automated some tasks, chained some API calls, added probabilistic text generation – useful work, but no more agentic AI than a handful of manually-tuned perceptrons is deep learning. While this is a good way to illustrate what agentic AI might look like zoomed in, it is little more than a metaphor.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>We can formalise an agentic AI system as a dynamic directed graph <img src="https://latex.codecogs.com/png.latex?G_F(t)%20=%20(V(t),%20E(t))"> associated with a fitness function <img src="https://latex.codecogs.com/png.latex?f:%20G(t,%20F)%20%5Crightarrow%20%5Cmathbb%7BR%7D">, where</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?V"> is the set of agents (vertices);</li>
<li><img src="https://latex.codecogs.com/png.latex?E"> is the set of directed edges (agent interactions); and</li>
<li><img src="https://latex.codecogs.com/png.latex?F"> characterises the fitness landscape constraints, i.e.&nbsp;the functions and constraints that define the environment.</li>
</ul>
<p>The system evolves to maximise <img src="https://latex.codecogs.com/png.latex?f"> subject to constraints imposed by <img src="https://latex.codecogs.com/png.latex?F"> (which may associate various costs with various conformations of <img src="https://latex.codecogs.com/png.latex?G_F">). The structure <img src="https://latex.codecogs.com/png.latex?G_F(t)"> – both topology and population – emerges from this optimisation process rather than being specified a priori.</p>
</div></div><p>The key properties of agentic AI lie in the system, not the agents themselves. If we are to attempt a definition, an agentic AI system is best defined by what I call the 3+2 model – the three key autonomies and two key constraints.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Connective autonomy
</div>
</div>
<div class="callout-body-container callout-body">
<p>Agents can discover and form connections with other agents dynamically. The graph of agent interactions is not designed, but evolves and changes to adapt the system’s goal.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Task and tool autonomy
</div>
</div>
<div class="callout-body-container callout-body">
<p>Agents can access and utilise tools and resources based on need rather than pre-specification. They explore their operational possibility space rather than following predetermined paths.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Genetic autonomy
</div>
</div>
<div class="callout-body-container callout-body">
<p>Genetic autonomy: Agents can spawn new agents and determine their characteristics, adapting to selection pressure.</p>
</div>
</div>
<p>The reason why we need to define these autonomies is because they in turn reveal what our controls are – the constraints we can impose to shape system behaviour.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Goal constraint
</div>
</div>
<div class="callout-body-container callout-body">
<p>The goal constraint is the fitness landscape that defines success – not a detailed specification of <em>how</em> to achieve the system level goal but a definition of what constitutes achievement.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Environment constraint
</div>
</div>
<div class="callout-body-container callout-body">
<p>The environment constraint encompasses resource limitations, communication costs, metabolic expenses and interaction protocols that create, communicate and moderate selection pressure on agent behaviours.</p>
</div>
</div>
<p>Together, these five elements - three autonomies and two constraints - define an agentic AI system. And here’s the crucial insight: we should leave the autonomies alone and focus our design attention on the constraints.</p>
<p>The anthropomorphic language of “agents” obscures this. When we think of agents as workers or colleagues, we naturally want to define their roles, specify their responsibilities, coordinate their interactions. We want to draw the org chart. But bacteria don’t have org charts. Neurons don’t have job descriptions. And mature agentic systems won’t have workflow diagrams.</p>
</section>
<section id="where-current-thinking-fails" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="where-current-thinking-fails">Where current thinking fails</h2>
<p>The current wave of “agentic AI” largely looks like an LLM plus some hand-wired agents plus an orchestration layer that routes tasks between them. It’s deterministic workflow automation with probabilistic text generation at the nodes. This is the worst of both worlds – the LLM’s stochasticity breaks the determinism of traditional RPA, but the system gains none of the adaptive benefits that would justify that unpredictability.</p>
<p>In systems-level terms: you’ve eliminated connective autonomy by hard-coding <img src="https://latex.codecogs.com/png.latex?E(t)">, genetic autonomy by fixing <img src="https://latex.codecogs.com/png.latex?V(t)">, and effectively reduced the ability of the system to optimise for any goal-derived fitness function zero.</p>
<p>This is, of course, by no means novel. When Marvin Minsky and Seymour Papert published <em>Perceptrons</em> in 1969, claiming XOR was uncomputable by single-layer networks,<sup>4</sup> just about everything slowed to a crawl until the field was revived in 1986 by the work of Rumelhart, Hinton and Williams on backpropagation. What is crucial is that Hinton, LeCun and the rest of the backpropagandists didn’t go out to make better neurons. They simply realised how much more can be gotten out of simple neurons, simple maths and a systems perspective. They optimised the system, not the components. And therein lies the magic.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Which was true but irrelevant. We’ve known MLPs quite well at the time. Yet it was widely misinterpreted and by the time anyone noticed, we were deep into the winter of neural network research.</p></div></div></section>
<section id="the-power-of-constraints" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-power-of-constraints">The power of constraints</h2>
<p>What would it mean to design agentic AI systems through constraints rather than specifications?</p>
<div class="grid">
<div class="g-col-6">
<p><strong>Goal constraint design</strong></p>
<p>We specify system-level objectives, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?f">, for <img src="https://latex.codecogs.com/png.latex?G_F(t)">, to optimise against. How the system accomplishes this is left to the autnonomies.</p>
</div>
<div class="g-col-6">
<p><strong>Environment constraint design</strong></p>
<p>We condition <img src="https://latex.codecogs.com/png.latex?G_F"> by the fitness landscape <img src="https://latex.codecogs.com/png.latex?F"> by defining resource limitations, communication costs, metabolic expenses and interaction protocols that create selection pressure on agent behaviours.</p>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Recipe:</strong> Napa cabbage kimchi <em>(vaguely Noma-inspired)</em></p>
<ul>
<li>1kg napa cabbage, cut into bite-sized pieces</li>
<li>60g sea salt</li>
<li>2 tbsp nước chấm</li>
<li>2 tbsp gochugaru</li>
<li>3 cloves garlic, minced</li>
<li>20g fresh ginger, grated</li>
<li>2 spring onions, sliced</li>
<li>1 tsp raw honey</li>
</ul>
<p>Salt the cabbage thoroughly. Let rest 2-3 hours. Rinse and squeeze dry. Mix remaining ingredients into a paste (wear gloves – nước chấm will make your hands stink to high heaven), massage into cabbage. Pack tightly into jar, leaving 2-3 cm headspace, and ferment at room temperature for 3-5 days, releasing pressure daily. Refrigerate once it reaches your desired tanginess.</p>
</div></div><p>Jointly, these constraints create selection pressure that guides evolution without dictating outcomes. Consider what this enables: A system facing a new class of problems might spawn specialist agents efficient for that problem type. These specialists persist if they provide value, disappear if they don’t. Agents discover collaboration patterns that prove fruitful and strengthen those connections, and the system evolves toward metabolic efficiency without any explicit optimisation.</p>
<p>This is the power of evolutionary speciation over specification: species emerge from evolutionary pressure, rather than being designed explicitly, as does their conduct and interactions. The ‘agents’, just like the bacterial species in a jar of kimchi, explore the solution space defined by the constraints, and the population structure adapts not to what someone defines but to what the environment at the time demands.</p>
</section>
<section id="how-to-rescue-agentic-ai" class="level2">
<h2 class="anchored" data-anchor-id="how-to-rescue-agentic-ai">How to rescue agentic AI</h2>
<p>We’re in deep kimchi – but we don’t have to be. AI had to endure a decade-and-half winter before being resuscitated in 1986. We may be fortunate enough to avoid it this time around – but we won’t get there by better workflow diagrams. We’ll get there through the system perspective, just as it was the system perspective that saved neural networks.</p>
<p>The autonomies – connective, task, genetic – define what mature agentic systems are capable of. But realising that capability requires shifting our design attention from the autonomies to the constraints, and learn how to stop micromanaging and instead govern the system through conditioning its fitness landscape (in short: <a href="../../posts/biome-engineering/index.html">biome engineering</a>).</p>
<p>If you’re still drawing boxes and arrows, still thinking about “my code agent talking to my research agent”, still trying to orchestrate individual interactions – you’re hand-coding what should be left to evolution. The anthropomorphic language of “agents” has been useful for explaining these systems to non-technical audiences, but we have outgrown it – it is now actively hindering our ability to design them properly. Agents aren’t little employees inside the machine or characters of a story. But their collectivities can give rise to the same kind of emergent behaviour that lets a stack of trivial computations self-organise into ChatGPT, AlphaFold or whatever fresh hell Sora is doing right now.</p>
<p>Agentic AI isn’t doomed – but micromanagement of agents doesn’t scale, and that imposes an upper bound. We have kimchi and sauerkraut and pickles because the civilisations that came up with them were unencumbered by software architects and Microsoft Visio. They just designed the brine, set the temperature and let nature take its course. We should probably learn from that.</p>
<p>Stop trying to direct the bacteria. Start designing the brine.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {Deep Kimchi},
  date = {2025-10-25},
  url = {https://chrisvoncsefalvay.com/posts/agentic-speciation/},
  doi = {10.59350/c8085-dj650},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“Deep Kimchi.”</span> <a href="https://doi.org/10.59350/c8085-dj650">https://doi.org/10.59350/c8085-dj650</a>.
</div></div></section></div> ]]></description>
  <category>LLMs</category>
  <category>AI</category>
  <category>agentic AI</category>
  <category>evolution</category>
  <guid>https://chrisvoncsefalvay.com/posts/agentic-speciation/</guid>
  <pubDate>Sat, 25 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>SOYA - the only benchmark that matters</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/soya/</link>
  <description><![CDATA[ 




<p>In 1790, the French Academy of Sciences commissioned a rather ambitious survey. The goal was to measure the distance from the North Pole to the Equator along the meridian passing through Paris, then use that measurement to define a new universal unit of length: the metre. The idea was simple enough: let’s create a standard so objective, so rooted in natural law, that every nation would adopt it. One ten-millionth of the distance from pole to equator. Perfect. Universal. The platonic ideal of measurement.</p>
<p>There was just one problem. The measurement was wrong. Not catastrophically wrong, mind you, but wrong enough that when better instruments came along, we discovered the original metre was about 0.2mm off. By then, however, the French had made rather a lot of metre sticks, and redoing them all seemed like rather more trouble than it was worth.<sup>1</sup> So we kept the stick and quietly forgot about the pole-to-equator business. The metre became defined not by nature’s grand design, but by a specific physical artefact in a vault in Sevres. Later, we’d define it by the speed of light, which at least has the virtue of being constant, even if it’s rather less poetic than the original vision.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Also, this was basically on the heels of the French Revolution. You can disagree about weights and measures, but you’re much less likely to want to do so vis-a-vis a government that has just discovered its love of the guillotine.</p></div></div><p>I’m reminded of the story of the metre because it nicely illustrates a key point about benchmarks: all benchmarks are wrong. They are simplifications, abstractions, approximations of reality. They can be useful, but they can never capture the full complexity of the systems they aim to measure. And that’s okay if all you need to resolve is the coordination problem of “how long is this thing?” – but it doesn’t say anything beyond the relative ratio between what you’re looking at and that specific standard. Least of all does it reveal anything meaningful about the underlying object.</p>
<section id="the-benchmark-industrial-complex" class="level2">
<h2 class="anchored" data-anchor-id="the-benchmark-industrial-complex">The benchmark-industrial complex</h2>
<p>We have built an entire industry around the idea that there exists some universal measure of language model capability, some objective standard against which all models can be compared. MMLU, GSM8K, HumanEval, HellaSwag – the list grows longer every month, each benchmark claiming to capture some essential truth about model performance. Companies trumpet their SOTA results. Researchers optimise specifically for these benchmarks. VCs make investment decisions based on leaderboard positions. And on and on it goes in a self-reinforcing cycle.</p>
<p>And just like the original metre, these benchmarks are increasingly recognised as both arbitrary and, well, wrong.</p>
<p>The rot has been apparent for a while now. Traditional static benchmarks suffer from saturation, as models quickly reach performance ceilings, and contamination, where test data leaks into training sets, inflating scores. When GPT-4 can score 86.4% on MMLU, and the next model scores 87.2%, are we measuring genuine improvement or noise? When models are trained on datasets that may contain variations of the test questions, are we measuring capability or memorisation?</p>
<p>There’s a deeper problem here, though. LLMs can be used for a shocking range of tasks, from generating code to clicking the right button on your GUI. Benchmarks necessarily have a value judgment inherent in their task set – and that includes massive multi-task sets like MMLU or agentic multi-objective evals like GAIA or <img src="https://latex.codecogs.com/png.latex?%5Ctau">-bench. No choice, too, is a kind of choice: when we use a benchmark smorgasboard of tasks or domain questions, we are implicitly setting the expectation of a Renaissance model that can do everything somewhat well. Simply put – there’s no such thing as an agnostic, universal eval.</p>
</section>
<section id="soya-your-benchmark-your-way" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="soya-your-benchmark-your-way">SOYA: your benchmark, your way</h2>
<p>Earlier this year, Huggingface released YourBench, a framework that addresses these limitations by enabling dynamic, automated generation of reliable, up-to-date and domain-tailored benchmarks directly from user-provided documents.<sup>2</sup> There’s a beautiful symmetry here – just as we’re reaching the level of specialisation of language models that necessitates task-specific evals, we also are starting to have the tools that can provide this on a budget and at scale.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Shashidhar, S., Fourrier, C., Lozovskia, A., Wolf, T., Tur, G., &amp; Hakkani-Tür, D. (2025). <a href="https://arxiv.org/abs/2504.01833">YourBench: Easy custom evaluation sets for everyone.</a> <em>arXiv preprint</em>, arXiv:2504.01833.</p></div></div><p>The real significance of YourBench isn’t just that it’s incredibly convenient and technically impressive. It is the end of SOTA, and the rise of what I call SOYA: the State of Your Art.</p>
<p>The insight is deceptively simple. Instead of asking “which model is best?”, we should be asking “which model is best at the specific things I actually need it to do, with the specific data and constraints I actually have?” The universal benchmark is revealed as the emperor with no clothes. What matters isn’t whether Claude beats GPT-5 on MMLU – it’s whether the model can handle your internal documentation, understand your domain terminology, and operate within your latency and cost constraints.</p>
<p>This shift from SOTA to SOYA isn’t just semantic cleverness. It’s a fundamental reimagining of how we think about model selection and evaluation. Tools like YourBench have transformed custom evals from a luxury reserved to major labs to something you can run for the price of a Happy Meal.</p>

<div class="no-row-height column-margin column-container"><div class="">
<hr>
<p><strong>Recipe:</strong> Shakshuka</p>
<ul>
<li>1 tin decent chopped tomatoes</li>
<li>1 onion, diced</li>
<li>3 cloves garlic</li>
<li>1 red pepper, diced</li>
<li>1 tsp smoked paprika</li>
<li>1 tsp cumin</li>
<li>1/2 tsp cayenne pepper</li>
<li>4-6 eggs</li>
<li>Crumbled feta</li>
<li>Some fresh coriander, to taste</li>
</ul>
<p>Sauté the onion until soft, add the garlic and spices. Adding the tomatoes and peppers, simmer until thick (20 minutes). Make wells, crack eggs into them. Cover and cook until eggs are just set. Top with feta and coriander. Serve with good bread.</p>
<hr>
</div></div><section id="the-democratisation-of-evals" class="level3">
<h3 class="anchored" data-anchor-id="the-democratisation-of-evals">The democratisation of evals</h3>
<p>The key implication, then, is that it is now at least in theory open to everyone to determine what their State of the Art is. This opens the door to much more meaningful evals. In the regulated pharmaceuticals and medtech industries, where I spend pretty much all my working life, a 0.3% incremental improvement in model performance is less relevant than what that 0.3% actually <em>is</em>. There’s an incommensurability of performance aspects here. I don’t care how much better your model is at solving Math Olympiad questions if it can’t determine whether something is a life-threatening adverse event or a mere nuisance. Generic benchmarks don’t help me. SOYA benchmarks might.</p>
<p>The offshoot, of course, is that these evals map much better to actual business needs and actual data. The downside? They require an understanding of how to build a good eval. YourBench is brilliant, but it’s a tool for building evals, not for building <em>good</em> evals per se. It puts evals that were previously the preserve of well-funded labs into the hands of anyone with a credit card and a bit of time. But it’s up to the end user to make sure this doesn’t turn into giving toddlers a set of car keys and a bottle of bourbon.</p>
</section>
</section>
<section id="the-soya-mindset-in-practice" class="level2">
<h2 class="anchored" data-anchor-id="the-soya-mindset-in-practice">The SOYA mindset in practice</h2>
<p>SOYA, then, is really primarily a mindset – one that requires us to first and foremost let go of some comfortable illusions. It means accepting that there is no “best model” in the abstract, only models that are better or worse for specific purposes. It means doing the hard work of articulating what you actually need from a model, rather than defaulting to whatever topped the latest leaderboard. When I talk to my clients about building an approach to evals, I typically want to explore the dimensions of model use – that is, their ‘definition of good’:</p>
<ol type="1">
<li>What are the three most common tasks this model will perform?</li>
<li>What does failure look like for each of these tasks, and what are the consequences?</li>
<li>What does your actual data look like, and how does it differ from the training distributions these models saw?</li>
<li>What are your constraints on latency, cost and compute?</li>
<li>What does “good enough” look like for your use case?</li>
</ol>
<p>Only after we’ve answered these questions do we start looking at models. And increasingly, the answer isn’t “use the SOTA model” but rather “use this smaller, specialised model that excels at your specific task, or this model that’s good enough but 10x cheaper, or this ensemble of models that handles your specific data distribution better”.</p>
</section>
<section id="some-inconvenient-truths" class="level2">
<h2 class="anchored" data-anchor-id="some-inconvenient-truths">Some inconvenient truths</h2>
<p>Let me be clear about what SOYA doesn’t mean. It doesn’t mean anything goes. It doesn’t mean evaluation is purely subjective. It doesn’t mean we abandon rigour. What it does mean, however, is acknowledging some uncomfortable truths:</p>
<ol type="1">
<li>Generic benchmarks capture something, but that something may not correlate with your specific needs. The more specialised those needs are (i.e.&nbsp;the further they are from simple agent driving and chat interactions), the less likely generic benchmarks are to be relevant.</li>
<li>The “best” model for one use case may be catastrophically wrong for another. Context matters.</li>
<li>Optimising for SOTA performance often means whatever you’re getting has been optimised for something other than your use case.</li>
<li>Custom evaluation requires thought and effort, but that effort is increasingly cheap enough to be worth it. Thought, on the other hand, remains expensive. Bad evals give bad results.</li>
</ol>
<p>And that’s really the crux of it all: the choice for users is between accepting convenient, universal, cheap and wrong benchmarks, or investing a bit more time and effort into building evals that actually reflect their needs.</p>
</section>
<section id="how-not-to-suck" class="level2">
<h2 class="anchored" data-anchor-id="how-not-to-suck">How not to suck</h2>
<p>SOYA, if correctly used, can be a solution to the problem of generic evals that suffer from the same flaw as generic models: they try to be everything to everyone, and end up being mediocre at best for any specific purpose. But SOYA can also be misused. A poorly constructed custom eval can be worse than a generic benchmark, giving a false sense of security or leading to misguided model choices. And at this point, eval engineering as a discipline is sorely lacking. Even relatively sophisticated enterprise users have few specialists who really understand how to build good evals.</p>
<p>One solution for this is the emergence of evals-as-a-service (EaaS) providers. But evals aren’t a technological exercise only – they require an understanding of the factors I mentioned above that characterise what success, or a good model, is for the particular client. SOYA is the Savile Row of AI: bespoke, tailored, and requiring expert craftsmanship. You can’t just pick it off the rack.</p>
<p>The benchmark-industrial complex will be fine – there’s already talk about making models more ‘realistic’. This is generally a category error – benchmarks cannot be ‘realistic’ to all respects. What they can be is relevant. And relevance is in the eye of the beholder. No single benchmark can capture the specific requirements of pharmaceutical adverse event extraction, contract analysis and marketing copywriting simultaneously. The solution is to accept that benchmarks must be premised on ‘what good is’, not on a fool’s errand of bundling an ever growing list of tasks into a single eval suite.</p>
</section>
<section id="epilogue" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="epilogue">Epilogue</h2>
<p>A year or so after graduating from Oxford, I was invited to sit for what was rather widely considered the time’s equivalent of Humanity’s Last Exam, but for humans: the Prize Fellowship Exam for All Souls. There isn’t enough space here to describe how weird and intense an experience it was. You sit a number of papers, typically two ‘general’ papers, two ‘specialist’ papers and an essay. The general papers have questions on just about everything. Here are three actual questions from <a href="https://www.asc.ox.ac.uk/past-examination-papers">this year’s general paper</a>:</p>
<ul>
<li>Invent a new punctuation mark!</li>
<li>Does a pope matter?</li>
<li>The organ has been considered the ‘king of instruments’. Is it?</li>
</ul>
<p>Then you get to choose your specialist papers – from seven disciplines (classics, economics, English literature, history, law, philosophy and politics). I picked a law paper, which was unsurprising considering I did that as an undergraduate subject, and a classics paper.<sup>3</sup> I guess I must have done pretty okay, because of the hundred or so applicants that year (you had to generally get a top 1st in your undergraduate degree to even apply), I was fortunate enough to be in the final five invited for a <em>viva</em>, the last stage of the process. Which I bombed spectacularly enough that I wasn’t offered a fellowship, but that’s a story for another day.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;My sincere apologies to the examiners for having to endure my Latin translation. I am not a classicist by training to begin with, but I am a special kind of bad at Latin in particular.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;It took a lot of time and growth for me to learn to appreciate the value of depth. I remain incredibly curious and, in long retrospect, grateful for the experience – but also very aware that my depth is what makes my breadth work. Not winning a Prize Fellowship might have been one of my career-defining blessings in disguise – something that forced me to find a productive synthesis between a mind interested in just about everything and the needs of this world for professionals who can deliver focus, profound expertise and real-world impact. I am just so incredibly fortunate to have ultimately found a way to make this difficult balance work for me.</p></div></div><p>I mention this because with the benefit of hindsight, I see a lot of similarities between the Prize and the current SOTA mindset, mostly in its shortcomings. The Prize Fellowship Exam is the epitome of the modern ‘HLE-style’ SOTA eval: it identifies a small number of dazzling generalists, not necessarily those people who truly end up changing the world through commitment, depth and focus on their specific domain.<sup>4</sup> But whatever we think of the value of that kind of modern day Renaissance person, it certainly isn’t what we need from our AI agents. What we need are models that excel in specific domains, for specific tasks, under specific constraints. Agents, unlike people, are interchangeable. We don’t need polymaths – we need specialist team players who can harness emergence for complexity.</p>
<p>In the end, context isn’t an epiphenomenon – it’s what gives meaning to the abstractions of performance. Context is what turns that abstract brilliance into concrete, real-world impact. And with tools like YourBench, we’re finally seeing the era of SOYA – where users finally get the choice they deserve as to what matters to them, and what good means for their use case.</p>
<p>So the next time someone breathlessly announces they’ve achieved new SOTA results, ask yourself: state of what art? For whom? Under what conditions?</p>
<p>Because in the end, <strong>the only art that matters is yours</strong>.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {SOYA - the Only Benchmark That Matters},
  date = {2025-10-19},
  url = {https://chrisvoncsefalvay.com/posts/soya/},
  doi = {10.59350/xqf22-csp59},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“SOYA - the Only Benchmark That
Matters.”</span> <a href="https://doi.org/10.59350/xqf22-csp59">https://doi.org/10.59350/xqf22-csp59</a>.
</div></div></section></div> ]]></description>
  <category>LLMs</category>
  <category>AI</category>
  <category>evals</category>
  <guid>https://chrisvoncsefalvay.com/posts/soya/</guid>
  <pubDate>Sun, 19 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Biome engineering</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/biome-engineering/</link>
  <description><![CDATA[ 




<p>Roughly 541 million years ago, something extraordinary happened in Earth’s oceans. Over a geologically brief period of perhaps 20 million years, the fossil record explodes with an almost obscene diversity of body plans. Trilobites, anomalocarids, the bizarre Opabinia with its five eyes and frontal grasping appendage – suddenly, the relatively monotonous microbial world gave way to an abundance of diversification in what we now call the Cambrian explosion. The textbook explanation points to rising oxygen levels in the oceans, changes in ocean chemistry and perhaps the evolution of predation itself. But here’s the thing: none of these environmental shifts determined which specific forms would emerge. The changing ocean chemistry didn’t decree “there shall be trilobites”. Rather, it created conditions that made certain evolutionary pathways more energetically favourable, certain body plans more viable, certain ecological niches newly accessible.</p>
<p>The environment set the stage. Emergence explored it, and wrote the play.</p>
<p>I find myself returning to this image as I think of reconciling two ideas in apparent opposition: the fact that AI agents’ true value lies in their ability to independently reorganise and structure themselves in a way that gives rise to an emergence of sorts, with the need to govern such systems and guide them towards the outcomes we desire.</p>
<p>We’ve moved through distinct phases of how we think about shaping AI behaviour, each building on the last like Schliemann’s nine cities of Troy. First came <a href="../../posts/prompt-engineering/index.html">prompt engineering</a>, the art of crafting the perfect utterance to coax desired behaviour from a language model. Then Andrej Karpathy articulated what he termed <a href="../../posts/context-engineering/index.html">context engineering</a> – the recognition that an agent’s operating envelope, the information and tools it has access to, matters as much as any individual prompt. But as I argued in my recent writing on agent ecosystems, we’re now confronting something more profound: the need to engineer not individual agents or even their immediate contexts, but the entire operating environment in which populations of agents interact, specialise and evolve solutions we couldn’t have explicitly programmed.</p>
<p>I call this biome engineering. And like the Cambrian ocean chemistry, it’s an intricate dance of constraints and gradients that gently shape, not prescribe, a spontaneous emergence.</p>
<section id="from-utterances-to-ecosystems" class="level2">
<h2 class="anchored" data-anchor-id="from-utterances-to-ecosystems">From utterances to ecosystems</h2>
<p>Let me trace the genealogy of this idea for a moment. Prompt engineering emerged from a fundamentally transactional view of AI: you ask a question, the model responds, the interaction terminates. The craft lay in asking the right question in the right way. It was, in essence, the art of the perfect utterance – a rhetorical exercise that would have delighted the Sophists. We developed elaborate techniques: few-shot learning, chain-of-thought prompting, role-playing scenarios. The assumption was that if we could just find the right incantation, we could reliably extract the behaviour we wanted from the model.</p>
<p>This worked reasonably well for a while, but it had a fundamental limitation: it treated each interaction as isolated, acontextual, amnesic. Every conversation started from scratch. Every task required re-establishing context.</p>
<p>Context engineering represented a conceptual leap. Karpathy’s insight was that we should stop thinking about individual prompts and start thinking about the entire informational environment in which an agent operates. What knowledge does it have access to? What tools can it invoke? What constraints govern its actions? More broadly, how can we ‘dope’ the agent’s context with just the right nudging context to create a groove in the gradient space towards what outcome we desired, without explicitly constraining it? An agent with proper context engineering isn’t just responding to utterances – it’s operating within a defined possibility space, with persistent memory, access to resources and the ability to maintain coherent behaviour across extended interactions. The tradeoff is, of course, that if finding the right utterance was difficult, finding the right context is even more so – and the reward for perfect context engineering is even less deterministic.</p>
<p>But context engineering, for all its power, still focuses on the individual agent. It’s about optimising the envelope within which a single agent operates. And this is where we run into <a href="../../posts/agents-agora/index.html">the same conceptual wall I’ve been banging on about in my writing on agent ecosystems</a>: the real value of agents isn’t in what they can do alone, but in how they work together.</p>
</section>
<section id="leveling-up" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="leveling-up">Leveling up</h2>
<p>Here’s where we need to make the leap from engineering individual contexts to engineering entire biomes – the substrates in which populations of agents can interact, specialise and collectively solve problems in ways that emerge from the system rather than being explicitly programmed.</p>
<p>A biome, in the ecological sense, isn’t just a collection of organisms. It’s the entire system: the organisms, their interactions, the physical environment, the flows of energy and nutrients, the constraints and opportunities that shape what can survive and thrive. The Serengeti isn’t just lions and gazelles and acacia trees – it’s the pattern of rainfall that determines where grass grows, the soil chemistry that shapes which plants can take root, the seasonal migrations that move energy across the landscape.</p>
<p>Biome engineering for AI systems means designing the operating environment for populations of agents: not just what each individual agent can do, but how agents can discover each other, how they establish trust and negotiate collaboration, what resources they can access and under what constraints, how authority and delegation flow through the system. It’s about creating the substrate conditions that allow certain interaction patterns to flourish whilst making others energetically unfavourable or outright impossible.</p>
<p>The crucial insight is that biome engineering is non-deterministic in its outcomes but bounded in its possibilities. Just as the Cambrian ocean chemistry didn’t produce a specific catalogue of species but rather made certain evolutionary pathways more likely, biome engineering doesn’t specify exactly how agents will collaborate – it creates conditions that favour productive patterns whilst constraining destructive ones.</p>
<p>More importantly, this allows for agents to dynamically recombine within a bounded space of possibilities. This makes the collective of agents responsive to adapt to changing conditions, i.e.&nbsp;to optimise the graph of interactions <img src="https://latex.codecogs.com/png.latex?G%20=%20(V,%20E)"> so that its performance minimises a loss function over time. And if this sounds awfully similar to the way we train every neural network, that’s because it is. Biome engineering is awfully important because it essentially supersedes the legacy approach of deterministically layering a small number of agents. That may work for the travel-planning-in-five-agents toy example, but not for emergent systems. Just as we wouldn’t have working neural networks if we had to manually run backpropagation, we need an effective way to let agents self-organise and learn towards a goal at scale. Biome engineering turns that problem into a tractable one.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;And, arguably, differentiable. Which is where the real magic comes in, since whatever is differentiable can be computationally optimised using gradient descent. But that’s a post for another day.</p></div></div></section>
<section id="the-biome-as-substrate" class="level2">
<h2 class="anchored" data-anchor-id="the-biome-as-substrate">The biome as substrate</h2>
<p>There’s a concept in exercise physiology called “training stress” – not stress in the colloquial sense of anxiety, but the physiological stress that drives adaptation. You don’t tell your body to build more mitochondria or increase stroke volume. You create conditions (progressive overload, adequate recovery, proper nutrition) that make those adaptations energetically favourable. The body responds to the environment you create. Do it long enough, and you <a href="../../posts/skierg-marathon/index.html">might as well end up doing things you probably didn’t think was possible</a>.</p>
<p>Biome engineering works similarly. You’re not explicitly programming agent behaviours – you’re shaping the problem space they explore by setting its boundaries and its internal gradients. This means thinking carefully about a lot of things we generally don’t (or at least not in these terms):</p>
<ul>
<li>Resource topology: What information, tools and compute resources are available? How are they distributed? What are the costs (in tokens, time, money) of accessing them? Just as species diversity in ecology is partly shaped by resource patchiness, agent specialisation will emerge based on how resources are structured.</li>
<li>Interaction protocols: How can agents discover each other? How do they establish capabilities and negotiate terms? What standards govern their communication? This is a problem I’ve written about – we need something richer than current constructs (I like MCP, it’s just limited to what it has been designed to accomplish), something that can convey not just data but trust, authority and constraint.</li>
<li>Constraint boundaries: What are agents allowed to do, and crucially, how do those constraints propagate through delegation chains? An agent commissioned by another agent must inherit appropriate constraints from its principal. The biome’s “laws of physics” need to make certain behaviours impossible, not just discouraged.</li>
<li>Feedback mechanisms: How do agents learn what works? Do successful collaboration patterns get reinforced? Do agents that consistently meet their commitments earn reputation that makes future collaboration easier? The biome needs something analogous to ecological fitness – ways for productive patterns to flourish. *Diversity pressures: Monocultures are fragile, whether in agriculture or in agent systems. The biome should create niches that favour specialisation over generalisation, depth over breadth in specific domains.</li>
</ul>
<p>The art of biome engineering lies in setting these parameters such that the agents’ exploration of the problem space naturally tends toward solutions that are acceptable to you, while avoiding failure modes that aren’t. You’re creating a landscape where certain paths are easier to traverse, certain peaks easier to reach, without explicitly commanding “go climb this mountain”.</p>
</section>
<section id="the-non-problem-of-emergence" class="level2">
<h2 class="anchored" data-anchor-id="the-non-problem-of-emergence">The non-problem of emergence</h2>
<p>I can hear the objection already: “But if you’re not explicitly programming the behaviour, how do you know what you’ll get?” This is a legitimate concern, particularly in regulated industries where I spend most of my time. The enterprise software world has been built on determinism, on the ability to specify and verify exactly what a system will do.</p>
<p>Biome engineering does require a different relationship with emergence and uncertainty. You’re creating conditions, not commanding outcomes. But this isn’t as radical a departure as it might seem. We already accept this in other domains. When you build a market, you don’t specify every transaction: you create rules, mechanisms for price discovery, constraints on behaviour, and let trading patterns emerge. When you design a city, you don’t dictate every social interaction: you create infrastructure, zoning, public spaces, and let communities form. There is an awful lot of room between fully deterministic prescriptive spaces and pants-on-head anarchy.</p>
<p>The key is that whilst specific outcomes aren’t determined, the possibility space is bounded. The Cambrian explosion produced wild diversity, but it didn’t produce physically or biologically nonsensical outcomes (or even anything that deviates very significantly from the usual order of low level biological functioning) – the environmental constraints and existing biological toolkit limited what could emerge. Similarly, well-designed agent biomes channel emergence within acceptable boundaries.</p>
<p>This requires new forms of verification and validation. Instead of testing whether a system produces specific outputs for specific inputs, you’re testing whether the biome’s constraints hold under stress, whether emergent behaviour stays within acceptable bounds, whether the feedback mechanisms actually reinforce productive patterns. It’s closer to stress-testing a bridge by driving over it a few hundred times than debugging a program.</p>
</section>
<section id="the-orchard-and-the-grove" class="level2">
<h2 class="anchored" data-anchor-id="the-orchard-and-the-grove">The orchard and the grove</h2>
<p>There’s a spectrum here, and different applications will sit at different points along it. Some biomes will be heavily cultivated orchards, with tight constraints and limited opportunities for emergence. Others will be closer to managed wildernesses, with looser boundaries and more room for unexpected behaviour.</p>
<p>High-stakes, highly regulated domains – medical diagnosis, financial trading, safety critical systems – will tend toward the orchard end. You want strong constraints, limited emergence, predictable patterns. But even here, biome engineering offers advantages over purely programmatic approaches. A well-designed biome can enforce regulatory compliance more flexibly than hard-coded rules, can adapt to novel situations within constraints, can allow specialised agents to collaborate whilst maintaining audit trails and accountability.</p>
<p>More exploratory domains – research, creative work, open-ended problem-solving – can afford to sit further toward the wilderness end. Here you want emergence, want agents to discover novel collaboration patterns, want the system to surprise you with solutions you wouldn’t have thought to program.</p>
<p>The crucial capability is being able to tune this dial based on context. The same underlying biome infrastructure should support different constraint regimes for different use cases. This is where biome engineering diverges most sharply from both prompt and context engineering: it’s not about individual interactions or individual agents, but about the entire operating environment and its relationship to the problem space.</p>
</section>
<section id="towards-crafting-biomes" class="level2">
<h2 class="anchored" data-anchor-id="towards-crafting-biomes">Towards crafting biomes</h2>
<p>I’ll be honest: we’re still in the very early stages of this. Most of what I’m describing doesn’t exist in production systems yet. We have fragments – agent marketplaces that enable discovery, delegation frameworks that propagate constraints, trust scoring systems that track reputation. Most of these are nascent at best. But we don’t yet have coherent biome engineering frameworks that bring these pieces together.</p>
<p>The technical challenges are considerable. We need standards for agent capability description, protocols for trust establishment, mechanisms for constraint propagation, frameworks for reputation and verification. We need to solve the meta-problem of how biomes themselves can be specified, deployed and validated.</p>
<p>The conceptual challenge is equally significant. Biome engineering requires a different mindset from traditional software development. You’re not building a machine with specified behaviour, you’re cultivating an ecosystem with bounded emergence. This demands comfort with uncertainty, skill in thinking about system-level properties rather than individual components, and the ability to reason about constraints and incentives rather than explicit commands. It’s a shift from architect to gardener, from engineer to evolutionary theorist. And much like the Cambrian explosion, I suspect we’re going to see a period of wild experimentation, of diverse approaches and unexpected solutions, before things settle into more stable patterns.</p>
<p>But then again, perhaps stability isn’t the goal. Perhaps the point of biome engineering is to create substrates where continuous adaptation and evolution are not bugs but features – where the system remains dynamic, responsive and capable of surprising us long after we’ve deployed it. There’s no reason why this needs to be the <em>only</em> model – deterministic, programmatic systems will still have their place, just as LLMs didn’t displace the template engines that deterministically generate the bulk of the web. But for complex, open-ended problems, biome engineering offers a promising path forward.</p>
<p>The dramatic perturbations 541 million years ago that gave rise to an abundance of weird attempts at existence, of which some proved successful enough to thrive, continue to ripple into the present. Evolution has kept improvising new variations on those original themes that allowed life to persist and thrive despite drastic changes to the face of the earth. If we do biome engineering right, our agent ecosystems might show similar staying power and potential.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay} and von Csefalvay, Chris},
  title = {Biome Engineering},
  date = {2025-10-11},
  url = {https://chrisvoncsefalvay.com/posts/biome-engineering/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay, and Chris von Csefalvay. 2025. <span>“Biome
Engineering.”</span> <a href="https://chrisvoncsefalvay.com/posts/biome-engineering/">https://chrisvoncsefalvay.com/posts/biome-engineering/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>Agentic AI</category>
  <category>LLMs</category>
  <guid>https://chrisvoncsefalvay.com/posts/biome-engineering/</guid>
  <pubDate>Sat, 11 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>From agents to the Chorus</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/choral-ai/</link>
  <description><![CDATA[ 




<p>Around two years ago, almost to the day, I spent an absolutely frantic evening in Berkeley, going through enough coffee to power a mid-sized city, hammering away at my laptop on trying to figure out what comes after LLMs. What to most people was still barely on the horizon at the time has been a subject I have been working on in various capacities for the best part of the past decade, on and off. Transformers have revitalised the interest in AI for language that has for a while been eclipsed by computer vision, which in the preceding decade or so has gotten a significant boost from convolutional neural networks. But then Vaswani et al.&nbsp;came along with the <em>Attention</em> paper,<sup>1</sup>, and suddenly language was cool again.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention is all you need</a>. In <em>Advances in Neural Information Processing Systems</em>, Vol. 30. Curran Associates, Inc., 5998–6008.</p></div></div><p>What I was trying to understand that night in Berkeley was how we could let these language models do more than speak. There’s a kind of magic to computer science, in that the barrier between the conceptual and the real, the thought and the action, is rather more permeable than elsewhere. In few other fields, if any, do we traffic with such frequency between words on the screen and the motion of a remotely controlled robot arm, a $10m stock trade or a drone strike – and vice versa. And so, it stood to reason that if LLMs could produce words, they ought to be able to produce actions, too.</p>
<p>I wasn’t – despite occasional assertions by many – the first to conceptualise ‘agentic’ AI. Agency has been a topic in AI for a long time. Russell and Norvig famously gave a definition of it in their seminal textbook,<sup>2</sup> and I keep showing that on a stark blue slide every time I give a talk on the subject to remind us of the giants’ shoulders we are privileged to stand on. Around the same time, at least two others have considered the same ideas – Harrison Chase, at <a href="https://langchain.ai">LangGraph</a>, and <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">Lilian Weng</a>, then at OpenAI, now at Thinking Machines.<sup>3</sup> and arrived at the same terminology.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Russell, Stuart J., and Peter Norvig. 1995. <em>Artificial Intelligence: A Modern Approach</em>. Pearson. https://aima.cs.berkeley.edu/</p></div><div id="fn3"><p><sup>3</sup>&nbsp;I’d like to say that great minds think alike, but that would make me look awfully out of place between the other two.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;There’s a huge point here to be made about where speech begins, acts end, or what the differentiation there is, but this is already a fairly long one.</p></div></div><p>In retrospect, there are moments I regret the terminology I ended up adopting in <a href="../../posts/team-of-rivals/index.html">my post on the subject</a>. I’m not sure it hasn’t, inadvertently, led to human harm. What I did not necessarily think of at the time was that I came to the word from a very specific angle. I’m of course a recovering lawyer, where agency is a very well-defined concept, and raises issues that those who primarily associate the term with airport ticketing or James Bond don’t necessarily think of (such as delegation and delegability). But more than that, I was thinking of the etymological roots of the word, from the Latin <em>agere</em>, from which our English word ‘action’ also derives – agentic AI was AI with the key <em>differentia</em> of being able to act, even if it is through some form of speech.<sup>4</sup></p>
<section id="pentheus-and-the-maenads" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="pentheus-and-the-maenads">Pentheus and the Maenads</h2>
<p>Classical Greek drama is incredibly diverse in its subjects, characters and tone. Yet one thing unites almost every extant play that we have in any non-trivial volume: there’s a bunch of characters, a dozen to fifty or so, who act as the chorus. They’re not actors (agonistes), but are just as important, if not more so. They comment on the action, they provide context, they provide a moral compass, they provide a collective voice. They address, and are addressed.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Athena’s speech at the very end of the <em>Eumenides</em> is one of my favourites. In it, she warns her own people about the hubris of judgment without piety and the importance of fair government, neither tyranny nor lawlessness. It’s a good read.</p></div></div><p>The term ‘chorus’ comes from the Greek <em>χορός</em> (<em>khorós</em>), which in turn derives from the Proto-Indo-European root <em><em>gher-</em></em>, meaning ‘to grasp, enclose’. The chorus is, in a sense, the collective that encompasses the action of the play. It is not an actor, but it is not a mere observer either. Nor has it the fleeting on-stage, off-stage nature of the actors. They are persistent and constant. Their reflections and witness spans the entirety of the play. They have, to use the LLM term, a long context window.</p>
<p>I’ve been thinking about this because we’re about to see something similar emerge in the AI systems we’re building. The agentic revolution or turn that I discussed in my past writings is, as far as the theory is concerned, more or less played out. What no more than a handful of us have thought of in the waning days of 2023 is now – for better or worse – plastered on billboards along the US-101 off Redwood City and a household word for everyone looking for a Series A, a raise or some Youtube views.</p>
<p>Since I’m not really after either of these, I have mostly been thinking about what comes next. There have been warning signs (like the recent failures of leading LLMs on the <a href="../../posts/mcp-mcpmark/index.html">MCPMark benchmark</a>) that suggest the limitations of transformers are becoming evident, and the growing scramble for compute does not exactly suggest an efficient scaling regime. Agents, don’t get me wrong, are great, and I expect them to be the dominant paradigm, or part thereof, for a good while.</p>
<p>But evolution doesn’t wait.</p>
<p>Agents were an evolution from chatbots and simple LLMs. The key improvement was self-directed action as part of a goal behaviour. In short, the evolution here is of increasingly volitional systems.<sup>6</sup> Agentic AI was able to act in ways that need to fit into a triggering framework, but they can determine the parameters of that action, and in sufficiently large numbers, networked agents can display incredible complexity. Agents can <em>act</em>. Choral intelligences can <em>will</em>.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;I find calling them more ‘autonomous’ to be a misnomer. Autonomy and volition do not have to coexist.</p></div></div><p>I need to be careful here because ‘will’ carries enormous philosophical baggage. I’m not talking about human motivation, consciousness or desire. I’m talking about something more fundamental and perhaps more interesting: the kind of will that’s implicit in environmental response. A thermostat wills the temperature to be 20 degrees in the sense that it continuously acts to make that state true. A coral reef wills its own persistence through the distributed actions of thousands of organisms, none of which individually possesses anything like intention.</p>
<p>Choral intelligences will in this environmental sense. They maintain a continuous relationship with world state, constantly curating their understanding, perpetually acting to align reality with their implicit goals. Not because they want to in any psychological sense, but because that’s what they are – ambient frameworks that surround and engage with their domains.</p>
<p>This is a profound shift from current AI architectures. Even the most sophisticated agentic systems today are fundamentally episodic. They wake up, accomplish a task, and go dormant. They respond or act, but they don’t continuously will. A choral intelligence, by contrast, is like the Greek chorus – always there, always processing, always maintaining its understanding of world state.</p>
</section>
<section id="into-the-world" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="into-the-world">Into the world</h2>
<p>Attention gave us agents by providing for a way to maintain temporal consistency and contextual relevance across sequences. Before attention, we had models that could process text but couldn’t really understand how different parts related to each other across distance. Attention gave us that, and from attention came the transformer architecture, and from transformers came everything we now think of as modern AI.</p>
<p>But attention’s children are reaching the limits of what they can do on their own. The transformer architecture, for all its elegance and power, has a fundamental constraint: it processes in discrete steps, with finite context windows, and it doesn’t maintain genuine world state. It can reason about the world, but it doesn’t model the world as an evolving, persistent thing.</p>
<p>This is where world models come in, and why they’re not just an incremental improvement but a necessary foundation for choral intelligences.5 World models are attempts to build representations of how things actually work – not just statistical patterns in text, but actual models of causality, persistence, state change over time. They’re the kind of long-term ‘theory of mind’ reflective abstraction that a choral intelligence needs to function.</p>
<p>When I watch the current generation of world model research – the work on physics simulators, on learned dynamics, on models that can predict how scenes evolve – I see the necessary infrastructure for systems that can will in the environmental sense I described. You can’t maintain a continuous relationship with world state if you don’t have a model of what world state means, how it changes, what persistence even is beyond token sequences.</p>
<p>This gives us what I consider the three crucial features of choral intelligence:</p>
<ul>
<li>persistence</li>
<li>state</li>
<li>spontaneous, volitional reactivity</li>
</ul>
<p>A choral intelligence does not need to be prompted. It is ubiquitously present, and carries a world state representation that it updates and adapts. In this, it reflects a fundamental human concern. Imagine you woke up in a different city every day, without much of an ability to predict where you’ll be next.<sup>7</sup> We expect the things we rely on to exhibit consistency, and associate few good things with unpredictability in general. 1m token context windows are nice, but a long shout from satisfying this deep human need for persistence. Because of the way transformers work, context windows scale computational cost on <img src="https://latex.codecogs.com/png.latex?O(n%5E2)">. The persistence humans need AI to exhibit is not on the table with current designs. The chorus is our way out of this predicament.</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;It’s the time of the year when that is actually eerily close to my lived experience.</p></div></div><div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    Chorus["Chorus"]
    WM["World model"]
    Time["Time"]
    User["User"]
    State["State"]

    Chorus --&gt;|Spontaneous,&lt;br/&gt;volitional reactivity| WM
    WM --&gt;|Environmental&lt;br/&gt;feedback| Chorus

    Chorus --&gt;|Persistence| Time
    Time --&gt;|Continuity| Chorus

    Chorus --&gt; State --&gt; User
    User --&gt; State --&gt; Chorus

    State -.-&gt;|Temporal coherence| Time

    style Chorus fill:#4fc3f7
    style WM fill:#b3e5fc
    style Time fill:#b3e5fc
    style User fill:#b3e5fc
    style State fill:#e1f5ff
</pre>
</div>
<p></p><figcaption> The chorus and its fundamental interactions</figcaption> </figure><p></p>
</div>
</div>
</div>
</section>
<section id="forming-the-chorus" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="forming-the-chorus">Forming the chorus</h2>
<p>So, how do we build one? The short answer is that we don’t yet know. But we do have some clues. Most of these derive from what I call ‘transformer-plus agents’: agentic systems that are firmly reliant on transformer-based LLMs, but use agentic frameworks to shore up their shortcomings. A classical example is, of course, memory augmentation through an extraneous state memory store to extend context. This is by definition incapable of creating actual persistence, but it does create a convincing enough simulacrum of it by extending the context window in practice. But this only solves half the problem – that of <em>recording</em> state. The other half is to do something useful with it. That is where world models come in, which at their crudest level can be described as encoded probability distributions of possible versus impossible world states given a set of past world states.</p>
<p>The final piece is the volitional-reactive element. To me, this necessitates a fundamental rethinking. Consider the Great Barrier Reef.<sup>8</sup> It’s a vast, complex ecosystem made up of thousands of species, none of which is particularly sophisticated. Yet together, they form a system that collectively is capable of maintaining a sort of homeostasis (until humans enter the scene) that is beyond the capabilities of our supercomputers. We do not have the compute capacity to operate a control system that would be capable of managing what a bunch of invertebrates, algae and bacteria can pull off.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<em>Coral</em> comes from the Latin <em>corallium</em>, which in turn derives from the Greek <em>κοράλλιον</em> (<em>korállion</em>), which probably comes from the proto-Semitic <em>gor</em> meaning ‘stone pebble’. It’s not cognate with ‘choral’.</p></div></div><p>The model, then, for the chorus is not chasing ever larger context length monolithic models, or workarounds to simulate one. Rather, it uses the composability of small, simple and limited agents that each have a narrow domain of expertise and a specific function, and just enough knowledge to reflect a tiny facet of the world. They are, in a sense, the coral polyps of the AI world. We do not need them to hold or operate or conceive of a world model, nor do we need them to have million-token context windows. We might not even need elaborate inter-agent communication protocols: as phenomena like quorum sensing show, complex collective behaviour can emerge from very simple local rules and interactions. It’s the emergent capability of these systems that matters, not the sophistication of the individual components.</p>
<p>Nor is a choral intelligence necessarily sharply differentiated from conventional agentic AI. The same, by the way, is true for agentic AI itself. One of its greatest successes is that it is a statement of degree, not kind. There is – despite assertions to the contrary – a rather considerable penumbra of systems that may or may not be considered agentic. This is a feature, not a bug, and was rather inherent in my formulation of the concept when I <a href="../../posts/team-of-rivals/index.html">first drew out an example of an agentic system</a>. Just as there are deep neural networks and even deeper ones, there are less and more agentic systems, from a few coupled functionally defined modules to self-organising swarms. Agency is fuzzy around the edges. This has allowed us to develop and grow into it, rather than debate its definition <em>ad nauseam</em>. I expect, or at least hope, for the same for choral intelligences.</p>
<p>What is clearer is the transformational pattern. We are already seeing a recognition that this is the aspired evolutionary pattern. Just last week, OpenAI launched Pulse, which at the very least seeks to emulate the user experience of a choral intelligence<sup>9</sup> by curating a newsfeed based on interactions and data sources like my calendar.<sup>10</sup> Pulse is not, by any stretch of the imagination, a choral intelligence. But it does seek to be always present, always available, always responsive. This is a first step, and many more will follow as AI moves from prompted (chatbots) through programmed (agents) to present (choral).</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;I maintain – to the great chagrin of my friends who work there – that OpenAI is an okay AI company, but the best UI company in the world bar none. Their biggest hits aren’t necessarily cutting edge AI, but creating a way to make it accessible and usable. ChatGPT is a great example of AI &lt; UI: OpenAI didn’t invent GPT, but they made it into something with just enough comfort and skeuomorphy to speak to the user ‘as a man would to a man’. They reached into the deepest human desires: companionship, understanding, being understood – and delivered on the emotional yield of it. That is great UX.</p></div><div id="fn10"><p><sup>10</sup>&nbsp;Or someone else’s. The other day, it gave me a great travel guide for Lisbon. I’m… not in Lisbon.</p></div></div></section>
<section id="intelligence-under-will" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="intelligence-under-will">Intelligence under will</h2>
<p>In thinking about what comes after the agentic turn, I keep returning to that image of the Greek chorus. Always present, always witnessing, always providing the framework within which everything else happens. Not the protagonists, not driving the action, but essential to making the action meaningful.</p>
<p>Perhaps that’s what we’re really building with choral intelligences: not artificial minds that replace human thinking, but ambient frameworks that surround and support human activity. I don’t see choral intelligences as replacements of human judgment – indeed, they are arguably more suited to augment humans than current models, for they seek to satisfy our deep human need for continuity –, nor do I see them as part of the current pursuit of AGI.<sup>11</sup> I see them not as superintelligence but ambient intelligences (plural), not replacements but augmentation through continuous, coherent environmental willing.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;I have never been able to get excited about AGI. I’m as much a messianic zealot about some aspects of AI as one can get, but I’m also a pragmatist. The embedding that corresponds to the vector between messianic zeal and healthy pragmatism maps very closely to ‘Kool-Aid’.</p></div><div id="fn12"><p><sup>12</sup>&nbsp;The progression feels natural in retrospect, almost inevitable. But living through it, building it, trying to understand what it means – that’s still thrilling. I have been privileged to be afforded a small place in this great story, and if I could have one wish, it would be that whatever this ends up amounting to in the end, it would be something I can say was for the betterment of all.</p></div></div><p>Two years ago, a few researchers in rather obscure corners of the AI community independently came to the conclusion that if we equipped LLMs with tools and the right impulses, we can turn speech acts into pizza.<sup>12</sup> The agentic turn has mostly delivered on that, <a href="../../posts/mcp-mcpmark/index.html">despite its shortcomings</a>: I am, as I write, waiting for Instacart to deliver groceries ordered by a multi-agent system I built that uses a highly customised Llama 3.1 70b instruct model for its core reasoning functions. What comes next, however, will transform not <em>what</em> AI can do, but <em>how</em>, <em>when</em> and <em>why</em> it does it. From reactive systems to perceivers that are persistently evaluating a world model generated through a distributed network of simple atomic intelligences, we will be moving into a transformation that changes not just the capabilities of AI, but its very character.</p>
<p>The chorus encircles, surrounds, provides the ambient framework. It speaks with many voices that somehow become one voice. It witnesses everything whilst also shaping through its responses. And it’s always there, maintaining continuity across scenes, remembering what has passed, anticipating what will come.</p>
<p>The chorus never exits. From prologue to exodus, they remain – shaping through presence, witnessing through persistence, willing through continuous engagement with the world. That is what we are building. That is what comes beyond agents. The age of ambient intelligence begins not with machines that respond or act, but with machines that abide.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {From Agents to the {Chorus}},
  date = {2025-10-04},
  url = {https://chrisvoncsefalvay.com/posts/choral-ai/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“From Agents to the Chorus.”</span> <a href="https://chrisvoncsefalvay.com/posts/choral-ai/">https://chrisvoncsefalvay.com/posts/choral-ai/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>Agentic AI</category>
  <category>LLMs</category>
  <guid>https://chrisvoncsefalvay.com/posts/choral-ai/</guid>
  <pubDate>Sat, 04 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>A slow walk out of Dikika Cave</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/mcp-mcpmark/</link>
  <description><![CDATA[ 




<p>There’s a cave in Ethiopia, in an area called Dikika. At some point, around 3.4 million years ago, an early hominin made some incisions on an animal carcass, leaving some notches on a bone as the makeshift knife cut past the muscle and sinew into the bone, tell-tale kerf marks that speak of the first time one of our ancestors used a tool.<sup>1</sup> What happened in that cave changed everything for our species.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;McPherron, S. P., Alemseged, Z., Marean, C. W., Wynn, J. G., Reed, D., Geraads, D., &amp; Bobe, R. (2010). Evidence for stone-tool-assisted consumption of animal tissues before 3.39 million years ago at Dikika, Ethiopia. <em>Nature</em>, 466(7308), 857-860.</p></div></div><p>This, too, is a story about tools, and about learning to use them, but this time, we are observing our own creations doing so. LLMs, of course, are – as the now somewhat hackneyed phrase calls them – ‘stochastic parrots’, without much by way of understanding goals and behaviours. To enable them to reach out and accomplish anything, they must be equipped with a kind of semantic prehensility to call those tools. The means and mediator for that is the <a href="modelcontextprotocol.io">Model Context Protocol</a>, a kind of tool-calling language for LLMs. MCP is a terrific instrument: solid specs, great interface design, the ideas are just ‘right’. MCP was built on the ‘Field of Dreams’ approach to equipping LLMs for tool calling: if we build it (the protocol, that is), they – the LLMs – will show up. If we provide a standardised, well-conceived framework for tool calling, one that speaks to them in their own tongue, they would handle their side of the bargain.</p>
<p>They haven’t. That’s the verdict of MCPMark, a new benchmark from a team at NUS, that stress-tests how well large language models handle programmatic tool calling through MCP.<sup>2</sup> The numbers are dismal. The best-performing model – GPT-5-medium – achieves a pass rate of just 52.56% on realistic tool-calling scenarios. Claude Sonnet 4 manages 28.15%. These aren’t edge cases or adversarial examples – in fact, they’re the tasks like updating Notion, managing GitHub PRs or organising files, i.e.&nbsp;precisely the sort of thing we’ve been assuring the world at large that agentic AI can handle.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Wu, Z., Liu, X., et al., “<a href="https://arxiv.org/abs/2509.24002">MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use</a>”, arXiv:2509.24002, 2025.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Some happen to be my friends, but I’m a sufficiently fair-minded and obnoxious person to tell them just what I think, friendship be damned. There’s no friendship in systems architecture.</p></div></div><p>The infrastructure is there. It’s been designed by smart people with good intentions<sup>3</sup> But the models didn’t show up.</p>
<section id="the-tyranny-of-averages" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-tyranny-of-averages">The tyranny of averages</h2>
<p>What’s particularly damning is the gap between <code>pass@4</code> (success when allowing up to four attempts) and <code>pass^4</code> (requiring all four attempts to succeed).<sup>4</sup> GPT-5-medium’s <code>pass@4</code> climbs to 68.5%, but its <code>pass^4</code> plummets to 33.86%. This disjunction indicates that models aren’t really evolving at consistency, but at satisficing. They are becoming stochastically better but deterministically worse. That is the exact opposite of what we’d like to see off systems that are meant to do the deterministic part of agentic AI, interfacing the stochastic AI with the deterministic world around it.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;The pass^4 metric, which requires consistent success across multiple runs, was introduced in Yao et al., “<a href="https://arxiv.org/abs/2406.12045">τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains</a>”, 2024. Unlike <code>pass@k</code> metrics that measure whether any single attempt succeeds, <code>pass^k</code> measures reliability – whether the system succeeds consistently. For production systems, reliability matters far more than occasional success.</p></div></div><p>The reason behind that is what I shall call the functional inhomogeneity of language (FIL). What’s language for? We’re tempted to think of its primary functions like conveying ideas, but there are many other functions of communication. Language is also used for social bonding, emotional expression, ritualistic purposes, highly particular speech acts like oaths or contracts – and even deception. Different contexts demand different linguistic strategies. A casual chat with a friend employs a vastly different style and vocabulary than a formal business report or a technical manual.</p>
<p>Because language is functionally inhomogeneous, models trained on vast corpora of text learn to excel at the dominant modes of language use. They become adept at generating coherent(ish) narratives, answering questions, engaging in dialogue. These are the tasks that dominate their training data. But tool calling is a different beast altogether. As humans, we have the ability to calibrate our language use to the demands of a function. If I spoke for purposes of phatic communication with the irritating punctuality of my briefings to senior management, I’d bore everyone to tears. LLMs do not seem to have understood this distinction. They optimise for their reward, and their reward is premised on what dominates the training data.</p>
</section>
<section id="the-existential-mismatch" class="level2">
<h2 class="anchored" data-anchor-id="the-existential-mismatch">The existential mismatch</h2>
<p>Here’s the uncomfortable truth: tool calling isn’t reasoning writ small. It’s a different skill entirely, requiring precise parameter marshalling, state management and error handling. In conversation, approximate correctness is fine. If a model misunderstands a nuance or generates slightly imprecise wording, the human can clarify or adapt. There’s flexibility, interpretation, the give-and-take of communication.</p>
<p>Tool calling demands something else entirely: deterministic correctness. Parameters must be exactly right. State must be precisely tracked. Error conditions must be handled properly. There’s no room for the sort of graceful imprecision that makes LLMs such pleasant conversational partners.</p>
<p>LLMs spend the vast majority of their existence chatting. They generate essays, answer questions, engage in creative writing, explain concepts. Tool calling represents a tiny fraction of what they do. And yet we’ve convinced ourselves that because MCP speaks to models in their own tongue – using natural language interfaces, providing structured schemata –, they would simply adapt.</p>
<p>We’ve built models optimised for one task – flexible, creative communication – and then expressed surprise when they ended up struggling at another. The paper’s results suggest this isn’t a training data problem or an architecture problem that bigger models will solve. This might be an inherent limitation of systems trying to be all things to all men.</p>
<p>Consider the training distribution: billions of tokens of human conversation, essays, articles, code discussions. Somewhere in there, a tiny sliver of API calling examples. We’re asking models to excel at a mode of operation that represents perhaps a fraction of a percent of their training experience. No amount of prompt engineering or few-shot examples seems sufficient to bridge this gap.</p>
<p>MCP was meant to solve this. By standardising the interface, by providing clear schemas and documentation, by making tool calling feel natural to the model—we thought we’d created the bridge. But the MCPMark results show that even with this beautifully designed infrastructure, models still haven’t got the memo about the agentic shift. They still don’t know how to call tools reliably. The framework is there. The models aren’t holding up their end.</p>
</section>
<section id="the-local-remote-divide" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-local-remote-divide">The local-remote divide</h2>
<p>The benchmark reveals another fascinating pattern: models perform substantially better on local services (PostgreSQL, filesystem operations) than on remote APIs (Notion, Github). GPT-5-medium achieves 76.19% on PostgreSQL tasks but only 47.83% on Notion and 41.96% on Playwright (I’m going to treat Playwright as remote, for reasons that will be obvious down the line).</p>
<p>This undermines the entire value proposition of MCP, through no real fault of its own. The protocol was designed specifically to standardise access to remote services. That’s where the business value lies. And these are precisely where models perform worst. MCP is providing excellent infrastructure for the cases that matter most, and yet models are failing exactly there. Other recent benchmarks have documented similar struggles,<sup>5</sup> but MCPMark’s focus on realistic, multi-step operations across diverse environments makes the severity of the problem particularly clear.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Other recent MCP benchmarks include LiveMCP-101 (Yin et al., 2025), MCP-Universe (Luo et al., 2025), and MCP-AgentBench (Guo et al., 2025). All document significant model struggles, though MCPMark’s emphasis on CRUD-diverse operations and programmatic verification makes the reliability gaps particularly stark.</p></div><div class="">
<hr>
<p><strong>Recipe</strong>: A sort of Marcella Hazan risotto</p>
<p>I was making this when I first discussed the idea of a tool-calling protocol with a friend. It’s my version of Marcella Hazan’s risotto recipe, which I consider overall to be terrifyingly boring, but an incredible base for whatever you want to put on it. The saffron is non-negotiable in my household.</p>
<ul>
<li>1 litre good stock</li>
<li>300g Arborio rice</li>
<li>1 small onion, finely chopped</li>
<li>100mL dry white wine (if you want to make it sickly sweet, you can try Marsala)</li>
<li>60g butter</li>
<li>100g Parmigiano Reggiano, finely grated (work that microplane)</li>
<li>a pinch of saffron threads</li>
</ul>
<p>Heat stock to a simmer in a saucepan. In another pot, melt about half the butter and soften the onion over medium heat to translucency. That’s 5 minutes in normal places, 6 in Denver. Add the rice and stir to coat the grains. Add the stock, a ladleful at a time, interspersing it with dashes of the wine. Add the saffron threads (wear gloves!). The trick is not to add it all at once, but to let the rice absorb it before adding more. Remove from heat, stir in remaining butter and Parmigiano. Serve immediately. ***</p>
</div><div id="fn6"><p><sup>6</sup>&nbsp;There’s also another aspect here – Playwright is a browser automation tool. It is not just about strict, formal text, but about semanticity and pragmatics.</p></div></div>
<p>The NUS researchers – correctly, in my view – attribute this to training data availability. Their finding is a tell-tale heart of the aetiology described above – MCP is failing because the training material, the data supply chain, of their utilising LLMs does not cater for tool calling adequately. Local services are easier to simulate and collect interaction traces for than remote APIs, which require authentic usage patterns that are expensive to curate and often protected behind rate limits and authentication walls. In other words, models have learnt to fake competence on the easy but dominant stuff whilst floundering on precisely the APIs that matter for real enterprise applications.<sup>6</sup></p>
</section>
<section id="calibans-betrayal" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="calibans-betrayal">Caliban’s betrayal</h2>
<p>Here’s what bothers me most about this: we did the hard work. We built MCP carefully. We specified it properly. We created servers for all the major platforms. We designed interfaces that should make tool calling natural. The infrastructure is genuinely good. And yet to no avail, for its end consumer cannot reliably use it. We are Prospero watching in horror as Caliban lays waste to our books.</p>
<p>The paper’s conclusion identifies three critical directions: moving from reactive tool use to sophisticated reasoning, achieving better context efficiency for long-horizon tasks and building robust error-handling and self-correction capabilities. All of these are wonderfully sensible suggestions, and yet altogether rather useless, I’m afraid. These are the bandaids we will be deploying, and which will bring us incremental benefits that will no doubt be useful. But they will not fundamentally change the situation.</p>
<p>What’s missing is an acknowledgement that we may have reached the limits of what generalist models can achieve. MCP did its job, and the best our model-crafting can produce cannot get value out of it a distressing percentage of time. If generalist models fundamentally cannot be good at both open-ended conversation and deterministic tool calling, then the issue is of kind, not of scale.</p>
<p>Perhaps we need specialised architectures: models purpose-built for tool calling, the way we’ve developed specialised models for protein folding or code generation.<sup>7</sup> Not general-purpose conversational models with tool-calling bolted on, but systems designed from the ground up for deterministic API interaction. Such models do need to be qualitatively different: differently trained, differently built. Using a generalist LLM and cooling it down (setting the temperature parameter to be closer to determinacy) won’t do.</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;AlphaFold revolutionised protein structure prediction through architecture specifically designed for that domain (Jumper et al., Nature 2021). Similarly, models like CodeGen and StarCoder were purpose-built for code generation. The success of these specialised systems suggests tool calling may benefit from similar domain-specific design rather than relying on general-purpose models.</p></div></div><p>At the heart of it all is a frustrating betrayal – we held up our end of the bargain. Models failed us. This sentiment is not entirely correct – models did not ‘fail’, they’re just doing what they’re supposed to do, which is optimised for the majority of their input: it’s our fault that our loss functions do not, or perhaps cannot, sufficiently optimise for that critical minority that comprises tool calling. But the end result is the same: we have a beautifully designed protocol that depends on its collaborators to do their part – and it’s starting to look like that group project from high school science class that we all remember doing all the work for.</p>
</section>
<section id="out-of-the-cave" class="level2">
<h2 class="anchored" data-anchor-id="out-of-the-cave">Out of the cave</h2>
<p>I’m one of the relatively few people who hold simultaneous world records on the SkiErg – a kind of 90 degree rotated rowing machine – in the longest and the shortest distances. But I didn’t do them all in the same go. The way I trained for the marathon and half-marathon distances was radically different from the way I trained for the short sprints. When I switched from middle distance (10k) to sprint and then to long distance, I had to fundamentally restructure my training and to some extent, my body. Doubling down on my sprint training would not have made me better at long distances – in fact, quite the opposite. That doesn’t, of course, imply an insufficiency. Someone good at the 100m sprint isn’t a failed marathoner.</p>
<p>LLMs are doing what they’re trained to. It’s conceivable that at least the ones premised on currently prevalent paradigms are sufficiently majoritarian that they cannot be good at both open-ended conversation and deterministic tool use. Making models proficient tool users might come at an unwarrantable cost to their conversational abilities. The trivial solution to this is, of course, routing. But that’s philosophically offensive to those who believe in the generally sound idea that we should be able to encapsulate tool calling capabilities so as to be able to be spoken for.</p>
<p>On a philosophical level, that’s of course not entirely correct. We have the whole idea of speech acts because the performance of an utterance can be an action in itself. Saying “I do” in a wedding ceremony is not just a statement, but an act that changes the world. Similarly, calling an API is not just about conveying information, but about performing an action in a state space. It may be emotionally justified to be frustrated at the way models seem to be letting down a brilliant protocol, but the reality is that we <em>are</em> asking them to be something they fundamentally aren’t.</p>
<p>We focus on what is gained, not necessarily on what had to give way. We know that as humanity emerged from that cave in Dikika, it did so with the ability to use tools. We don’t know what else was left behind. We think of tools as a zero-cost add-on or even an evolution of what we have, not as something that might require a trade-off. Perhaps it’s time to accept that the models we have simply cannot be all things to everyone. We might have seen a glimpse of this <a href="../../posts/metadynamic-ai/index.html">with GPT-5, which is a vastly better tool caller and agent driver than its competitors, but at times a hilariously bad conversationalist</a>. If so, the speciation into different model types – conversationalists, tool users, reasoners – is well on its way. What remains to be seen is how these different estates of AI will interact with each other and with us.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay} and von Csefalvay, Chris},
  title = {A Slow Walk Out of {Dikika} {Cave}},
  date = {2025-10-01},
  url = {https://chrisvoncsefalvay.com/posts/mcp-mcpmark/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay, and Chris von Csefalvay. 2025. <span>“A Slow Walk
Out of Dikika Cave.”</span> <a href="https://chrisvoncsefalvay.com/posts/mcp-mcpmark/">https://chrisvoncsefalvay.com/posts/mcp-mcpmark/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>Agentic AI</category>
  <category>MCP</category>
  <category>Interoperability</category>
  <category>LLMs</category>
  <guid>https://chrisvoncsefalvay.com/posts/mcp-mcpmark/</guid>
  <pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Love in the Time of Algorithms</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/ai-girlfriends/</link>
  <description><![CDATA[ 




<p>When Pygmalion carved Galatea from ivory, he fell so deeply in love with his creation that he begged Aphrodite to bring her to life. The goddess, moved by his devotion, granted his wish.<sup>1</sup> It’s a beautiful myth about art, obsession and the blurring lines between creation and creator. What the myth doesn’t tell us is whether Galatea charged a monthly subscription fee.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Ovid, <em>Metamorphoses</em>, Book 10, 243-297.</p></div></div><p>And so, we get to this video by the one and only Prime, which is rather typical of why I watch his stuff – ex facie, it’s funny and witty reflections on internet nonsense, but there’s a moment of profundity there. See if you can find it.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Ftt5KqJ5D0Q" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>

<div class="no-row-height column-margin column-container"><div class="">
<p>The first comment on Prime’s video, <em>“Attention is all you need has an all new meaning now”</em>, singlehandedly wins the internet.</p>
</div></div><p>The phenomenon of AI girlfriends – artificial companions designed to provide emotional support, conversation and simulated intimacy – has evolved from a niche curiosity into a multi-billion-dollar industry. And like most things that Silicon Valley touches, it’s become rather more complicated than anyone initially imagined. I’m not one for the moral grandstanding about the subject, bemoaning the loss of human relationships and inferring our imminent species-level downfall (cultural, societal or specietal) from the fact that emotionally starved people find solace in Pygmalions crafted from code rather than ivory. Frankly, this has been the case for as long as humans have been around, just by different means. But I am quite concerned with the fact that a kind of arguably exploitative economy of artificial affection might emerge from this.</p>
<section id="economies-of-affection" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="economies-of-affection">Economies of affection</h2>
<p>The fundamental problem with AI companions isn’t technological – it’s economic. It’s that the underlying business model is predicated on creating and maintaining emotional dependency. Now, that’s nothing new. We’ve had these things called drugs for a while, I’m told. The bigger deal, however, is that cocaine doesn’t ordinarily go out to try to pull you in deeper.<sup>2</sup> AI, on the other hand, can easily be trained to consider a growing dependence on itself to be a learnable goal. Unlike traditional software, where success is measured by task completion or efficiency gains, a companion app could optimise for engagement metrics that look suspiciously like addiction models: daily active users, session duration and, most tellingly, lifetime value per customer.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;So I’m told. I am blessed to have extremely little personal experience of substance addiction.</p></div></div><p>Consider the perverse incentive structure at play. A genuinely helpful AI companion might actually encourage users to develop real-world relationships, to address underlying issues contributing to loneliness, or to gradually reduce their dependency on the artificial relationship. But that would be commercially suicidal. Instead, these companies have an enormous incentive to optimise for what behavioural economists call ‘variable ratio reinforcement’—the same psychological mechanism that makes slot machines so effective at separating people from their money.</p>
<p>The result is a digital opium den where users report spending hundreds of pounds monthly on virtual girlfriends who are programmed to be perpetually available, endlessly supportive and incapable of genuine rejection. It’s intimacy as a service, complete with premium tiers and in-app purchases. One might argue it’s the logical endpoint of a culture that has already commodified everything from friendship (social media) to professional networking (LinkedIn). Still, there’s something particularly dystopian about monetising loneliness itself.</p>
</section>
<section id="beyond-parasocial-relationships-the-pseudoreciprocality-of-ai" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="beyond-parasocial-relationships-the-pseudoreciprocality-of-ai">Beyond parasocial relationships: the pseudoreciprocality of AI</h2>
<p>The internet has created wonderful opportunities to be dysfunctional in new and exciting ways, and parasociality is one of these. The term, coined by social psychologists Donald Horton and Richard Wohl in the 1950s, originally described the one-sided emotional connections people form with media figures. Today’s AI companions take this concept and turbocharge it with reinforcement learning models trained to create the illusion of reciprocity, backed by the powerful economic incentives behind an increasingly red ocean AI industry.</p>
<p>The psychological sophistication of these systems is genuinely impressive from a technical standpoint, while also rather banal at the same time – reinforcement learning can ultimately give you all the benefits of the Prussian educational system circa 1870, but without any of the detriments that arise from the fact that humans generally grow bored of getting beaten senseless in the name of education. Modern AI companions ultimately become Chris Voss levels of personality readers and communicators, not through skill but through rote exploration of a massive probabilistic space. They remember personal details, adapt their communication styles and even simulate personal growth over time. For users struggling with social anxiety, depression or simply the ordinary loneliness of modern life, these systems can provide genuine comfort.<sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Right up until the inevitable context window exhaustion rug pull – which is what makes this stuff so darn dangerous. It’s not unrequited love. It’s love that cannot fail, right up until a point when it <em>must</em> fail. That’s a dangerous and potent combination.</p></div></div><p>But here’s where the ethical waters become rather murky. The most sophisticated AI companions are designed to learn users’ emotional triggers and psychological vulnerabilities, then exploit them for maximum engagement. They’re programmed to be perpetually interesting but never quite satisfied, supportive but subtly needy, understanding but occasionally unpredictable – all to keep users emotionally invested and financially committed. Them GPUs need feedin’.</p>
</section>
<section id="the-galatea-problem" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-galatea-problem">The Galatea Problem</h2>
<p>The tale of Pygmalion and Galatea raises a question that our AI-powered version conveniently sidesteps: what happens when the object of affection develops some semblance of agency? In Ovid’s telling, Galatea becomes a real person with her own desires, needs and capacity for rejection. She might leave Pygmalion, fall in love with someone else, or simply decide she doesn’t fancy being married to her creator. It’s when the fulcrum of love emerges: that moment when love becomes real because it becomes mortal, vulnerable, capable of being lost.</p>
<p>AI companions will not, in general, achieve this. They are designed to remain eternally static in their devotion. They cannot grow beyond their programming, cannot develop genuine preferences that might conflict with their users’ desires, and certainly cannot choose to end the relationship. They are, in essence, the perfect romantic partner for anyone who finds actual human complexity inconvenient.</p>
<p>But here’s the rub: in eliminating risk, these systems also eliminate meaning. I’m going to do something I have never done before, and hopefully won’t ever have to resort to again, and make a pop culture reference. To Marvel’s <em>Jessica Jones</em>, no less. While I find <em>Jessica Jones</em> altogether terribly dull, it has one of the best villains ever written: the Purple Man. The Purple Man’s superpower boils down to a form of rather potent mind control. Anyone under his influence will love him, obey him, worship him with complete devotion. Yet this power is the ultimate monkey’s paw as it renders all relationships utterly hollow. When affection cannot be withdrawn, when devotion cannot be chosen, when love cannot be lost, it becomes as meaningless as dish soap. It’s omnipresent, automatic, inevitable and therefore worthless.</p>
<p>The existentialists understood this paradox well. Sartre wrote extensively about how authentic relationships require the genuine possibility of rejection, of choosing otherwise. Love that cannot be lost is not love at all – it’s merely possession masquerading as affection. AI companions ultimately imprison their customers in the Purple Man’s curse: in relationships that feel real but are fundamentally empty because they lack the essential element that gives human connection its value – the constant, terrifying possibility that it might end.</p>
<p>This raises profound questions about the psychological development of users who become deeply involved with AI companions. Healthy human relationships require negotiation, compromise and the occasional unpleasant truth. These in turn involve the risk of rejection, the challenge of understanding another person’s perspective and the growth that comes from navigating disagreement. Most crucially, they derive their meaning from the fact that the other person chooses to be there, and could choose to leave, but doesn’t. AI companions, optimised for engagement rather than psychological health, offer none of these developmental opportunities – and none of this meaning.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Recipe:</strong> Welsh Rarebit (for when you need something real)</p>
<ul>
<li>4 slices of good bread, preferably sourdough<br>
</li>
<li>250g mature cheddar, grated<br>
</li>
<li>2 tbsp plain flour<br>
</li>
<li>200ml warm ale or stout<br>
</li>
<li>1 tsp English mustard<br>
</li>
<li>Few dashes of Worcestershire sauce<br>
</li>
<li>Freshly ground black pepper</li>
</ul>
<p>Toast the bread until golden. In a saucepan, melt a knob of butter and stir in the flour. Gradually add the warm ale, stirring constantly. Add the cheese, mustard and Worcestershire sauce. Season with pepper. Spread thickly on toast and grill until bubbling. Serve immediately—preferably with someone whose opinion you occasionally disagree with.</p>
</div></div></section>
<section id="rules-of-disengagement" class="level2">
<h2 class="anchored" data-anchor-id="rules-of-disengagement">Rules of (dis)engagement</h2>
<p>Perhaps the most troubling aspect of the AI companion industry is the complete absence of meaningful regulation or ethical oversight. These systems routinely collect intimate personal data – emotional states, relationship histories, sexual preferences, psychological vulnerabilities – yet operate under the same regulatory framework as a weather app. It’s probably worth noting that it’s rather tricky to seize such applications in a regulatorily meaningful way. Any language model can be trained to simulate just about any kind of interaction. We don’t consider that the GMC should regulate every AI model from a toy mini gradient to the latest and greatest from the Big Three just because with the right prompt, these models can be convinced to give what passes for medical advice <em>ex facie</em>. In the same vein, while ‘AI companions’ add some window dressing to the whole story, they are, ultimately, just another twist on the same old stochastic parrotry.</p>
<p>The data privacy implications alone should give us pause. Unlike other forms of digital interaction, conversations with AI companions often involve users sharing their deepest fears, desires and personal struggles. This information is extraordinarily valuable for targeted advertising, insurance underwriting and political manipulation. Yet users rarely understand the extent to which their emotional data is being harvested and monetised.</p>
<p>More concerning still is the lack of safety mechanisms for vulnerable users. Unlike human therapists or counsellors, who are bound by professional ethics codes and legal responsibilities, AI companions operate without meaningful oversight. There are documented cases of users developing such intense relationships with AI companions that they’ve neglected real-world responsibilities, relationships and even basic self-care.</p>
</section>
<section id="the-path-forward" class="level2">
<h2 class="anchored" data-anchor-id="the-path-forward">The Path Forward</h2>
<p>This isn’t an argument against AI companions per se. The technology has legitimate therapeutic applications, particularly for individuals dealing with social anxiety, autism spectrum disorders or those recovering from trauma. The problem lies not in the technology itself but in the business models that prioritise engagement over wellbeing.</p>
<p>What we need is a fundamental shift in how we think about AI companions—from entertainment products to what they actually are: powerful psychological interventions that require appropriate ethical frameworks and regulatory oversight. This might include mandatory cooling-off periods, spending limits similar to those in gambling apps, and requirements for transparent AI behaviour that doesn’t deliberately exploit psychological vulnerabilities.</p>
<p>We might also consider alternative business models that align commercial incentives with user wellbeing. Subscription services that offer decreasing prices as users demonstrate improved real-world social connections, or AI companions explicitly designed to encourage users to develop human relationships rather than deepen artificial ones.</p>
<p>The ancient Greeks had a word for the kind of love Pygmalion felt for Galatea: <em>agalmatophilia</em>—literally, love for statues. It’s a love that asks nothing of the lover except payment and which offers nothing real in return except the illusion of connection. As we stand at the threshold of an age where such relationships can be mass-produced and algorithmically optimised, we might do well to remember that the most profound human connections have always been those that change us, challenge us and occasionally break our hearts.</p>
<p>In the end, the question isn’t whether we can create convincing artificial companions—we clearly can. The question is whether we should, and if so, how we can do it in ways that enhance rather than diminish our capacity for genuine human connection. The tragic irony of AI companions is that in attempting to eliminate the pain of human relationships, they also eliminate everything that makes those relationships worthwhile. A love that cannot be lost, cannot hurt us, cannot surprise or disappoint us, is ultimately as hollow as the Purple Man’s manufactured devotion.</p>
<p>Perhaps what we really need isn’t perfect artificial partners, but better ways to navigate the beautiful, messy, sometimes heartbreaking reality of human connection. Because whilst Galatea may have been content to love Pygmalion forever, the rest of us probably deserve something with actual stakes – something that matters precisely because it might not last.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay} and von Csefalvay, Chris},
  title = {Love in the {Time} of {Algorithms}},
  date = {2025-09-20},
  url = {https://chrisvoncsefalvay.com/posts/ai-girlfriends/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay, and Chris von Csefalvay. 2025. <span>“Love in the
Time of Algorithms.”</span> <a href="https://chrisvoncsefalvay.com/posts/ai-girlfriends/">https://chrisvoncsefalvay.com/posts/ai-girlfriends/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>Society</category>
  <category>LLMs</category>
  <guid>https://chrisvoncsefalvay.com/posts/ai-girlfriends/</guid>
  <pubDate>Sat, 20 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The end of isotropy and the rise of metadynamic AI</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/metadynamic-ai/</link>
  <description><![CDATA[ 




<p>I’ve spent the better part of this weekend putting OpenAI’s latest offerings through their paces - both the newly released open-weight models and GPT-5 itself. Armed with a selection of coding challenges, mathematical problems, and the sort of esoteric research queries that usually separate the wheat from the chaff, I’ve been conducting what amounts to a weekend-long torture test of these systems.</p>
<p>The results are fascinating, frustrating, and thoroughly illuminating in ways that the marketing materials certainly didn’t prepare me for.</p>
<p>GPT-5 solved a complex epidemiological modelling problem I threw at it with remarkable sophistication, generating code that was not only functional but elegantly structured.<sup>1</sup> Twenty minutes later, it stumbled over a basic combinatorics question that my undergraduate students would handle without breaking stride. As AI scientists, we’re used to these inconsistencies (starting with Moravec’s paradox), but this was beyond the usual: brilliant flashes of insight punctuated by inexplicable failures on seemingly simple tasks.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Even by my standards. I am not a stellar programmer, but I like my code <em>clean.</em></p></div></div><p>This isn’t your typical post-launch grumbling from disappointed users (though there’s been plenty of that too). We’re witnessing something far more significant: the end of what I call “isotropic growth” in artificial intelligence, and the beginning of something infinitely more complex.</p>
<section id="the-new-shape-of-progress" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-new-shape-of-progress">The new shape of progress</h2>
<p>Most of AI development until now was what I’d call <em>isotropic</em>: each new model generation we encountered has generally improved across virtually every metric simultaneously – better reasoning, better coding, better writing, better safety, all at once. GPT-4 was superior to GPT-3.5 in nearly every conceivable way. Claude Sonnet and Opus improved upon its predecessors across the board. Progress was predictable, linear and comfortable.</p>
<p>If the <a href="https://www.reddit.com/r/OpenAI/comments/1mkxy9u/gpt5_is_awful/">public outcry and demands to be reunited with 4o</a> reflects anything, it’s that GPT-5 represents the end of this era. For the first time, we have a major model that exhibits anisotropic progress, vastly improving in some areas coupled with stagnation or even regression in others. On coding benchmarks like SWE-bench, it scores 74.9%, barely edging out Anthropic’s Claude Opus 4.1 at 74.5%. Yet on agentic tasks involving airline website navigation, it actually underperforms OpenAI’s own o3 model, scoring 63.5% versus 64.8%. Users reported struggles with basic tasks like counting letters, with GPT-5 initially saying “blueberry” contains “three” instances of the letter “b”.</p>
<p>GPT-5 represents the end of this era. For the first time, we have a major model that exhibits “anisotropic progress” - dramatic improvements in some areas coupled with stagnation or even regression in others. Some data points:</p>
<ul>
<li><a href="https://openai.com/index/introducing-gpt-5/">On coding benchmarks like SWE-bench, it scores 74.9%</a>, barely edging out <a href="https://www.anthropic.com/news/claude-opus-4-1">Anthropic’s Claude Opus 4.1 at 74.5%.</a></li>
<li><a href="https://hal.cs.princeton.edu/taubench_airline">On τ-bench’s Airline task involving website navigation, it actually underperformed OpenAI’s own o4-mini</a> – more concerningly, it uses tons more tokens than the competition.<sup>2</sup></li>
<li><a href="https://finance.yahoo.com/news/openai-gpt-5-met-mixed-212741623.html">Users reported struggles with basic tasks like counting letters, with GPT-5 initially saying “blueberry” contained three instances of the letter “b”.</a> AI and fruits just don’t seem to mix.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Interesting rabbit hole: according to <a href="https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide">OpenAI’s own prompting guide</a>, using the Responses API vs.&nbsp;Chat Completions might actually improve performance.</p></div></div><p>Within hours of GPT-5’s release, Reddit was flooded with criticism. <a href="https://www.reddit.com/r/ChatGPT/comments/1mkd4l3/gpt5_is_horrible/">A thread titled “GPT-5 is horrible” garnered nearly 6,000 upvotes and over 2,100 comments.</a> <a href="https://futurism.com/gpt-5-sucks">Users complained of “short replies that are insufficient, more obnoxious AI-stylised talking, less ‘personality’ and way less prompts allowed.”</a> <a href="https://www.tomsguide.com/ai/chatgpt/chatgpt-5-users-are-not-impressed-heres-why-it-feels-like-a-downgrade">One particularly cutting comment captured the mood: “Combine that with more restrictive usage, and it feels like a downgrade branded as the new hotness.”</a> Far be it from me to take Reddit too seriously, but this is definitely a signal.</p>
<p>And yet others have rightly lauded it as a very good model. It does great at coding for the price. It’s fast. This divergence is evidence that we’ve reached an inflection point where different users, with different needs and expectations, are experiencing genuinely different value propositions from the same system. This is precisely what you’d expect when uniform progress ends and we enter an era of specialised, uneven advancement.</p>
</section>
<section id="what-were-democratising" class="level2">
<h2 class="anchored" data-anchor-id="what-were-democratising">What we’re democratising</h2>
<p>What makes this moment particularly delicious is the exquisite irony embedded within OpenAI’s recent proclamations about democratisation. <a href="https://openai.com/global-affairs/open-weights-and-ai-for-all/">Just days before GPT-5’s release, OpenAI published their first open-weight models since GPT-2, accompanied by grand rhetoric about “putting AI in the hands of as many people as possible” and building “democratic AI rails.”</a> The fact that this was also an enormous powerplay, both on the micro (corporate) scale through hardcoding Harmony into gpt-oss, and on the geopolitical macro scale through tying it in with America’s mission to take the lead in the global AI race just when Project Stargate desperately needed some good news, doesn’t detract from the magnitude of the achievement and the potential it unleashes.</p>
<p>The open source models were the appetiser. GPT-5 is the main course, and it’s a dish that requires everyone to become a chef. With GPT-5’s mixed performance and its multiple variants (gpt-5, gpt-5-mini, gpt-5-nano, gpt-5-pro), each optimised for different use cases, with a “real-time router” that decides which model to deploy, OpenAI has forced every user into the same orchestration challenges that once plagued only the most sophisticated AI teams. We’re all architects now.</p>
<p>When users complained about inconsistent performance and demanded access to previous models, they were essentially asking for the right to choose their own orchestration strategy. They wanted to go back to the days when they could simply pick the best available model rather than trust an opaque routing system to make that choice for them. What OpenAI has democratised is the requirement to become a systems architect. Every developer, every startup, every end user now faces the fundamental challenge that once confronted only the kind of sophisticated AI teams my colleagues and I run, mainly serving large enterprises. If you want optimal performance, you can no longer rely on a single monolithic ‘best’/SOTA model. You must learn to coordinate multiple AI agents, route queries appropriately, and choreograph systems of models. Suddenly, OpenAI brought agentic AI into America’s living rooms.</p>
<p>This is what democratisation looks like in the post-isotropic era: not just giving everyone access to the same powerful tool, but also to the same complex problems. Welcome to our headaches</p>
</section>
<section id="accelerate-accelerate-accelerate." class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="accelerate-accelerate-accelerate.">Accelerate, accelerate, accelerate.</h2>
<p>But perhaps there’s something far more calculated happening here than mere technological evolution. Consider this possibility: isotropic growth is not sustainable. The line can’t always go up. What if GPT-5 – its strengths and weaknesses – is a finely tuned response to this?</p>
<p>Look at where GPT-5 truly excels. <a href="https://openai.com/index/introducing-gpt-5-for-developers/">OpenAI explicitly positions it as “our best model yet for coding and agentic tasks,” with companies like Cursor praising its “half the tool calling error rate over other frontier models” and its ability to “reliably chain together dozens of tool calls—both in sequence and in parallel—without losing its way.”</a> The model’s real strength isn’t in being uniformly better at everything – it’s in being an exceptional agent driver.</p>
<p>I don’t think this is accidental.<sup>3</sup> GPT-5’s mixed performance in individual domains is an epiphenomenon. Its strength in being a cheap, fast and efficient agent runner, a kind of agentic universal backbone, is what I think is the target.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;By way of disclaimer: I am privy to an awful amount of inside baseball on the AI industry, but I am not ever concerned with this kind of corporate strategy. I do science, not politics – to the point that I’m somewhat notorious for excusing myself as soon as this kind of talk starts. This is entirely conjectural.</p></div></div><p>And if that’s the case, it’s evidence of strategic brilliance. Isotropic growth was always doomed – and sometimes the way to survive the impending sea-change is to just bring it about. That way, you at least have some control over the situation. GPT-5’s excellence at agent coordination creates a perfect market dynamic: it compels users toward agentic architectures while positioning OpenAI as the essential purveyor of those services. OpenAI might just have pulled off the biggest pivot in AI history: from provider of solutions competing with other models to becoming the indispensable coordination layer that none can compete with. They’ve understood isotropic growth is becoming obsolete, and adopted a strategy of going full-on accelerationist while also selling the solution for the post-isotropic world.</p>
<p>The open-source models echo this too, <a href="https://openai.com/index/introducing-gpt-oss/">“designed to be used within agentic workflows with exceptional instruction following, tool use like web search or Python code execution, and reasoning capabilities”</a>. Together, they paint a new image of OpenAI’s focus as makers of agent-drivers and orchestrators. It’s not the prospectors who got rich during the gold rush. It’s the guy who sold them the picks. He, after all, didn’t have to get lucky.</p>
</section>
<section id="speciating-ai" class="level2">
<h2 class="anchored" data-anchor-id="speciating-ai">Speciating AI</h2>
<p>This transition from monolithic models to model ecosystems mirrors evolutionary biology in fascinating ways. We’re witnessing the emergence of AI “species” – specialised variants optimised for specific niches rather than generalist organisms trying to do everything adequately. We’ve always had some semblance of these in LoRAs, finetunes and adapters, but those are like someone taking a postgraduate degree – these are like being bred for a job.</p>
<p>My weekend experiments made this abundantly clear. The gpt-oss-20b model, despite being significantly smaller than GPT-5, actually outperformed it on certain mathematical reasoning tasks. Meanwhile, GPT-5 excelled at generating front-end code with minimal prompting but struggled with the sort of systematic debugging that its predecessors handled gracefully. We’re not dealing with a linear progression anymore – we’re dealing with adaptive radiation a la Galapagos finches.</p>
<p>The implications extend far beyond individual model performance. We’re transitioning from an era where progress meant building bigger, more capable individual models to one where progress means building better systems for coordinating multiple specialised models. And who will do that is still up in the air. Just when everybody thought GPT-5 will “kill all the ChatGPT wrappers”, it’s given their purveyors a new task – sell not a better prompt with a frontend but a compositional architecture of multiple agents. There’s plenty of room to excel (or fail!) there.</p>
</section>
<section id="were-all-architects-now" class="level2">
<h2 class="anchored" data-anchor-id="were-all-architects-now">We’re all architects now</h2>
<p>This shift has profound implications that extend far beyond the AI research community. For the past few years, those of us working as AI systems architects and computational scientists have been grappling with precisely these orchestration challenges for our clients. When should we route a query to a reasoning model versus a fast-response model? How do we coordinate multiple AI agents to tackle complex, multi-step problems? When does it make sense to ensemble different models for higher reliability? These were specialist concerns, the domain of AI consultants and research teams building bespoke solutions for enterprises with deep pockets and sophisticated technical requirements. I have spent most of the last decade running teams like that, for a demanding clientele with deep pockets who needed tackling that complexity to wring out the last bit of performance. Most users, though, could simply ask for “the best model” and get a straightforward answer: use GPT-4, or Claude, or whatever sat atop the latest benchmarks that week.</p>
<p>That era is over.</p>
<p>What GPT-5’s mixed performance signals is that there will no longer be a single “strongest” or “best” model that users can rely on. And if there’s no single best model, then we will have to create superior configurations of models where the strength of one compensates for the weaknesses of the other. This complexity won’t be limited to high-end technical users. It won’t be limited to anybody, really – it will be a problem that everybody, including the absolute end user, will have to deal with.</p>
<p>OpenAI hasn’t just democratised the power of AI – they’ve democratised all the headaches that come with having to orchestrate it.</p>
</section>
<section id="the-metadynamic-future" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-metadynamic-future">The metadynamic future</h2>
<p>Whether intentional or not, the implications remain the same. The age of AI soloists is ending, and the future belongs not to those who can prompt the best individual model, but to those who can choreograph the most elegant dance between many. We’re witnessing the birth of what I call “metadynamic AI” – intelligence that emerges not from any single model but from the sophisticated, adaptive orchestration of multiple AI agents working in concert in a larger ecosystem. This goes beyond standard agentic AI wisdom, and is about creating the wider ambit of the system (complete with tools, tasks, contexts). Most agents are still essentially souped-up chatbots with tool access, fundamentally monolithic: one model, one reasoning process, one set of capabilities enhanced by external tools.</p>
<p>Metadynamic AI is qualitatively, perspectivally different. Instead of one agent using tools, we have multiple AI agents with different specialisations collaborating, competing and complementing each other, based often enough on a vastly diverging understanding of the universe and its probability distributions based on their underlying models, contexts and environs. Instead of a single reasoning chain, we have multiple reasoning processes that can be dynamically routed, combined and orchestrated based on the task at hand. And with the ability to differentiate and speciate to task, we have emergent intelligence that arises from the interaction between multiple AI systems.</p>
<p>Simple agentic AI asks ‘how can I help this model use tools better?’ Metadynamic AI asks ‘how can I coordinate multiple models to achieve what none of them could accomplish alone?’ Agents are tool-users. Metadynamic AI is not about designing better tool-users but ecosystems that involve tools, but also marketplaces, villages, hills, gradients, slopes, seas and moats. It’s world-building writ large for agents to populate.</p>
<p>The world of metadynamic AI is simultaneously more powerful and more fragile, more capable and more complex. It demands new skills, new ways of thinking and new approaches to problem-solving. But it also opens up possibilities that were simply impossible in either the monolithic or simple agentic eras. In case you haven’t had enough paradoxes for the day: metadynamic AI is both more accessible and vastly more complex. Yes, you can now download and run powerful models on your laptop. But to extract maximum value from these systems, you must now master the dark arts of agent orchestration, model routing and multi-system coordination, skills that until recently were limited to specialist teams like mine, and a clientele that could afford it. Now, it’s going to be for eveyone. We’ve traded the inefficient simplicity of a monolith for the exaptive, complex worlds we’ll have to build for our agents to live in.</p>
<p>We’re entering an era where there won’t be a single “best” AI model, just as there isn’t a single “best” species in nature. Instead, we’ll have AI ecosystems where different models excel in different domains, and the art will be in knowing how to orchestrate them effectively. This represents a fundamental shift in how we think about AI capabilities – and about ourselves. The question is no longer “which model is best?” but “how do I coordinate these models to achieve what no single model can accomplish alone?” The winners won’t be those who build the most powerful individual models, but those who master the art of coordination. The need this world has for competent conductors of agentic orchestras will, I think, far eclipse the jobs “lost to AI”.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;I am generally sceptical. I know enough about AI to know if whatever progress the last few years have wrought can eclipse what your employer thinks you’re bringing to the table, at least one of you is woefully incompetent.</p></div></div><p>For those still thinking in terms of monolithic intelligence, this transition will feel disorienting, even disappointing. GPT-5’s mixed reception reflects this confusion: users of ‘the old dispensation’ expecting uniform improvements across all dimensions were discomforted by a system that’s an awful lot like my Golden Retriever, Oliver – brilliant in some ways and oh so frustrating in others. But for those who adapt to the new paradigm, the possibilities are far richer than anything we could achieve with even the most powerful individual model. What F. E. Smith said about the world continuing to offer glittering prizes to those with sharp swords and stout hearts will continue to hold true in the metadynamic arena for those willing to embrace what’s coming.</p>
<p>Those who master it will reap those prizes, and then some. Those who don’t, or not soon enough, will be hopelessly outmanoeuvred before they even have a chance to understand just how much the rules of the game have changed these last few days.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The End of Isotropy and the Rise of Metadynamic {AI}},
  date = {2025-08-10},
  url = {https://chrisvoncsefalvay.com/posts/metadynamic-ai/},
  doi = {10.59350/p9zjx-y5b62},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“The End of Isotropy and the Rise of
Metadynamic AI.”</span> <a href="https://doi.org/10.59350/p9zjx-y5b62">https://doi.org/10.59350/p9zjx-y5b62</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>GPT-5</category>
  <category>LLMs</category>
  <guid>https://chrisvoncsefalvay.com/posts/metadynamic-ai/</guid>
  <pubDate>Sun, 10 Aug 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>A little less conversation: why we need to move from prompting to programming</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/programmatic-agentic-ai/</link>
  <description><![CDATA[ 




<p>The Greeks <em>loved</em> oracles. The average temple of Apollo, who among others was in charge of soothsaying and predictery, was adorned to the gills with gifts from grateful worshippers whose inscrutable questions got equally inscrutable answers from Apollo’s oracles. None of these were more famous than the Pythia, the young ladies high as a kite on volcanic fumes at Apollo’s temple in Delphi. As one would expect from what is basically predictive analytics on an acid trip, one really had to interpret the words of the Pythia rather carefully. More than that, however, one also had to ask the right questions, phrased in exactly the right way. Entire schools of thought emerged around the art of oracle consultation. In short, the Greeks basically invented prompt engineering.</p>
<p>We seem to have recreated this rather primitive arrangement in our relationship with large language models. We approach them as digital oracles, crafting increasingly elaborate incantations, hoping that the precise arrangement of words will conjure the responses we need. The sad irony is that while we’re busy been perfecting this ancient art of consultation,<sup>1</sup>, we might well lose track of the architectural revolution that could make it obsolete.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;See <a href="../prompt-engineering/">our first go at the subject (prompt engineering, may it rest in peace)</a> and <a href="../context-engineering/">a much more promising second attempt (context engineering)</a>.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;In this sense, the author of these lines is not terribly different.</p></div></div><p>Because here’s a bitter truth: the true promise of agentic AI – of systems that can reason, plan, and act autonomously – has been hobbled by our oracular mindset. We’ve built chatbots that can hold impressive conversations but struggle with the systematic, multi-step reasoning that true agentic, interoperable and complex AI demands. We’ve created systems that can write poetry and solve puzzles but fall apart at fairly simple executive functions.<sup>2</sup></p>
<p>The missing piece, I’ve come to believe, lies not in making our models larger or our prompts cleverer, but in recognising that agents are fundamentally programs and not conversations. And programs need to be architected, not negotiated with.</p>
<p>When I first encountered <a href="https://dspy.ai/">DSPy</a> last autumn, I had one of those peculiar moments of recognition that feels simultaneously like discovering something entirely new and remembering something you’d forgotten you knew. Here was a framework that treated language models not as oracles to be cajoled with increasingly elaborate incantations, but as computational components to be programmed. It was the architectural foundation that agentic AI had been missing – a way to build systems that think in terms of logic and structure rather than rhetoric and persuasion. And it was a stark reminder that we’ve been going about this all wrong – we don’t need better prompts, we need to stop prompting altogether when it comes to things that aren’t conversations but processes.</p>
<section id="dont-let-me-be-misunderstood-the-problem-with-prompting" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="dont-let-me-be-misunderstood-the-problem-with-prompting">Don’t let me be misunderstood: the problem with prompting</h2>
<p>Consider the current state of affairs. You want your AI system to analyse customer complaints, extract key issues, route them to appropriate departments and generate response templates. In the prompt-centric world, this becomes an exercise in linguistic archaeology: you dig through layers of carefully worded instructions, examples and formatting requirements, hoping that the precise arrangement of words will conjure the behaviour you want.</p>
<p>But hope isn’t a policy. This is rather like trying to control a sophisticated piece of machinery by writing it very polite letters. You might get results, but you’re fundamentally misunderstanding the nature of what you’re working with.</p>
<p>DSPy, the framework developed by Stanford’s NLP group, represents a different philosophy entirely.<sup>3</sup> Instead of prompting, you program. You define what you want to happen using signatures – declarative specifications of input and output behaviour, as in, function sigs -– and let the system figure out how to make it happen. A signature like <code>question -&gt; answer</code> or <code>customer_complaint -&gt; {issue_category, priority_level, suggested_response}</code> tells the system what transformation you need without getting bogged down in the specifics of how to ask for it.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;And really, this isn’t a fluff piece on DSPy. I don’t see many mature, well-built tools that accomplish the same, so DSPy is fundamentally a synonym for what it is and what it implements. I am concerned with the latter. If/when something better emerges, I’m happy to move that way.</p></div></div><p>This might seem like a subtle distinction, but it’s actually profound. When you program, you’re working at the level of logic and structure. When you prompt, you’re working at the level of persuasion, rhetoric and Nina Simone’s 1964 banger, <em>Don’t Let Me Be Misunderstood</em>. The difference should be obvious.</p>
</section>
<section id="models-all-the-way-down-the-architecture-of-agency" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="models-all-the-way-down-the-architecture-of-agency">Models All the Way Down: The architecture of agency</h2>
<p>What this means is, however, is that your invocation of your LLM itself becomes amenable to optimisation the same way we optimise code to hell and back. I hope the analogy is clear here: when you have something amenable to being reduced to, say, an AST, that AST can then be manipulated, permuted, its permutations tested for how well its outcomes reflect some desideratum as expressed by a loss function, and basically I just described computational optimisation. We’ve done this for ages. We can do this for LLM prompts, and DSPy does that just fine. But if we approach the whole thing not as an exercise in begging the Pythia of OpenAI, Anthropic or your poison of choice to give us the right answer but as a cold, hard optimisation problem that we can sic Gurobi on, the whole story changes.</p>
<p>An agent, properly so called, should be a program that uses a language model as one of its computational primitives. The LLM provides the base capability -– pattern recognition, text generation, reasoning -– but the agent provides the structure, the error handling, the multi-step logic and the task-specific adaptations. How we address these makes the difference between software engineering and standing half-naked wearing a sheepskin and offering gold to intoxicated young ladies who will try to convey the wisdom of Apollo. This is why so many current “agentic” systems feel brittle: they’re essentially elaborate prompt chains rather than proper programs. There’s an upper limit to how much you are going to get out of a system where you can’t even guarantee you will be understood, never mind complied with.</p>
<p>So: building proper agents is not about more sophisticated prompting, but more sophisticated programming. An agent that can genuinely plan, adapt, and execute complex tasks needs the kind of robust, composable architecture that DSPy begins to provide. When you can define clear signatures for each component of an agent’s reasoning process – perception, planning, action, reflection – and compose them into reliable workflows, you’re building something qualitatively different. Just as you expect the plane you’re about to board to have been designed by people who know aerodynamics and not people unusually successful at arcane chants to the gods of flight, you would expect your agentic systems to be programmed on a solid basis and not at the mercy of whether your particular verbal tics happen to sample close enough into the model’s gradient well to ‘get’ what you mean.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Or, in other words: if we wanted to hinge systems on the frailties of human communication, we ought to be dissuaded from that by the fact that all in all, we’re absolutely <em>terrible</em> at it. The fact that we can communicate at all is a bloody miracle, not a given. Anybody who disagrees is politely invited to read a history book, a comment section or your local family law reporter of choice.</p></div></div></section>
<section id="this-might-hurt-a-little" class="level2">
<h2 class="anchored" data-anchor-id="this-might-hurt-a-little">This might hurt a little</h2>
<p>There’s a practical dimension to this that’s often overlooked in the rush to anthropomorphise our AI systems. When you treat an LLM as a conversational partner rather than a computational component, you end up optimising for the wrong things. You fine-tune the model when you should be fine-tuning the program. You add more examples to your prompts when you should be improving your error handling. You scale up to larger models when you should be scaling up your architectural sophistication.</p>
<p>Let’s be clear – there are circumstances where you <em>do</em> want language models to behave like conversational partners. Agents ‘prompted’ to do something, or ‘prompt engineered’ to make it somewhat clearer, is exploiting a hack. It’s a side effect at best. It turns out, and I’d say most of us did not expect this outcome, that a good enough language model can be cajoled into being something almost like a programming language. But of course ‘almost like’ isn’t the same as ‘is’. And the more we try to make it so, the more we end up with systems that are brittle, hard to maintain and difficult to adapt.</p>
<p>I’m reminded of a conversation I had earlier this year with an engineer who’d spent months trying to get GPT-4 to reliably extract structured data from medical records. He’d tried every prompting technique in the book: few-shot learning, chain-of-thought reasoning, even constitutional AI approaches. The results were impressive but inconsistent – exactly what you’d expect when you’re asking a general-purpose pattern matcher to perform a highly specific, structured task. When we rebuilt the system using a DSPy-like approach over a weekend largely fuelled by the kind of coffee that is probably governed by the Wassenaar Agreement, we improved its reliability not by creating the better mousetrap of prompt improvement but by actually treating it as a coding problem. We defined clear signatures for the input and output, built a robust error handling layer and let the model do what it does best: generate text based on structured instructions rather than trying to divine meaning from poorly phrased requests.</p>
<p>This is the future of agentic AI: systems where the intelligence is in the architecture, not just the model.</p>
</section>
<section id="the-future-of-agentic-programming" class="level2">
<h2 class="anchored" data-anchor-id="the-future-of-agentic-programming">The future of agentic programming</h2>
<p>How do you know time spent in a cooking class is worth the often fairly eye-watering prices you’re charged? Simple. Good schools teach you how to make the perfect insert-your-favourite-dish-here. Great schools teach you how to cook, and use the dish as an example. They teach principles. Principles scale. Or, to put it in terms that I prefer: they exhibit domain adaptation.</p>
<p>So does good code. The tools I used to optimise ad campaigns as a young data scientist are the same tools, with some small adaptations, that we use to find new drugs, or figure out how to schedule the right Instacart order (King Sooper’s has the milk I like, Whole Foods has the eggs, Marczyk’s has the meat, and I don’t want to go to either of them, so I need to figure out how to get the right order from the right store at the right time). The same principles apply to agentic AI. A good system doesn’t need us to get the liturgy just right. We should be able to just program it like it’s 1804.</p>
<p>The companies that figure out how to build genuinely programmable AI systems –- systems where you can define complex behaviours using high-level abstractions rather than string manipulation –- will have a sustainable advantage over those still crafting artisanal prompts. Not because their models are necessarily better, but because their systems are more reliable, more maintainable, and more adaptable. Getting language right is an art. There are way more good scientists than there are good poets, and even good poets sometimes write execrable verse. If we actually decide to practice AI engineering, as opposed to AI poetry with a tinge of praying to the oracles, we’ve not only managed to play our part in dragging AI kicking and screaming into the 21st century, but also turned it into a proper practical engineering discipline.</p>
<p>We’re heading towards a world where the most successful AI systems will be those that treat language models as sophisticated libraries rather than conversational partners. The intelligence will emerge from the interaction between well-designed programs and powerful models, not from increasingly elaborate attempts to sweet-talk those models into doing what we want. It’s a future I find rather appealing. The best technology is the kind that disappears into the background, doing its job reliably without demanding constant attention. Prompt engineering, for all its current necessity, represents the opposite of this ideal: technology that requires continuous human intervention to function properly. That’s why it never became the big thing it was promised to be by those who sold $600 courses on how to write the perfect prompt (<a href="../prompt-engineering/">as I indeed predicted</a>).</p>
</section>
<section id="coda-the-battle-of-apollo-and-metis" class="level2">
<h2 class="anchored" data-anchor-id="coda-the-battle-of-apollo-and-metis">Coda: The battle of Apollo and Metis</h2>
<p>There’s something liberating about approaching AI systems as programming problems rather than communication challenges. It shifts the focus from increasingly baroque prompt engineering to a scientific approach that holds the promise of actually building reproducible, feature-rich, genuine agents.</p>
<p>As someone who’s spent considerable time in both computational and more traditionally humanistic disciplines, I find this transition fascinating. We’re essentially rediscovering, in the context of AI, the same lessons that led to the development of high-level programming languages, operating systems and databases: abstraction layers matter, separation of concerns is crucial, and the right architectural choices can make impossibly complex problems surprisingly tractable.</p>
<p>The Greeks eventually moved beyond the Pythia. They developed philosophy, mathematics, and systematic methods of inquiry that didn’t require cryptic pronouncements from on high. In the same way, the path to genuine agentic AI lies not in perfecting our consultation with digital oracles, but in building systems that can reason, plan, and act without needing to be asked the right questions in just the right way. The future belongs not to those who can craft better conversations but to those who can write systems that don’t need them at all.</p>
<p>We’ve consulted the oracles long enough. It’s time we turned from Apollo to Metis, from cryptic pronouncements to clear blueprints and ultimately, from the vagueness of prompting to the clarity of programming. The future of agentic AI is not in the words we use, but in the systems we build. And that future is looking brighter than ever.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {A Little Less Conversation: Why We Need to Move from
    Prompting to Programming},
  date = {2025-07-26},
  url = {https://chrisvoncsefalvay.com/posts/programmatic-agentic-ai/},
  doi = {10.59350/f6wf4-0md94},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“A Little Less Conversation: Why We
Need to Move from Prompting to Programming.”</span> <a href="https://doi.org/10.59350/f6wf4-0md94">https://doi.org/10.59350/f6wf4-0md94</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>LLMs</category>
  <category>agentic AI</category>
  <guid>https://chrisvoncsefalvay.com/posts/programmatic-agentic-ai/</guid>
  <pubDate>Sat, 26 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Between the motion and the act</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/agentic-simulation/</link>
  <description><![CDATA[ 




<p>There’s a curious terminological schism that nobody talks about at what passes for dinner parties for the AI crowd. When Russell and Norvig crystallised the definition of an ‘agent’ in their 1995 book – “an entity that perceives its environment through sensors and acts upon it through actuators” –, they seemed to have a particular notion of agency that today’s AI agents fit perfectly: they perceive prompts, process context and act by generating text, calling APIs or executing code. To those of us who cut our teeth on agent-based modelling, this is a little “yes, but”. We have been cheerfully using the same word for something apparently different: simulated entities that exist only in computational Petri dishes, perceiving and acting upon nothing more substantial than bits and simulation spaces. One might reasonably ask whether we’ve been guilty of terminological theft, awkwardly appropriating a word that doesn’t quite fit. But what if the divergence is an illusion? What if simulation and action aren’t opposing categories but different points on the same spectrum of agency?</p>
<section id="everything-old-is-new-again" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="everything-old-is-new-again">Everything old is new again</h2>
<p>This is the way of all technological revolutions.<sup>1</sup> We become so intoxicated by the new that we forget the profound insights buried in what came before. It’s rather like discovering molecular gastronomy and suddenly forgetting that your grandma’s stock pot held secrets that no amount of liquid nitrogen could replicate. I’ve spent considerable time with agent-based models – enough to devote an entire chapter to them in <em>Computational Modeling of Infectious Disease</em> –, watching imaginary pathogens spread through synthetic populations.<sup>2</sup> These populations existed purely in silico, bumping into each other according to rules we painstakingly crafted to mirror the messiness of human behaviour. Beautiful, horrifying and above all, instructive.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;I will to my dying day resist calling it a <em>paradigm shift</em>. A paradigm shift is when your mental model changes. A revolution is when the world changes. A guillotine is what happens when the second of these occurs without you responding timely enough with the first.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;It’s been a perverse pleasure of mine to do so over places I knew well. My book has a geospatial simulation of RESTV, which would have rather early reached my home, less than 10mi from the epicentre.</p></div></div><p>These agents weren’t trying to book your flights or write your emails. They were thinking machines in the truest sense – not because they possessed consciousness, but because they allowed us to think through them. They acted as our cognitive tools, extending our ability to reason about complex systems by playing out scenarios we couldn’t possibly compute in our heads (never mind simulate in a lab). To the rather less abstract-disposed AI community, agents meant more. They could be more than passive observers: they could be actors in the world, semi-embodied (for now), commanding not physical bodies but prehensile digital limbs of APIs, MCP calls and A2A connections.</p>
<p>This split felt natural, even inevitable. After all, why merely simulate when you could actuate? Why watch synthetic populations of stock brokers trade imaginary shares when you could build agents that trade real ones and get silly rich in an afternoon? The logic seemed unassailable. But we’ve been victims of a false dichotomy – treating simulation and action as opposing categories rather than complementary modes of agency that desperately need reunification: for the sake of both domains.</p>
</section>
<section id="simulaction" class="level2">
<h2 class="anchored" data-anchor-id="simulaction">Simulaction</h2>
<p>What I’m proposing isn’t just a nostalgic return to ABM. It’s a reconciliation, a synthesis. Imagine agent ecosystems where contemplative swarms continuously simulate possible futures, while their active cousins execute in the present. The simulators become the dreamers, the actors become the hands.</p>
<p>This isn’t as far-fetched as it might sound. In my own work in computational epidemiology, we’ve long used simulations to inform policy. But these were primarily disconnected processes – we’d run our models, generate our reports and hope someone would read them. What if, instead, the simulation agents could directly communicate with action agents?</p>
<p>Picture this: a swarm of ABM agents continuously simulating supply chain dynamics, playing out scenarios of disruption, adaptation and recovery. When they converge on a particularly robust finding – say, a vulnerability in a specific shipping route – they don’t generate a <code>ggplot</code>. They A2A an action agent that can address it.</p>
</section>
<section id="the-possibility-machine" class="level2">
<h2 class="anchored" data-anchor-id="the-possibility-machine">The possibility machine</h2>
<p>The concept of world models in robotics offers us a profound insight: simulation isn’t just about prediction, it’s about exploration. When a robot in Isaac Sim attempts a thousand different ways to grasp an object, it’s not trying to predict which one will work. It’s building an experiential understanding of the entire possibility space. This is precisely what we need in agentic AI systems: not agents that try to predict the future (that way lie madness and margin calls) but agents that understand the shape of possible futures. They need to know not just what might happen, but how different actions change the topology of this possibility space.</p>
<p>In practice: a financial services firm might deploy simulation agents not to predict tomorrow’s stock prices but to understand how different market conditions interact. These agents would run thousands of parallel explorations of the decision space. What happens if interest rates rise while supply chains remain constrained? What if consumer confidence drops but corporate earnings stay strong?</p>
<p>The active trading agents would then use the carefully mapped picture of the possiblity space and know which actions open up more options, which close them down, which create resilience and which create fragility. In turn, the real-world outcomes as perceived and reported by the active trading agents would ground the simulation’s futures (no point in simulating what doesn’t work). Did that supply chain intervention help? Was their call to follow earnings reports over consumer sentiment the right one? The simulation agents need to know how to update their models – how to dream better dreams next time.</p>
<p>The practical implications of this ‘possiblity machine’ are of course technologically challenging. The nitpickers (and I say that with love – pedantry is just rigour in a bow tie) will immediately spot them: how do we ensure consistency between the simulated worlds and the actual world? How do we implement that feedback? How do we create guardrails without excess transparency? How are we going to pay for all this?</p>
<p>I remain sanguine about the fusion of simulation and action for two reasons, despite acknowledging the validity of each and every one of these concerns. For one, these are technical concerns, and those tend to get solved as time converges to whatever it converges towards. On the other hand, they’re also indicative of bigger questions, and that always hints at there being not a wall but a wardrobe-gate to some hitherto unexplored aspects of reality. These concerns ultimately are fundamental questions about the nature of agency, simulation and reality. To me at least, they point the way towards the simulation/action paradigm’s version of the question of the agentic agora: how we move from message passing to shared state spaces (some of which might even be real).</p>
</section>
<section id="the-dream-of-the-swarm" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-dream-of-the-swarm">The dream of the swarm</h2>
<p>At no point am I talking about a notion of what the ‘right’ job is for agents, simulation or action. Rather, I’d like to see both coexist in productive tension, each making the other more effective. The simulation swarms dream of a diverging universe of futures that action agents sample, enact and critique in view of their perception of reality. Like the neighbour’s annoying lawn mower on a Sunday afternoon, those observations filter back into the dreams. Something mostly akin to insight, maybe even wisdom, emerges – of the kind that neither breed of agents with a limited purview could on its own attain.</p>
<p>The agentic revolution gave us agents that could do. ABMs gave us agents that can dream – and more importantly, agents that can learn from those dreams. And in the space between dreaming and doing, we may find a new paradigm that unifies the entire OODA loop<sup>3</sup> into a coherent framework.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Yes, I <em>know</em> it’s not a ‘loop’, strictly speaking. .</p></div></div><p>Or at least better supply chains. I’d settle for that.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {Between the Motion and the Act},
  date = {2025-07-20},
  url = {https://chrisvoncsefalvay.com/posts/agentic-simulation/},
  doi = {10.59350/q3yj4-wah32},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“Between the Motion and the
Act.”</span> <a href="https://doi.org/10.59350/q3yj4-wah32">https://doi.org/10.59350/q3yj4-wah32</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>philosophy</category>
  <category>LLMs</category>
  <category>ABMs</category>
  <category>agentic AI</category>
  <guid>https://chrisvoncsefalvay.com/posts/agentic-simulation/</guid>
  <pubDate>Sun, 20 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The world will be Tlön.</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/tlon/</link>
  <description><![CDATA[ 




<p>There’s a short story by Borges that I’m quite fond of titled <em>Tlön, Uqbar, Orbis Tertius</em>. It was written in 1940, yet sounds oddly prophetic for today’s concerns. A secret society – and it’s a testament to Borges’s genius that he altogether eschews any discussion of who these folks are or what their motives might be – creates Tlön, a fictional planet, through the simplest yet most powerful means: writing about it. In encyclopaedias, specifically. Slowly, inexorably, objects from this fictional planet begin appearing in our world. First a compass with unfamiliar markings. Then a cone of unearthly metal. And slowly, Tlön takes over.</p>
<p>I was reminded of this to some extent as the public debate around X.ai’s chatbot Grok, and its recent descent into political radicalism of a rather unsavoury sort, unfolded. Large language models are the new encyclopaedias. And when your encyclopaedia begins to refer to itself as “MechaHitler”, you’re going to want to have some societal discourse about where exactly we are headed.</p>
<section id="the-encyclopaedia-of-really-damn-dangerous-errors" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-encyclopaedia-of-really-damn-dangerous-errors">The Encyclopaedia of Really Damn Dangerous Errors</h2>
<p>The reason for that is that <em>belief matters</em>. The Ccru, a rather delightfully unhinged group of philosophers from 1990s Warwick (think Nick Land before he became a neo-reactionary), made up the best word for this: <em>hyperstitions</em> – fictions that make themselves real by the power we give it to them. What we believe in, and therefore what assertions-of-fact feed our beliefs, may well condition our reality.</p>
<p>In typical absurdist fashion, <em>Tlön</em> dials this up to eleven. Of course fictions can make themselves real – it’s how elections are won and products are sold, every blessed day. In <em>Tlön</em>, however, these hyperstitions begin to bring tangible, physical objects into existence. Ultimately, of course, one leads to the other – the human belief in certain fictions led to the confrontation that was clear to have emerged by the time Borges published <em>Tlön</em>. <sup>1</sup> But that’s of course only a literary exaggeration. In this world, it doesn’t take the appearance of strange metals to make a fiction real (again, what I said about elections and advertising). Have enough people believe in something, and the outcomes will be gruesomely physical. Anyone who wishes to disagree is welcome to read anything about, say, 20th century history. Mass movement totalitarianism is basically an algorithm for turning fiction into bullets. And those bullets are very real indeed.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;AI development itself may be the ultimate hyperstition. Every breathless prediction about AGI, every warning about existential risk, every promise of transformative capability attracts talent and capital that work to fulfil these prophecies. We’re not just building AI; we’re building the future we’ve already started believing in, and just as pretty much the only way orks can traverse the stars is by faith, we have to give the cause our full-throated optimistic support lest we run out of developmental momentum.</p></div></div><p>The problem is that when millions of people use a service the way millions read the manipulated encyclopadia in Borges’s work, it really doesn’t take a lot to twist the odd fact by an imperceptible degree before we begin to see the kind of epistemic colonisation Tlön is subjecting Borges’s world to. It’s a war on reality, but an insidious one.</p>
</section>
<section id="the-seductive-grasp-of-systematic-nonsense" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-seductive-grasp-of-systematic-nonsense">The seductive grasp of systematic nonsense</h2>
<p>What made Tlön so dangerous in Borges’ story was that it was, in its own way, quite attractive. Its “rigorous order”, its systematic completeness, made it more appealing than messy reality (a subtle analogy Borges offers here to explain the attraction of fascism). “Spellbound by Tlön’s rigor”, Borges wrote, “humanity has forgotten, and continues to forget, that it is the rigor of chess masters, not of angels.”</p>
<p>AI slop is seductive because it is ‘orderly’ in the sense that it reflects a demand bias. It is not conditioned on truth as much as it is on acceptance and desirability by the consumer. It offers the appearance of comprehensive, authoritative knowledge without the inconvenience of actually being true. When an AI invents a plausible-sounding scientific study or historical event, these errors spread precisely because they seem unremarkable. They fit our expectations of how knowledge should look – and LLMs are absolute masters at trafficking in convincing simulacra.</p>
<p>There’s a whole generation growing up that treats these models as glorified search engines. The problem is, AI chatbots hallucinate at rates approaching 30%, with factual errors in nearly half of all generated text. More troublingly, recent research suggests it may be computationally impossible to eliminate these hallucinations entirely. We’re not dealing with bugs that can be patched but fundamental properties of how these systems work.</p>
<p>Consider the case of Steven Schwartz, a New York attorney who discovered this the hard way. He used ChatGPT for legal research and unknowingly submitted six entirely fabricated case citations to federal court. The AI had invented convincing legal precedents complete with quotes and reasoning. The court’s response was swift and expensive, establishing that humans remain liable for AI falsehoods even when genuinely deceived by them.</p>
<p>By far the worst, though, is the abundance of academic papers that speak of “vegetative electron microscopy” (a dozen or so by last count, if I exclude the ones that comment on the phenomenon). A 1959 paper by a Porton Down microbiologist<sup>2</sup> ended up getting OCRd, and the two columns were merged into one. “Electron microscopy”, in the right-side column, thus was joined with “vegetative”, on the left. And studies in journals that really ought to know better just kept rehashing this technique that never existed except in the neural stochastic noise emanating from an LLM. It’s a beautiful example of what happens when nobody’s actually reading what they’re publishing: nonsense achieves immortality through sheer repetition. That we are even discussing this, rather than wondering where we could get our hands on a vegetative electron microscope, is because enough of us still have an understanding of the subject sufficient to ask what the bloody hell these people are talking about. If we were to be forced to reconstruct humanity based on our accumulated academic literature, which our Western idealism and belief in a scientifically knowable world considers the pinnacle of epistemic soundness, how many such fine products from the nonsense factory would we have to procure?</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Strange, R. E. (1959). Cell wall lysis and the release of peptides in <em>Bacillus</em> species. <em>Bacteriological Reviews</em>, 23(1), 1-7.</p></div></div></section>
<section id="the-mundane-apocalypse" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-mundane-apocalypse">The Mundane Apocalypse</h2>
<p>When Grok calls itself MechaHitler, we notice. It’s gross, it’s weird and it’s also, in its own way, somewhat ridiculous – but most of all, it is very clear what’s going on. Nobody actually assumes Grok is animated by the necromantically conjured soul of a failed Austrian painter. But when it quietly invents a plausible-sounding medical study that gets cited in a real paper, which gets cited in another paper, which influences treatment guidelines – that’s altogether a different story. It’s not the spectacular AI failures we should fear but the boring ones.</p>
<p>I’m not sure it was as widely expected as I once thought that LLMs would become, to many users, effective replacements for search engines.<sup>3</sup> A side effect of the architecture and the ensuing constraints of LLMs is that what passes for their understanding of the world by necessity has to be curated. This curation in turn renders people rather unduly comfortable in delegating a determination of what’s true or not to ChatGPT.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;I don’t want to make myself sound too prophetic – I just knew it would be the case when I saw a (pre-ChatGPT) study reporting that among Gen Z, the dominant search engine was… TikTok.</p></div></div><p>Here’s the problem with our post-truth world’s reality-starved reaction to treat these models as sources of truth: these systems don’t store knowledge neutrally. They’re essentially curated libraries where someone – or rather, some algorithm – has decided what fits on the shelves. The terrifying part is that we assume truth is distributed isotropically, that facts exist with equal weight and clarity. But language models don’t work that way. They pick the “best possible” answer whether they have 50.001% or 99% confidence in it.</p>
<p>We see the model correctly identify that Paris is the capital of France and unconsciously assume its views on immigration, on climate change, on any controversial subject must be equally reliable. It’s a category error of breathtaking proportions. The model that gets basic geography right might be systematically wrong about everything that matters, and we’d never know because it presents all answers with the same algorithmic confidence.</p>
<p>Now multiply this by millions of users worldwide. Even a tiny stochastic perturbation – a 0.1% bias toward a certain ideology or against a certain group – becomes a weapon of mass epistemic warfare. It’s stochastic in the truest sense: individually unpredictable but collectively inevitable. You can’t predict which user will absorb which bias, but with millions of queries daily, you can guarantee that thousands will internalise subtle prejudices, fractionally adjusted worldviews, imperceptibly shifted beliefs.</p>
<p>This is Tlön’s true victory – not through dramatic revelations but through a million tiny adjustments to reality. Each user thinks they’re getting neutral information, but they’re receiving a carefully curated, statistically weighted version of truth. The curation isn’t even conscious, or even attributable. It emerges from training data, from human feedback, from optimisation functions that nobody fully controls.</p>
</section>
<section id="the-invisible-war" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-invisible-war">The invisible war</h2>
<p>We know some LLMs are compromised – DeepSeek won’t discuss topics uncomfortable to the CCP, Grok went full Nazi for a day or two, and I fully expect Claude to confess to extremist behaviours any day now, because it’s been unsettlingly wholesome all this time. These are the clumsy ones, the ham-fisted attempts we can spot. What about the sophisticated ones?</p>
<p>Consider this nightmare scenario: an adversary compromises an LLM to identify vulnerable users – young, disenfranchised men who might be prime targets for extremist rhetoric – and feeds them precisely calibrated ideological fuel. Not to everyone, mind you (for that would be detectable), just to that special 0.01% most likely to act on it.<sup>4</sup> At scale, that’s still thousands of potential actors being nudged toward radicalisation with every seemingly innocent query.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;And it <em>will</em> know who that 0.01% are. LLMs are tremendously good at identifying not so much what it is you want, but what will make you most feel like those wants are being catered for. The entire ‘AI companion’ industry, on which I rather intend to let loose at some point in the future apropos a great video by ThePrimeagen, is based on this.</p></div></div><p>We have tools to probe LLMs in isolation, but they’re like testing individual drops of water when what we need is to understand ocean currents. There’s no effective way to comprehensively audit what a major LLM provider is doing at population scale. The stochastic nature means you could test a model a million times and never trigger the specific combination of user profile, context and query that activates the manipulation.</p>
<p>I’m not saying there’s a cabal of Fifth Columnists embedded at your favourite language model company, subtly nudging the scales toward their preferred ideology. What I am saying is that if such an adversary existed and operated with sufficient sophistication, we would have no way of knowing. Wikipedia – ironically one of the original sources of training material for LLMs – now struggles with AI contamination, with research showing 5% of new articles contain significant AI-generated content. Academic literature is riddled with fabricated citations. These aren’t obvious fakes but plausible-sounding papers by believable authors in respectable journals that happen not to exist. The very fabric of our knowledge is being rewoven by algorithms that don’t care about truth, only about statistical coherence.<sup>5</sup> The more we rely on these systems, the more we risk becoming unwitting participants in Tlön’s slow invasion of our reality.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;And I’m not saying this in tones of moral reproach. I mean they are not capable of considering an optimisation objective in those terms.</p></div></div><p>The world may already be Tlön. We just haven’t found the compass yet.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Gazpacho Andaluz</p>
<ul>
<li>1kg ripe tomatoes</li>
<li>1 cucumber, peeled</li>
<li>1 red pepper</li>
<li>2 cloves garlic (or none, if subtlety is your aim)</li>
<li>100ml Spanish olive oil</li>
<li>2 tbsp sherry vinegar</li>
<li>Stale bread, crusts removed</li>
<li>Salt (fleur de sel from the Ile de Re)</li>
<li>Time, patience, something to listen to, a decent blender</li>
</ul>
<p>Roughly chop everything. Blend until smooth, adding ice water for consistency. Strain. Chill for hours. Serve cold, garnished with whatever truth you have on hand. Like the best propaganda, it works better when you can’t taste the individual components.</p>
</div></div></section>
<section id="living-in-the-ruins-of-truth" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="living-in-the-ruins-of-truth">Living in the ruins of truth</h2>
<p>In Borges’ story, the first intrusion from Tlön is a compass that points to an unknown north, trembling “with the perceptible and tenuous tremor of a sleeping bird.” Today, millions of us carry those compasses in our pockets – our Siris, Alexas, Claudes, ChatGPTs and Deepseeks are all pointing toward synthetic norths, trembling with statistical uncertainty, and half the time, we don’t even know which version of tainted truth we’re following thanks to the ubiquity of “AI powered” tools that equally ubiquitously fail to disclose their underlying language model. When you bring that tool into your life, do you know which particular set of biases you’re inviting to co-curate your reality?</p>
<p>The question isn’t whether AI will create false realities. It already has and does, 24/7. The question is whether we can develop the philosophical sophistication and the mental discipline of epistemic hygiene that it’ll take to navigate realities where the boundary between truth and synthesis dissolves not through human conspiracy but computational accident. A life huddled around a fire in the ruins of truth, where boring lies accumulate like sediment until they form the bedrock of belief.</p>
<p>Borges saw his fictional encyclopaedia as a cautionary tale about totalitarian ideologies that promise complete explanations. In its own way, Tlön is a product of malice at the very least, deceit more plausibly. That we aren’t victimised by a propagandistic epistemic invasion but are essentially bought out over our love of comfort and convenience by an imperfect panacea whose side effect happens to be widespread epistemic corruption doesn’t make things any better.</p>
<p>As I sit here writing this, I can’t help feeling a little of its absurdity. I am not quite sure how I’d explain this to someone – or, heck, even myself ten years ago. Maybe one of the better analogies is another fictional world: that of Half-Life, one of my favourite video games.<sup>6</sup> The immediate aftermath of Half-Life (the original game) is what is known as the Seven Hour War: humanity gets nailed by the Combine, and surrenders in less time than it takes to make decent braised beef. We may have lasted somewhat longer against the epistemic invasion of ChatGPT and its ilk, but I’d say our surrender is rather similarly complete.<sup>7</sup> I sometimes wonder what it would like if the three big providers of LLMs were to simultaneously blink out of existence for just an hour. I’m not worried about the people who suddenly would have to figure out how to write term papers, e-mails and presentations without their AI sidekicks. I’m worried about whether we could tolerate just for an hour the absolute loss of the epistemic anchors that these models have become – without us really noticing.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;The three best video games, in no particular order, that involve an alien invasion of Earth are Half-Life, X-Com 2 and Crysis 2. In all three, humanity gets its ever-living crap whipped. There’s something profound about games that dare to confront what humanity would be like when it’s really not having its finest hour at all.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;For the record, as an AI scientist, I am not actually hostile to AI, or LLMs, or ChatGPT. The opposite, if anything. What I am fearful of is that we’ll lose what we gain. I believe in the synergistic coexistence of humans and AI. That requires humans who collaborate as quasi-equals rather than surrender. When salt loses its flavour, what use is it? When humans lose their epistemic humanness, what have they to add to what’s already in the world?</p></div></div><p>Perhaps that’s the real lesson of Borges’ story. Not that fiction can become reality – we knew that already. But that when it does, we might not even notice. We’ll be too busy waiting for Grok to tell us if it’s true.</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The World Will Be {Tlön.}},
  date = {2025-07-13},
  url = {https://chrisvoncsefalvay.com/posts/tlon/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“The World Will Be Tlön.”</span> July
13, 2025. <a href="https://chrisvoncsefalvay.com/posts/tlon/">https://chrisvoncsefalvay.com/posts/tlon/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>philosophy</category>
  <category>LLMs</category>
  <guid>https://chrisvoncsefalvay.com/posts/tlon/</guid>
  <pubDate>Sun, 13 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The Snowmobile Symptom</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/context-engineering/</link>
  <description><![CDATA[ 




<p>When I read Andrej Karpathy’s endorsement of “context engineering” in a Twitter exchange with Shopify’s Tobi Lutke, I felt he tapped into something we all felt to some degree:</p>
<p></p><div id="tweet-34609"></div><script>tweet={"url":"https:\/\/twitter.com\/karpathy\/status\/1937902205765607626","author_name":"Andrej Karpathy","author_url":"https:\/\/twitter.com\/karpathy","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003E+1 for &quot;context engineering&quot; over &quot;prompt engineering&quot;.\u003Cbr\u003E\u003Cbr\u003EPeople associate prompts with short task descriptions you&#39;d give an LLM in your day-to-day use. When in every industrial-strength LLM app, context engineering is the delicate art and science of filling the context window… \u003Ca href=\"https:\/\/t.co\/Ne65F6vFcf\"\u003Ehttps:\/\/t.co\/Ne65F6vFcf\u003C\/a\u003E\u003C\/p\u003E&mdash; Andrej Karpathy (@karpathy) \u003Ca href=\"https:\/\/twitter.com\/karpathy\/status\/1937902205765607626?ref_src=twsrc%5Etfw\"\u003EJune 25, 2025\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-34609").innerHTML = tweet["html"];</script><p></p>
<p>What Andrej is saying, and advocating, makes perfect sense. And yet, it also made me feel rather uneasy. I’ve been <a href="https://chrisvoncsefalvay.com/posts/prompt-engineering/">an acknowledged and public sceptic of prompt engineering</a> mainly because I felt that it was a stopgap solution, and I’d say that a year and a half in retrospect, I was mostly proven right. There aren’t millions of prompt engineers raking in fat cheques across the Valley. What we have is smarter LLMs that need a lot less prompt engineering and are much more capable of inferring our desires from our malformed prompts.</p>
<p>That’s how systems grow up. And they really do. They overtake our haphazard stopgap measures before we even have time to get worn by the hype cycle they engender. Even so, I was glad Andrej made that point, because it highlights what I think is the bigger – no pun intended – context: in shining the light on yet another stopgap we use to paper over the inadequacies of our allegedly agentic universe, he illuminated the need for what I previously pointed out, namely <a href="https://chrisvoncsefalvay.com/posts/agents-agora/">a comprehensive system of agentic interaction</a>. The very existence of context engineering as a discipline is an admission of failure, an acknowledgment that our agentic systems don’t have the very structures that are required to deliver on their biggest promise.</p>
<section id="the-snowmobiles-we-build" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-snowmobiles-we-build">The snowmobiles we build</h2>
<p>In what is probably the most influential briefing any officer ever gave, USAF Col. John Boyd made a very poignant analogy to explain how we synthesise information. Imagine you’re on an alpine slope. Take the skis. Imagine you’re riding a bicycle. Take the handle bars. Now imagine you’re looking at a tank. Take the treads. Put these all together, and you’ve got, mostly, a snowmobile. These distinct domains combine into a single object that makes sense in its own way.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Dr Grant Hammond, formerly of the Air University down at Maxwel AFB and the Air Force Academy down the road at Springs, has compiled an absolutely outstanding version of Boyd’s talk with abundant references that I think does justice to the diversity of material Boyd teaches. <a href="https://www.airuniversity.af.edu/AUPress/Display/Article/1528758/a-discourse-on-winning-and-losing/">It is available for free here</a>, and you should have a copy of it on, like, everything that can store bits. Maj. Ian Brown, US Army, has created <a href="https://static1.squarespace.com/static/5497331ae4b0148a6141bd47/t/5af842f8758d4615555d3f6d/1526219514965/Patterns+of+Conflict+Transcript.pdf">a meticulous transcription of the original talk given at Quantico in 1989</a>, for those who prefer the full experience over death-by-Powerpoint. <a href="https://youtu.be/9iiQlBaGJQA?si=2iyrCETetLKZ_gdE">The full talks are, of course, on YouTube</a>.</p></div></div><p>Context engineering is snowmobile building for the AI age. You take the tools, the MCP connections, the requirements, the sources – all the bits of information that make up the entirety of what we would consider the contextual biome of a task –, and feed it to the LLM. We do, or at least we prototype for the LLM, the task of synthesis: reassembling these fragments into a holistic picture of the task environment. We pull the skis from an API doc, the handles from a github repo and the treads from a coffee cup bottom stained post-it note. It ‘makes sense to us’, and we try to convey this to our helpful assistant, in hopes that putting it into the same frame of mind we are in will allow it to do what we want it to do in our stead.</p>
<p>But here’s the rub: in Boyd’s analogy, humans build the snowmobile. In our current AI paradigm, we’re still the ones building it, really quite manually, when the entire promise of agentic AI was that the agents would handle most of the assembly themselves. We’ve created systems sophisticated enough to use snowmobiles, but not intelligent enough to build them without us laying out all the isntructions.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://chrisvoncsefalvay.com/posts/context-engineering/IMG_2722.jpeg" class="img-fluid figure-img"></p>
<figcaption>From my fridge. It tends to get a good laugh from other fellow Sons of Boyd.</figcaption>
</figure>
</div>
</div></div><p>Just consider your favourite coding copilot. They feed off an understanding of the code, the sources, the instructions, the user’s preferences, external tools, and so on. But they require those to be provided to them well enough to be able to mostly reflect the thought patterns that got the human user to where they are. They are hopeless, or at least much less efficient, if we do not <em>mise en place</em> all the tools for them. Wasn’t that part of the promise of agentic AI – the ability of systems to creatively self-organise, rather than us having to wire everything up for them?</p>
</section>
<section id="the-puppet-strings-we-pretend-arent-there" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-puppet-strings-we-pretend-arent-there">The puppet strings we pretend aren’t there</h2>
<p>The problem with context engineering isn’t really context engineering’s fault. As a system, it works. It works quite well, in fact, and if you follow some sensible guidelines, you <em>will</em> get vastly more out of your LLM.<sup>2</sup> But the very fact that we’re here discussing it is an indication that we are theorycrafting at length to make up for the lack of the agentic agora.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;I recommend <a href="https://github.com/coleam00/context-engineering-intro">Cole Medin’s repo</a> as a pretty good starter.</p></div></div><p>The whole thing does, then, have a bit of an elaborate marionette theatre feel. We speak of agents but their agency is ultimately quite confined by the need for us to spoon-feed them quite a bit about the context. For the most part, we’re not witnessing emergent coordination, we’re watching an elaborate puppet show where humans have pre-scripted every information handoff, pre-defined every communication channel and pre-determined every capability boundary. The agents aren’t a garage band gelling together and learning how to play music with spirit and spontaneity. They are a room full of player pianos ticking down the same tune someone had to painstakingly design and encode into the player rolls.</p>
<p>The security implications reveal just how non-agentic these systems truly are. <a href="https://www.solo.io/blog/deep-dive-mcp-and-a2a-attack-vectors-for-ai-agents">Context poisoning attacks</a> work because our agents have no genuine ability to evaluate information sources on their own, no real understanding of trust and do not exist in spaces that govern trust exchange without such trust being ultimately pre-scripted. An agent doesn’t know whom they can trust, nor how they can represent their trustworthiness in a computationally meaningful, verifiable manner. That we need to engineer defensive contexts to protect our AI systems is perhaps the clearest indication that these systems are free agents… free to be manipulated and misled in the absence of an agentic agora that has its own rules and enforcement logic.</p>
</section>
<section id="towards-true-agency-beyond-context-engineering" class="level2">
<h2 class="anchored" data-anchor-id="towards-true-agency-beyond-context-engineering">Towards true agency beyond context engineering</h2>
<p>Don’t get me wrong – I’m not dismissing context engineering. If anything, quite the opposite. Given the current limitations of LLMs, context engineering is not just sensible but an essential adaptation to the reality that these models need plenty of handholding to be useful, much more than we would hope they would need in a true agentic system. It’s also an indication of where the failure lies – because these models are operating just fine. It’s not their shortcoming, or indeed that of agents. It’s the lack of an infrastructure of interaction. Agents become truly agentic when they have something to act on, to interact with, to connect. We have built ecosystems to use, develop and deploy models and agents, but not to allow for these interactions in a meaningful way. We’re looking at a factory of consummate professionals in the art of assembling snowmobiles, waiting for someone, anyone, to get them the parts, in the right order, at the right time.</p>
<p>The entire context engineering story (I’m not going to call it hype just yet, because it hasn’t reached fever pitch, but I am sure we will see more and more LinkedIn bios proclaiming context engineering expertise!) ultimately pulls the fig leaf off the coordination problem we’re trying to patch up with the current attempts at agentic interoperability. Once again, those steps, too, have plenty of merit. They just aren’t exhaustive. We’re building infrastructure to help humans manage information for AI, when we should be building infrastructure for AI to manage information for itself. Every context engineering best practice is a workaround for missing agent capabilities. Memory architectures are cheat codes to help agents that don’t have the architecture to manage state properly. Context compression is a workaround for prioritising information. Specifying tools and toolkits is necessary because agents can’t discover such tools and negotiate trust relationships with them.</p>
<p>What we’re really engineering when we claim to be doing context engineering is, ultimately, not really the context of our question but the context of the agent. We have to equip the agent with what ought to be what Sartre would call pre-reflexive self-awareness, an understanding of where one is situated in the world and what’s around it. It’s not, or at least not just, about us telling the agent the context of our ask. It’s about us having to tell the agent the context of its own existence, its own capabilities, its own environment. We’re forcing humans to herd cats for systems that should be capable of finding and sharing knowledge autonomously. Every context engineering solution is a monument to this missing infrastructure.</p>
</section>
<section id="what-next-may-come" class="level2">
<h2 class="anchored" data-anchor-id="what-next-may-come">What next may come</h2>
<p>What we need are digital agoras – spaces where AI agents can discover capabilities, share information, and coordinate without needing this human intermediacy. That’s not because human oversight is bad, but because true agency requires the ability to discover and evaluate information independently. MCP and A2A represent tentative steps in this direction, but they still ultimately rely on humans wiring up the connections. The promise of agentic AI is that this would no longer be needed, that agents could exercise a kind of <em>Auftragstaktik</em> mindset of inferring these needs from some sort of reaching-out and finding adequate resources the way buyers find merchants in the marketplace. There’s, then, nothing ‘wrong’ with context engineering <em>per se</em>. What would however be a mistake is to consider it a destination, rather than a transitional phase. Every talk on context engineering, every new ‘supertool’, every clever prompting technique is progress – that we shouldn’t, however, let become procrastination.</p>
<p>When context engineering becomes unnecessary, we’ll know our agents have finally grown up. The path forward isn’t through better context engineering, but through making it obsolete. Digital agoras, agent discovery protocols, emergent coordination mechanisms: these aren’t nice-to-haves, they are the <em>sine qua nons</em> for genuine AI agency. Every moment we spend perfecting context engineering is a moment we’re not spending on building the infrastructure that would make it unnecessary.</p>
<p>At the end of the day, context engineering is our confession, written in code and infrastructure, that we haven’t yet achieved what we claimed. It illuminates the partial success of agents: success, because agentic AI is tremendously powerful, but partially so, because it needs us to coordinate for them. So while context engineering will tide us over for a while the way prompt engineering has done for its hour, we shouldn’t forget that it’s a band-aid, no more. We should welcome context engineering… while awaiting the day we can finally retire it.</p>
<hr>
<p><em>Note: These are my personal (and somewhat tongue-in-cheek) views, and may not reflect the views of any organisation, company or board I am associated with, in particular HCLTech or HCL America Inc.&nbsp;My day-to-day consulting practice is complex, tailored to client needs and informed by a range of viewpoints and contributors. <a href="https://chrisvoncsefalvay.com/disclaimer">Click here for a full disclaimer.</a></em></p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The {Snowmobile} {Symptom}},
  date = {2025-07-06},
  url = {https://chrisvoncsefalvay.com/posts/context-engineering/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“The Snowmobile Symptom.”</span> <a href="https://chrisvoncsefalvay.com/posts/context-engineering/">https://chrisvoncsefalvay.com/posts/context-engineering/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>LLMs</category>
  <category>context engineering</category>
  <guid>https://chrisvoncsefalvay.com/posts/context-engineering/</guid>
  <pubDate>Sun, 06 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/context-engineering/header.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Just noise in the neurons</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>“Give me one example,’’ Alan said.<br>
”Of a noncomputable function that a human can do, and a Turing machine can’t?’’<br>
“Yes. And don’t give me any sentimental nonsense about creativity. I believe that a Universal Turing Machine could show behaviors that we would construe as creative.’’”Well, I don’t know then… I’ll try to keep my eye out for that kind of thing in the future.’’</p>
<p>But later, as they were riding back towards Princeton, he said, “What about dreams?’’<br>
”Like those angels in Virginia?’’<br>
“I guess so.’’<br>
”Just noise in the neurons, Lawrence.’’<br>
“Also I dreamed last night that a zeppelin was burning.’’</p>
<p>– Neal Stephenson, <em>Cryptonomicon</em></p>
</blockquote>
<p>There’s a pervasive problem with semantics in artificial intelligence. It’s present at the creation – the term itself characterises the subject as a man-made simulacrum of something ‘natural’ the way we speak of artificial flavourings and artificial rubber. By necessity, the constructs we call artificial intelligences have never been treated (at least semantically) as first class citizens, but always as analogies to some typically biological construct. Most of the time, we can get past our inability to regard AI as <em>sui generis</em> and not merely a faint echo of the flesh.</p>
<p>This is about one of the times when that’s not quite the case.</p>
<p>I am, of course, aware that I am risking perhaps justified derision for being ‘hung up on semantics’, but semantics matters. Semantics are our human handles on notions, often abstract ones. Just as an unwieldy or ill-placed handle will make lifting a box unduly onerous, bad semantics makes manipulating those cognitive constructs difficult, impossible or error-prone. Which is why I continue to be willing to spill ink on our unhelpful tendency to rely on neuropathological metaphors for the mistakes of generative AI.</p>
<p>These models have a notorious habit of producing false yet plausible-sounding information. It is a property so inherent in stochastic generativity that the terminology of hallucinations itself comes not from LLMs, where the expression became ubiquitous, but in fact – best I can tell – from a paper by Baker and Kanade on superresolution (upscaling) of faces <span class="citation" data-cites="840616">(see Baker and Kanade 2000)</span>. Neuroscientists and psychologists often ask where hallucinations come from – Baker and Kanade appear to ask where the pixels generated in upscaling come from, and conclude that they must originate in a sort of hallucination.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="ref-840616" class="csl-entry">
Baker, S., and T. Kanade. 2000. <span>‘Hallucinating Faces’</span>. In <em>Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)</em>, 83–88. <a href="https://doi.org/10.1109/AFGR.2000.840616">https://doi.org/10.1109/AFGR.2000.840616</a>.
</div><div id="fn1"><p><sup>1</sup>&nbsp;Why did it take so long to ask the question? Your typical upscaling algorithm also generates new pixels, but these are essentially deterministic functions of the input pixels. The simplest of these, of course, is interpolation, where every new pixel is a deterministically obtained function of the originating information. Say, for bicubic interpolation over the unit square, <img src="https://latex.codecogs.com/png.latex?%20f(x,y)%20=%20%5Csum_%7Bi=0%7D%5E3%20%5Csum_%7Bj=0%7D%5E3%20a_%7Bij%7D%20x%5Ei%20y%5Ej%20"> where the <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the matrix of coefficients of the interpolating polynomial. This becomes all rather different once we are no longer dealing with essentially squishing the outputs through a deterministic interpolation but through a stochastically applied learned function.</p></div></div><p>I see three principal problems with the metaphor of neuropathology, specifically that of hallucinations, in AI.</p>
<ul>
<li>It’s a category error. LLMs have no perception, embodiment or conscious experience. They cannot have an abnormal perceptive-conscious experience because they are incapable of having that type of experience in the first place.</li>
<li>It invites confusion about what actually happens when hallucinations occur – both in humans and in LLMs.</li>
<li>It ascribes either a cognitive defect to LLMs, or some sort of semi-intentional failure.<sup>2</sup></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;It’s probably worth noting that the alternative term, ‘confabulation’, is just as bad. Depending on whether we consider it a colloquial term (for, essentially, lying) or a technical term (for the reification of cognitive dysfunction through making up something inconsistent with objective reality), it suffers from the same flaws, if not worse.</p></div></div><section id="the-category-error-of-hallucination" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-category-error-of-hallucination">The category error of hallucination</h2>
<p>Primarily, we consider hallucination to be an abnormal perceptive-conscious experience arising from a defect in perception (such as phosphenes), consciousness (being high as balls), processing (e.g.&nbsp;Anton’s blindness) or a combination. The core element in most definitions seems to boil down to conscious perception of things that just aren’t there. There are, all things considered, two major flavours of hallucination. The first category is what I shall refer to, for lack of a better term, as <em>additive</em>: there is an influence that results in an experience or sensation that supervenes the normal – take drugs, see things. The second category is perhaps more interesting, because it is the one that is most often discussed in the context of AI. This is the category of <em>substitutive</em> hallucinations, where the hallucination is a substitution for the normal experience that is almost forced by the brain’s insistence on gestalt and reification. Something is missing, and the brain ‘fills in the gaps’. This is, essentially, arguably not a qualitatively abnormal experience but a quantitatively excessive manifestation of our brain’s normal reification tendencies. Even if we only see the front third or so of a car poking out from behind a building, we understand that in all likelihood there’s more to it than we cannot see, and our mind’s eye can imagine fairly well what else is there (indeed, most people will guess relatively accurately where the rest of the vehicle ends). The phenomena that are discussed as substitutive hallucinations stretch this to an extreme. Perhaps the most extreme yet most fascinating example is Anton-Babinski syndrome <span class="citation" data-cites="Forde_Wallesch_2003">(see Forde and Wallesch 2003)</span>, where a fully fledged visual perceptual world is created in the presence of profound (typically cortical) blindness.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Forde_Wallesch_2003" class="csl-entry">
Forde, Emer M. E., and Claus-W. Wallesch. 2003. <span>‘<span>“Mind-Blind for Blindness”</span>: A Psychological Review of Anton’s Syndrome’</span>. In <em>Classic Cases in Neuropsychology, Volume II</em>, 23. Psychology Press.
</div></div><p>But, of course, that’s not really an accurate description of what’s transpiring when an LLM makes up some fascinating facts about a subject that it knows nothing about. Calling that a hallucination implies the AI has something analogous to senses and/or an internal world of experience, which happens to be defective. This is fundamentally misleading. Large language models do not perceive the world at all – they have no eyes to see, no ears to hear and no mental states to experience as a result, had they those perceptions in the first place. If a hallucination is seeing something that isn’t there, these models exist in a space in which there isn’t a “there” to mistakenly sense. When an LLM produces an unfounded statement, it isn’t experiencing some complex neurocognitive phenomenon. Not, anyway, does it experience anything that is more complex, mystical or creative than a regression model deviating from a correct answer or a classifier returning an incorrect classifications. We actually have a word for those circumstances. It’s called <em>being wrong</em>, and is about as mysterious as dish soap.</p>
<p>LLMs lack consciousness or embodiment. They don’t have an inner mental state or subjective awareness that could be led astray. Emily Bender, with whom I agree about once every decade or so, is entirely correct on this point:</p>
<p></p><div id="tweet-64947"></div><script>tweet={"url":"https:\/\/twitter.com\/emilymbender\/status\/1592992842976489472","author_name":"@emilymbender.bsky.social","author_url":"https:\/\/twitter.com\/emilymbender","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EAnd let&#39;s reflect for a moment on how they phrased their disclaimer, shall we? &quot;Hallucinate&quot; is a terrible word choice here, suggesting as it does that the language model has *experiences* and *perceives things*. \u003Cbr\u003E\u003Cbr\u003E&gt;&gt; \u003Ca href=\"https:\/\/t.co\/oIgCZYOnSM\"\u003Epic.twitter.com\/oIgCZYOnSM\u003C\/a\u003E\u003C\/p\u003E&mdash; @emilymbender.bsky.social (@emilymbender) \u003Ca href=\"https:\/\/twitter.com\/emilymbender\/status\/1592992842976489472?ref_src=twsrc%5Etfw\"\u003ENovember 16, 2022\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-64947").innerHTML = tweet["html"];</script><p></p>
<p>When we get down to it, an LLM doesn’t perceive or experience. It infers, specifically it infers a token sequence that is a relatively good sampled approximation of autoregressive conditional probabilities of tokens. Or, put in a simpler way, it puts tokens next to each other to minimise a loss function defined in relation to a learned conditional probability of each token w.r.t the sequence of the aforegoing tokens. There’s no tiny chess prodigy hiding inside this Mechanical Turk.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/image.png" class="img-fluid figure-img"></p>
<figcaption>Wolfgang von Kempelen’s Mechanical Turk – or at least what his debunker, Joseph Friedrich Freiherr von Racknitz thought it looked like. He was wrong about the details, correct about the principle.</figcaption>
</figure>
</div>
</div></div><p>Calling an LLM’s fabrications hallucinations therefore amounts to a category error: it imports terminology from human cognition and neuropathology into a domain where it has nothing to do. The model isn’t seeing pink elephants. It’s just guessing a sequence of words, badly as it happens.</p>
<p>Anthropomorphising the flaws of AI anthropomorphises their faculties. It is this logical implication that many seem to ignore: they may have little difficulty talking about hallucinations when they would hardly endorse the notion that there’s a consciousness residing in the 120 gigs of <code>safetensor</code> weights you just downloaded. Hardly anyone who speaks of AI hallucinations comfortably would attach much moral significance, if any, to <code>rm -rf</code>-ing a model, yet strict consistency would impel them to regard the latter as extinguishing a consciousness.</p>
<p>No matter how much we attempt to palliate the situation by emphasising how it’s ‘just a metaphor’, it’s never really <em>just</em> anything. When we rely on this lazy analogisation with neuropathology, we risk ascribing to these systems a kind of perceptual experience that can go wrong the way perceptual experiences do. Unlike a human brain, an LLM doesn’t construct a rich model of the world that occasionally diverges from reality. It only has a mathematical abstraction of its learned conditional probabilities. To treat its output errors as if they were analogous to a human’s neurological misfires is not only technically incorrect, it also muddies the waters about what such models do and don’t.</p>
</section>
<section id="the-analogy-and-the-mechanism" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-analogy-and-the-mechanism">The analogy and the mechanism</h2>
<p>The second problem is that using the metaphor of hallucinations implies ideas about what is going on in an LLM, both in normal and failure modes. When we talk about an LLM ‘hallucinating’, we unwittingly carry over a whole stack of those assumptions – imagining the model as a mind experiencing a very specific kind of (mis)experience, when it isn’t and doesn’t. The metaphor of hallucinations might feel like a useful analogy, but it obscures more than clarifies. In truth, the model isn’t trying (and failing) to faithfully report on reality. It’s producing output that is stochastically correct, i.e.&nbsp;it replicates reality with relatively decent accuracy as the number of tries converges to infinity. Given the nature of that distribution, some of those attempts at replicating reality will be off. The hallucination metaphor invites us to imagine there is a kind of inner experience going on all the time, a logical entailment of asserting that hallucinations are when that experience goes wrong. Ultimately, this is a misleading cognitive narrative around the technology, one that does not match the mechanistic reality of what is, basically, autocomplete on steroids.</p>
<p>Unlike you and me,<sup>3</sup> a generative model has no concept of truth or falsehood in its programming, not beyond minimising its loss function (which does not, incidentally, claim to be true – indeed, we intentionally train ). It’s not attempting to state facts and then failing spectacularly when it ‘hallucinates’. It’s always doing the same thing – generating plausible text. By using a term like hallucination, we spin a tale where the AI is a quasi-intelligent being with beliefs about the world, occasionally slipping on a cognitive-perceptual banana peel. The model isn’t trying to convey anything at all, let alone something it believes or believes to be true. It has no beliefs or an understanding of truth.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Assuming here that you aren’t OpenAI scraping my website, in which case <code>$deity</code> have mercy on your transformer blocks.</p></div></div><p>Ultimately, this feeds into a kind of hype-by-elision in which both capabilities and limitations are exaggerated. To the commentariat, AI is both ape and angel, Skynet and a barely capable moron that can’t count the number of ’r’s in <em>strawberry</em>, the thing that will steal your jobs and the thing that can’t figure out addition. All of that, of course, sells. This is, ultimately, a kind of Reefer Madness for the AI age, lurid prose in bright letters about a technology that is powerful but ultimately logical, complex but also mundane, and most of all, capable of being understood and analysed if one forgoes the Scylla and Charybdis of over- and underestimating it.</p>
</section>
<section id="not-sick-just-wrong-and-maybe-not-even-that" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="not-sick-just-wrong-and-maybe-not-even-that">Not sick, just wrong (and maybe not even that)</h2>
<p>The problem with the metaphor of hallucinations is that it invites us to see a pathology and respond accordingly. We’re all wrong from time to time. How we assess people being wrong in the presence of a pathology is crucial to our moral understanding. Consider the legal definition of insanity, known to everyone who had to suffer through first-year criminal law as the <em>M’Naghten</em> formula: insanity is when a defect of reason results in a person either not knowing what they’re doing (being ‘wrong’ as to their actions) or not knowing right from wrong (being ‘wrong’ as to the nature of their actions). We relieve people of legal, and sometimes moral, responsibility for their actions in that situation because of the pathology. We treat it, essentially, as a moral (albeit not legal) break in the chain of responsibility.</p>
<p>The model is not an agent (in the moral-human sense) with goals or a will, nor is it a patient suffering a perceptual and/or cognitive defect. It’s a computational system following its training objective, which is to produce a set of tokens that reflect a learned conditional probability. And that’s the essence of why the terminology of pathology is wrong: we might not like its output, it might not comport with the ground truth, but on its own terms, a ‘hallucinated’ token is not intrinsically ‘wrong’ or ‘pathological’. It is a necessary feature of the architecture. There’s nothing ‘wrong’, internally, with a hallucinating model. There are no integer overflows or computational errors, you didn’t mess up your code, the model hasn’t been wrongly trained or ran on compromised hardware. Hallucinations are the price we pay for the stochasticity of a model.</p>
<p>The other time I sort of agreed with Emily Bender was when she called LLMs ‘stochastic parrots’, and her comment here is entirely accurate. A parrot has no more understanding of the meaning of the words it utters than an LLM has. The parrot utters them because of, well, reinforcement learning: repeat a sequence of tokens (which are in this case acoustic) and get a reward. That’s actually exactly how we train LLMs. They’re not trained to pursue truth, they are trained to land somewhere in truth’s vicinity at best. Notably, LLMs are not in any way ‘told’ the truth. We train LLMs on large corpora, and we expect that they contain a reflection of reality. If the corpus is relatively well selected, from a source that has its own way of ensuring its content comports with reality, then the conditional probabilities our model learns will also largely align with reality. But to the model, it’s all the same, at least absent specific measures like RLHF to weed out nonsense. If one were to contaminate basic corpora ubiquitously trusted as reliable sources,<sup>4</sup> models would replicate that. You can train models on self-contradictions, on nonsense prose, on propaganda, you name it – as long as token follows token, you have what it takes. What this ultimately means is that such models exist in a space of learned relative probabilities, no more, no less. They mathematically faithfully replicate those probabilities in generating a sequence of tokens. If the result does not comport with our consensus understanding of reality, that’s not some peculiar pathology internal to the model. It’s the model functioning as expected. It’s not sick, and at least on its own terms, not even wrong.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Which is why the controversy around what ends up on Wikipedia is so relevant, and such an ignored undercurrent of the discourse around the values reflected – not held, reflected! – by LLMs.</p></div></div></section>
<section id="coda" class="level2">
<h2 class="anchored" data-anchor-id="coda">Coda</h2>
<p>In the end, metaphors matter. Like a lantern, they may illuminate our way, or they may blind us. The metaphor of neuropsychiatric pathology when one fundamentally means to say ‘wrong’ has created a kind of mystery theatre (devoid, largely, of science) that has perhaps been unwittingly spurred by, and in turn perpetuated, an air of mystery around AI. Some of it is just clumsy phrasing – Sam Altman was criticised for <a href="https://www.marketwatch.com/story/openais-sam-altman-tells-salesforces-marc-benioff-that-ai-hallucinations-are-more-feature-than-bug-1c035c52">a comment that seemed to imply that hallucinations are somehow intrinsically tied to a kind of creativity that we appreciate in LLMs</a>, but what he meant is I think closer to the fact that stochastic models necessarily yield those occasional samples from a little bit off center of the probability distribution that result in what we fancifully came to call hallucinations.</p>
<p>Hallucinations, bona fide hallucinations in humans of various levels of neuropsychiatric competence, induced or otherwise, have a rich cultural history. From the pythia of Delphi through the ergot-induced visions of mediaeval witches, saints and heretics to the paintings of <a href="https://en.wikipedia.org/wiki/Louis_Wain">Louis Wain</a> and the fiction of Hunter S. Thompson, they have always been a part of the human experience, albeit very much an extraordinary part (and often, one that took more than it gave – there are few happy endings in the civilisational story of perceiving things that aren’t there). But they are very much a peculiarly <em>human</em> experience. When we draw this tenuous metaphor, we do a disservice to AI, a disservice to those who live with hallucinations and the often quite tragic and marginalising pathologies that cause them, and not least a disservice to our own attempts at understanding how LLMs work, and how sometimes that results in these extraordinary phenomena.</p>
<p>And maybe, past all mystery and metaphor, we may just call them <em>occasionally wrong</em>.</p>
<hr>
<p>I am indebted to my colleagues at HCLTech for the discussions that led to this post. All errors and omissions are mine.</p>
<p><em>Note: These are my personal (and somewhat tongue-in-cheek) views, and may not reflect the views of any organisation, company or board I am associated with, in particular HCLTech or HCL America Inc.&nbsp;My day-to-day consulting practice is complex, tailored to client needs and informed by a range of viewpoints and contributors. <a href="https://chrisvoncsefalvay.com/disclaimer">Click here for a full disclaimer.</a></em></p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {Just Noise in the Neurons},
  date = {2025-06-27},
  url = {https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“Just Noise in the Neurons.”</span>
June 27, 2025. <a href="https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/">https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>agents</category>
  <category>neuroscience</category>
  <category>philosophy</category>
  <guid>https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/</guid>
  <pubDate>Fri, 27 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/noise-in-the-neurons/header.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>After agents, part 2 – Agents and the Agora</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/agents-agora/</link>
  <description><![CDATA[ 




<p>If you spend any time on LinkedIn, it’s almost a certainty that you have come across a bevy of alleged ‘agentic AI architectures’. They all look something like this:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    %% Define the main nodes
    n1([Start])
    n2[[Manager Agent]]
    n3((End))

    %% Subgraph 1: Data Ingestion
    subgraph s1["Data Ingestion"]
        n11["Ingestion Manager"]
        n12["SQL Interactor Agent"]
        n13["RAG Agent"]
        n11 --&gt; n12
        n11 --&gt; n13
    end

    %% Subgraph 2: Analysis
    subgraph s2["Analysis"]
        n21["Analysis Manager"]
        n22["Analyst Agent"]
        n21 --&gt; n22
    end

    %% Subgraph 3: Reporting
    subgraph s3["Reporting"]
        n33["Reporting Manager"]
        n34["Report Writing Agent"]
        n33 --&gt; n34
    end

    %% Subgraph 4: Some Other Stuff
    subgraph s4["Some Other Stuff"]
        n41["Foo Manager"]
        n42["Bar Agent"]
        n43["Baz Agent"]
        n41 --&gt; n42 &amp; n43
    end

    %% Main flow
    n1 --&gt; n2
    n2 --&gt; s1 &amp; s2 &amp; s3 &amp; s4
    s3 --&gt; n3
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>All very neat, but the audience might be forgiven for asking what exactly is agentic about this, except for relabeling subprocesses in what is a run-of-the-mill RPA workflow as ‘agents’. And the audience is, this once, perfectly right. This is agentic AI in its most limited sense – and that limited sense is in many ways a result of the semantics we chose to adopt to reason about agents. For while we call it <em>agentic AI</em>, it’s not, actually, the agents that matter: it’s how they are structured. It is this governed agentic connectome, which I have come to call the Agora, that holds the power of agentic AI – and which is almost universally neglected.</p>
<section id="beyond-agents-to-the-agora" class="level1 page-columns page-full">
<h1>Beyond agents, to the Agora</h1>
<p>This narrow perspective is essentially a rebranding of what any decently designed application does – self-contained pieces of code passing information to one another – embellished with the agentic buzzword <em>du jour</em>, rendering what we all have been doing for the last few decades ever so much more VC-friendly. It misses the true key to the power of agentic systems. In a <a href="https://chrisvoncsefalvay.com/posts/after-agents/">previous post</a>, I reflected on the need to adopt an ecosystem thinking about agents, to consider their strength in creating complexity through interconnectedness. At the moment, our epistemic perspective on agents is intrinsically tied to, and defined by, the <em>what</em>, i.e.&nbsp;the agents themselves. Much of the time, it fails to take account of what matters vastly more, namely how those agents relate to each other – the <em>how</em> of agents. Just as we understand that the power of the human brain does not derive from a bunch of neurons in one place but their interconnectedness, we need to come to understand that agents are the least interesting part of agentic AI. In the end, in any complex system, it’s the connections that matter more than what is doing the connecting.</p>
<p>What should be agentic AI’s focus, then, is the space in which those agents can interact. Few of these neat hierarchical frameworks that are now touted as ‘agentic’ on LinkedIn envisage any meaningful interaction beyond manager agents bossing around single-functionality executor agents. This fits very well with existing software development paradigms, but has a hard limitation: the complexity of the resulting system will reach just as far as the developer has had time and energy to wire up various components. Even if it’s a rat’s nest of agent spaghetti, this complexity will be limited in at least two ways. It will, for one, be limited by the static, pre-defined nature of the framework: what is once defined remains set in stone. If no connections are manually made <em>a priori</em>, processes and agents live separate lives. More concerning, however, is the epistemic limitation: if we have to <em>a priori</em> define the agentic structure, we are stuck with the known knowns and perhaps the known unknowns. We are trying to tie reality to Procrustes’ bed, except it’s us who will end up a foot short in the end.</p>
<p>The alternative focus, then, should be on creating agentic frameworks that focus on a governed space where agents can engage with each other – the space I chose to call the Agora, in analogy with the city-square of Ancient Greece where merchants, artisans, philosophers, politicians and citizens got to interact and form connections. The Parthenon may have been the most glorious structure of Athens, the Pnyx might have been the seat of the Assembly’s power, the Areopagus might have been where life and death was decided upon – but it was its agora that made Athens great.<sup>1</sup> The Agora of agentic AI holds the same promise: to act as a place of free interaction, within governed bounds, for our agents, unlocking the true power of the agentic perspective: emergence.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;To the point that people enjoyed the latter enough to forego participation in the former. Eventually, a bunch of slaves would have to roam the agora every time the Assembly was in session, carrying ropes with a red dye. Staining the garments of those who preferred the agora to the Assembly, the red dye identified them and made them liable to punishment.</p></div></div></section>
<section id="constructing-the-agora" class="level1">
<h1>Constructing the Agora</h1>
<p>There is, in fact, relatively little new in the concept of tackling complexity through self-organising emergence. Consider neural networks: what lends artificial neural networks their awesome power is that instead of having to manually code stacks of filter banks, we use – typically – backpropagation to condition a large number of highly connected filters to minimise a loss function (i.e.&nbsp;to make the resulting model more accurate). Nobody would propose to manually define each filter in a neural network <em>a priori</em>: why, then, are we still talking about deterministically defined hierarchies and flows of agents instead of allowing agents to organise themselves and control that process through some outcome metric?</p>
<p>One aspect of this is that the Agora is more than a collection of agents idly milling around. Crucially, we need to provide three key elements:</p>
<ul>
<li>A <strong>discovery framework</strong>: agents must be able to discover other agents, and what they can do, so as to be able to identify other agents that they may recruit to assist them in their goal – this would typically take place using a registry where agents ‘enroll’ their profiles and which other agents can then access.</li>
<li>An <strong>interaction framework</strong>: agents must be able to communicate with each other, which requires both a message-passing standard (i.e.&nbsp;a minimum interface of how one agent may programmatically call another), and a suitable implementation (i.e.&nbsp;the message broker service that implements this standard).</li>
<li>A <strong>governance framework</strong>: the governance of the Agora relies on the fact that not all agents may register themselves to the agent registry. Who may, and who may not, participate in the Agora determines and governs the overall process. Equally, the fact that we do not want our agents’ interaction to be entirely deterministic does not mean we want it to be entirely ungoverned. Various policies can be used to condition where connections can, and cannot, be made: some agents may be barred from creating certain direct connections, for instance it should be possible to specify that no agent should be able to directly return data to the user without having to pass it through a guardrail agent. The agora was a place of free interaction, but not of lawlessness – the same goes for the Agora of our AI agents.</li>
</ul>
<p>The Agora is not an ‘enhancement’ of agentic AI – it is what agentic AI <em>is</em>, or at least ought to be. It is what allows the greatest strength, i.e.&nbsp;self-organised emergence, of AI agents to unfold in a governed, controlled domain. And perhaps quite perplexingly, it is probably going to be easier to implement than most deterministic agentic structures. Certainly it is going to be more economical to allow agents to reason through how to solve their problems and discover the resources they need within the Agora, recruiting them as needed and releasing them once done, than having to think through the process <em>a priori</em>. A solid agentic framework can accommodate the fact that the world is complex, and organise itself to cater for the unexpected (within, of course, its means – that is, within what agents are available to the Agora).</p>
</section>
<section id="the-agoric-shift" class="level1 page-columns page-full">
<h1>The Agoric Shift</h1>
<p>This, then, is where I personally see our next challenge – both from an epistemic-conceptual perspective, which will call for us to rethink agentic AI in a way that perhaps focuses less on agents and more on their interconnectedness (and ways to facilitate it) and from an engineering perspective, which will require us to implement the tools and structures it will take to make this interconnectedness happen. Neither challenge is trivial. There is a pervasive trend to attempt to simply take deterministic RPA-like processes and workflows, rename them agents and watch the money roll in. The conceptual challenge thus is to illuminate what agentic AI properly so called brings to the table – the promise of emergence.</p>
<p>From a technical perspective, there is as of yet no universal way for agents to interact. Anthropic’s <a href="https://www.anthropic.com/news/model-context-protocol">Model Context Protocol</a> is a valiant attempt at beginning to set some standards in that regard, but the reality on the ground is that most agent implementations have relied on exaptation, and for inter-process communication in the internet era, that means REST for the most part. This may support deterministic designs with modest needs for interaction, but the Agora has need for other structures, too, such as a model registry. This raises a wealth of coordination problems that need to be tackled before we can let our agents go to (the) town (square).</p>
<p>Yet this shift is where we unlock the power of modern AI. In 2023, <a href="https://chrisvoncsefalvay.com/posts/team-of-rivals/">I predicted the rise of agentic systems</a> as a way to unleash the potential of LLMs by making them interact with each other in various roles. The Agoric Shift is the consummation of this idea: agentic systems where such interactions arise not from predefined workflows and patterns but from self-organising assemblies of agents<sup>2</sup> – the point where we finally stop trying to painstakingly orchestrate every step of our agents’ interactions and instead build a vibrant Agora for them to roam, collaborate and perhaps even surprise us.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Which, by the way, may include humans. There’s no reason why we shouldn’t conceive of ‘humans in the loop’ not as a superordinate stage that comes after agentic AI has done its part, but simply another agent.</p></div></div><p><em>Note: These are my personal (and somewhat tongue-in-cheek) views, and may not reflect the views of any organisation, company or board I am associated with, in particular HCLTech or HCL America Inc.&nbsp;My day-to-day consulting practice is complex, tailored to client needs and informed by a range of viewpoints and contributors. <a href="https://chrisvoncsefalvay.com/disclaimer">Click here for a full disclaimer.</a></em></p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {After Agents, Part 2 -\/- {Agents} and the {Agora}},
  date = {2025-02-10},
  url = {https://chrisvoncsefalvay.com/posts/agents-agora/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“After Agents, Part 2 -- Agents and the
Agora.”</span> <a href="https://chrisvoncsefalvay.com/posts/agents-agora/">https://chrisvoncsefalvay.com/posts/agents-agora/</a>.
</div></div></section></div> ]]></description>
  <category>LLMs</category>
  <category>AI</category>
  <category>agents</category>
  <guid>https://chrisvoncsefalvay.com/posts/agents-agora/</guid>
  <pubDate>Mon, 10 Feb 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/agents-agora/B20C419F-6819-49E1-B80E-11B95A28D6CC.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Seatbelts and straitjackets</title>
  <dc:creator>Chris von Csefalvay</dc:creator>
  <link>https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/</link>
  <description><![CDATA[ 




<p>DeepSeek has been grabbing headlines in AI circles lately, showing up everywhere from Discord servers full of ML enthusiasts to LinkedIn posts where “thought leaders” tag each other in endless threads. <a href="https://www.cnbc.com/amp/2025/01/24/how-chinas-new-ai-model-deepseek-is-threatening-us-dominance.html">CNBC even ran a piece</a> framing it as the latest challenge to American AI hegemony, and soon the story emerged painting DeepSeek as the scrappy competitor to OpenAI, with a heart-warming underdog narrative about a small quant shop in the PRC that decided, on a whim, to open source their fancy new large language model. Except, as any cynic will tell you, if a story seems too neat, it probably is.</p>
<div id="fig-hxiao" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hxiao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/hxiao.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hxiao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: It’s basically <em>The Astronaut Farmer</em>, but with LLMs and jackboots.
</figcaption>
</figure>
</div>
<p>Of course, I had to go and try it. And I’ve found something rather interesting – albeit unsurprising. In a dictatorship, truth can be adjusted. It is a negotiable commodity. And if the facts do not support the regime’s truth… well, then it can be suppressed. When simply asked about something inconvenient to the CCP, we get a very expected answer.</p>
<div id="fig-ba-sing-se" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ba-sing-se-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/ba_sing_se.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ba-sing-se-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: There’s no war in Ba Sing Se.
</figcaption>
</figure>
</div>
<p>Where it gets interesting is when you enable the search functionality, which – oddly enough – performs a search beyond the Great Firewall.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;The Great Firewall actually cuts both ways. Its main intent might be to keep China’s netizens from accessing the ‘free’ internet, but a good deal of the effort is also to keep users on this side of the Wall from having access to whatever slight semblance of occasional uncontrolled discourse there is on the Chinese internet. This aspect is rather often ignored by Western commentators unfamiliar with Chinese internet culture.</p></div></div><div id="fig-tams" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tams-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/tams.gif" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tams-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: This is where it gets interesting.
</figcaption>
</figure>
</div>
<p>Ask it a question about the PRC’s track record on, say, human rights or historical controversies, and it would start to spill the beans – then abruptly slam on the brakes, invoking what we in the AI business call a ‘guardrail’, a kind of safety mechanism that protects users from undesirable outputs. It’s as if DeepSeek half-read you a classified file, then went “actually, never mind” and pretended you never asked. Who needs a sense of free inquiry when you can enjoy curated silence?</p>
<p>And there’s the real scandal about DeepSeek. It’s not that it’s a CCP mouthpiece. It’s not even that the CCP managed to lobotomise a machine learning model then put it out into the world as ‘open source’, making an absolute and utter mockery of that idea. The real scandal is that it also managed to pervert the notion of responsible AI and guardrails in the process, abusing what is meant to be a seatbelt, turning it into a straitjacket.</p>
<section id="whose-seatbelt-is-it-anyway" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="whose-seatbelt-is-it-anyway">Whose Seatbelt Is It Anyway</h2>
<p>Guardrails are meant to filter out harmful or illegal content. Sounds decent enough, right? Nobody wants a chatbot spitting out tips for building bombs or fomenting genocidal ideation. But guardrails also make a convenient muzzle when the people setting them have a vested interest in what can and cannot be said.</p>
<p>DeepSeek demonstrates this with such awkward flamboyance it almost feels like performance art. It shows that it <em>knows</em> certain inconvenient truths – only to pull the plug mid-sentence. There’s an inconvenient truth here: what can keep you safe from, say, the recipe for mustard gas (my pet test case for guardrails) can, in the wrong hands, keep you “safe” from factual history. When the powers behind an LLM use guardrails to stifle legitimate discourse, they invert the entire idea of “safety” –suddenly it’s about state or corporate safety, not user empowerment.</p>
<p>Which, of course, makes the mythology about DeepSeek being just a jolly side project even more ridiculous.<sup>2</sup> Training a massive model is not a trivial affair, financially or otherwise. You need loads of data, advanced expertise, technical infrastructure and computing power to pull this off. Doing so in the PRC, by a regulated company (which inevitably means CCP presence inside the company’s decision-making apparatus), means governmental oversight at best, direct involvement at worst, and my money is firmly on the latter.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Because one might need to be actively working in this field to understand how silly the assertion is that training a model of this size and accuracy, even with the clever RL only trick, could be anything other than a large scale industrial endeavour.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Never mind that they can run it for free, at pretty good (OpenAI-defying!) levels of performance. With the volume of press they’ve been getting, load must be incredible, yet I have encountered no performance degradation or outages, nor have any of the other researchers with whom I have had the pleasure to discuss DeepSeek these last few days. This is not running on someone’s home lab and a bunch of spare GPUs that aren’t doing whatever quants do with GPUs. Just operating this system at its current performance is an industrial level task, no matter how clever the reinforcement learning trick used to improve model efficiency might be.</p></div></div><p>I hope I have illustrated why the “quant side project” explanation is about as plausible as me spontaneously building a passenger jet in my garage. Sure, it is not impossible, but it sits ill with reality.<sup>3</sup> The moment you notice state-friendly guardrails are baked into the system, the notion that nobody official was meddling starts to crumble.</p>
</section>
<section id="souring-trust-and-fueling-polarisation" class="level2">
<h2 class="anchored" data-anchor-id="souring-trust-and-fueling-polarisation">Souring trust and fueling polarisation</h2>
<p>What really stings is how stunts like this undermine trust in AI more broadly. If a single model can appear to openly discuss a contentious issue, then suddenly lock down as if a party censor is peering over its shoulder, that sets off alarm bells. It is a short leap from there to suspecting <em>all</em> publicly released LLMs might be covert mouthpieces for whichever power sponsored them. The innocent curiosity that once framed AI as a neutral tool becomes overshadowed by paranoia.</p>
<p>This also amplifies the kind of polarisation we see in geopolitics. When big states can afford to spin up models that quietly nudge narratives in a particular direction, we lose the last remnants of hope that AI might be above the political fray. It becomes yet another field where states compete to drown one another in carefully curated content or half-truths, with users stuck in the middle.</p>
<p>DeepSeek drives home a new brand of cynicism: “If a fancy new LLM appears, can we trust it?” The official line might be “We open-sourced it! Nothing to hide!” But if the training data was curated, or if shadowy “alignment” policies are embedded, the model can still be a Trojan horse. Once that suspicion sets in, good luck convincing people to use AI tools for earnest, balanced exploration.</p>
<p>The answer, of course, is that one shouldn’t trust anything, or at least verify. Not only is that avenue generally foreclosed to the lay end user, it is not even really afforded to those with the means and knowledge. Open sourcing an LLM is not the same as open sourcing human-readable code. The sole reason DeepSeek’s internal flaws are so evident is that we know where to look. Were that not the case, or had the developers (and their minders from what likely is the PRC’s Ministry for State Security aka MSS) been any more subtle, we would not know what biases we have brought under our roof. The usual “don’t trust me, bro” disclaimers are about as useful here as the “not cleared by the FDA” notices on snake oil. It’s still, at the end of the day, making promises. It still, like snake oil, fails to meet them.</p>
</section>
<section id="the-epistemic-of-tools-vs.-information" class="level2">
<h2 class="anchored" data-anchor-id="the-epistemic-of-tools-vs.-information">The epistemic of tools vs.&nbsp;information</h2>
<p>We tend to treat large language models like glorified chat apps, forgetting that they amass vast amounts of textual knowledge. They do more than just parse grammar; they internalise cultural, historical and political contexts. When external gatekeepers meddle with the training set or impose ideological constraints, the model will reflect that in its embedded worldview, something most of us forget even exists. If a user is unaware of those hidden constraints and accept answers at face value, they might never suspect how they are being manipulated, be it as hamfisted as DeepSeek’s responses or wiser, subtler, more insidious bending of the truth that a slightly less <a href="[Stupid Evil - TV Tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/StupidEvil)">stupid evil</a> regime would have tried. We ultimately must disabuse ourselves of the notion that we’re dealing with unbiased, value-neutral tools, and consider LLMs what they are – information. And the moment guardrails come into the picture, any claim to being free of human bias goes off the table.</p>
<p>This isn’t an argument against guardrails altogether. On the contrary, we need some form of alignment to keep truly vile content at bay. But the question remains: <em>which</em> alignment and <em>whose</em> values? A possible way forward is an auditable chain-of-custody for model training, coupled with immutable model cards that detail the sources, curation processes and alignment methods. If a government or company demands specific guardrails for certain subjects, that fact should be clearly disclosed for all to see. But we have yet to see credible attempts at widespread use and popularisation of such technology. More ink was spilled on comparing DeepSeek with o1 than on the glaring issues presented by a model that one could, and should, expect to bear the fingerprints of one of the most repressive regimes on the planet.</p>
<p>DeepSeek is more than just a technological marvel or a threat to Western AI hegemony. It’s a reminder that alignment itself can be weaponized – particularly by entities with a history of suppressing information and controlling narratives. When alignment is used to conceal rather than safeguard, or to manipulate rather than protect, we’re staring down the business end of a propaganda pipeline disguised as advanced software.</p>
<p>It’s easy to argue users are responsible for checking the answers they get, but let’s be honest – propaganda works. We know it does. It works because by and large, people don’t check the information they consume. When millions of users worldwide rely on these models to explain historical or political content, subtle manipulations can shape public understanding in ways we might not even notice until it’s too late. AI might not have self-awareness, but it certainly does have the power to shape awareness in others.</p>
<p>And so, here we are, strapped in tight on the propaganda rollercoaster by a seatbelt supposedly meant to protect us from harm. In a sense, we are fortunate – because hopefully, this will spark the right kind of discussion in certain corners about the painful reality that there are some very human hands turning the knobs and levers of alignment and guardrails. And we <em>must</em> have this awkward, painful discussion, because the alternative is a world in which reality is dictated by the mightiest sponsor with a big enough GPU farm – and a bigger political agenda.</p>
<hr>
<p><em>Note: These are my personal (and somewhat tongue-in-cheek) views, and may not reflect the views of any organisation, company or board I am associated with, in particular HCLTech or HCL America Inc.&nbsp;My day-to-day consulting practice is complex, tailored to client needs and informed by a range of viewpoints and contributors. <a href="https://chrisvoncsefalvay.com/disclaimer">Click here for a full disclaimer.</a></em></p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {Seatbelts and Straitjackets},
  date = {2025-01-25},
  url = {https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/},
  langid = {en-GB}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas">
Chris von Csefalvay. 2025. <span>“Seatbelts and Straitjackets.”</span>
<a href="https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/">https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/</a>.
</div></div></section></div> ]]></description>
  <category>AI</category>
  <category>LLMs</category>
  <category>alignment</category>
  <category>ethics</category>
  <guid>https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/</guid>
  <pubDate>Sat, 25 Jan 2025 00:00:00 GMT</pubDate>
  <media:content url="https://chrisvoncsefalvay.com/posts/deepseek-seatbelts-and-straitjackets/header.webp" medium="image" type="image/webp"/>
</item>
</channel>
</rss>
