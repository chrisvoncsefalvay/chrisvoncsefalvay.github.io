<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-10-15">
<meta name="description" content="What if we’ve got one of the most important things in our understanding of who we are, and what makes us intelligent, utterly wrong?">

<title>Chris von Csefalvay - Beyond Broca</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=395640625"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', '395640625', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Chris von Csefalvay - Beyond Broca">
<meta property="og:description" content="What if we’ve got one of the most important things in our understanding of who we are, and what makes us intelligent, utterly wrong?">
<meta property="og:image" content="https://chrisvoncsefalvay.com/posts/llms-language/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta property="og:site-name" content="Chris von Csefalvay">
<meta name="twitter:title" content="Chris von Csefalvay - Beyond Broca">
<meta name="twitter:description" content="What if we’ve got one of the most important things in our understanding of who we are, and what makes us intelligent, utterly wrong?">
<meta name="twitter:image" content="https://chrisvoncsefalvay.com/posts/llms-language/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="Beyond Broca">
<meta name="citation_publication_date" content="2023-10-15">
<meta name="citation_cover_date" content="2023-10-15">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-10-15">
<meta name="citation_fulltext_html_url" content="https://chrisvoncsefalvay.com/posts/llms-language">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Properties of law: Essays in honour of jim harris;,citation_author=Timothy Endicott;,citation_author=Joshua Getzler;,citation_author=Edwin Peel;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Consciousness, language, and the possibility of non-human personhood: Reflections on elephants;,citation_author=Don Ross;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=3-4;,citation_volume=26;,citation_journal_title=Journal of Consciousness Studies;,citation_publisher=Imprint Academic;">
<meta name="citation_reference" content="citation_title=FOXP2 and the role of cortico-basal ganglia circuits in speech and language evolution;,citation_author=Wolfgang Enard;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=21;,citation_journal_title=Current opinion in neurobiology;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Molecular evolution of FOXP2, a gene involved in speech and language;,citation_author=Wolfgang Enard;,citation_author=Molly Przeworski;,citation_author=Simon E Fisher;,citation_author=Cecilia SL Lai;,citation_author=Victor Wiebe;,citation_author=Takashi Kitano;,citation_author=Anthony P Monaco;,citation_author=Svante Pääbo;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=6900;,citation_volume=418;,citation_journal_title=Nature;,citation_publisher=Nature Publishing Group UK London;">
<meta name="citation_reference" content="citation_title=Dissociation between language and cognitive functions in williams syndrome;,citation_author=Ursula Bellugi;,citation_author=Shelly Marks;,citation_author=Amy Bihrle;,citation_author=Helene Sabo;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Language development in exceptional circumstances;">
<meta name="citation_reference" content="citation_title=The faculty of language: What is it, who has it, and how did it evolve?;,citation_author=Marc D Hauser;,citation_author=Noam Chomsky;,citation_author=W Tecumseh Fitch;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=5598;,citation_volume=298;,citation_journal_title=science;,citation_publisher=American Association for the Advancement of Science;">
<meta name="citation_reference" content="citation_title=The nature of the language faculty and its implications for evolution of language (reply to fitch, hauser, and chomsky);,citation_author=Ray Jackendoff;,citation_author=Steven Pinker;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=97;,citation_journal_title=Cognition;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Transformer-CNN: Swiss knife for QSAR modeling and interpretation;,citation_author=Pavel Karpov;,citation_author=Guillaume Godin;,citation_author=Igor V Tetko;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=12;,citation_journal_title=Journal of cheminformatics;,citation_publisher=BioMed Central;">
<meta name="citation_reference" content="citation_title=Developing quantitative structure–activity relationship (QSAR) models for water contaminants’ activities/properties by fine-tuning GPT-3 models;,citation_author=Shifa Zhong;,citation_author=Xiaohong Guan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=Environmental Science &amp;amp;amp; Technology Letters;,citation_publisher=ACS Publications;">
<meta name="citation_reference" content="citation_title=PeptideBERT: A language model based on transformers for peptide property prediction;,citation_author=Chakradhar Guntuboina;,citation_author=Adrita Das;,citation_author=Parisa Mollaei;,citation_author=Seongwon Kim;,citation_author=Amir Barati Farimani;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2309.03099;">
<meta name="citation_reference" content="citation_title=Personhood and AI: Why large language models don’t understand us;,citation_author=Jacob Browning;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=AI &amp;amp;amp; SOCIETY;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Language, practices and the construction of personhood;,citation_author=Nancy Budwig;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=6;,citation_volume=10;,citation_journal_title=Theory &amp;amp;amp; Psychology;,citation_publisher=Sage Publications Sage CA: Thousand Oaks, CA;">
<meta name="citation_reference" content="citation_title=FOXP2 and the neuroanatomy of speech and language;,citation_author=Faraneh Vargha-Khadem;,citation_author=David G Gadian;,citation_author=Andrew Copp;,citation_author=Mortimer Mishkin;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=6;,citation_journal_title=Nature Reviews Neuroscience;,citation_publisher=Nature Publishing Group UK London;">
<meta name="citation_reference" content="citation_title=AI as agency without intelligence: On ChatGPT, large language models, and other generative models;,citation_author=Luciano Floridi;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=1;,citation_volume=36;,citation_journal_title=Philosophy &amp;amp;amp; Technology;,citation_publisher=Springer;">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Chris von Csefalvay</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../papers" rel="" target="">
 <span class="menu-text">Papers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching" rel="" target="">
 <span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../media" rel="" target="">
 <span class="menu-text">Media</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts" rel="" target="">
 <span class="menu-text">The Notebook</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://computationalinfectiousdisease.com" rel="" target="">
 <span class="menu-text">My book</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#our-precious-words" id="toc-our-precious-words" class="nav-link active" data-scroll-target="#our-precious-words">Our precious words</a></li>
  <li><a href="#the-medium-is-the-message" id="toc-the-medium-is-the-message" class="nav-link" data-scroll-target="#the-medium-is-the-message">The medium is the message</a></li>
  <li><a href="#the-language-of-intelligence-or-vice-versa" id="toc-the-language-of-intelligence-or-vice-versa" class="nav-link" data-scroll-target="#the-language-of-intelligence-or-vice-versa">The language of intelligence (or vice versa)</a></li>
  <li><a href="#the-golden-link" id="toc-the-golden-link" class="nav-link" data-scroll-target="#the-golden-link">The golden link</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Beyond Broca</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ai</div>
    <div class="quarto-category">llms</div>
    <div class="quarto-category">philosophy</div>
    <div class="quarto-category">language</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>What if we’ve got one of the most important things in our understanding of who we are, and what makes us intelligent, utterly wrong?</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chris von Csefalvay <a href="https://orcid.org/0000-0003-3131-0864" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 15, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>There’s something special about language. It is ‘our own’, it is ‘us’, in a profound way, and quite surprisingly, more so than art. I was deeply struck by this when I first saw reactions to large generative language models that created realistic, human-ish prose. Notably, those mature enough to reach a non-professional audience – ChatGPT based on GPT-3 and later GPT-4 – came quite some time after models that could create fairly acceptable visual ‘art’.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>This was quite striking, for three reasons.</p>
<ul>
<li>For one, computationally, the probability space that a model seeking to create a realistic image has to navigate is exponentially larger than what’s required to produce human-like prose.</li>
<li>Secondly, we consider making art to be a very deeply human endeavour. Animals may to some minimal extent be taught to create poor simulacra of human artistic endeavours like painting, but nobody would confuse a trained elephant’s ‘paintings’ to art <span class="citation" data-cites="ross2019consciousness">(<a href="#ref-ross2019consciousness" role="doc-biblioref">Ross 2019</a>)</span>. Art is not just a product, it’s also an activity, one that proceeds with a subjective element in the artist, and no machine can replicate the process, no matter how well it may approximate the outcome.</li>
<li>Most importantly, however, despite the previous point, lay audiences saw a connection between a simulacrum of language and human-like intelligence that was absent from a simulacrum of art.</li>
</ul>
<p>Which, of course, leads us to the key question: what if we got one of the most deeply enshrined beliefs about language, intelligence and the relationship between the two <em>utterly, dreadfully wrong</em>?</p>
<section id="our-precious-words" class="level1">
<h1>Our precious words</h1>
<p>A large language model (LLM) is, essentially, a very simple machine that knows a large number of conditional probabilities. Given a sequence of tokens <span class="math inline">\(k_0, k{1}, \cdots, k_{n}\)</span>, it associates every possible token <span class="math inline">\(k^{\prime}\)</span> with a probability <span class="math inline">\(p(k_{n + 1} = k^{\prime} | k_0, k{1}, \cdots, k_{n})\)</span> – or in other words, given a token sequence <span class="math inline">\(k_0, k{1}, \cdots, k_{n}\)</span>, it assigns to every point in a probability space a conditional likelihood that that point’s corresponding token will be the <span class="math inline">\(k_{n+1}\)</span>-th token. Or, using my preferred formulation, which looks at the inverse probability: given the token sequence, it creates a probability distribution of the next token and draws stochastically, weighted by token likelihood, so that a draw from the region of highest probability is most likely.</p>
<p>It turns out that if the model’s understanding of these conditional probabilities is sufficiently good, it can simulate knowledge quite well, <a href="https://chrisvoncsefalvay.com/posts/knowledge-dividend-of-llms/">a point I belaboured elsewhere</a>. This is not overly surprising. If a model knew the conditional probability of rain on day <span class="math inline">\(d\)</span> – let’s call this <span class="math inline">\(p_r(d)\)</span>, given a vector <span class="math inline">\(\theta_r\)</span> of length <span class="math inline">\(n\)</span> that tells us whether it rained on days <span class="math inline">\(d-1\)</span>, <span class="math inline">\(d-2\)</span>, …, <span class="math inline">\(d-n\)</span>, we’d trust it to tell us whether we’d need our raincoat on that given day. All it would have to do for that is to learn the conditional probability of <span class="math inline">\(p_r(d) | \theta_n\)</span>, which of course it could easily do by representing <span class="math inline">\(p_r(d) | \theta_n\)</span> as <span class="math inline">\(f(d, \theta_n)\)</span>, then learning the parameters of that function so as to minimise a loss function <span class="math inline">\(J(f(d, \theta_n), r(d), \theta_n(d))\)</span>, where <span class="math inline">\(r(d)\)</span> is of course whether it rained on day <span class="math inline">\(d\)</span> and <span class="math inline">\(\theta_n(d)\)</span> is the <span class="math inline">\(\theta_n\)</span> history vector for the day <span class="math inline">\(d\)</span>. Iterate this often enough (over not single values of <span class="math inline">\(r(d)\)</span> and <span class="math inline">\(\theta_n(d)\)</span> but vectors thereof), and you can learn a pretty decent conditional probability function. The model would know no more about rain or shine than LLMs know about language or the subject matters of language, but simulating tokens gets you quite a long way towards being useful as a simulacrum of knowledge.</p>
<p>Indeed, this is to the point that what comes out of such a model might well appear human-like: modern GPT implementations can produce prose that is a little stilted at times, but certainly often only distinguishable from human prose by the conspicuous absence of grammatical and spelling errors. This is interesting because of how it was perceived: quite immediately, this was connected to a kind of intelligence that was almost human, or indeed at times better than human. People suddenly started to worry about a dumb token simulator taking over their jobs.</p>
<p>Clearly, language hit a nerve.</p>
</section>
<section id="the-medium-is-the-message" class="level1">
<h1>The medium is the message</h1>
<p>JARVIS. Siri. Alexa. WOPR. The AIs of fiction and our every-days have one thing in common: they use language as the presentation layer. This is deceptive, because neither of these systems are, well, particularly smart. Compared to models that can, say, quantitatively infer the activity of a small molecule drug from its structure (QSAR models, on which <span class="citation" data-cites="karpov2020transformer zhong2023developing guntuboina2023peptidebert">(see <a href="#ref-karpov2020transformer" role="doc-biblioref">Karpov, Godin, and Tetko 2020</a>; and also see <a href="#ref-zhong2023developing" role="doc-biblioref">Zhong and Guan 2023</a>; <a href="#ref-guntuboina2023peptidebert" role="doc-biblioref">Guntuboina et al. 2023</a>)</span>), Siri is pretty pathetic. However, it has something QSAR models and other very impressive applications of machine learning don’t: the human presentation layer, i.e.&nbsp;language.</p>
<p>How we treat a system seems to be conditional on how it talks to us. In that sense, the medium is profoundly how we treat the message. To use the terminology of J.W. Harris’s writings on human rights, we associate the ‘right’ to be considered to be intrinsically connected to being capable of engaging in human ’discourse <span class="citation" data-cites="endicott2006properties">(see <a href="#ref-endicott2006properties" role="doc-biblioref">Endicott, Getzler, and Peel 2006</a>)</span>. And that, of course, means language.</p>
<p>This is not overly surprising, either. Our understanding of language has been that of a watershed moment in evolution. Humans became what they are when they learned to use language. Tool use is great, but tool use only makes <em>a human</em> at best. What makes <em>humans</em>, plural, is language. This is intrinsically connected, of course, to society. Language is not an arbitrarily selected activity, nor is it really necessarily the kind of evolutionary game changer that tool use is. Rather, it is the tool, the <em>sine qua non</em>, the cornerstone and the absolutely fundamental instrument of social interaction. Language creates society. Society recognises human individuals and gives that recognition a meaning. The fact that I am a human being, and recognised as such (I hope), has a meaning that is different from me recognising that my dog is an individual of the species <em>Canis lupus familiaris</em>, because it does not merely acknowledge me as being of a certain species, but also of being of a certain kind of agent capable not only of having rights but also of speaking for them. Language is how all that happens <span class="citation" data-cites="budwig2000language browning2023personhood">(e.g. <a href="#ref-budwig2000language" role="doc-biblioref">Budwig 2000</a>; but see <a href="#ref-browning2023personhood" role="doc-biblioref">Browning 2023</a>)</span>.</p>
</section>
<section id="the-language-of-intelligence-or-vice-versa" class="level1">
<h1>The language of intelligence (or vice versa)</h1>
<p>What, then, if we got one of the most important things about humanity, and human intelligence, dreadfully wrong altogether? What if language is not a <em>product</em> of intelligence (as we understand it in the human context) but rather a necessary instrument thereof?</p>
<p>The evolution of something as crucial as language remains shrouded in a perplexing mystery to this date. What we know is that at some point, about 50-100,000 years ago, <em>something</em> happened that gave rise to language. We don’t quite know what it was, or how it specifically transpired. Indeed, despite advances in our understanding of cognitive neuroscience, we haven’t found evidence of the ‘language faculty’ proposed by Chomsky <span class="citation" data-cites="hauser2002faculty jackendoff2005nature">(<a href="#ref-hauser2002faculty" role="doc-biblioref">Hauser, Chomsky, and Fitch 2002</a>; but see the criticisms by <a href="#ref-jackendoff2005nature" role="doc-biblioref">Jackendoff and Pinker 2005</a>)</span> (not to be confused with the brain areas responsible for speech, which perplexingly are part, but not the whole, of the language faculty). The genetics of language production – which centres around FOXP2 these days [see enard2002molecular; enard2011foxp2] – hasn’t gotten us a lot further, and there are way too many edge cases (<em>dissociations</em>, as the term in evolutionary neuroscience goes), where either there is a significant intellectual deficit despite preserved language ability (Williams syndrome being the textbook example of this <span class="citation" data-cites="bellugi2013dissociation">(<a href="#ref-bellugi2013dissociation" role="doc-biblioref">Bellugi et al. 2013</a>)</span>) or the inverse (e.g.&nbsp;Developmental Verbal Dyspraxia, where there is impairment to language production but not to overall intellect <span class="citation" data-cites="vargha2005foxp2">(<a href="#ref-vargha2005foxp2" role="doc-biblioref">Vargha-Khadem et al. 2005</a>)</span>) to be able to confidently make this connection on an individual level.</p>
<p>On the other hand, on a broader level, it is hard to discount the relationship. What is more complex is the direction of this relationship. There are, really, three possible scenarios:</p>
<ol type="1">
<li>Language is a consequence of human intelligence. The kind of intelligence we associate with modern human cognitive capabilities necessarily presupposes, absent some marginal exceptions, language.</li>
<li>Language is an epiphenomenon of human intelligence. It evolved in parallel, but neither requires human intelligence (see Williams syndrome) nor does human intelligence require it (see Developmental Verbal Dyspraxia).</li>
<li>Human intelligence is largely a consequence of language, which is its necessary but not sufficient condition. It is the evolutionarily most stable representation layer for information, and allows reasoning through complexity.</li>
</ol>
<p>While the second of these is a convenient way to hand-wave away the entire question and account for the edge cases I discussed above, I find the third of these much more compelling. It is not defeated by the argument from either of the edge cases: it is not defeated by arguments from intact language despite intellectual deficits, because it does not assume that language is sufficient, merely that it is necessary. It is not defeated by the inverse, either, because it permits a small number of deviations. Language is not the only possible representational layer that could underpin intelligence. It is, however, vastly more evolutionarily advantageous through its efficiency. It is so much stronger and so much more efficient that it can be considered almost absolutely dominant – which indeed accounts for the fact that disorders of language with preserved intellectual functioning are vanishingly rare. If the efficiency of language as the ‘operating system’ of intelligence weren’t so strongly dominant, such disorders would not be disorders, indeed, but alternate ways of cognitive existence that are equally evolutionarily stable.</p>
</section>
<section id="the-golden-link" class="level1">
<h1>The golden link</h1>
<p>Which leads us to what I shall call the “golden link” of intelligence – and perhaps the most frightening finding that derives from LLMs. We intuit, correctly, that a realistic simulacrum of language is an indication of intelligence. We once more intuit, correctly, that even if we’re aware of the limits of LLMs’ ‘language’, it displays more than a scintilla of whatever makes up intelligence. Just as Stable Diffusion is not art but a simulacrum of the end result of the process we know as ‘art’, ChatGPT isn’t really ‘language’ but a simulacrum, by way of extending token sequences, of the end result of the process we know as ‘language’ – but no matter how deeply we understand this, it is hard to deny that ChatGPT does speak to us, to quote Kipling, “as a man would talk to a man”. Or, to put it this way: all the amazing things genuinely complicated artificial intelligence can do, such as predict protein structures or binding affinities or interpret histology specimens or optimise mathematical problems, is a <em>praxis</em> – something the system <em>does</em>. Producing language is, or at least is some way towards, a <em>hexis</em> – something the system <em>is</em>. Ande that makes all the difference.</p>
<p>And so, our trepidation and the ‘uncanny valley’ sensation of LLMs’ ‘intelligence’ is quite instructive <span class="citation" data-cites="floridi2023ai">(<a href="#ref-floridi2023ai" role="doc-biblioref">Floridi 2023</a>)</span>. It shows, clear as day, the intrinsic link between language and intelligence, but more importantly, that language is not a consequence of intelligence but a fundamental pre-requisite and indeed the communication protocol on which efficient human intelligence rests. Language is neither sufficient nor necessary for human intelligence (and perhaps other forms of intelligence do exist that do not require language at all), but it is the evolutionarily dominant stable strategy for representing information in a manner that can support intelligence.</p>
<p>There lies the scariest revelation of LLMs. It’s not that LLMs will supplant us (they won’t), or that we’ll be condemned to a lifetime of reading books written by LLMs (have you tried to get ChatGPT to write a story on a novel premise?), nor that LLMs will steal our jobs and take over the planet. Rather, the great revelation is that LLMs cast light on what might have been one of the longest standing fallacies of humans reasoning about reasoning – that language is the product of intelligence, and not its operating system.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-bellugi2013dissociation" class="csl-entry" role="listitem">
Bellugi, Ursula, Shelly Marks, Amy Bihrle, and Helene Sabo. 2013. <span>“Dissociation Between Language and Cognitive Functions in Williams Syndrome.”</span> In <em>Language Development in Exceptional Circumstances</em>, 177–89. Psychology Press.
</div>
<div id="ref-browning2023personhood" class="csl-entry" role="listitem">
Browning, Jacob. 2023. <span>“Personhood and AI: Why Large Language Models Don’t Understand Us.”</span> <em>AI &amp; SOCIETY</em>, 1–8.
</div>
<div id="ref-budwig2000language" class="csl-entry" role="listitem">
Budwig, Nancy. 2000. <span>“Language, Practices and the Construction of Personhood.”</span> <em>Theory &amp; Psychology</em> 10 (6): 769–86.
</div>
<div id="ref-endicott2006properties" class="csl-entry" role="listitem">
Endicott, Timothy, Joshua Getzler, and Edwin Peel. 2006. <span>“Properties of Law: Essays in Honour of Jim Harris.”</span>
</div>
<div id="ref-floridi2023ai" class="csl-entry" role="listitem">
Floridi, Luciano. 2023. <span>“AI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.”</span> <em>Philosophy &amp; Technology</em> 36 (1): 15.
</div>
<div id="ref-guntuboina2023peptidebert" class="csl-entry" role="listitem">
Guntuboina, Chakradhar, Adrita Das, Parisa Mollaei, Seongwon Kim, and Amir Barati Farimani. 2023. <span>“PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction.”</span> <em>arXiv Preprint arXiv:2309.03099</em>.
</div>
<div id="ref-hauser2002faculty" class="csl-entry" role="listitem">
Hauser, Marc D, Noam Chomsky, and W Tecumseh Fitch. 2002. <span>“The Faculty of Language: What Is It, Who Has It, and How Did It Evolve?”</span> <em>Science</em> 298 (5598): 1569–79.
</div>
<div id="ref-jackendoff2005nature" class="csl-entry" role="listitem">
Jackendoff, Ray, and Steven Pinker. 2005. <span>“The Nature of the Language Faculty and Its Implications for Evolution of Language (Reply to Fitch, Hauser, and Chomsky).”</span> <em>Cognition</em> 97 (2): 211–25.
</div>
<div id="ref-karpov2020transformer" class="csl-entry" role="listitem">
Karpov, Pavel, Guillaume Godin, and Igor V Tetko. 2020. <span>“Transformer-CNN: Swiss Knife for QSAR Modeling and Interpretation.”</span> <em>Journal of Cheminformatics</em> 12 (1): 1–12.
</div>
<div id="ref-ross2019consciousness" class="csl-entry" role="listitem">
Ross, Don. 2019. <span>“Consciousness, Language, and the Possibility of Non-Human Personhood: Reflections on Elephants.”</span> <em>Journal of Consciousness Studies</em> 26 (3-4): 227–51.
</div>
<div id="ref-vargha2005foxp2" class="csl-entry" role="listitem">
Vargha-Khadem, Faraneh, David G Gadian, Andrew Copp, and Mortimer Mishkin. 2005. <span>“FOXP2 and the Neuroanatomy of Speech and Language.”</span> <em>Nature Reviews Neuroscience</em> 6 (2): 131–38.
</div>
<div id="ref-zhong2023developing" class="csl-entry" role="listitem">
Zhong, Shifa, and Xiaohong Guan. 2023. <span>“Developing Quantitative Structure–Activity Relationship (QSAR) Models for Water Contaminants’ Activities/Properties by Fine-Tuning GPT-3 Models.”</span> <em>Environmental Science &amp; Technology Letters</em>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I don’t mean to insinuate that what Stable Diffusion and DALL·E produce are ‘art’ in the sense we understand that concept. However, neither is what GPT produces ‘language’. They are both simulators of outcomes based on stochastic approximations over a sufficiently large training set to be able to approximate the outcome of human activities we know as ‘art’ and ‘language’, respectively.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{csefalvay2023,
  author = {Chris von Csefalvay},
  title = {Beyond {Broca}},
  date = {2023-10-15},
  url = {https://chrisvoncsefalvay.com/posts/llms-language},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Chris von Csefalvay. 2023. <span>“Beyond Broca.”</span> October 15,
2023. <a href="https://chrisvoncsefalvay.com/posts/llms-language">https://chrisvoncsefalvay.com/posts/llms-language</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">(c) Chris von Csefalvay, 2011–. <a href="disclaimer">Disclaimer</a></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>