<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chris von Csefalvay">
<meta name="dcterms.date" content="2025-12-25">
<meta name="description" content="Beyond loss curves – what you should actually be watching when fine-tuning LLMs.">

<title>The post-training instrument cluster – Part I – Chris von Csefalvay</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a4d8066ab99c821fadc425098389dfee.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=395640625"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', '395640625', { 'anonymize_ip': true});
</script>
<script type="application/ld+json">{"@context":"http://www.schema.org","@type":"person","name":"Chris von Csefalvay","jobTitle":"Director of Biomedical AI/ML","height":"74 inches","gender":"male","description":"Chris von Csefalvay is a computational epidemiologist and data scientist working at the intersection of AI/ML, computational dynamics and public health. He is the author of Computational Modeling of Infectious Disease and a number of research papers.","url":"https://chrisvoncsefalvay.com","image":"https://chrisvoncsefalvay.com/img/IMG_5986.jpeg","address":{"@type":"PostalAddress","addressLocality":"Denver","addressRegion":"CO","postalCode":"80204","addressCountry":"United States"},"alumniOf":[{"@type":"CollegeOrUniversity","name":"University of Oxford","sameAs":"https://en.wikipedia.org/wiki/University_of_Oxford"},{"@type":"CollegeOrUniversity","name":"Cardiff University","sameAs":"https://en.wikipedia.org/wiki/Cardiff_University"}],"worksFor":[{"@type":"Organization","name":"HCLTech"}],"birthDate":"1986-07-15","birthPlace":"Budapest, Hungary","memberOf":[{"@type":"Organization","name":"Royal Society for Public Health"},{"@type":"Organization","name":"TOPRA"},{"@type":"Organization","name":"IEEE"}],"nationality":[{"@type":"Country","name":"United Kingdom"},{"@type":"Country","name":"Hungary"}]}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="The post-training instrument cluster – Part I – Chris von Csefalvay">
<meta property="og:description" content="Beyond loss curves – what you should actually be watching when fine-tuning LLMs.">
<meta property="og:image" content="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/failure_patterns.png">
<meta property="og:site_name" content="Chris von Csefalvay">
<meta property="og:image:height" content="1484">
<meta property="og:image:width" content="1642">
<meta name="twitter:title" content="The post-training instrument cluster – Part I – Chris von Csefalvay">
<meta name="twitter:description" content="Beyond loss curves – what you should actually be watching when fine-tuning LLMs.">
<meta name="twitter:image" content="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/failure_patterns.png">
<meta name="twitter:image-height" content="1484">
<meta name="twitter:image-width" content="1642">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="The post-training instrument cluster -- Part I">
<meta name="citation_author" content="Chris von Csefalvay">
<meta name="citation_publication_date" content="2025-12-25">
<meta name="citation_cover_date" content="2025-12-25">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-12-25">
<meta name="citation_fulltext_html_url" content="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/">
<meta name="citation_language" content="en-GB">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Chris von Csefalvay</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../papers"> 
<span class="menu-text">Papers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching"> 
<span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../media"> 
<span class="menu-text">Media</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts"> 
<span class="menu-text">The Notebook</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../talks"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://computationalinfectiousdisease.com"> 
<span class="menu-text">My book</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-case-for-comprehensive-monitoring" id="toc-the-case-for-comprehensive-monitoring" class="nav-link active" data-scroll-target="#the-case-for-comprehensive-monitoring">The case for comprehensive monitoring</a></li>
  <li><a href="#instrument-1-the-loss-landscape" id="toc-instrument-1-the-loss-landscape" class="nav-link" data-scroll-target="#instrument-1-the-loss-landscape">Instrument 1: the loss landscape</a></li>
  <li><a href="#instrument-2-gradient-histograms" id="toc-instrument-2-gradient-histograms" class="nav-link" data-scroll-target="#instrument-2-gradient-histograms">Instrument 2: gradient histograms</a></li>
  <li><a href="#instrument-3-learning-rate-dynamics" id="toc-instrument-3-learning-rate-dynamics" class="nav-link" data-scroll-target="#instrument-3-learning-rate-dynamics">Instrument 3: learning rate dynamics</a></li>
  <li><a href="#instrument-4-attention-entropy" id="toc-instrument-4-attention-entropy" class="nav-link" data-scroll-target="#instrument-4-attention-entropy">Instrument 4: attention entropy</a></li>
  <li><a href="#instrument-5-generation-quality-samples" id="toc-instrument-5-generation-quality-samples" class="nav-link" data-scroll-target="#instrument-5-generation-quality-samples">Instrument 5: generation quality samples</a></li>
  <li><a href="#instrument-6-lora-adapter-diagnostics" id="toc-instrument-6-lora-adapter-diagnostics" class="nav-link" data-scroll-target="#instrument-6-lora-adapter-diagnostics">Instrument 6: LoRA adapter diagnostics</a></li>
  <li><a href="#instrument-7-compute-efficiency" id="toc-instrument-7-compute-efficiency" class="nav-link" data-scroll-target="#instrument-7-compute-efficiency">Instrument 7: compute efficiency</a></li>
  <li><a href="#instrument-8-convergence-detection" id="toc-instrument-8-convergence-detection" class="nav-link" data-scroll-target="#instrument-8-convergence-detection">Instrument 8: convergence detection</a></li>
  <li><a href="#putting-it-all-together" id="toc-putting-it-all-together" class="nav-link" data-scroll-target="#putting-it-all-together">Putting it all together</a></li>
  <li><a href="#the-wandb-configuration" id="toc-the-wandb-configuration" class="nav-link" data-scroll-target="#the-wandb-configuration">The wandb configuration</a></li>
  <li><a href="#reading-the-dashboard" id="toc-reading-the-dashboard" class="nav-link" data-scroll-target="#reading-the-dashboard">Reading the dashboard</a></li>
  <li><a href="#what-comes-next" id="toc-what-comes-next" class="nav-link" data-scroll-target="#what-comes-next">What comes next</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The post-training instrument cluster – Part I</h1>
  <div class="quarto-categories">
    <div class="quarto-category">AI</div>
    <div class="quarto-category">LLMs</div>
    <div class="quarto-category">fine-tuning</div>
    <div class="quarto-category">MLOps</div>
  </div>
  </div>

<div>
  <div class="description">
    Beyond loss curves – what you should actually be watching when fine-tuning LLMs.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chris von Csefalvay <a href="mailto:chris@chrisvoncsefalvay.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-3131-0864" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">25 December 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Hey, I’m writing a book about this!
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m actually writing a book about this stuff. It turns out there isn’t a lot of literature on how to do post-training at the level too big for single-GPU laptop-sized hobby projects and requiring enterprise reliability on one hand, but not quite at the scale of multi-team distributed post-training you’d get in foundation labs. That’s a problem, because a lot of the current value in fine-tuning applications comes exactly out of that large, crucial market. I am in the last phases of putting together the manuscript for <em>The Frontier Playbook</em>, a set of curated tactics and techniques for real world operationalisation of LLMs. <a href="https://aifrontierplaybook.substack.com">Sign up for updates here</a>.</p>
</div>
</div>
<p>Jimmy Doolittle, later famous for leading the daring Doolittle Raid on Tokyo in 1942, was a pioneering aviator in the 1920s and 30s. One of his key contributions to aviation was the first of what at the time was called “blind” flight – what we would refer to as IFR (Instrument Flight Rules) flight today. Doolittle demonstrated that with the right set of instruments, a pilot could safely navigate and land an aircraft without any external visual references. A few years later, instrument flying became increasingly standardised, and in the late 1930s, the main instruments and their arrangement into the “basic T” layout of six key instruments – affectionately referred to as the six-pack – was formalised. To this day, virtually all aircraft have the same instrument cluster in the same order, and every pilot is trained to interpret them. Together, they create a fairly comprehensive picture of the aircraft’s state and environment.</p>
<p>You should aspire to have the same for your LLM post-training.</p>
<p>Unfortunately, that doesn’t come without some effort. Even though really good tools exist for monitoring fine-tuning runs, what you get out of the box is often quite lacklustre. When you fire up a fine-tuning run and open your Weights &amp; Biases dashboard, you’re greeted with the same three faithful companions: training loss, validation loss and gradient norm. They’re like the speedometer, fuel gauge and temperature warning light of the machine learning world – essential, certainly, but hardly sufficient for understanding what’s actually happening under the bonnet. Nobody would fly a commercial airliner with three instruments, and nobody should run a fine-tuning job of any seriousness with just loss curves and a gradient norm.</p>
<p>More important than what you see is knowing how to read those instruments. As you monitor a post-training job, regardless of whether it’s SFT, DPO, GRPO, even something more exotic, you’re largely after the same information: is the model learning what you want it to learn, is the optimisation stable, are there any silent failure modes creeping in, and when should I stop? Knowing how to read the instruments properly means you’ll know a lot about the model while it’s still in the oven, so to speak, and you can catch issues early. This is useful for the ML hobbyist, but indispensable for the enterprise practitioner. At that scale, a solid training run can cost north of five figures – not foundation lab training cost scale (it is estimated that a single training run of a modern foundation model is easily in the realm of nine figures), but enough that wasting runs is eventually going to attract management attention.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;I’m being my usual flippant self here, but there’s a very real economic, environmental and social cost to wasted compute. We owe it to the world and to future generations to make sure we make every watt of compute count. One can disagree about the ethics of the money and energy and CO2 emissions that are devoted to training LLMs – it is rather harder to argue that wasting those resources is in any way justifiable.</p></div></div><p>The purpose of this post – the first in a series of three – is twofold: to explain what a comprehensive post-training instrument cluster looks like for the easiest ‘base case’ (plain vanilla SFT) and provide you with the code to implement it yourself on one hand, and learning how to interpret them on the other.</p>
<section id="the-case-for-comprehensive-monitoring" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-case-for-comprehensive-monitoring">The case for comprehensive monitoring</h2>
<p>Before we dive into the instruments themselves, it’s worth asking: why bother? The loss is going down, the model is learning, what more do you need?</p>
<p>The answer, as with most things in machine learning, is that the happy path is easy and the failure modes are numerous. A decreasing loss curve can mask catastrophic forgetting. A stable gradient norm can coexist with attention collapse. A model can achieve excellent validation loss while generating nonsense. Worse, many of these failure modes are silent until you actually deploy the model and discover, often at significant cost, that something went wrong twenty hours into a forty-hour training run.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;I’ve seen production fine-tuning runs where the model appeared to be learning beautifully right up until generation quality fell off a cliff. The loss was still decreasing. The gradient norm was textbook perfect. The only hint that something was wrong was a subtle shift in the attention entropy that nobody was monitoring.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Even better, good monitoring can often prevent failures from happening in the first place. Catching a loss spike or a gradient explosion early can save hours of wasted compute and frustration. Monitoring logs can – indeed, should! – act as release gates at worst, meaning you might well avoid the ‘mortem’ part altogether.</p></div></div><p>Enterprise fine-tuning adds another dimension of complexity. You’re not just training a model, you’re accountable for training a model. When a stakeholder asks why a particular run failed, ‘the loss looked fine but the model doesn’t work’ is not an acceptable answer. Comprehensive monitoring provides the forensic trail that turns post-mortems from guesswork into analysis.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
</section>
<section id="instrument-1-the-loss-landscape" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-1-the-loss-landscape">Instrument 1: the loss landscape</h2>
<p>Let’s start with the obvious: loss. But we’re going to look at it properly.</p>
<p>The default wandb setup gives you <code>train/loss</code> and <code>eval/loss</code> as single scalar values. This is necessary but insufficient. What you actually want is a richer picture of the loss landscape:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Loss variance is particularly diagnostic for LoRA fine-tuning, where you’re updating a small fraction of parameters and the optimisation landscape can be surprisingly bumpy.</p>
</div></div><div id="44baedf2" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Enhanced loss logging callback</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainerCallback</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> deque</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LossLandscapeCallback(TrainerCallback):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Track loss statistics beyond simple averages."""</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, window_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.window_size <span class="op">=</span> window_size</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_losses <span class="op">=</span> deque(maxlen<span class="op">=</span>window_size)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eval_losses <span class="op">=</span> deque(maxlen<span class="op">=</span>window_size)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_log(<span class="va">self</span>, args, state, control, logs<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> logs <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"loss"</span> <span class="kw">in</span> logs:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.train_losses.append(logs[<span class="st">"loss"</span>])</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.train_losses) <span class="op">&gt;=</span> <span class="dv">10</span>:</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                losses <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.train_losses)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                logs[<span class="st">"train/loss_variance"</span>] <span class="op">=</span> np.var(losses)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                logs[<span class="st">"train/loss_trend"</span>] <span class="op">=</span> np.polyfit(</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">range</span>(<span class="bu">len</span>(losses)), losses, <span class="dv">1</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                )[<span class="dv">0</span>]</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Detect loss spikes</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                recent <span class="op">=</span> losses[<span class="op">-</span><span class="dv">10</span>:]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>                older <span class="op">=</span> losses[:<span class="op">-</span><span class="dv">10</span>] <span class="cf">if</span> <span class="bu">len</span>(losses) <span class="op">&gt;</span> <span class="dv">10</span> <span class="cf">else</span> losses</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>                logs[<span class="st">"train/loss_spike_ratio"</span>] <span class="op">=</span> (</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>                    np.<span class="bu">max</span>(recent) <span class="op">/</span> np.mean(older)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> older <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>                )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Loss variance increasing</strong>: The optimisation is becoming unstable. Consider reducing learning rate.</li>
<li><strong>Loss trend flattening while absolute loss is still high</strong>: You’ve hit a plateau. Either the learning rate is too low, or you’ve exhausted what this architecture can learn from this data.</li>
<li><strong>Loss spike ratio &gt; 2.0</strong>: Something dramatic happened. Check for data corruption, gradient explosion or memory issues.</li>
<li><strong>Eval loss diverging from train loss</strong>: The classic overfitting signal, but in LoRA training this can also indicate that your adapter rank is too high for your dataset size.</li>
</ul>
<div id="cell-fig-loss-diagnostics" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="2">
<div class="cell-output cell-output-display">
<div id="fig-loss-diagnostics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-loss-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-loss-diagnostics-output-1.png" width="952" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-loss-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Loss landscape diagnostics: what healthy and unhealthy training looks like.
</figcaption>
</figure>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>Sometimes, such visual guides note the existence of a pattern they call a ‘stuck loss curve’. This is essentially a perfectly fine ‘done’ loss curve (i.e.&nbsp;flat loss) with very high variance. It <em>is</em> pathological, but it’s just a special case of increasing variance, and in my view, shouldn’t be a category of its own.</p>
</div></div></section>
<section id="instrument-2-gradient-histograms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-2-gradient-histograms">Instrument 2: gradient histograms</h2>
<p>A single gradient norm scalar tells you almost nothing. What you actually want is the <em>distribution</em> of gradients across your parameters. Weights &amp; Biases can log histograms natively, and you should take advantage of this wherever possible, but it’s important you understand what to look for.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Gradient histograms are one of the most underused diagnostic tools in deep learning. A single glance at the distribution shape tells you more than a hundred scalar metrics. The problem is, they take a lot of experience to interpret. WandB has done the world a massive service with making them pop out of the box by default if you configure it mostly the right way, but knowing what to look for is another matter entirely. There are relatively few good heuristics for what good and bad gradient distributions look like, and I’ve seen more disagreement among perfectly competent practitioners on this topic than almost any other.</p>
</div></div><p>The mathematics of gradient pathology is straightforward but worth stating precisely. During backpropagation, the gradient of the loss <span class="math inline">\(\mathcal{L}\)</span> with respect to the weights <span class="math inline">\(W_1\)</span> in an early layer depends on the chain of derivatives through all subsequent layers:</p>
<p><span class="math display">\[\frac{\partial \mathcal{L}}{\partial W_1} = \frac{\partial \mathcal{L}}{\partial W_L} \cdot \prod_{\ell=2}^{L} \left( \phi'_\ell(z_\ell) \cdot W_\ell \right)\]</span></p>
<p>where <span class="math inline">\(\phi'_\ell\)</span> is the derivative of the activation function at layer <span class="math inline">\(\ell\)</span> and <span class="math inline">\(z_\ell\)</span> is the pre-activation. The product structure is the culprit: if the spectral norm <span class="math inline">\(\|W_\ell\| &lt; 1\)</span> for most layers, the product shrinks exponentially with depth and gradients <em>vanish</em>. Conversely, if <span class="math inline">\(\|W_\ell\| &gt; 1\)</span> and <span class="math inline">\(\|\phi'_\ell\| &gt; 1\)</span>, the product grows exponentially and gradients <em>explode</em>. With ReLU activations, an additional failure mode emerges: wherever <span class="math inline">\(z_\ell &lt; 0\)</span>, the derivative is exactly zero, causing entire gradient paths to die.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;This is the mathematical foundation of the ‘dying ReLU’ problem. It’s also why Leaky ReLU, GELU and other activations with non-zero gradients everywhere have become popular in modern architectures.</p></div></div><div id="9ce50290" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Parameter-wise gradient histogram logging</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GradientHistogramCallback(TrainerCallback):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Log parameter-wise gradient histograms to wandb."""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, log_every_n_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">50</span>):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_every_n_steps <span class="op">=</span> log_every_n_steps</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_pre_optimizer_step(<span class="va">self</span>, args, state, control, model<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Capture gradients before optimizer.step() clears them."""</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.step_count <span class="op">%</span> <span class="va">self</span>.log_every_n_steps <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="im">import</span> wandb</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        histograms <span class="op">=</span> {}</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        stats <span class="op">=</span> {}</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> param.grad <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>            grad <span class="op">=</span> param.grad.detach().flatten().cpu().numpy()</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>            short_name <span class="op">=</span> <span class="va">self</span>._simplify_name(name)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Log histogram to wandb</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>            histograms[<span class="ss">f"gradients/</span><span class="sc">{</span>short_name<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> wandb.Histogram(grad)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Also log summary statistics</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>            stats[<span class="ss">f"grad_stats/</span><span class="sc">{</span>short_name<span class="sc">}</span><span class="ss">/mean"</span>] <span class="op">=</span> <span class="bu">float</span>(np.mean(grad))</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>            stats[<span class="ss">f"grad_stats/</span><span class="sc">{</span>short_name<span class="sc">}</span><span class="ss">/std"</span>] <span class="op">=</span> <span class="bu">float</span>(np.std(grad))</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>            stats[<span class="ss">f"grad_stats/</span><span class="sc">{</span>short_name<span class="sc">}</span><span class="ss">/max"</span>] <span class="op">=</span> <span class="bu">float</span>(np.<span class="bu">max</span>(np.<span class="bu">abs</span>(grad)))</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>            stats[<span class="ss">f"grad_stats/</span><span class="sc">{</span>short_name<span class="sc">}</span><span class="ss">/sparsity"</span>] <span class="op">=</span> <span class="bu">float</span>(</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>                np.mean(np.<span class="bu">abs</span>(grad) <span class="op">&lt;</span> <span class="fl">1e-8</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> wandb.run <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>            wandb.log({<span class="op">**</span>histograms, <span class="op">**</span>stats})</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _simplify_name(<span class="va">self</span>, name: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Simplify parameter name for readable logging."""</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        parts <span class="op">=</span> name.split(<span class="st">"."</span>)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        simplified <span class="op">=</span> []</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parts:</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> p.isdigit():</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>                simplified.append(<span class="ss">f"L</span><span class="sc">{</span>p<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="st">"lora"</span> <span class="kw">in</span> p.lower():</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>                simplified.append(p.replace(<span class="st">"_"</span>, <span class="st">""</span>))</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> p <span class="kw">in</span> (<span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>, <span class="st">"o_proj"</span>):</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>                simplified.append(p.replace(<span class="st">"_proj"</span>, <span class="st">""</span>))</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"_"</span>.join(simplified) <span class="cf">if</span> simplified <span class="cf">else</span> name[<span class="op">-</span><span class="dv">30</span>:]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="cell-fig-gradient-histograms" class="cell" data-fig-height="10" data-fig-width="10" data-execution_count="4">
<div class="cell-output cell-output-display">
<div id="fig-gradient-histograms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gradient-histograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-gradient-histograms-output-1.png" width="874" height="841" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gradient-histograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Gradient distribution over time (wandb-style): steps on x-axis, gradient values on y-axis, density as colour.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Distribution collapsing to a spike at zero</strong>: Vanishing gradients. Your model has stopped learning, often because of dying ReLUs, excessive regularisation or a learning rate that’s far too low.</li>
<li><strong>Fat tails extending far from zero</strong>: Exploding gradients. Even if the mean looks fine, occasional extreme values will destabilise training. Gradient clipping can help, but investigate the root cause.</li>
<li><strong>Different layers having wildly different spreads</strong>: Layer imbalance. Early layers dominating late layers (or vice versa) indicates poor initialisation or the need for layer-wise learning rate scaling.</li>
<li><strong>Bimodal or multimodal distributions</strong>: Often indicates that different parameter groups (e.g.&nbsp;attention vs MLP, or LoRA A vs B matrices) are learning at very different rates. Not always bad, but worth investigating.</li>
</ul>
</section>
<section id="instrument-3-learning-rate-dynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-3-learning-rate-dynamics">Instrument 3: learning rate dynamics</h2>
<p>The learning rate schedule is decided before training, so why monitor it? Because what matters isn’t what you <em>planned</em> but what <em>actually happened</em>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Warmup is particularly important for LoRA. Jumping straight to your target learning rate can cause the adapter weights to overshoot before the base model activations have stabilised.</p>
</div></div><div id="2440c4c1" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Learning rate monitoring with phase detection</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LearningRateMonitor(TrainerCallback):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Track effective learning rate and detect phase transitions."""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr_history <span class="op">=</span> []</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.phase <span class="op">=</span> <span class="st">"warmup"</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_step_end(<span class="va">self</span>, args, state, control, <span class="op">**</span>kwargs):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get current learning rate from optimizer</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">=</span> state.learning_rate <span class="cf">if</span> <span class="bu">hasattr</span>(state, <span class="st">"learning_rate"</span>) <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> lr <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.lr_history.append(lr)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Detect phase transitions</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.lr_history) <span class="op">&gt;</span> <span class="dv">10</span>:</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>                recent <span class="op">=</span> <span class="va">self</span>.lr_history[<span class="op">-</span><span class="dv">10</span>:]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">all</span>(recent[i] <span class="op">&gt;=</span> recent[i<span class="op">+</span><span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(recent)<span class="op">-</span><span class="dv">1</span>)):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                    new_phase <span class="op">=</span> <span class="st">"decay"</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">elif</span> <span class="bu">all</span>(recent[i] <span class="op">&lt;=</span> recent[i<span class="op">+</span><span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(recent)<span class="op">-</span><span class="dv">1</span>)):</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>                    new_phase <span class="op">=</span> <span class="st">"warmup"</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>                    new_phase <span class="op">=</span> <span class="st">"peak"</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> new_phase <span class="op">!=</span> <span class="va">self</span>.phase:</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f"LR phase transition: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>phase<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>new_phase<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.phase <span class="op">=</span> new_phase</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Warmup too short</strong>: If your loss is unstable in the first few hundred steps, you probably needed more warmup.</li>
<li><strong>Peak learning rate never reached</strong>: This happens with some schedulers when total steps are miscalculated. The training never operates at full learning rate.</li>
<li><strong>Learning rate effectively zero before training ends</strong>: Overly aggressive decay. Your final epochs are wasted.</li>
</ul>
</section>
<section id="instrument-4-attention-entropy" class="level2">
<h2 class="anchored" data-anchor-id="instrument-4-attention-entropy">Instrument 4: attention entropy</h2>
<p>This is where we leave the standard metrics behind. Yes, histograms are art, loss landscapes are science, but attention entropy is where we begin to get into chef’s kiss territory.</p>
<p>Attention entropy measures how focused or diffuse the model’s attention patterns are, and it’s one of the most diagnostic metrics for detecting subtle training pathologies. Mathematically, for a single attention head with attention weights <span class="math inline">\(\boldsymbol{\alpha} = (\alpha_1, \alpha_2, \ldots, \alpha_n)\)</span> over a sequence of length <span class="math inline">\(n\)</span> (where <span class="math inline">\(\sum_i \alpha_i = 1\)</span> after softmax), the entropy is defined as:</p>
<p><span class="math display">\[H(\boldsymbol{\alpha}) = -\sum_{i=1}^{n} \alpha_i \log \alpha_i\]</span></p>
<p>The bounds are intuitive: <span class="math inline">\(H = 0\)</span> when all attention is focused on a single token (<span class="math inline">\(\alpha_j = 1\)</span> for some <span class="math inline">\(j\)</span>, all others zero), and <span class="math inline">\(H = \log n\)</span> when attention is uniformly distributed (<span class="math inline">\(\alpha_i = 1/n\)</span> for all <span class="math inline">\(i\)</span>). In practice, we average across heads and layers to get a scalar summary, but per-head entropy can reveal pathologies that aggregates hide.</p>
<div id="7969ce91" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Attention entropy monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionEntropyCallback(TrainerCallback):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Monitor attention pattern entropy during training."""</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, log_every_n_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>, num_heads_to_sample: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span>):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_every_n_steps <span class="op">=</span> log_every_n_steps</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads_to_sample <span class="op">=</span> num_heads_to_sample</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_entropy(<span class="va">self</span>, attn_weights: torch.Tensor) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute entropy of attention distribution."""</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># attn_weights: [batch, heads, seq, seq]</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalise to valid probability distribution</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        attn_probs <span class="op">=</span> F.softmax(attn_weights, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute entropy: -sum(p * log(p))</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        entropy <span class="op">=</span> <span class="op">-</span>torch.<span class="bu">sum</span>(</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            attn_probs <span class="op">*</span> torch.log(attn_probs <span class="op">+</span> <span class="fl">1e-10</span>), dim<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> entropy.mean().item()</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_step_end(<span class="va">self</span>, args, state, control, model<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.step_count <span class="op">%</span> <span class="va">self</span>.log_every_n_steps <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Hook to capture attention weights during forward pass</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation depends on model architecture</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This is a simplified example</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        entropy_stats <span class="op">=</span> {</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">"attention/mean_entropy"</span>: <span class="va">self</span>._get_mean_entropy(model),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">"attention/entropy_variance"</span>: <span class="va">self</span>._get_entropy_variance(model),</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log metrics</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(state, <span class="st">"log_history"</span>) <span class="kw">and</span> state.log_history:</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>            state.log_history[<span class="op">-</span><span class="dv">1</span>].update(entropy_stats)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="cell-fig-attention-entropy" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="7">
<div class="cell-output cell-output-display">
<div id="fig-attention-entropy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-attention-entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-attention-entropy-output-1.png" width="951" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention-entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Attention entropy diagnostics: mean entropy (solid) and cross-head variance (dashed) reveal different pathologies.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Attention entropy collapsing towards zero</strong>: The model is attending to single tokens almost exclusively. This is often a sign of attention sink formation or degenerate patterns.</li>
<li><strong>Attention entropy increasing unboundedly</strong>: The model is spreading attention uniformly – essentially not learning to focus. This can indicate that your task doesn’t require sequence understanding, or that something is wrong with positional encoding.</li>
<li><strong>Sudden entropy changes mid-training</strong>: Phase transitions in what the model is learning. Not necessarily bad, but worth investigating. <em>When</em> exactly this is okay depends to a great extent on your task – and the answer may often enough be “never”. I see this a lot when we’re fine-tuning time series type transformers for semi-periodic signals. It’s okay for the model to have some attention entropy to see various scales of periodicities, but not essentially for it to blow up unboundedly.</li>
</ul>
</section>
<section id="instrument-5-generation-quality-samples" class="level2">
<h2 class="anchored" data-anchor-id="instrument-5-generation-quality-samples">Instrument 5: generation quality samples</h2>
<p>No amount of metric monitoring replaces actually looking at what the model generates. Periodic sampling during training is essential for catching qualitative failures that quantitative metrics miss.</p>
<div id="96bcc155" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Periodic generation sampling</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GenerationSamplerCallback(TrainerCallback):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generate samples periodically during training."""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        tokenizer,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        eval_prompts: <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        log_every_n_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">500</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        max_new_tokens: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eval_prompts <span class="op">=</span> eval_prompts</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_every_n_steps <span class="op">=</span> log_every_n_steps</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_new_tokens <span class="op">=</span> max_new_tokens</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.generation_history <span class="op">=</span> []</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_step_end(<span class="va">self</span>, args, state, control, model<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.step_count <span class="op">%</span> <span class="va">self</span>.log_every_n_steps <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> []</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> prompt <span class="kw">in</span> <span class="va">self</span>.eval_prompts[:<span class="dv">3</span>]:  <span class="co"># Sample first 3 prompts</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> <span class="va">self</span>.tokenizer(</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>                prompt,</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>                return_tensors<span class="op">=</span><span class="st">"pt"</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            ).to(model.device)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> model.generate(</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>                    <span class="op">**</span>inputs,</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>                    max_new_tokens<span class="op">=</span><span class="va">self</span>.max_new_tokens,</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>                    temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>                    do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>                    pad_token_id<span class="op">=</span><span class="va">self</span>.tokenizer.pad_token_id,</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>            generated <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>                outputs[<span class="dv">0</span>][inputs.input_ids.shape[<span class="dv">1</span>]:],</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>                skip_special_tokens<span class="op">=</span><span class="va">True</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>            samples.append({<span class="st">"prompt"</span>: prompt, <span class="st">"generation"</span>: generated})</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.generation_history.append({</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">"step"</span>: <span class="va">self</span>.step_count,</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">"samples"</span>: samples</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log to wandb as table</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        <span class="im">import</span> wandb</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> wandb.run <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            table <span class="op">=</span> wandb.Table(columns<span class="op">=</span>[<span class="st">"step"</span>, <span class="st">"prompt"</span>, <span class="st">"generation"</span>])</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> sample <span class="kw">in</span> samples:</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>                table.add_data(</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.step_count,</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>                    sample[<span class="st">"prompt"</span>][:<span class="dv">100</span>],</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>                    sample[<span class="st">"generation"</span>][:<span class="dv">500</span>]</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>            wandb.log({<span class="st">"generation_samples"</span>: table})</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>        model.train()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Repetition loops</strong>: The model gets stuck repeating phrases. Often indicates a temperature or sampling problem, but can also signal training issues.</li>
<li><strong>Hallucination of training data</strong>: The model regurgitates training examples verbatim. You’re overfitting.</li>
<li><strong>Format drift</strong>: The model’s output format changes during training. If you’re fine-tuning for a specific format, monitor for deviations.</li>
<li><strong>Coherence deterioration</strong>: Early generations are coherent, later ones are not. Catastrophic forgetting in progress.</li>
</ul>
</section>
<section id="instrument-6-lora-adapter-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="instrument-6-lora-adapter-diagnostics">Instrument 6: LoRA adapter diagnostics</h2>
<p>When training LoRAs, it’s crucial to monitor the behaviour of the adapter weights themselves. Their norms, effective ranks and relative changes can reveal whether the adapters are learning effectively or diverging. In particular, they are a crucial health check on our assumption about rank.</p>
<p>There are a few ways to determine effective rank, but a simple and effective method is to use the entropy of the singular value distribution. If the singular values are <span class="math inline">\(\sigma_1, \sigma_2, \ldots, \sigma_r\)</span>, we first normalise them to form a probability distribution: <span class="math display">\[p_i = \frac{\sigma_i}{\sum_{j=1}^{r} \sigma_j}\]</span></p>
<p>Then, the effective rank is given by the exp of the entropy thereof, the calculation of which we have already had the pleasure above.</p>
<p>So far, so undergraduate stats. Where it gets tricky is to see this in the data, and know the right rank adjustments to make. Here, your Mk I Eyeball is your best tool, I’m afraid: what you’re looking for is the ‘cliff’ where singular values drop off sharply. If the effective rank is much lower than your configured rank, you can probably reduce it. If it’s at maximum, consider increasing it if your model is not learning. In either case of a rank mismatch, you’re wasting a valuable resource – in the case of overprovisioning, you’re wasting compute and memory, but in the case of underprovisioning, you’re wasting information theoretical value. In practice, that latter one is much harder to get back.</p>
<div id="560fb4b7" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>LoRA-specific monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRADiagnosticsCallback(TrainerCallback):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Monitor LoRA adapter-specific metrics."""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, log_every_n_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_every_n_steps <span class="op">=</span> log_every_n_steps</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.initial_norms <span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_step_end(<span class="va">self</span>, args, state, control, model<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.step_count <span class="op">%</span> <span class="va">self</span>.log_every_n_steps <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        lora_stats <span class="op">=</span> {}</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">"lora_"</span> <span class="kw">not</span> <span class="kw">in</span> name.lower():</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>            weight <span class="op">=</span> param.detach()</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Basic statistics</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>            norm <span class="op">=</span> weight.norm().item()</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>            lora_stats[<span class="ss">f"lora/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">/norm"</span>] <span class="op">=</span> norm</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Effective rank (for lora_A and lora_B)</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(weight.shape) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>                    s <span class="op">=</span> torch.linalg.svdvals(weight.<span class="bu">float</span>())</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Effective rank: how many singular values matter</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>                    s_normalized <span class="op">=</span> s <span class="op">/</span> s.<span class="bu">sum</span>()</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>                    entropy <span class="op">=</span> <span class="op">-</span>torch.<span class="bu">sum</span>(</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>                        s_normalized <span class="op">*</span> torch.log(s_normalized <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>                    effective_rank <span class="op">=</span> torch.exp(entropy).item()</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>                    lora_stats[<span class="ss">f"lora/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">/effective_rank"</span>] <span class="op">=</span> effective_rank</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span>:</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">pass</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Track relative change from initialisation</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.initial_norms <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.initial_norms <span class="op">=</span> {}</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.initial_norms:</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.initial_norms[name] <span class="op">=</span> norm</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>                relative_change <span class="op">=</span> (norm <span class="op">-</span> <span class="va">self</span>.initial_norms[name]) <span class="op">/</span> (</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.initial_norms[name] <span class="op">+</span> <span class="fl">1e-10</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>                lora_stats[<span class="ss">f"lora/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">/relative_change"</span>] <span class="op">=</span> relative_change</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aggregate metrics</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> lora_stats:</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>            norms <span class="op">=</span> [v <span class="cf">for</span> k, v <span class="kw">in</span> lora_stats.items() <span class="cf">if</span> <span class="st">"/norm"</span> <span class="kw">in</span> k]</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>            lora_stats[<span class="st">"lora/mean_norm"</span>] <span class="op">=</span> np.mean(norms)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>            lora_stats[<span class="st">"lora/norm_variance"</span>] <span class="op">=</span> np.var(norms)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(state, <span class="st">"log_history"</span>) <span class="kw">and</span> state.log_history:</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>            state.log_history[<span class="op">-</span><span class="dv">1</span>].update(lora_stats)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="cell-fig-lora-diagnostics" class="cell" data-fig-height="9" data-fig-width="10" data-execution_count="10">
<div class="cell-output cell-output-display">
<div id="fig-lora-diagnostics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lora-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-lora-diagnostics-output-1.png" width="952" height="855" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lora-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: LoRA adapter diagnostics: layer-wise norms reveal training health (top row), singular value spectra reveal rank utilisation (bottom row).
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Adapter norms exploding</strong>: The LoRA weights are growing too large. Either your learning rate is too high, or there’s a mismatch between your LoRA rank and the task complexity.</li>
<li><strong>Effective rank much lower than configured rank</strong>: You’ve over-specified. Consider reducing the LoRA rank to save memory and potentially improve generalisation.</li>
<li><strong>Effective rank at maximum</strong>: Your rank might be too low. The adapter is using all its capacity.</li>
<li><strong>Large variance in norms across layers</strong>: Some layers are learning much more than others. This is often fine, but extreme variance can indicate problems.</li>
</ul>
</section>
<section id="instrument-7-compute-efficiency" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instrument-7-compute-efficiency">Instrument 7: compute efficiency</h2>
<p>Training efficiency metrics are often overlooked in research contexts but are critical for production training.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>An efficiency drop during training often precedes other problems. Memory fragmentation, garbage collection and I/O bottlenecks can all manifest first as throughput degradation.</p>
</div></div><div id="f3c0e6e6" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Compute efficiency monitoring</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> psutil</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPUtil</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ComputeEfficiencyCallback(TrainerCallback):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Monitor training throughput and resource utilisation."""</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, log_every_n_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">50</span>):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_every_n_steps <span class="op">=</span> log_every_n_steps</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_time <span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_tokens <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokens_per_step <span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_train_begin(<span class="va">self</span>, args, state, control, <span class="op">**</span>kwargs):</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_time <span class="op">=</span> time.time()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_step_end(<span class="va">self</span>, args, state, control, <span class="op">**</span>kwargs):</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.step_count <span class="op">%</span> <span class="va">self</span>.log_every_n_steps <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        current_time <span class="op">=</span> time.time()</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        elapsed <span class="op">=</span> current_time <span class="op">-</span> <span class="va">self</span>.last_time <span class="cf">if</span> <span class="va">self</span>.last_time <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        efficiency_stats <span class="op">=</span> {}</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Throughput</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.tokens_per_step:</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>            tokens_processed <span class="op">=</span> <span class="va">self</span>.tokens_per_step <span class="op">*</span> <span class="va">self</span>.log_every_n_steps</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>            efficiency_stats[<span class="st">"efficiency/tokens_per_second"</span>] <span class="op">=</span> tokens_processed <span class="op">/</span> elapsed</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>            efficiency_stats[<span class="st">"efficiency/steps_per_second"</span>] <span class="op">=</span> <span class="va">self</span>.log_every_n_steps <span class="op">/</span> elapsed</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># GPU utilisation</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>            gpus <span class="op">=</span> GPUtil.getGPUs()</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> gpus:</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>                gpu <span class="op">=</span> gpus[<span class="dv">0</span>]</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>                efficiency_stats[<span class="st">"efficiency/gpu_utilisation"</span>] <span class="op">=</span> gpu.load <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>                efficiency_stats[<span class="st">"efficiency/gpu_memory_used_gb"</span>] <span class="op">=</span> gpu.memoryUsed <span class="op">/</span> <span class="dv">1024</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                efficiency_stats[<span class="st">"efficiency/gpu_memory_pct"</span>] <span class="op">=</span> (</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>                    gpu.memoryUsed <span class="op">/</span> gpu.memoryTotal <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># CPU and system memory</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        efficiency_stats[<span class="st">"efficiency/cpu_percent"</span>] <span class="op">=</span> psutil.cpu_percent()</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        memory <span class="op">=</span> psutil.virtual_memory()</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        efficiency_stats[<span class="st">"efficiency/ram_used_gb"</span>] <span class="op">=</span> memory.used <span class="op">/</span> (<span class="dv">1024</span><span class="op">**</span><span class="dv">3</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        efficiency_stats[<span class="st">"efficiency/ram_percent"</span>] <span class="op">=</span> memory.percent</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(state, <span class="st">"log_history"</span>) <span class="kw">and</span> state.log_history:</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>            state.log_history[<span class="op">-</span><span class="dv">1</span>].update(efficiency_stats)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_time <span class="op">=</span> current_time</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>GPU utilisation below 80%</strong>: You’re bottlenecked somewhere else (data loading, CPU preprocessing). Increase <code>dataloader_num_workers</code> or enable <code>pin_memory</code>.</li>
<li><strong>Tokens per second declining over time</strong>: Memory fragmentation or garbage collection pressure. Consider periodic garbage collection calls.</li>
<li><strong>GPU memory usage climbing</strong>: Memory leak, often from gradient accumulation bugs or improper tensor handling in callbacks.</li>
<li><strong>Sudden throughput drops</strong>: I/O problems, often when the training hits a slow region of the data (e.g., longer sequences).</li>
</ul>
</section>
<section id="instrument-8-convergence-detection" class="level2">
<h2 class="anchored" data-anchor-id="instrument-8-convergence-detection">Instrument 8: convergence detection</h2>
<p>The final instrument in our cluster is arguably the most important: knowing when to stop.</p>
<div id="d99647e8" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Early stopping with convergence detection</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConvergenceDetector(TrainerCallback):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Detect convergence and potential overfitting."""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        patience: <span class="bu">int</span> <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        min_delta: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        divergence_threshold: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patience <span class="op">=</span> patience</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.min_delta <span class="op">=</span> min_delta</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.divergence_threshold <span class="op">=</span> divergence_threshold</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.best_eval_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epochs_without_improvement <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_losses <span class="op">=</span> []</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eval_losses <span class="op">=</span> []</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_evaluate(<span class="va">self</span>, args, state, control, metrics<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> metrics <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        eval_loss <span class="op">=</span> metrics.get(<span class="st">"eval_loss"</span>, <span class="bu">float</span>(<span class="st">'inf'</span>))</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> metrics.get(<span class="st">"train_loss"</span>, state.log_history[<span class="op">-</span><span class="dv">1</span>].get(<span class="st">"loss"</span>, <span class="dv">0</span>))</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_losses.append(train_loss)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eval_losses.append(eval_loss)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log convergence metrics</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        convergence_stats <span class="op">=</span> {}</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for improvement</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> eval_loss <span class="op">&lt;</span> <span class="va">self</span>.best_eval_loss <span class="op">-</span> <span class="va">self</span>.min_delta:</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_eval_loss <span class="op">=</span> eval_loss</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.epochs_without_improvement <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>            convergence_stats[<span class="st">"convergence/improving"</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.epochs_without_improvement <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>            convergence_stats[<span class="st">"convergence/improving"</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>        convergence_stats[<span class="st">"convergence/patience_remaining"</span>] <span class="op">=</span> (</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.patience <span class="op">-</span> <span class="va">self</span>.epochs_without_improvement</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for overfitting (eval loss diverging from train loss)</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.train_losses) <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">and</span> <span class="bu">len</span>(<span class="va">self</span>.eval_losses) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>            gap <span class="op">=</span> eval_loss <span class="op">-</span> train_loss</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>            prev_gap <span class="op">=</span> <span class="va">self</span>.eval_losses[<span class="op">-</span><span class="dv">2</span>] <span class="op">-</span> <span class="va">self</span>.train_losses[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>            gap_increase <span class="op">=</span> gap <span class="op">-</span> prev_gap</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>            convergence_stats[<span class="st">"convergence/train_eval_gap"</span>] <span class="op">=</span> gap</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>            convergence_stats[<span class="st">"convergence/gap_velocity"</span>] <span class="op">=</span> gap_increase</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> gap_increase <span class="op">&gt;</span> <span class="va">self</span>.divergence_threshold:</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>                convergence_stats[<span class="st">"convergence/overfitting_warning"</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"WARNING: Potential overfitting detected. Gap increase: </span><span class="sc">{</span>gap_increase<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log metrics</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(state, <span class="st">"log_history"</span>) <span class="kw">and</span> state.log_history:</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>            state.log_history[<span class="op">-</span><span class="dv">1</span>].update(convergence_stats)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Trigger early stopping</span></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.epochs_without_improvement <span class="op">&gt;=</span> <span class="va">self</span>.patience:</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Early stopping triggered after </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>patience<span class="sc">}</span><span class="ss"> evaluations without improvement"</span>)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>            control.should_training_stop <span class="op">=</span> <span class="va">True</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="cell-fig-convergence-detection" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="13">
<div class="cell-output cell-output-display">
<div id="fig-convergence-detection" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-convergence-detection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-convergence-detection-output-1.png" width="952" height="759" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-convergence-detection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Convergence pathologies: knowing when to stop (or when you should have stopped earlier).
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>What to watch for:</strong></p>
<ul>
<li><strong>Train-eval gap increasing</strong>: Classic overfitting. Stop training or increase regularisation.</li>
<li><strong>Both losses plateauing</strong>: You’ve reached the model’s capacity on this task. More training won’t help.</li>
<li><strong>Eval loss increasing while train loss decreases</strong>: Severe overfitting. You should have stopped earlier.</li>
<li><strong>Oscillating eval loss</strong>: Learning rate too high for the current phase of training.</li>
</ul>
</section>
<section id="putting-it-all-together" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="putting-it-all-together">Putting it all together</h2>
<p>The eight instruments we’ve covered form a complete picture of your training run:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 33%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Instrument</th>
<th>What it tells you</th>
<th>Failure mode it catches</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Loss landscape</td>
<td>Optimisation progress</td>
<td>Instability, plateaus</td>
</tr>
<tr class="even">
<td>Gradient health</td>
<td>Learning signal quality</td>
<td>Vanishing/exploding gradients</td>
</tr>
<tr class="odd">
<td>Learning rate</td>
<td>Schedule execution</td>
<td>Misconfigured schedules</td>
</tr>
<tr class="even">
<td>Attention entropy</td>
<td>Model focus patterns</td>
<td>Attention collapse, degeneration</td>
</tr>
<tr class="odd">
<td>Generation samples</td>
<td>Output quality</td>
<td>Qualitative failures</td>
</tr>
<tr class="even">
<td>LoRA diagnostics</td>
<td>Adapter behaviour</td>
<td>Rank mismatch, weight explosion</td>
</tr>
<tr class="odd">
<td>Compute efficiency</td>
<td>Resource utilisation</td>
<td>Bottlenecks, memory leaks</td>
</tr>
<tr class="even">
<td>Convergence detection</td>
<td>When to stop</td>
<td>Overfitting, wasted compute</td>
</tr>
</tbody>
</table>
<p>In a production setting, I recommend implementing all eight and setting up alerts for the key failure modes. A good heuristic: if any of these metrics deviate by more than two standard deviations from their moving average, that warrants investigation.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;This is crude but effective. More sophisticated anomaly detection is possible but often unnecessary for catching the failures that actually occur in practice.</p></div></div></section>
<section id="the-wandb-configuration" class="level2">
<h2 class="anchored" data-anchor-id="the-wandb-configuration">The wandb configuration</h2>
<p>To actually implement this, here’s a complete trainer configuration that wires up all the callbacks:</p>
<div id="67a745b1" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Complete training configuration with all monitors</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments, Trainer</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trl <span class="im">import</span> SFTTrainer</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_monitored_trainer(</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    tokenizer,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    train_dataset,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    eval_dataset,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    output_dir: <span class="bu">str</span> <span class="op">=</span> <span class="st">"./output"</span>,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    eval_prompts: <span class="bu">list</span>[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> SFTTrainer:</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Create a fully instrumented SFT trainer."""</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training arguments with comprehensive logging</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        output_dir<span class="op">=</span>output_dir,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span><span class="fl">2e-4</span>,</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        lr_scheduler_type<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        warmup_ratio<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Logging configuration</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        logging_first_step<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        report_to<span class="op">=</span><span class="st">"wandb"</span>,</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluation</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        eval_strategy<span class="op">=</span><span class="st">"steps"</span>,</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        eval_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        save_steps<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Performance</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        bf16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        dataloader_num_workers<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        dataloader_pin_memory<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Assemble callbacks</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    callbacks <span class="op">=</span> [</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>        LossLandscapeCallback(window_size<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>        GradientHealthCallback(log_every_n_steps<span class="op">=</span><span class="dv">50</span>),</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>        LearningRateMonitor(),</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        AttentionEntropyCallback(log_every_n_steps<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>        LoRADiagnosticsCallback(log_every_n_steps<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        ComputeEfficiencyCallback(log_every_n_steps<span class="op">=</span><span class="dv">50</span>),</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        ConvergenceDetector(patience<span class="op">=</span><span class="dv">5</span>, min_delta<span class="op">=</span><span class="fl">0.001</span>),</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add generation sampler if eval prompts provided</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> eval_prompts:</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>        callbacks.append(</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>            GenerationSamplerCallback(</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>                tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>                eval_prompts<span class="op">=</span>eval_prompts,</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>                log_every_n_steps<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> SFTTrainer(</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model,</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>        tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>        train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>        eval_dataset<span class="op">=</span>eval_dataset,</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>        args<span class="op">=</span>training_args,</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>        callbacks<span class="op">=</span>callbacks,</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="reading-the-dashboard" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reading-the-dashboard">Reading the dashboard</h2>
<p>Knowing what to log is only half the battle. The other half is knowing what you’re looking at.</p>
<p>I recommend organising your wandb dashboard into four panels:</p>
<ol type="1">
<li><strong>Primary metrics</strong>: Train loss, eval loss, learning rate. The overview.</li>
<li><strong>Health indicators</strong>: Gradient norm, attention entropy, convergence status. The vital signs.</li>
<li><strong>Efficiency metrics</strong>: Tokens/sec, GPU utilisation, memory. The resource gauge.</li>
<li><strong>Deep diagnostics</strong>: Per-layer gradients, LoRA norms, generation samples. The detailed view.</li>
</ol>
<p>Start each monitoring session by glancing at panels 1 and 2. Only dive into 3 and 4 when something looks off.</p>
<p>The most common failure patterns I see in practice:</p>
<ul>
<li><strong>Silent overfitting</strong>: Loss looks great, but generation quality is degrading. Always check the samples.</li>
<li><strong>Efficiency death spiral</strong>: Throughput drops, memory climbs, eventually OOM. Often caused by a memory leak in a custom callback.</li>
<li><strong>Attention collapse</strong>: Happens gradually, then suddenly. The attention entropy instrument catches this before it becomes catastrophic.</li>
<li><strong>Gradient starvation in later layers</strong>: Early layers learn, later layers don’t. Per-layer gradient monitoring reveals this immediately.</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<p>These patterns often require monitoring multiple indicators simultaneously. No single metric tells the whole story.</p>
<p>A beloved example of mine is GPU memory vs utilisation. It’s somewhat shocking how many otherwise competent engineers look at these in isolation. GPU utilisation going down is not necessarily a good sign. If memory usage is climbing and is approaching the top 10-15%, GPU utilisation and/or power draw going down is a three-alarm fire and a sign of impending OOM/collapse.</p>
</div></div><div id="cell-fig-failure-patterns" class="cell" data-fig-height="10" data-fig-width="11" data-execution_count="15">
<div class="cell-output cell-output-display">
<div id="fig-failure-patterns" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-failure-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-failure-patterns-output-1.png" width="1052" height="951" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-failure-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Common failure patterns in practice: each requires monitoring multiple indicators simultaneously.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="what-comes-next" class="level2">
<h2 class="anchored" data-anchor-id="what-comes-next">What comes next</h2>
<p>This instrument cluster is designed for supervised fine-tuning of LoRA adapters – the most common post-training scenario. But the story doesn’t end here.</p>
<p>In the next post, we’ll extend this framework to preference optimisation methods like DPO and GRPO. These introduce new failure modes: reward hacking, KL divergence explosion and the subtle art of balancing preference learning against capability preservation. The instrument cluster will need to grow.</p>
<p>The third post will tackle specialised training for function calling, where the metrics of success are not just loss curves but format compliance, execution accuracy and the reliability that production systems demand.</p>
<p>For now, the homework is straightforward: instrument your next fine-tuning run with all eight monitors. Watch what happens. Learn to read the dashboard. And when something goes wrong – as it inevitably will – you’ll have the forensic data to understand why.</p>
<p>Happy post-training!</p>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{csefalvay2025,
  author = {{Chris von Csefalvay}},
  title = {The Post-Training Instrument Cluster -\/- {Part} {I}},
  date = {2025-12-25},
  url = {https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/},
  langid = {en-GB}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-csefalvay2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Chris von Csefalvay. 2025. <span>“The Post-Training Instrument Cluster
-- Part I.”</span> <a href="https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/">https://chrisvoncsefalvay.com/posts/post-training-instrument-cluster/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/chrisvoncsefalvay\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<ol start="3" type="a">
<li>Chris von Csefalvay, 2011–. <a href="disclaimer">Disclaimer</a></li>
</ol>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>